[[1;34mINFO[m] Scanning for projects...
[[1;34mINFO[m] [1m------------------------------------------------------------------------[m
[[1;34mINFO[m] [1mReactor Build Order:[m
[[1;34mINFO[m] 
[[1;34mINFO[m] Strimzi - Apache Kafka on Kubernetes and OpenShift                 [pom]
[[1;34mINFO[m] test                                                               [jar]
[[1;34mINFO[m] crd-annotations                                                    [jar]
[[1;34mINFO[m] crd-generator                                                      [jar]
[[1;34mINFO[m] api                                                                [jar]
[[1;34mINFO[m] mockkube                                                           [jar]
[[1;34mINFO[m] config-model                                                       [jar]
[[1;34mINFO[m] certificate-manager                                                [jar]
[[1;34mINFO[m] operator-common                                                    [jar]
[[1;34mINFO[m] systemtest                                                         [jar]
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m-------------------------< [0;36mio.strimzi:strimzi[0;1m >-------------------------[m
[[1;34mINFO[m] [1mBuilding Strimzi - Apache Kafka on Kubernetes and OpenShift 0.29.0-SNAPSHOT [1/10][m
[[1;34mINFO[m] [1m--------------------------------[ pom ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36mstrimzi[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36mstrimzi[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] No tests to run.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] Skipping pom project
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--------------------------< [0;36mio.strimzi:test[0;1m >---------------------------[m
[[1;34mINFO[m] [1mBuilding test 0.29.0-SNAPSHOT                                     [2/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/test/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/ec2-user/strimzi-kafka-operator/test/src/main/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/ec2-user/strimzi-kafka-operator/test/src/test/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] No sources to compile
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] No tests to run.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36mtest[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/test/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36mtest[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] Building jar: /home/ec2-user/strimzi-kafka-operator/test/target/test-0.29.0-SNAPSHOT-sources.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] No tests to run.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m---------------------< [0;36mio.strimzi:crd-annotations[0;1m >---------------------[m
[[1;34mINFO[m] [1mBuilding crd-annotations 0.29.0-SNAPSHOT                          [3/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/crd-annotations/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/ec2-user/strimzi-kafka-operator/crd-annotations/src/main/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/ec2-user/strimzi-kafka-operator/crd-annotations/src/test/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36mcrd-annotations[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/crd-annotations/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36mcrd-annotations[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Building jar: /home/ec2-user/strimzi-kafka-operator/crd-annotations/target/crd-annotations-0.29.0-SNAPSHOT-sources.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36mcrd-annotations[0;1m ---[m
[[1;33mWARNING[m] useSystemClassLoader setting has no effect when not forking
[[1;33mWARNING[m] The parameter forkCount should likely not be 0, not forking a JVM for tests reduce test accuracy, ensure to have a <forkCount> >= 1.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m----------------------< [0;36mio.strimzi:crd-generator[0;1m >----------------------[m
[[1;34mINFO[m] [1mBuilding crd-generator 0.29.0-SNAPSHOT                            [4/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/crd-generator/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/ec2-user/strimzi-kafka-operator/crd-generator/src/main/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 7 resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36mcrd-generator[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/crd-generator/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36mcrd-generator[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Building jar: /home/ec2-user/strimzi-kafka-operator/crd-generator/target/crd-generator-0.29.0-SNAPSHOT-sources.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-shade-plugin:3.1.0:shade[m [1m(default)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Including io.strimzi:crd-annotations:jar:0.29.0-SNAPSHOT in the shaded jar.
[[1;34mINFO[m] Including com.fasterxml.jackson.core:jackson-core:jar:2.12.6 in the shaded jar.
[[1;34mINFO[m] Including com.fasterxml.jackson.core:jackson-databind:jar:2.12.6.1 in the shaded jar.
[[1;34mINFO[m] Including com.fasterxml.jackson.dataformat:jackson-dataformat-yaml:jar:2.12.6 in the shaded jar.
[[1;34mINFO[m] Including org.yaml:snakeyaml:jar:1.27 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-client:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-rbac:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-admissionregistration:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-apps:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-autoscaling:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-apiextensions:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-batch:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-certificates:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-coordination:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-discovery:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-events:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-extensions:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-flowcontrol:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-networking:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-metrics:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-policy:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-scheduling:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-storageclass:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-node:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including com.squareup.okhttp3:okhttp:jar:3.12.12 in the shaded jar.
[[1;34mINFO[m] Including com.squareup.okio:okio:jar:1.15.0 in the shaded jar.
[[1;34mINFO[m] Including com.squareup.okhttp3:logging-interceptor:jar:3.12.12 in the shaded jar.
[[1;34mINFO[m] Including org.slf4j:slf4j-api:jar:1.7.36 in the shaded jar.
[[1;34mINFO[m] Including com.fasterxml.jackson.datatype:jackson-datatype-jsr310:jar:2.13.1 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:zjsonpatch:jar:0.3.0 in the shaded jar.
[[1;34mINFO[m] Including com.github.mifmif:generex:jar:1.0.2 in the shaded jar.
[[1;34mINFO[m] Including dk.brics.automaton:automaton:jar:1.11-8 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-core:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-common:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including com.fasterxml.jackson.core:jackson-annotations:jar:2.12.6 in the shaded jar.
[[1;33mWARNING[m] Discovered module-info.class. Shading will break its strong encapsulation.
[[1;33mWARNING[m] Discovered module-info.class. Shading will break its strong encapsulation.
[[1;33mWARNING[m] Discovered module-info.class. Shading will break its strong encapsulation.
[[1;33mWARNING[m] Discovered module-info.class. Shading will break its strong encapsulation.
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, generex-1.0.2.jar define 7 overlapping classes: 
[[1;33mWARNING[m]   - com.mifmif.common.regex.GenerexIterator
[[1;33mWARNING[m]   - com.mifmif.common.regex.Generex
[[1;33mWARNING[m]   - com.mifmif.common.regex.GenerexIterator$Step
[[1;33mWARNING[m]   - com.mifmif.common.regex.Node
[[1;33mWARNING[m]   - com.mifmif.common.regex.Main
[[1;33mWARNING[m]   - com.mifmif.common.regex.util.Iterable
[[1;33mWARNING[m]   - com.mifmif.common.regex.util.Iterator
[[1;33mWARNING[m] kubernetes-model-rbac-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 80 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.SubjectBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.ClusterRoleBindingFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.RoleListFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.ClusterRoleBindingFluent$MetadataNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.RoleBindingBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.ClusterRoleBindingBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.AggregationRuleFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.SubjectFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.ClusterRoleListFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.PolicyRuleFluent
[[1;33mWARNING[m]   - 70 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, jackson-annotations-2.12.6.jar define 71 overlapping classes: 
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonAutoDetect
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonInclude
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.ObjectIdGenerators
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonFormat$Features
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonFormat$Feature
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonIgnore
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonSetter
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonTypeInfo$None
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonFormat$Shape
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonSubTypes
[[1;33mWARNING[m]   - 61 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-extensions-5.12.0.jar define 264 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.DaemonSetConditionBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.NetworkPolicyListFluent$ItemsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.DeploymentStrategyFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.IngressListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.NetworkPolicySpecFluent$IngressNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.IngressStatus
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.DaemonSetFluentImpl$SpecNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.IngressSpecFluent$RulesNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.DaemonSetSpecFluent$UpdateStrategyNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.NetworkPolicyPeerBuilder
[[1;33mWARNING[m]   - 254 more...
[[1;33mWARNING[m] kubernetes-model-autoscaling-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 350 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta1.MetricSpecFluentImpl$ObjectNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta2.HorizontalPodAutoscalerSpec
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta1.CrossVersionObjectReferenceBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta1.HorizontalPodAutoscalerStatusFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta2.HorizontalPodAutoscalerFluent$SpecNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta2.ContainerResourceMetricStatusFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta1.HorizontalPodAutoscalerStatus
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta1.MetricStatusFluent$ObjectNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta2.HorizontalPodAutoscalerSpecFluent$ScaleTargetRefNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta1.HorizontalPodAutoscalerFluent$SpecNested
[[1;33mWARNING[m]   - 340 more...
[[1;33mWARNING[m] kubernetes-model-storageclass-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 172 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.v1beta1.CSIStorageCapacityListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.CSINodeFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.CSINodeDriverFluentImpl$AllocatableNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.StorageClass
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.VolumeAttachmentSourceBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.VolumeAttachmentSourceFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.TokenRequestFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.v1beta1.CSINodeDriverFluent$AllocatableNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.v1beta1.CSIDriverSpecBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.VolumeAttachmentSpecFluent
[[1;33mWARNING[m]   - 162 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-batch-5.12.0.jar define 112 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1.JobFluentImpl$StatusNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1.CronJobStatusFluentImpl$ActiveNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1.JobSpecFluent$TemplateNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1beta1.CronJobListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1beta1.CronJobSpecFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1.JobSpecFluentImpl$TemplateNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1.Job
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1beta1.CronJobFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1beta1.CronJobListFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1.CronJobListFluent
[[1;33mWARNING[m]   - 102 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-apiextensions-5.12.0.jar define 350 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.CustomResourceDefinitionVersionBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.JSONSchemaPropsOrBoolBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.CustomResourceDefinitionSpecFluent$ValidationNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.CustomResourceDefinitionVersionFluentImpl$SchemaNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.JSONSchemaPropsOrStringArraySerDe$Deserializer$1
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.CustomResourceValidationFluentImpl$OpenAPIV3SchemaNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.JSONSchemaPropsFluentImpl$NotNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.WebhookClientConfigFluentImpl$ServiceNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.JSONSchemaPropsOrArrayFluent$SchemaNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1.JSONSchemaPropsOrBoolSerDe
[[1;33mWARNING[m]   - 340 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-discovery-5.12.0.jar define 88 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1beta1.EndpointSliceFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1beta1.EndpointFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1.EndpointSliceBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1beta1.EndpointPort
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1beta1.ForZoneBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1.EndpointFluent$TargetRefNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1beta1.EndpointFluentImpl$ConditionsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1.EndpointSliceListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1beta1.EndpointConditionsFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1beta1.EndpointSliceListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - 78 more...
[[1;33mWARNING[m] okhttp-3.12.12.jar, crd-generator-0.29.0-SNAPSHOT.jar define 208 overlapping classes: 
[[1;33mWARNING[m]   - okhttp3.WebSocket
[[1;33mWARNING[m]   - okhttp3.Cookie$Builder
[[1;33mWARNING[m]   - okhttp3.internal.http.HttpHeaders
[[1;33mWARNING[m]   - okhttp3.internal.http2.Http2Connection$ReaderRunnable
[[1;33mWARNING[m]   - okhttp3.internal.http2.Http2Reader$ContinuationSource
[[1;33mWARNING[m]   - okhttp3.internal.tls.OkHostnameVerifier
[[1;33mWARNING[m]   - okhttp3.Cache$Entry
[[1;33mWARNING[m]   - okhttp3.internal.http2.Http2Connection$3
[[1;33mWARNING[m]   - okhttp3.internal.ws.RealWebSocket$Streams
[[1;33mWARNING[m]   - okhttp3.CacheControl$Builder
[[1;33mWARNING[m]   - 198 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-metrics-5.12.0.jar define 30 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.PodMetricsFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.NodeMetricsListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.ContainerMetricsFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.NodeMetrics
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.NodeMetricsListFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.NodeMetricsListFluent$ItemsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.NodeMetricsFluent$MetadataNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.PodMetricsFluentImpl$ContainersNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.PodMetricsListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.PodMetricsListBuilder
[[1;33mWARNING[m]   - 20 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-flowcontrol-5.12.0.jar define 132 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.PriorityLevelConfigurationFluentImpl$SpecNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.FlowSchemaConditionFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.FlowDistinguisherMethodBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.PriorityLevelConfigurationReferenceBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.QueuingConfiguration
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.QueuingConfigurationFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.PriorityLevelConfiguration
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.PriorityLevelConfigurationReference
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.PolicyRulesWithSubjects
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.PriorityLevelConfigurationListFluent$ItemsNested
[[1;33mWARNING[m]   - 122 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-events-5.12.0.jar define 44 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1beta1.EventFluent$MetadataNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1beta1.EventFluent$SeriesNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1.EventList
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1.EventListBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1beta1.EventFluent$RegardingNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1.EventSeriesFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1beta1.EventFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1beta1.EventBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1beta1.EventListFluent$ItemsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1beta1.EventListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - 34 more...
[[1;33mWARNING[m] automaton-1.11-8.jar, crd-generator-0.29.0-SNAPSHOT.jar define 25 overlapping classes: 
[[1;33mWARNING[m]   - dk.brics.automaton.AutomatonMatcher
[[1;33mWARNING[m]   - dk.brics.automaton.ShuffleOperations$ShuffleConfiguration
[[1;33mWARNING[m]   - dk.brics.automaton.RegExp$Kind
[[1;33mWARNING[m]   - dk.brics.automaton.RunAutomaton
[[1;33mWARNING[m]   - dk.brics.automaton.Automaton
[[1;33mWARNING[m]   - dk.brics.automaton.RegExp
[[1;33mWARNING[m]   - dk.brics.automaton.AutomatonProvider
[[1;33mWARNING[m]   - dk.brics.automaton.RegExp$1
[[1;33mWARNING[m]   - dk.brics.automaton.MinimizationOperations$StateListNode
[[1;33mWARNING[m]   - dk.brics.automaton.State
[[1;33mWARNING[m]   - 15 more...
[[1;33mWARNING[m] jackson-core-2.12.6.jar, crd-generator-0.29.0-SNAPSHOT.jar define 124 overlapping classes: 
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.JsonGenerator$Feature
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.json.JsonReadFeature
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.util.ThreadLocalBufferManager$ThreadLocalBufferManagerHolder
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.util.Separators
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.io.SegmentedStringWriter
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.TreeNode
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.sym.Name
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.util.RequestPayload
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.util.JsonGeneratorDelegate
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.async.NonBlockingInputFeeder
[[1;33mWARNING[m]   - 114 more...
[[1;33mWARNING[m] kubernetes-model-networking-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 234 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1beta1.IngressClassListFluent$ItemsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1beta1.IngressClassListFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1.IngressServiceBackend
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1.NetworkPolicyPort
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1beta1.IngressFluentImpl$StatusNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1beta1.IngressClassSpec
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1.IngressStatus
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1.IngressClassFluent$SpecNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1.NetworkPolicyBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1.IngressRuleFluentImpl$HttpNestedImpl
[[1;33mWARNING[m]   - 224 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-coordination-5.12.0.jar define 18 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseFluentImpl$SpecNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseSpec
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseFluent$SpecNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseListFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseSpecBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseSpecFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseFluentImpl$MetadataNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseListFluent
[[1;33mWARNING[m]   - 8 more...
[[1;33mWARNING[m] zjsonpatch-0.3.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 24 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.internal.collections4.sequence.InsertCommand
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.Operation
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.internal.collections4.sequence.CommandVisitor
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.internal.guava.Strings
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.internal.collections4.sequence.EditCommand
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.JsonDiff$EncodePathFunction
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.internal.collections4.sequence.SequencesComparator
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.Diff
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.internal.collections4.ListUtils
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.JsonPatch
[[1;33mWARNING[m]   - 14 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-common-5.12.0.jar define 16 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.annotation.Plural
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.annotation.Group
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.jackson.JsonUnwrappedDeserializer$CancelUnwrapped
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.jackson.JsonUnwrappedDeserializer
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.annotation.PrinterColumn
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.jackson.UnwrappedTypeResolverBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.annotation.Singular
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.annotation.StatusReplicas
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.annotation.SpecReplicas
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.annotation.Version
[[1;33mWARNING[m]   - 6 more...
[[1;33mWARNING[m] kubernetes-model-admissionregistration-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 362 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.admissionregistration.v1beta1.MutatingWebhookFluent$ObjectSelectorNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.authorization.v1.SubjectAccessReviewSpecFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.authorization.v1beta1.SubjectRulesReviewStatusBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.admissionregistration.v1.ValidatingWebhookConfigurationBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.authentication.TokenReviewFluentImpl$MetadataNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.authorization.v1beta1.SelfSubjectRulesReviewSpec
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.admissionregistration.v1beta1.MutatingWebhookFluentImpl$NamespaceSelectorNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.admissionregistration.v1beta1.MutatingWebhookConfigurationFluentImpl$WebhooksNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.authorization.v1beta1.SelfSubjectAccessReviewFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.admissionregistration.v1.MutatingWebhookFluent$ClientConfigNested
[[1;33mWARNING[m]   - 352 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, okio-1.15.0.jar define 44 overlapping classes: 
[[1;33mWARNING[m]   - okio.ByteString
[[1;33mWARNING[m]   - okio.Source
[[1;33mWARNING[m]   - okio.ForwardingSink
[[1;33mWARNING[m]   - okio.BufferedSource
[[1;33mWARNING[m]   - okio.Util
[[1;33mWARNING[m]   - okio.AsyncTimeout$1
[[1;33mWARNING[m]   - okio.HashingSource
[[1;33mWARNING[m]   - okio.GzipSink
[[1;33mWARNING[m]   - okio.Okio$1
[[1;33mWARNING[m]   - okio.Pipe$PipeSink
[[1;33mWARNING[m]   - 34 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-certificates-5.12.0.jar define 60 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1.CertificateSigningRequestStatusFluent$ConditionsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1.CertificateSigningRequestFluent$SpecNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1.CertificateSigningRequestFluentImpl$StatusNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1beta1.CertificateSigningRequestListFluent$ItemsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1beta1.CertificateSigningRequestStatusFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1beta1.CertificateSigningRequestFluent$MetadataNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1beta1.CertificateSigningRequestConditionFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1.CertificateSigningRequestStatusBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1beta1.CertificateSigningRequestStatusFluent$ConditionsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1.CertificateSigningRequestFluentImpl
[[1;33mWARNING[m]   - 50 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, jackson-datatype-jsr310-2.13.1.jar define 59 overlapping classes: 
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.deser.LocalDateDeserializer
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.deser.key.Jsr310KeyDeserializer
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.PackageVersion
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.deser.YearDeserializer
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.ser.key.Jsr310NullKeySerializer
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.deser.key.LocalDateTimeKeyDeserializer
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.util.DurationUnitConverter
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.ser.InstantSerializerBase
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.ser.LocalDateTimeSerializer
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.ser.OffsetDateTimeSerializer
[[1;33mWARNING[m]   - 49 more...
[[1;33mWARNING[m] crd-annotations-0.29.0-SNAPSHOT.jar, crd-generator-0.29.0-SNAPSHOT.jar define 8 overlapping classes: 
[[1;33mWARNING[m]   - io.strimzi.api.annotations.VersionRange
[[1;33mWARNING[m]   - io.strimzi.api.annotations.ApiVersion
[[1;33mWARNING[m]   - io.strimzi.api.annotations.ApiVersion$Stability
[[1;33mWARNING[m]   - io.strimzi.api.annotations.ApiVersion$1
[[1;33mWARNING[m]   - io.strimzi.api.annotations.DeprecatedType
[[1;33mWARNING[m]   - io.strimzi.api.annotations.DeprecatedProperty
[[1;33mWARNING[m]   - io.strimzi.api.annotations.VersionRange$VersionParser
[[1;33mWARNING[m]   - io.strimzi.api.annotations.KubeVersion
[[1;33mWARNING[m] kubernetes-model-apps-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 212 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.ReplicaSetSpec
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.StatefulSetConditionFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.DeploymentStrategyFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.ControllerRevisionFluent$DeploymentDataNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.ReplicaSetSpecFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.DeploymentFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.ReplicaSetStatusFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.ControllerRevisionFluentImpl$PersistentVolumeClaimDataNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.ReplicaSetCondition
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.StatefulSetSpecFluent$UpdateStrategyNested
[[1;33mWARNING[m]   - 202 more...
[[1;33mWARNING[m] logging-interceptor-3.12.12.jar, crd-generator-0.29.0-SNAPSHOT.jar define 8 overlapping classes: 
[[1;33mWARNING[m]   - okhttp3.logging.HttpLoggingInterceptor$Logger$1
[[1;33mWARNING[m]   - okhttp3.logging.LoggingEventListener$Factory
[[1;33mWARNING[m]   - okhttp3.logging.HttpLoggingInterceptor$Level
[[1;33mWARNING[m]   - okhttp3.logging.HttpLoggingInterceptor
[[1;33mWARNING[m]   - okhttp3.logging.package-info
[[1;33mWARNING[m]   - okhttp3.logging.LoggingEventListener
[[1;33mWARNING[m]   - okhttp3.logging.LoggingEventListener$1
[[1;33mWARNING[m]   - okhttp3.logging.HttpLoggingInterceptor$Logger
[[1;33mWARNING[m] jackson-dataformat-yaml-2.12.6.jar, crd-generator-0.29.0-SNAPSHOT.jar define 17 overlapping classes: 
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.YAMLMapper$Builder
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.snakeyaml.error.Mark
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.YAMLGenerator
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.UTF8Reader
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.YAMLParser
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.util.StringQuotingChecker
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.YAMLGenerator$Feature
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.JacksonYAMLParseException
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.YAMLParser$Feature
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.util.StringQuotingChecker$Default
[[1;33mWARNING[m]   - 7 more...
[[1;33mWARNING[m] kubernetes-model-core-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 2394 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.BaseKubernetesListFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.StatusBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.KubeSchemaFluentImpl$APIResourceNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.NodeListBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.ResourceQuotaListFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.WatchEventFluentImpl$APIServiceStatusObjectNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.WatchEventFluent$VsphereVirtualDiskVolumeSourceObjectNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.ProbeFluentImpl$HttpGetNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.PatchOptionsFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.ServerAddressByClientCIDRFluentImpl
[[1;33mWARNING[m]   - 2384 more...
[[1;33mWARNING[m] slf4j-api-1.7.36.jar, crd-generator-0.29.0-SNAPSHOT.jar define 34 overlapping classes: 
[[1;33mWARNING[m]   - org.slf4j.helpers.SubstituteLogger
[[1;33mWARNING[m]   - org.slf4j.helpers.NamedLoggerBase
[[1;33mWARNING[m]   - org.slf4j.helpers.NOPMDCAdapter
[[1;33mWARNING[m]   - org.slf4j.MarkerFactory
[[1;33mWARNING[m]   - org.slf4j.helpers.BasicMarker
[[1;33mWARNING[m]   - org.slf4j.spi.LoggerFactoryBinder
[[1;33mWARNING[m]   - org.slf4j.MDC$MDCCloseable
[[1;33mWARNING[m]   - org.slf4j.spi.LocationAwareLogger
[[1;33mWARNING[m]   - org.slf4j.helpers.MessageFormatter
[[1;33mWARNING[m]   - org.slf4j.helpers.Util$ClassContextSecurityManager
[[1;33mWARNING[m]   - 24 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-node-5.12.0.jar define 78 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1beta1.OverheadBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1.RuntimeClassListFluent$ItemsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1alpha1.Scheduling
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1beta1.RuntimeClassFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1beta1.RuntimeClassListBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1.RuntimeClassFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1alpha1.SchedulingFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1alpha1.RuntimeClassSpecFluent$OverheadNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1.RuntimeClassBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1.RuntimeClassFluentImpl
[[1;33mWARNING[m]   - 68 more...
[[1;33mWARNING[m] jackson-databind-2.12.6.1.jar, crd-generator-0.29.0-SNAPSHOT.jar define 700 overlapping classes: 
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.introspect.AnnotationCollector$NoAnnotations
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.jsontype.BasicPolymorphicTypeValidator$Builder
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.BeanDescription
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.deser.impl.BeanAsArrayBuilderDeserializer
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.introspect.AnnotatedMethodMap
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.SerializerProvider
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.introspect.AnnotationCollector$OneAnnotation
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.ser.std.StaticListSerializerBase
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.ser.std.NumberSerializers$ShortSerializer
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.ser.BeanSerializerFactory
[[1;33mWARNING[m]   - 690 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, snakeyaml-1.27.jar define 216 overlapping classes: 
[[1;33mWARNING[m]   - org.yaml.snakeyaml.emitter.Emitter$ExpectBlockMappingValue
[[1;33mWARNING[m]   - org.yaml.snakeyaml.parser.ParserImpl$ParseBlockNode
[[1;33mWARNING[m]   - org.yaml.snakeyaml.emitter.Emitter$ExpectBlockMappingSimpleValue
[[1;33mWARNING[m]   - org.yaml.snakeyaml.emitter.Emitter$ExpectDocumentEnd
[[1;33mWARNING[m]   - org.yaml.snakeyaml.Yaml$3
[[1;33mWARNING[m]   - org.yaml.snakeyaml.emitter.Emitter$ExpectBlockSequenceItem
[[1;33mWARNING[m]   - org.yaml.snakeyaml.parser.ParserImpl$ParseBlockSequenceEntry
[[1;33mWARNING[m]   - org.yaml.snakeyaml.util.ArrayUtils
[[1;33mWARNING[m]   - org.yaml.snakeyaml.tokens.Token$ID
[[1;33mWARNING[m]   - org.yaml.snakeyaml.reader.StreamReader
[[1;33mWARNING[m]   - 206 more...
[[1;33mWARNING[m] kubernetes-client-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 536 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.internal.CertUtils
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.CustomResource
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.osgi.ManagedKubernetesClient
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.V1beta1ApiextensionAPIGroupDSL
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.internal.PatchUtils$SingletonHolder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.VersionInfo$1
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.utils.ReplaceValueStream
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.dsl.CreateFromServerGettable
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.dsl.ApiextensionsAPIGroupDSL
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.dsl.Containerable
[[1;33mWARNING[m]   - 526 more...
[[1;33mWARNING[m] kubernetes-model-scheduling-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 24 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1.PriorityClassFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1.PriorityClassFluentImpl$MetadataNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1.PriorityClassListFluent$ItemsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1.PriorityClassList
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1beta1.PriorityClassListFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1.PriorityClassListFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1.PriorityClass
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1.PriorityClassListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1beta1.PriorityClassBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1beta1.PriorityClassFluent$MetadataNested
[[1;33mWARNING[m]   - 14 more...
[[1;33mWARNING[m] kubernetes-model-policy-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 162 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1.PodDisruptionBudgetList
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.HostPortRangeBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.EvictionFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.PodSecurityPolicyFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.PodSecurityPolicySpecFluentImpl$AllowedCSIDriversNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.PodSecurityPolicyListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.AllowedFlexVolumeBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.IDRangeFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.SELinuxStrategyOptionsFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.PodSecurityPolicySpecFluentImpl$FsGroupNestedImpl
[[1;33mWARNING[m]   - 152 more...
[[1;33mWARNING[m] maven-shade-plugin has detected that some class files are
[[1;33mWARNING[m] present in two or more JARs. When this happens, only one
[[1;33mWARNING[m] single version of the class is copied to the uber jar.
[[1;33mWARNING[m] Usually this is not harmful and you can skip these warnings,
[[1;33mWARNING[m] otherwise try to manually exclude artifacts based on
[[1;33mWARNING[m] mvn dependency:tree -Ddetail=true and the above output.
[[1;33mWARNING[m] See http://maven.apache.org/plugins/maven-shade-plugin/
[[1;34mINFO[m] Replacing original artifact with shaded artifact.
[[1;34mINFO[m] Replacing /home/ec2-user/strimzi-kafka-operator/crd-generator/target/crd-generator-0.29.0-SNAPSHOT.jar with /home/ec2-user/strimzi-kafka-operator/crd-generator/target/crd-generator-0.29.0-SNAPSHOT-shaded.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36mcrd-generator[0;1m ---[m
[[1;33mWARNING[m] useSystemClassLoader setting has no effect when not forking
[[1;33mWARNING[m] The parameter forkCount should likely not be 0, not forking a JVM for tests reduce test accuracy, ensure to have a <forkCount> >= 1.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m---------------------------< [0;36mio.strimzi:api[0;1m >---------------------------[m
[[1;34mINFO[m] [1mBuilding api 0.29.0-SNAPSHOT                                      [5/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/api/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/ec2-user/strimzi-kafka-operator/api/src/main/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mexec-maven-plugin:1.6.0:exec[m [1m(generate-crd-co-install-v1)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mexec-maven-plugin:1.6.0:exec[m [1m(generate-crd-co-install-v1-eo)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mexec-maven-plugin:1.6.0:exec[m [1m(generate-doc)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 99 resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-test-compile)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36mapi[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/api/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36mapi[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:test-jar[m [1m(default)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36mapi[0;1m ---[m
[[1;33mWARNING[m] useSystemClassLoader setting has no effect when not forking
[[1;33mWARNING[m] The parameter forkCount should likely not be 0, not forking a JVM for tests reduce test accuracy, ensure to have a <forkCount> >= 1.
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m------------------------< [0;36mio.strimzi:mockkube[0;1m >-------------------------[m
[[1;34mINFO[m] [1mBuilding mockkube 0.29.0-SNAPSHOT                                 [6/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/mockkube/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/ec2-user/strimzi-kafka-operator/mockkube/src/main/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 1 resource
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36mmockkube[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/mockkube/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36mmockkube[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Building jar: /home/ec2-user/strimzi-kafka-operator/mockkube/target/mockkube-0.29.0-SNAPSHOT-sources.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36mmockkube[0;1m ---[m
[[1;33mWARNING[m] useSystemClassLoader setting has no effect when not forking
[[1;33mWARNING[m] The parameter forkCount should likely not be 0, not forking a JVM for tests reduce test accuracy, ensure to have a <forkCount> >= 1.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m----------------------< [0;36mio.strimzi:config-model[0;1m >-----------------------[m
[[1;34mINFO[m] [1mBuilding config-model 0.29.0-SNAPSHOT                             [7/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/config-model/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/ec2-user/strimzi-kafka-operator/config-model/src/main/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/ec2-user/strimzi-kafka-operator/config-model/src/test/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36mconfig-model[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/config-model/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36mconfig-model[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Building jar: /home/ec2-user/strimzi-kafka-operator/config-model/target/config-model-0.29.0-SNAPSHOT-sources.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36mconfig-model[0;1m ---[m
[[1;33mWARNING[m] useSystemClassLoader setting has no effect when not forking
[[1;33mWARNING[m] The parameter forkCount should likely not be 0, not forking a JVM for tests reduce test accuracy, ensure to have a <forkCount> >= 1.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m-------------------< [0;36mio.strimzi:certificate-manager[0;1m >-------------------[m
[[1;34mINFO[m] [1mBuilding certificate-manager 0.29.0-SNAPSHOT                      [8/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/certificate-manager/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 1 resource
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 1 resource
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36mcertificate-manager[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/certificate-manager/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36mcertificate-manager[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Building jar: /home/ec2-user/strimzi-kafka-operator/certificate-manager/target/certificate-manager-0.29.0-SNAPSHOT-sources.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36mcertificate-manager[0;1m ---[m
[[1;33mWARNING[m] useSystemClassLoader setting has no effect when not forking
[[1;33mWARNING[m] The parameter forkCount should likely not be 0, not forking a JVM for tests reduce test accuracy, ensure to have a <forkCount> >= 1.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m---------------------< [0;36mio.strimzi:operator-common[0;1m >---------------------[m
[[1;34mINFO[m] [1mBuilding operator-common 0.29.0-SNAPSHOT                          [9/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/operator-common/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/ec2-user/strimzi-kafka-operator/operator-common/src/main/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 9 resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36moperator-common[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/operator-common/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36moperator-common[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Building jar: /home/ec2-user/strimzi-kafka-operator/operator-common/target/operator-common-0.29.0-SNAPSHOT-sources.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:test-jar[m [1m(default)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36moperator-common[0;1m ---[m
[[1;33mWARNING[m] useSystemClassLoader setting has no effect when not forking
[[1;33mWARNING[m] The parameter forkCount should likely not be 0, not forking a JVM for tests reduce test accuracy, ensure to have a <forkCount> >= 1.
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m-----------------------< [0;36mio.strimzi:systemtest[0;1m >------------------------[m
[[1;34mINFO[m] [1mBuilding systemtest 0.29.0-SNAPSHOT                              [10/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/systemtest/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 3 resources
[[1;34mINFO[m] Copying 2 resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Changes detected - recompiling the module!
[[1;34mINFO[m] Compiling 149 source files to /home/ec2-user/strimzi-kafka-operator/systemtest/target/classes
[[1;34mINFO[m] /home/ec2-user/strimzi-kafka-operator/systemtest/target/generated-sources/annotations/io/strimzi/systemtest/kafkaclients/internalClients/BaseClientsFluentImpl.java: Some input files use unchecked or unsafe operations.
[[1;34mINFO[m] /home/ec2-user/strimzi-kafka-operator/systemtest/target/generated-sources/annotations/io/strimzi/systemtest/kafkaclients/internalClients/BaseClientsFluentImpl.java: Recompile with -Xlint:unchecked for details.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 32 resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Changes detected - recompiling the module!
[[1;34mINFO[m] Compiling 68 source files to /home/ec2-user/strimzi-kafka-operator/systemtest/target/test-classes
[[1;34mINFO[m] /home/ec2-user/strimzi-kafka-operator/systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthPlainIsolatedST.java: Some input files use or override a deprecated API.
[[1;34mINFO[m] /home/ec2-user/strimzi-kafka-operator/systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthPlainIsolatedST.java: Recompile with -Xlint:deprecation for details.
[[1;34mINFO[m] /home/ec2-user/strimzi-kafka-operator/systemtest/src/test/java/io/strimzi/systemtest/operators/CustomResourceStatusIsolatedST.java: /home/ec2-user/strimzi-kafka-operator/systemtest/src/test/java/io/strimzi/systemtest/operators/CustomResourceStatusIsolatedST.java uses unchecked or unsafe operations.
[[1;34mINFO[m] /home/ec2-user/strimzi-kafka-operator/systemtest/src/test/java/io/strimzi/systemtest/operators/CustomResourceStatusIsolatedST.java: Recompile with -Xlint:unchecked for details.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;33mWARNING[m] Corrupted STDOUT by directly writing to native stream in forked JVM 1. See FAQ web page and the dump file /home/ec2-user/strimzi-kafka-operator/systemtest/target/surefire-reports/2022-04-02T08-45-47_366-jvmRun1.dumpstream
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Building jar: /home/ec2-user/strimzi-kafka-operator/systemtest/target/systemtest-0.29.0-SNAPSHOT.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36msystemtest[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/systemtest/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36msystemtest[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Building jar: /home/ec2-user/strimzi-kafka-operator/systemtest/target/systemtest-0.29.0-SNAPSHOT-sources.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36msystemtest[0;1m ---[m
[[1;33mWARNING[m] useSystemClassLoader setting has no effect when not forking
[[1;33mWARNING[m] The parameter forkCount should likely not be 0, not forking a JVM for tests reduce test accuracy, ensure to have a <forkCount> >= 1.
2022-04-02 08:46:16 [main] [32mINFO [m [TestExecutionListener:29] =======================================================================
2022-04-02 08:46:16 [main] [32mINFO [m [TestExecutionListener:30] =======================================================================
2022-04-02 08:46:16 [main] [32mINFO [m [TestExecutionListener:31]                         Test run started
2022-04-02 08:46:16 [main] [32mINFO [m [TestExecutionListener:32] =======================================================================
2022-04-02 08:46:16 [main] [32mINFO [m [TestExecutionListener:33] =======================================================================
2022-04-02 08:46:16 [main] [32mINFO [m [TestExecutionListener:48] Following testclasses are selected for run:
2022-04-02 08:46:16 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.operators.user.UserST
2022-04-02 08:46:16 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.operators.topic.ThrottlingQuotaST
2022-04-02 08:46:16 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.operators.topic.TopicST
2022-04-02 08:46:16 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.operators.ReconciliationST
2022-04-02 08:46:16 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.bridge.HttpBridgeScramShaST
2022-04-02 08:46:16 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.bridge.HttpBridgeTlsST
2022-04-02 08:46:16 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.tracing.TracingST
2022-04-02 08:46:16 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.cruisecontrol.CruiseControlApiST
2022-04-02 08:46:16 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST
2022-04-02 08:46:16 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.cruisecontrol.CruiseControlST
2022-04-02 08:46:16 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.kafka.listeners.ListenersST
2022-04-02 08:46:16 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.kafka.listeners.MultipleListenersST
2022-04-02 08:46:16 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfST
2022-04-02 08:46:16 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfSharedST
2022-04-02 08:46:16 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.kafka.KafkaST
2022-04-02 08:46:16 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.kafka.ConfigProviderST
2022-04-02 08:46:16 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.security.custom.CustomAuthorizerST
2022-04-02 08:46:16 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.security.OpaIntegrationST
2022-04-02 08:46:16 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.security.SecurityST
2022-04-02 08:46:16 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.rollingupdate.AlternativeReconcileTriggersST
2022-04-02 08:46:16 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.rollingupdate.RollingUpdateST
2022-04-02 08:46:16 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.log.LoggingChangeST
2022-04-02 08:46:16 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.log.LogSettingST
2022-04-02 08:46:16 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.operators.FeatureGatesIsolatedST
2022-04-02 08:46:16 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.operators.NamespaceRbacScopeOperatorIsolatedST
2022-04-02 08:46:16 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.operators.RecoveryIsolatedST
2022-04-02 08:46:16 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST
2022-04-02 08:46:16 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.operators.MultipleClusterOperatorsIsolatedST
2022-04-02 08:46:16 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.operators.ClusterOperatorRbacIsolatedST
2022-04-02 08:46:16 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.bridge.HttpBridgeIsolatedST
2022-04-02 08:46:16 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.specific.HelmChartIsolatedST
2022-04-02 08:46:16 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.specific.SpecificIsolatedST
2022-04-02 08:46:16 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.specific.DrainCleanerIsolatedST
2022-04-02 08:46:16 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.watcher.MultipleNamespaceIsolatedST
2022-04-02 08:46:16 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.watcher.AllNamespaceIsolatedST
2022-04-02 08:46:16 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST
2022-04-02 08:46:16 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST
2022-04-02 08:46:16 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.security.oauth.OauthScopeIsolatedST
2022-04-02 08:46:16 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST
2022-04-02 08:46:16 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST
2022-04-02 08:46:16 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.connect.ConnectIsolatedST
2022-04-02 08:46:16 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.connect.ConnectBuilderIsolatedST
2022-04-02 08:46:16 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.backup.ColdBackupScriptIsolatedST
2022-04-02 08:46:16 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST
2022-04-02 08:46:16 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST
2022-04-02 08:46:16 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.metrics.MetricsIsolatedST
2022-04-02 08:46:16 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.metrics.JmxIsolatedST
2022-04-02 08:46:16 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.dump.LogDumpScriptIsolatedST
2022-04-02 08:46:16 [main] [32mINFO [m [TestExecutionListener:52] =======================================================================
2022-04-02 08:46:16 [main] [32mINFO [m [TestExecutionListener:53] =======================================================================
[[1;34mINFO[m] Running io.strimzi.systemtest.operators.user.UserST
2022-04-02 08:46:17 [main] [32mINFO [m [Environment:219] Used environment variables:
2022-04-02 08:46:17 [main] [32mINFO [m [Environment:220] CONFIG: /home/ec2-user/strimzi-kafka-operator/systemtest/config.json
2022-04-02 08:46:17 [main] [32mINFO [m [Environment:221] STRIMZI_RBAC_SCOPE: CLUSTER
2022-04-02 08:46:17 [main] [32mINFO [m [Environment:221] OLM_APP_BUNDLE_PREFIX: strimzi-cluster-operator
2022-04-02 08:46:17 [main] [32mINFO [m [Environment:221] TEST_CLIENTS_VERSION: 0.2.0
2022-04-02 08:46:17 [main] [32mINFO [m [Environment:221] OLM_SOURCE_NAMESPACE: openshift-marketplace
2022-04-02 08:46:17 [main] [32mINFO [m [Environment:221] CLUSTER_OPERATOR_INSTALL_TYPE: BUNDLE
2022-04-02 08:46:17 [main] [32mINFO [m [Environment:221] STRIMZI_COMPONENTS_LOG_LEVEL: INFO
2022-04-02 08:46:17 [main] [32mINFO [m [Environment:221] SKIP_TEARDOWN: false
2022-04-02 08:46:17 [main] [32mINFO [m [Environment:221] LB_FINALIZERS: false
2022-04-02 08:46:17 [main] [32mINFO [m [Environment:221] OLM_OPERATOR_DEPLOYMENT_NAME: strimzi-cluster-operator
2022-04-02 08:46:17 [main] [32mINFO [m [Environment:221] DOCKER_ORG: strimzi
2022-04-02 08:46:17 [main] [32mINFO [m [Environment:221] TEST_LOG_DIR: /home/ec2-user/strimzi-kafka-operator/systemtest/../systemtest/target/logs/
2022-04-02 08:46:17 [main] [32mINFO [m [Environment:221] COMPONENTS_IMAGE_PULL_POLICY: IfNotPresent
2022-04-02 08:46:17 [main] [32mINFO [m [Environment:221] DOCKER_REGISTRY: quay.io
2022-04-02 08:46:17 [main] [32mINFO [m [Environment:221] TEST_CLIENT_IMAGE: quay.io/strimzi/test-client:latest-kafka-3.1.0
2022-04-02 08:46:17 [main] [32mINFO [m [Environment:221] SYSTEM_TEST_STRIMZI_IMAGE_PULL_SECRET: 
2022-04-02 08:46:17 [main] [32mINFO [m [Environment:221] TEST_ADMIN_IMAGE: quay.io/strimzi-test-clients/test-client-kafka-admin:0.2.0-kafka-3.1.0
2022-04-02 08:46:17 [main] [32mINFO [m [Environment:221] TEST_HTTP_PRODUCER_IMAGE: quay.io/strimzi-test-clients/test-client-http-producer:0.2.0
2022-04-02 08:46:17 [main] [32mINFO [m [Environment:221] OLM_OPERATOR_NAME: strimzi-kafka-operator
2022-04-02 08:46:17 [main] [32mINFO [m [Environment:221] DOCKER_TAG: latest
2022-04-02 08:46:17 [main] [32mINFO [m [Environment:221] OLM_SOURCE_NAME: community-operators
2022-04-02 08:46:17 [main] [32mINFO [m [Environment:221] STRIMZI_FEATURE_GATES: 
2022-04-02 08:46:17 [main] [32mINFO [m [Environment:221] CLIENTS_KAFKA_VERSION: 3.1.0
2022-04-02 08:46:17 [main] [32mINFO [m [Environment:221] TEST_HTTP_CONSUMER_IMAGE: quay.io/strimzi-test-clients/test-client-http-consumer:0.2.0
2022-04-02 08:46:17 [main] [32mINFO [m [Environment:221] STRIMZI_LOG_LEVEL: DEBUG
2022-04-02 08:46:17 [main] [32mINFO [m [Environment:221] ST_KAFKA_VERSION: 3.1.0
2022-04-02 08:46:17 [main] [32mINFO [m [Environment:221] OPERATOR_IMAGE_PULL_POLICY: Always
2022-04-02 08:46:17 [main] [32mINFO [m [Environment:221] DEFAULT_TO_DENY_NETWORK_POLICIES: true
2022-04-02 08:46:17 [main] [32mINFO [m [Environment:221] TEST_PRODUCER_IMAGE: quay.io/strimzi-test-clients/test-client-kafka-producer:0.2.0-kafka-3.1.0
2022-04-02 08:46:17 [main] [32mINFO [m [Environment:221] BRIDGE_IMAGE: latest-released
2022-04-02 08:46:17 [main] [32mINFO [m [Environment:221] TEST_STREAMS_IMAGE: quay.io/strimzi-test-clients/test-client-kafka-streams:0.2.0-kafka-3.1.0
2022-04-02 08:46:17 [main] [32mINFO [m [Environment:221] TEST_CONSUMER_IMAGE: quay.io/strimzi-test-clients/test-client-kafka-consumer:0.2.0-kafka-3.1.0
2022-04-02 08:46:17 [main] [32mINFO [m [Environment:221] OLM_OPERATOR_VERSION: 
2022-04-02 08:46:17 [main] [32mINFO [m [KubeCluster:87] Using cluster: minikube
2022-04-02 08:46:17 [main] [32mINFO [m [KubeClusterResource:60] Cluster default namespace is 'default'
2022-04-02 08:46:17 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7e2e5e3d
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-02 08:46:17 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-02 08:46:18 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-02 08:46:18 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-02 08:46:18 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 08:46:18 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 08:46:18 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 08:46:18 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 08:46:18 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 08:46:18 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 08:46:19 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 08:46:19 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 08:46:19 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 08:46:19 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 08:46:19 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 08:46:19 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 08:46:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 08:46:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 08:46:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 08:46:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 08:46:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 08:46:20 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-02 08:46:20 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 08:46:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 08:46:20 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-02 08:46:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 08:46:20 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-02 08:46:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 08:46:20 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 08:46:20 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 08:46:20 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-02 08:46:20 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 08:46:20 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-02 08:46:20 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-02 08:46:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 08:46:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-02 08:46:20 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 08:46:20 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-02 08:46:37 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-02 08:46:37 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-02 08:46:47 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-02 08:46:47 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: user-st
2022-04-02 08:46:47 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: user-st
2022-04-02 08:46:47 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: user-st
2022-04-02 08:46:48 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka user-cluster-name in namespace user-st
2022-04-02 08:46:48 [main] [33mWARN [m [VersionUsageUtils:60] The client is using resource type 'kafkas' with unstable version 'v1beta2'
2022-04-02 08:46:48 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: user-cluster-name will have desired state: Ready
2022-04-02 08:48:09 [main] [32mINFO [m [ResourceManager:444] Kafka: user-cluster-name is in desired state: Ready
2022-04-02 08:48:09 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 08:48:09 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.user.UserST.testTlsExternalUserWithQuotas-STARTED
2022-04-02 08:48:09 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 08:48:09 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-853912890-691238121 in namespace user-st
2022-04-02 08:48:09 [main] [33mWARN [m [VersionUsageUtils:60] The client is using resource type 'kafkausers' with unstable version 'v1beta2'
2022-04-02 08:48:09 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-853912890-691238121 will have desired state: Ready
2022-04-02 08:48:10 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-853912890-691238121 is in desired state: Ready
2022-04-02 08:48:13 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace user-st exec user-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --describe --user CN=my-user-853912890-691238121
2022-04-02 08:48:13 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 08:48:13 [main] [32mINFO [m [KafkaUserUtils:62] Waiting for KafkaUser deletion my-user-853912890-691238121
2022-04-02 08:48:13 [main] [33mWARN [m [KafkaUserUtils:68] KafkaUser my-user-853912890-691238121 is not deleted yet! Triggering force delete by cmd client!
2022-04-02 08:48:14 [main] [32mINFO [m [KafkaUserUtils:75] KafkaUser my-user-853912890-691238121 deleted
2022-04-02 08:48:17 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace user-st exec user-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --describe --user CN=my-user-853912890-691238121
2022-04-02 08:48:17 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 08:48:17 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 08:48:17 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTlsExternalUserWithQuotas
2022-04-02 08:48:17 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-853912890-691238121 in namespace user-st
2022-04-02 08:48:17 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 08:48:17 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.user.UserST.testTlsExternalUserWithQuotas-FINISHED
2022-04-02 08:48:17 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 08:48:17 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 08:48:17 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.user.UserST.testUserTemplate-STARTED
2022-04-02 08:48:17 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 08:48:17 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-662764371-668846676 in namespace user-st
2022-04-02 08:48:17 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-662764371-668846676 will have desired state: Ready
2022-04-02 08:48:18 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-662764371-668846676 is in desired state: Ready
2022-04-02 08:48:18 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 08:48:18 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testUserTemplate
2022-04-02 08:48:18 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-662764371-668846676 in namespace user-st
2022-04-02 08:48:28 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 08:48:28 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.user.UserST.testUserTemplate-FINISHED
2022-04-02 08:48:28 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 08:48:28 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 08:48:28 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.user.UserST.testUpdateUser-STARTED
2022-04-02 08:48:28 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 08:48:28 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-680815964-1692901413 in namespace user-st
2022-04-02 08:48:28 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-680815964-1692901413 will have desired state: Ready
2022-04-02 08:48:29 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-680815964-1692901413 is in desired state: Ready
2022-04-02 08:48:30 [main] [32mINFO [m [SecretUtils:46] Waiting for Secret my-user-680815964-1692901413
2022-04-02 08:48:30 [main] [32mINFO [m [SecretUtils:50] Secret my-user-680815964-1692901413 created
2022-04-02 08:48:30 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-680815964-1692901413 will have desired state: Ready
2022-04-02 08:48:30 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-680815964-1692901413 is in desired state: Ready
2022-04-02 08:48:30 [main] [32mINFO [m [KafkaUserUtils:62] Waiting for KafkaUser deletion my-user-680815964-1692901413
2022-04-02 08:48:30 [main] [32mINFO [m [KafkaUserUtils:75] KafkaUser my-user-680815964-1692901413 deleted
2022-04-02 08:48:30 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 08:48:30 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testUpdateUser
2022-04-02 08:48:30 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-680815964-1692901413 in namespace user-st
2022-04-02 08:48:30 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 08:48:30 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.user.UserST.testUpdateUser-FINISHED
2022-04-02 08:48:30 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 08:48:30 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 08:48:30 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.user.UserST.testTlsExternalUser-STARTED
2022-04-02 08:48:30 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 08:48:30 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-0 for test case:testTlsExternalUser
2022-04-02 08:48:30 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-0
2022-04-02 08:48:30 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-0
2022-04-02 08:48:30 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-0
2022-04-02 08:48:30 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-87066525 in namespace namespace-0
2022-04-02 08:48:30 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-0
2022-04-02 08:48:30 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-87066525 will have desired state: Ready
2022-04-02 08:49:45 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-87066525 is in desired state: Ready
2022-04-02 08:49:45 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-276492359-1466037954 in namespace namespace-0
2022-04-02 08:49:45 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-0
2022-04-02 08:49:45 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-276492359-1466037954 will have desired state: Ready
2022-04-02 08:49:46 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-276492359-1466037954 is in desired state: Ready
2022-04-02 08:49:46 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-276492359-1466037954 will have desired state: Ready
2022-04-02 08:49:46 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-276492359-1466037954 is in desired state: Ready
2022-04-02 08:49:46 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 08:49:46 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTlsExternalUser
2022-04-02 08:49:46 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-276492359-1466037954 in namespace namespace-0
2022-04-02 08:49:46 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-87066525 in namespace namespace-0
2022-04-02 08:49:56 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 08:49:56 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-0 for test case:testTlsExternalUser
2022-04-02 08:50:01 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.user.UserST.testTlsExternalUser-FINISHED
2022-04-02 08:50:01 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 08:50:01 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 08:50:01 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.user.UserST.testUserWithNameMoreThan64Chars-STARTED
2022-04-02 08:50:01 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 08:50:01 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser user-with-correct-nameabcdefghijklmnopqrstuvxyzabcdefghijklmnopq in namespace user-st
2022-04-02 08:50:01 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: user-with-correct-nameabcdefghijklmnopqrstuvxyzabcdefghijklmnopq will have desired state: Ready
2022-04-02 08:50:02 [main] [32mINFO [m [ResourceManager:444] KafkaUser: user-with-correct-nameabcdefghijklmnopqrstuvxyzabcdefghijklmnopq is in desired state: Ready
2022-04-02 08:50:02 [main] [32mINFO [m [KafkaUserUtils:90] Wait until KafkaUser user-with-correct-nameabcdefghijklmnopqrstuvxyzabcdefghijklmnopq status is available
2022-04-02 08:50:02 [main] [32mINFO [m [KafkaUserUtils:95] KafkaUser user-with-correct-nameabcdefghijklmnopqrstuvxyzabcdefghijklmnopq status is available
2022-04-02 08:50:02 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser sasl-userabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef in namespace user-st
2022-04-02 08:50:02 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: sasl-userabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef will have desired state: Ready
2022-04-02 08:50:03 [main] [32mINFO [m [ResourceManager:444] KafkaUser: sasl-userabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef is in desired state: Ready
2022-04-02 08:50:03 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser userabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdefghijk in namespace user-st
2022-04-02 08:50:03 [main] [32mINFO [m [KafkaUserUtils:90] Wait until KafkaUser userabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdefghijk status is available
2022-04-02 08:50:04 [main] [32mINFO [m [KafkaUserUtils:95] KafkaUser userabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdefghijk status is available
2022-04-02 08:50:04 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 08:50:04 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testUserWithNameMoreThan64Chars
2022-04-02 08:50:04 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser sasl-userabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef in namespace user-st
2022-04-02 08:50:04 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaUser user-with-correct-nameabcdefghijklmnopqrstuvxyzabcdefghijklmnopq in namespace user-st
2022-04-02 08:50:04 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaUser userabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdefghijk in namespace user-st
2022-04-02 08:50:14 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 08:50:14 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.user.UserST.testUserWithNameMoreThan64Chars-FINISHED
2022-04-02 08:50:14 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 08:50:14 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 08:50:14 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.user.UserST.testTlsUserWithQuotas-STARTED
2022-04-02 08:50:14 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 08:50:14 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser encrypted-arnost in namespace user-st
2022-04-02 08:50:14 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: encrypted-arnost will have desired state: Ready
2022-04-02 08:50:15 [main] [32mINFO [m [ResourceManager:444] KafkaUser: encrypted-arnost is in desired state: Ready
2022-04-02 08:50:18 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace user-st exec user-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --describe --user CN=encrypted-arnost
2022-04-02 08:50:18 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 08:50:18 [main] [32mINFO [m [KafkaUserUtils:62] Waiting for KafkaUser deletion encrypted-arnost
2022-04-02 08:50:18 [main] [33mWARN [m [KafkaUserUtils:68] KafkaUser encrypted-arnost is not deleted yet! Triggering force delete by cmd client!
2022-04-02 08:50:19 [main] [32mINFO [m [KafkaUserUtils:75] KafkaUser encrypted-arnost deleted
2022-04-02 08:50:22 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace user-st exec user-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --describe --user CN=encrypted-arnost
2022-04-02 08:50:22 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 08:50:22 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 08:50:22 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTlsUserWithQuotas
2022-04-02 08:50:22 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser encrypted-arnost in namespace user-st
2022-04-02 08:50:22 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 08:50:22 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.user.UserST.testTlsUserWithQuotas-FINISHED
2022-04-02 08:50:22 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 08:50:22 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 08:50:22 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.user.UserST.testScramUserWithQuotas-STARTED
2022-04-02 08:50:22 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 08:50:22 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser scramed-arnost in namespace user-st
2022-04-02 08:50:22 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: scramed-arnost will have desired state: Ready
2022-04-02 08:50:23 [main] [32mINFO [m [ResourceManager:444] KafkaUser: scramed-arnost is in desired state: Ready
2022-04-02 08:50:26 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace user-st exec user-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --describe --user scramed-arnost
2022-04-02 08:50:26 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 08:50:26 [main] [32mINFO [m [KafkaUserUtils:62] Waiting for KafkaUser deletion scramed-arnost
2022-04-02 08:50:26 [main] [33mWARN [m [KafkaUserUtils:68] KafkaUser scramed-arnost is not deleted yet! Triggering force delete by cmd client!
2022-04-02 08:50:27 [main] [32mINFO [m [KafkaUserUtils:75] KafkaUser scramed-arnost deleted
2022-04-02 08:50:29 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace user-st exec user-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --describe --user scramed-arnost
2022-04-02 08:50:29 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 08:50:29 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 08:50:29 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testScramUserWithQuotas
2022-04-02 08:50:29 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser scramed-arnost in namespace user-st
2022-04-02 08:50:29 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 08:50:29 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.user.UserST.testScramUserWithQuotas-FINISHED
2022-04-02 08:50:29 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 08:50:29 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 08:50:29 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.user.UserST.testCreatingUsersWithSecretPrefix-STARTED
2022-04-02 08:50:29 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 08:50:29 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-1 for test case:testCreatingUsersWithSecretPrefix
2022-04-02 08:50:29 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-1
2022-04-02 08:50:29 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-1
2022-04-02 08:50:29 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-1
2022-04-02 08:50:30 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-7157fb85 in namespace namespace-1
2022-04-02 08:50:30 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-1
2022-04-02 08:50:30 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-7157fb85 will have desired state: Ready
2022-04-02 08:51:45 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-7157fb85 is in desired state: Ready
2022-04-02 08:51:45 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1110995375-46265860 in namespace namespace-1
2022-04-02 08:51:45 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-1
2022-04-02 08:51:45 [main] [33mWARN [m [VersionUsageUtils:60] The client is using resource type 'kafkatopics' with unstable version 'v1beta2'
2022-04-02 08:51:45 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1110995375-46265860 will have desired state: Ready
2022-04-02 08:51:46 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1110995375-46265860 is in desired state: Ready
2022-04-02 08:51:46 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser encrypted-leopold in namespace namespace-1
2022-04-02 08:51:46 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-1
2022-04-02 08:51:46 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: encrypted-leopold will have desired state: Ready
2022-04-02 08:51:47 [main] [32mINFO [m [ResourceManager:444] KafkaUser: encrypted-leopold is in desired state: Ready
2022-04-02 08:51:47 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser scramed-leopold in namespace namespace-1
2022-04-02 08:51:47 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-1
2022-04-02 08:51:47 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: scramed-leopold will have desired state: Ready
2022-04-02 08:51:48 [main] [32mINFO [m [ResourceManager:444] KafkaUser: scramed-leopold is in desired state: Ready
2022-04-02 08:51:48 [main] [32mINFO [m [UserST:346] Deploying KafkaClients pod for TLS listener
2022-04-02 08:51:48 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-7157fb85-tls-kafka-clients in namespace namespace-1
2022-04-02 08:51:48 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-1
2022-04-02 08:51:48 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-7157fb85-tls-kafka-clients will be ready
2022-04-02 08:51:50 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-7157fb85-tls-kafka-clients is ready
2022-04-02 08:51:50 [main] [32mINFO [m [UserST:350] Deploying KafkaClients pod for PLAIN listener
2022-04-02 08:51:50 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-7157fb85-plain-kafka-clients in namespace namespace-1
2022-04-02 08:51:50 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-1
2022-04-02 08:51:50 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-7157fb85-plain-kafka-clients will be ready
2022-04-02 08:51:52 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-7157fb85-plain-kafka-clients is ready
2022-04-02 08:51:52 [main] [32mINFO [m [UserST:357] Checking if user secrets with secret prefixes exists
2022-04-02 08:51:52 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-02 08:51:52 [main] [32mINFO [m [UserST:373] Checking if TLS user is able to send messages
2022-04-02 08:51:52 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@29fc2276, messages=[], arguments=[USER=top_secret_encrypted_leopold, --max-messages, 100, --topic, my-topic-467311057-683530871, --bootstrap-server, my-cluster-7157fb85-kafka-bootstrap.namespace-1.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-7157fb85-tls-kafka-clients-6db4bd8cfb-gs487', podNamespace='namespace-1', bootstrapServer='my-cluster-7157fb85-kafka-bootstrap.namespace-1.svc:9093', topicName='my-topic-467311057-683530871', maxMessages=100, kafkaUsername='top-secret-encrypted-leopold', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@ba08ffd}
2022-04-02 08:51:52 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-7157fb85-kafka-bootstrap.namespace-1.svc:9093:my-topic-467311057-683530871 from pod my-cluster-7157fb85-tls-kafka-clients-6db4bd8cfb-gs487
2022-04-02 08:51:52 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-7157fb85-tls-kafka-clients-6db4bd8cfb-gs487 -n namespace-1 -- /opt/kafka/producer.sh USER=top_secret_encrypted_leopold --max-messages 100 --topic my-topic-467311057-683530871 --bootstrap-server my-cluster-7157fb85-kafka-bootstrap.namespace-1.svc:9093
2022-04-02 08:51:56 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-02 08:51:56 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-02 08:51:56 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@a6ddf29, messages=[], arguments=[USER=top_secret_encrypted_leopold, --max-messages, 100, --group-instance-id, instance1344481078, --group-id, my-consumer-group-1584883029, --topic, my-topic-467311057-683530871, --bootstrap-server, my-cluster-7157fb85-kafka-bootstrap.namespace-1.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-7157fb85-tls-kafka-clients-6db4bd8cfb-gs487', podNamespace='namespace-1', bootstrapServer='my-cluster-7157fb85-kafka-bootstrap.namespace-1.svc:9093', topicName='my-topic-467311057-683530871', maxMessages=100, kafkaUsername='top-secret-encrypted-leopold', consumerGroupName='my-consumer-group-1584883029', consumerInstanceId='instance1344481078', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@2de85350}
2022-04-02 08:51:56 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-7157fb85-kafka-bootstrap.namespace-1.svc:9093:my-topic-467311057-683530871 from pod my-cluster-7157fb85-tls-kafka-clients-6db4bd8cfb-gs487
2022-04-02 08:51:56 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-7157fb85-tls-kafka-clients-6db4bd8cfb-gs487 -n namespace-1 -- /opt/kafka/consumer.sh USER=top_secret_encrypted_leopold --max-messages 100 --group-instance-id instance1344481078 --group-id my-consumer-group-1584883029 --topic my-topic-467311057-683530871 --bootstrap-server my-cluster-7157fb85-kafka-bootstrap.namespace-1.svc:9093
2022-04-02 08:52:03 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-02 08:52:03 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-02 08:52:03 [main] [32mINFO [m [UserST:386] Checking if SCRAM-SHA user is able to send messages
2022-04-02 08:52:03 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@2895091, messages=[], arguments=[USER=top_secret_scramed_leopold, --max-messages, 100, --topic, my-topic-467311057-683530871, --bootstrap-server, my-cluster-7157fb85-kafka-bootstrap.namespace-1.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-7157fb85-plain-kafka-clients-5f5ffc87f6-f2cjd', podNamespace='namespace-1', bootstrapServer='my-cluster-7157fb85-kafka-bootstrap.namespace-1.svc:9092', topicName='my-topic-467311057-683530871', maxMessages=100, kafkaUsername='top-secret-scramed-leopold', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@4ac1f746}
2022-04-02 08:52:03 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-7157fb85-kafka-bootstrap.namespace-1.svc:9092:my-topic-467311057-683530871 from pod my-cluster-7157fb85-plain-kafka-clients-5f5ffc87f6-f2cjd
2022-04-02 08:52:03 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-7157fb85-plain-kafka-clients-5f5ffc87f6-f2cjd -n namespace-1 -- /opt/kafka/producer.sh USER=top_secret_scramed_leopold --max-messages 100 --topic my-topic-467311057-683530871 --bootstrap-server my-cluster-7157fb85-kafka-bootstrap.namespace-1.svc:9092
2022-04-02 08:52:06 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-02 08:52:06 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-02 08:52:06 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@964ff4f, messages=[], arguments=[USER=top_secret_scramed_leopold, --max-messages, 100, --group-instance-id, instance1046791457, --group-id, my-consumer-group-1584883029, --topic, my-topic-467311057-683530871, --bootstrap-server, my-cluster-7157fb85-kafka-bootstrap.namespace-1.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-7157fb85-plain-kafka-clients-5f5ffc87f6-f2cjd', podNamespace='namespace-1', bootstrapServer='my-cluster-7157fb85-kafka-bootstrap.namespace-1.svc:9092', topicName='my-topic-467311057-683530871', maxMessages=100, kafkaUsername='top-secret-scramed-leopold', consumerGroupName='my-consumer-group-1584883029', consumerInstanceId='instance1046791457', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6d94e143}
2022-04-02 08:52:06 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-7157fb85-kafka-bootstrap.namespace-1.svc:9092#my-topic-467311057-683530871 from pod my-cluster-7157fb85-plain-kafka-clients-5f5ffc87f6-f2cjd
2022-04-02 08:52:06 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-7157fb85-plain-kafka-clients-5f5ffc87f6-f2cjd -n namespace-1 -- /opt/kafka/consumer.sh USER=top_secret_scramed_leopold --max-messages 100 --group-instance-id instance1046791457 --group-id my-consumer-group-1584883029 --topic my-topic-467311057-683530871 --bootstrap-server my-cluster-7157fb85-kafka-bootstrap.namespace-1.svc:9092
2022-04-02 08:52:33 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-02 08:52:33 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-02 08:52:33 [main] [32mINFO [m [UserST:392] Checking owner reference - if the secret will be deleted when we delete KafkaUser
2022-04-02 08:52:33 [main] [32mINFO [m [UserST:394] Deleting KafkaUser:encrypted-leopold
2022-04-02 08:52:33 [main] [32mINFO [m [KafkaUserUtils:62] Waiting for KafkaUser deletion encrypted-leopold
2022-04-02 08:52:33 [main] [32mINFO [m [KafkaUserUtils:75] KafkaUser encrypted-leopold deleted
2022-04-02 08:52:33 [main] [32mINFO [m [UserST:398] Deleting KafkaUser:scramed-leopold
2022-04-02 08:52:33 [main] [32mINFO [m [KafkaUserUtils:62] Waiting for KafkaUser deletion scramed-leopold
2022-04-02 08:52:33 [main] [32mINFO [m [KafkaUserUtils:75] KafkaUser scramed-leopold deleted
2022-04-02 08:52:33 [main] [32mINFO [m [UserST:402] Checking if secrets are deleted
2022-04-02 08:52:33 [main] [32mINFO [m [SecretUtils:54] Waiting for Secret deletion top-secret-encrypted-leopold
2022-04-02 08:52:34 [main] [32mINFO [m [SecretUtils:58] Secret top-secret-encrypted-leopold deleted
2022-04-02 08:52:34 [main] [32mINFO [m [SecretUtils:54] Waiting for Secret deletion top-secret-scramed-leopold
2022-04-02 08:52:34 [main] [32mINFO [m [SecretUtils:58] Secret top-secret-scramed-leopold deleted
2022-04-02 08:52:34 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 08:52:34 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCreatingUsersWithSecretPrefix
2022-04-02 08:52:34 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser scramed-leopold in namespace namespace-1
2022-04-02 08:52:34 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-7157fb85 in namespace namespace-1
2022-04-02 08:52:34 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaUser encrypted-leopold in namespace namespace-1
2022-04-02 08:52:34 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1110995375-46265860 in namespace namespace-1
2022-04-02 08:52:34 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-7157fb85-plain-kafka-clients in namespace namespace-1
2022-04-02 08:52:34 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-7157fb85-tls-kafka-clients in namespace namespace-1
2022-04-02 08:53:14 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 08:53:14 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-1 for test case:testCreatingUsersWithSecretPrefix
2022-04-02 08:53:20 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.user.UserST.testCreatingUsersWithSecretPrefix-FINISHED
2022-04-02 08:53:20 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 08:53:20 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 08:53:20 [main] [32mINFO [m [ResourceManager:348] Delete all resources for UserST
2022-04-02 08:53:20 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka user-cluster-name in namespace user-st
2022-04-02 08:53:30 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;33mWARNING[m] Tests run: 12, Failures: 0, Errors: 0, Skipped: 4, Time elapsed: 460.553 s - in io.strimzi.systemtest.operators.user.UserST
[[1;34mINFO[m] Running io.strimzi.systemtest.operators.topic.ThrottlingQuotaST
2022-04-02 08:53:57 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: throttling-quota-st
2022-04-02 08:53:57 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: throttling-quota-st
2022-04-02 08:53:57 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: throttling-quota-st
2022-04-02 08:53:57 [main] [32mINFO [m [ThrottlingQuotaST:304] Deploying shared Kafka across all test cases in throttling-quota-st namespace
2022-04-02 08:53:57 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka quota-cluster in namespace throttling-quota-st
2022-04-02 08:53:57 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: quota-cluster will have desired state: Ready
2022-04-02 08:55:07 [main] [32mINFO [m [ResourceManager:444] Kafka: quota-cluster is in desired state: Ready
2022-04-02 08:55:07 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 08:55:07 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.topic.ThrottlingQuotaST.testThrottlingQuotasCreateAlterPartitions-STARTED
2022-04-02 08:55:07 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 08:55:07 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-2022782023-1895741686 in namespace throttling-quota-st
2022-04-02 08:55:07 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-2022782023-1895741686 will have desired state: Ready
2022-04-02 08:55:08 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-2022782023-1895741686 is in desired state: Ready
2022-04-02 08:55:08 [main] [32mINFO [m [ResourceManager:155] Create/Update Job create-admin-my-cluster-7d1ec064-kafka-clients in namespace throttling-quota-st
2022-04-02 08:55:08 [main] [32mINFO [m [JobUtils:81] Waiting for job: create-admin-my-cluster-7d1ec064-kafka-clients will be in active state
2022-04-02 08:55:09 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-02 08:59:11 [main] [32mINFO [m [PodUtils:189] Message org.apache.kafka.common.errors.ThrottlingQuotaExceededException: The throttling quota has been exceeded. found in create-admin-my-cluster-7d1ec064-kafka-clients-spc6s log
2022-04-02 08:59:16 [main] [32mINFO [m [ResourceManager:155] Create/Update Job create-admin-my-cluster-7d1ec064-kafka-clients in namespace throttling-quota-st
2022-04-02 08:59:16 [main] [32mINFO [m [JobUtils:81] Waiting for job: create-admin-my-cluster-7d1ec064-kafka-clients will be in active state
2022-04-02 08:59:17 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-02 09:00:19 [main] [32mINFO [m [PodUtils:189] Message All topics created found in create-admin-my-cluster-7d1ec064-kafka-clients-2dq7r log
2022-04-02 09:00:24 [main] [32mINFO [m [ResourceManager:155] Create/Update Job alter-admin-my-cluster-7d1ec064-kafka-clients in namespace throttling-quota-st
2022-04-02 09:00:24 [main] [32mINFO [m [JobUtils:81] Waiting for job: alter-admin-my-cluster-7d1ec064-kafka-clients will be in active state
2022-04-02 09:00:25 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-02 09:04:27 [main] [32mINFO [m [PodUtils:189] Message org.apache.kafka.common.errors.ThrottlingQuotaExceededException: The throttling quota has been exceeded. found in alter-admin-my-cluster-7d1ec064-kafka-clients-j957g log
2022-04-02 09:04:32 [main] [32mINFO [m [ResourceManager:155] Create/Update Job teardown-delete in namespace throttling-quota-st
2022-04-02 09:04:32 [main] [32mINFO [m [JobUtils:81] Waiting for job: teardown-delete will be in active state
2022-04-02 09:04:33 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:teardown-delete to finished
2022-04-02 09:05:40 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 09:05:40 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testThrottlingQuotasCreateAlterPartitions
2022-04-02 09:05:40 [main] [32mINFO [m [ResourceManager:241] Delete of Job create-admin-my-cluster-7d1ec064-kafka-clients in namespace throttling-quota-st
2022-04-02 09:05:40 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-2022782023-1895741686 in namespace throttling-quota-st
2022-04-02 09:05:40 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job create-admin-my-cluster-7d1ec064-kafka-clients in namespace throttling-quota-st
2022-04-02 09:05:40 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job teardown-delete in namespace throttling-quota-st
2022-04-02 09:05:40 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Job alter-admin-my-cluster-7d1ec064-kafka-clients in namespace throttling-quota-st
2022-04-02 09:05:50 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 09:05:50 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.topic.ThrottlingQuotaST.testThrottlingQuotasCreateAlterPartitions-FINISHED
2022-04-02 09:05:50 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 09:05:50 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 09:05:50 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.topic.ThrottlingQuotaST.testKafkaAdminTopicOperations-STARTED
2022-04-02 09:05:50 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 09:05:50 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-846428325-1457929082 in namespace throttling-quota-st
2022-04-02 09:05:50 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-846428325-1457929082 will have desired state: Ready
2022-04-02 09:05:51 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-846428325-1457929082 is in desired state: Ready
2022-04-02 09:05:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Job create-admin-my-cluster-2cd3c920-kafka-clients in namespace throttling-quota-st
2022-04-02 09:05:51 [main] [32mINFO [m [JobUtils:81] Waiting for job: create-admin-my-cluster-2cd3c920-kafka-clients will be in active state
2022-04-02 09:05:52 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-02 09:07:22 [main] [32mINFO [m [PodUtils:189] Message All topics created found in create-admin-my-cluster-2cd3c920-kafka-clients-znxl4 log
2022-04-02 09:07:32 [main] [32mINFO [m [ResourceManager:155] Create/Update Job list-admin-my-cluster-2cd3c920-kafka-clients in namespace throttling-quota-st
2022-04-02 09:07:32 [main] [32mINFO [m [JobUtils:81] Waiting for job: list-admin-my-cluster-2cd3c920-kafka-clients will be in active state
2022-04-02 09:07:33 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-02 09:07:35 [main] [32mINFO [m [PodUtils:189] Message quota-topic-test-simple-99 found in list-admin-my-cluster-2cd3c920-kafka-clients-hg7v5 log
2022-04-02 09:07:40 [main] [32mINFO [m [ResourceManager:155] Create/Update Job delete-admin-my-cluster-2cd3c920-kafka-clients in namespace throttling-quota-st
2022-04-02 09:07:40 [main] [32mINFO [m [JobUtils:81] Waiting for job: delete-admin-my-cluster-2cd3c920-kafka-clients will be in active state
2022-04-02 09:07:41 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-02 09:09:11 [main] [32mINFO [m [PodUtils:189] Message Successfully removed all 100 found in delete-admin-my-cluster-2cd3c920-kafka-clients-92rtk log
2022-04-02 09:09:16 [main] [32mINFO [m [ResourceManager:155] Create/Update Job list-admin-my-cluster-2cd3c920-kafka-clients in namespace throttling-quota-st
2022-04-02 09:09:16 [main] [32mINFO [m [JobUtils:81] Waiting for job: list-admin-my-cluster-2cd3c920-kafka-clients will be in active state
2022-04-02 09:09:17 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:list-admin-my-cluster-2cd3c920-kafka-clients to finished
2022-04-02 09:09:19 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 09:09:19 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaAdminTopicOperations
2022-04-02 09:09:19 [main] [32mINFO [m [ResourceManager:241] Delete of Job list-admin-my-cluster-2cd3c920-kafka-clients in namespace throttling-quota-st
2022-04-02 09:09:19 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job list-admin-my-cluster-2cd3c920-kafka-clients in namespace throttling-quota-st
2022-04-02 09:09:19 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-846428325-1457929082 in namespace throttling-quota-st
2022-04-02 09:09:19 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job create-admin-my-cluster-2cd3c920-kafka-clients in namespace throttling-quota-st
2022-04-02 09:09:19 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Job delete-admin-my-cluster-2cd3c920-kafka-clients in namespace throttling-quota-st
2022-04-02 09:09:29 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 09:09:29 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.topic.ThrottlingQuotaST.testKafkaAdminTopicOperations-FINISHED
2022-04-02 09:09:29 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 09:09:29 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 09:09:29 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.topic.ThrottlingQuotaST.testThrottlingQuotasDeleteTopic-STARTED
2022-04-02 09:09:29 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 09:09:29 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1953862640-1512578852 in namespace throttling-quota-st
2022-04-02 09:09:29 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1953862640-1512578852 will have desired state: Ready
2022-04-02 09:09:30 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1953862640-1512578852 is in desired state: Ready
2022-04-02 09:09:30 [main] [32mINFO [m [ThrottlingQuotaST:112] Executing 1/5 iteration.
2022-04-02 09:09:30 [main] [32mINFO [m [ResourceManager:155] Create/Update Job create-admin-my-cluster-085d125f-kafka-clients in namespace throttling-quota-st
2022-04-02 09:09:30 [main] [32mINFO [m [JobUtils:81] Waiting for job: create-admin-my-cluster-085d125f-kafka-clients will be in active state
2022-04-02 09:09:31 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:create-admin-my-cluster-085d125f-kafka-clients to finished
2022-04-02 09:11:02 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-02 09:11:02 [main] [32mINFO [m [PodUtils:189] Message All topics created found in create-admin-my-cluster-085d125f-kafka-clients-7l9bg log
2022-04-02 09:11:07 [main] [32mINFO [m [ThrottlingQuotaST:112] Executing 2/5 iteration.
2022-04-02 09:11:07 [main] [32mINFO [m [ResourceManager:155] Create/Update Job create-admin-my-cluster-085d125f-kafka-clients in namespace throttling-quota-st
2022-04-02 09:11:07 [main] [32mINFO [m [JobUtils:81] Waiting for job: create-admin-my-cluster-085d125f-kafka-clients will be in active state
2022-04-02 09:11:08 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:create-admin-my-cluster-085d125f-kafka-clients to finished
2022-04-02 09:12:42 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-02 09:12:42 [main] [32mINFO [m [PodUtils:189] Message All topics created found in create-admin-my-cluster-085d125f-kafka-clients-99w52 log
2022-04-02 09:12:47 [main] [32mINFO [m [ThrottlingQuotaST:112] Executing 3/5 iteration.
2022-04-02 09:12:47 [main] [32mINFO [m [ResourceManager:155] Create/Update Job create-admin-my-cluster-085d125f-kafka-clients in namespace throttling-quota-st
2022-04-02 09:12:47 [main] [32mINFO [m [JobUtils:81] Waiting for job: create-admin-my-cluster-085d125f-kafka-clients will be in active state
2022-04-02 09:12:48 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:create-admin-my-cluster-085d125f-kafka-clients to finished
2022-04-02 09:14:22 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-02 09:14:22 [main] [32mINFO [m [PodUtils:189] Message All topics created found in create-admin-my-cluster-085d125f-kafka-clients-mpsn8 log
2022-04-02 09:14:27 [main] [32mINFO [m [ThrottlingQuotaST:112] Executing 4/5 iteration.
2022-04-02 09:14:27 [main] [32mINFO [m [ResourceManager:155] Create/Update Job create-admin-my-cluster-085d125f-kafka-clients in namespace throttling-quota-st
2022-04-02 09:14:27 [main] [32mINFO [m [JobUtils:81] Waiting for job: create-admin-my-cluster-085d125f-kafka-clients will be in active state
2022-04-02 09:14:28 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:create-admin-my-cluster-085d125f-kafka-clients to finished
2022-04-02 09:16:02 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-02 09:16:03 [main] [32mINFO [m [PodUtils:189] Message All topics created found in create-admin-my-cluster-085d125f-kafka-clients-2rpq5 log
2022-04-02 09:16:08 [main] [32mINFO [m [ThrottlingQuotaST:112] Executing 5/5 iteration.
2022-04-02 09:16:08 [main] [32mINFO [m [ResourceManager:155] Create/Update Job create-admin-my-cluster-085d125f-kafka-clients in namespace throttling-quota-st
2022-04-02 09:16:08 [main] [32mINFO [m [JobUtils:81] Waiting for job: create-admin-my-cluster-085d125f-kafka-clients will be in active state
2022-04-02 09:16:09 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:create-admin-my-cluster-085d125f-kafka-clients to finished
2022-04-02 09:17:43 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-02 09:17:43 [main] [32mINFO [m [PodUtils:189] Message All topics created found in create-admin-my-cluster-085d125f-kafka-clients-m647v log
2022-04-02 09:17:48 [main] [32mINFO [m [ResourceManager:155] Create/Update Job delete-admin-my-cluster-085d125f-kafka-clients in namespace throttling-quota-st
2022-04-02 09:17:48 [main] [32mINFO [m [JobUtils:81] Waiting for job: delete-admin-my-cluster-085d125f-kafka-clients will be in active state
2022-04-02 09:17:49 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-02 09:21:51 [main] [32mINFO [m [PodUtils:189] Message org.apache.kafka.common.errors.ThrottlingQuotaExceededException: The throttling quota has been exceeded. found in delete-admin-my-cluster-085d125f-kafka-clients-s528h log
2022-04-02 09:21:56 [main] [32mINFO [m [ThrottlingQuotaST:144] Executing 1/5 iteration for delete-admin-my-cluster-085d125f-kafka-clients.
2022-04-02 09:21:56 [main] [32mINFO [m [ResourceManager:155] Create/Update Job delete-admin-my-cluster-085d125f-kafka-clients in namespace throttling-quota-st
2022-04-02 09:21:56 [main] [32mINFO [m [JobUtils:81] Waiting for job: delete-admin-my-cluster-085d125f-kafka-clients will be in active state
2022-04-02 09:21:57 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:delete-admin-my-cluster-085d125f-kafka-clients to finished
2022-04-02 09:23:04 [main] [32mINFO [m [ThrottlingQuotaST:144] Executing 2/5 iteration for delete-admin-my-cluster-085d125f-kafka-clients.
2022-04-02 09:23:04 [main] [32mINFO [m [ResourceManager:155] Create/Update Job delete-admin-my-cluster-085d125f-kafka-clients in namespace throttling-quota-st
2022-04-02 09:23:04 [main] [32mINFO [m [JobUtils:81] Waiting for job: delete-admin-my-cluster-085d125f-kafka-clients will be in active state
2022-04-02 09:23:05 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:delete-admin-my-cluster-085d125f-kafka-clients to finished
2022-04-02 09:24:13 [main] [32mINFO [m [ThrottlingQuotaST:144] Executing 3/5 iteration for delete-admin-my-cluster-085d125f-kafka-clients.
2022-04-02 09:24:13 [main] [32mINFO [m [ResourceManager:155] Create/Update Job delete-admin-my-cluster-085d125f-kafka-clients in namespace throttling-quota-st
2022-04-02 09:24:13 [main] [32mINFO [m [JobUtils:81] Waiting for job: delete-admin-my-cluster-085d125f-kafka-clients will be in active state
2022-04-02 09:24:14 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:delete-admin-my-cluster-085d125f-kafka-clients to finished
2022-04-02 09:25:21 [main] [32mINFO [m [ThrottlingQuotaST:144] Executing 4/5 iteration for delete-admin-my-cluster-085d125f-kafka-clients.
2022-04-02 09:25:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Job delete-admin-my-cluster-085d125f-kafka-clients in namespace throttling-quota-st
2022-04-02 09:25:21 [main] [32mINFO [m [JobUtils:81] Waiting for job: delete-admin-my-cluster-085d125f-kafka-clients will be in active state
2022-04-02 09:25:22 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:delete-admin-my-cluster-085d125f-kafka-clients to finished
2022-04-02 09:26:29 [main] [32mINFO [m [ThrottlingQuotaST:144] Executing 5/5 iteration for delete-admin-my-cluster-085d125f-kafka-clients.
2022-04-02 09:26:29 [main] [32mINFO [m [ResourceManager:155] Create/Update Job delete-admin-my-cluster-085d125f-kafka-clients in namespace throttling-quota-st
2022-04-02 09:26:29 [main] [32mINFO [m [JobUtils:81] Waiting for job: delete-admin-my-cluster-085d125f-kafka-clients will be in active state
2022-04-02 09:26:30 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:delete-admin-my-cluster-085d125f-kafka-clients to finished
2022-04-02 09:27:38 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 09:27:38 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testThrottlingQuotasDeleteTopic
2022-04-02 09:27:38 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job delete-admin-my-cluster-085d125f-kafka-clients in namespace throttling-quota-st
2022-04-02 09:27:38 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job delete-admin-my-cluster-085d125f-kafka-clients in namespace throttling-quota-st
2022-04-02 09:27:38 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job delete-admin-my-cluster-085d125f-kafka-clients in namespace throttling-quota-st
2022-04-02 09:27:38 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Job create-admin-my-cluster-085d125f-kafka-clients in namespace throttling-quota-st
2022-04-02 09:27:38 [main] [32mINFO [m [ResourceManager:241] Delete of Job delete-admin-my-cluster-085d125f-kafka-clients in namespace throttling-quota-st
2022-04-02 09:27:38 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job create-admin-my-cluster-085d125f-kafka-clients in namespace throttling-quota-st
2022-04-02 09:27:38 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Job delete-admin-my-cluster-085d125f-kafka-clients in namespace throttling-quota-st
2022-04-02 09:27:38 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Job create-admin-my-cluster-085d125f-kafka-clients in namespace throttling-quota-st
2022-04-02 09:27:38 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job delete-admin-my-cluster-085d125f-kafka-clients in namespace throttling-quota-st
2022-04-02 09:27:38 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job create-admin-my-cluster-085d125f-kafka-clients in namespace throttling-quota-st
2022-04-02 09:27:38 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1953862640-1512578852 in namespace throttling-quota-st
2022-04-02 09:27:38 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job create-admin-my-cluster-085d125f-kafka-clients in namespace throttling-quota-st
2022-04-02 09:27:48 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 09:27:48 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.topic.ThrottlingQuotaST.testThrottlingQuotasDeleteTopic-FINISHED
2022-04-02 09:27:48 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 09:27:48 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 09:27:48 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.topic.ThrottlingQuotaST.testThrottlingQuotasCreateTopic-STARTED
2022-04-02 09:27:48 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 09:27:48 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1900402606-847116112 in namespace throttling-quota-st
2022-04-02 09:27:48 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1900402606-847116112 will have desired state: Ready
2022-04-02 09:27:49 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1900402606-847116112 is in desired state: Ready
2022-04-02 09:27:49 [main] [32mINFO [m [ResourceManager:155] Create/Update Job create-admin-my-cluster-9ec5af23-kafka-clients in namespace throttling-quota-st
2022-04-02 09:27:49 [main] [32mINFO [m [JobUtils:81] Waiting for job: create-admin-my-cluster-9ec5af23-kafka-clients will be in active state
2022-04-02 09:27:50 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-02 09:31:52 [main] [32mINFO [m [PodUtils:189] Message org.apache.kafka.common.errors.ThrottlingQuotaExceededException: The throttling quota has been exceeded. found in create-admin-my-cluster-9ec5af23-kafka-clients-9s2z8 log
2022-04-02 09:32:17 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 09:32:17 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testThrottlingQuotasCreateTopic
2022-04-02 09:32:17 [main] [32mINFO [m [ResourceManager:241] Delete of Job create-admin-my-cluster-9ec5af23-kafka-clients in namespace throttling-quota-st
2022-04-02 09:32:17 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1900402606-847116112 in namespace throttling-quota-st
2022-04-02 09:32:27 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 09:32:27 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.topic.ThrottlingQuotaST.testThrottlingQuotasCreateTopic-FINISHED
2022-04-02 09:32:27 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 09:32:27 [main] [32mINFO [m [ThrottlingQuotaST:353] Tearing down resources after all test
2022-04-02 09:32:49 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 09:32:49 [main] [32mINFO [m [ResourceManager:348] Delete all resources for ThrottlingQuotaST
2022-04-02 09:32:49 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka quota-cluster in namespace throttling-quota-st
2022-04-02 09:32:59 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2,369.11 s - in io.strimzi.systemtest.operators.topic.ThrottlingQuotaST
[[1;34mINFO[m] Running io.strimzi.systemtest.operators.topic.TopicST
2022-04-02 09:33:26 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: topic-st
2022-04-02 09:33:26 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: topic-st
2022-04-02 09:33:26 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: topic-st
2022-04-02 09:33:26 [main] [32mINFO [m [TopicST:491] Deploying shared Kafka across all test cases in topic-st namespace
2022-04-02 09:33:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka topic-cluster-name in namespace topic-st
2022-04-02 09:33:26 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: topic-cluster-name will have desired state: Ready
2022-04-02 09:34:39 [main] [32mINFO [m [ResourceManager:444] Kafka: topic-cluster-name is in desired state: Ready
2022-04-02 09:34:39 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 09:34:39 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.topic.TopicST.testCreateTopicViaAdminClient-STARTED
2022-04-02 09:34:39 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 09:34:39 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-65637c6d in namespace topic-st
2022-04-02 09:34:39 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-65637c6d will have desired state: Ready
2022-04-02 09:36:05 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-65637c6d is in desired state: Ready
2022-04-02 09:36:05 [main] [32mINFO [m [AdminClientConfig:376] AdminClientConfig values: 
	bootstrap.servers = [192.168.49.2:32081]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-04-02 09:36:05 [main] [32mINFO [m [AppInfoParser:119] Kafka version: 3.1.0
2022-04-02 09:36:05 [main] [32mINFO [m [AppInfoParser:120] Kafka commitId: 37edeed0777bacb3
2022-04-02 09:36:05 [main] [32mINFO [m [AppInfoParser:121] Kafka startTimeMs: 1648892165273
2022-04-02 09:36:05 [main] [32mINFO [m [TopicST:166] Creating async topic my-topic-1851457400-1793632552 via Admin client
2022-04-02 09:36:05 [main] [32mINFO [m [TopicST:172] Verify that in Kafka cluster contains 3 topics
2022-04-02 09:36:05 [main] [32mINFO [m [KafkaTopicUtils:78] Waiting for KafkaTopic my-topic-1851457400-1793632552 creation 
2022-04-02 09:36:07 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1851457400-1793632552 will have desired state: Ready
2022-04-02 09:36:07 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1851457400-1793632552 is in desired state: Ready
2022-04-02 09:36:07 [kafka-admin-client-thread | adminclient-1] [32mINFO [m [AppInfoParser:83] App info kafka.admin.client for adminclient-1 unregistered
2022-04-02 09:36:07 [kafka-admin-client-thread | adminclient-1] [32mINFO [m [Metrics:659] Metrics scheduler closed
2022-04-02 09:36:07 [kafka-admin-client-thread | adminclient-1] [32mINFO [m [Metrics:663] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-04-02 09:36:07 [kafka-admin-client-thread | adminclient-1] [32mINFO [m [Metrics:669] Metrics reporters closed
2022-04-02 09:36:07 [main] [32mINFO [m [TopicST:182] Verify that corresponding 1 KafkaTopic custom resources were created and topic is in Ready state
2022-04-02 09:36:07 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 09:36:07 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCreateTopicViaAdminClient
2022-04-02 09:36:07 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-65637c6d in namespace topic-st
2022-04-02 09:36:17 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 09:36:17 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.topic.TopicST.testCreateTopicViaAdminClient-FINISHED
2022-04-02 09:36:17 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 09:36:17 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 09:36:17 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.topic.TopicST.testCreateDeleteCreate-STARTED
2022-04-02 09:36:17 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 09:36:17 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-5430efad in namespace topic-st
2022-04-02 09:36:17 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-5430efad will have desired state: Ready
2022-04-02 09:37:34 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-5430efad is in desired state: Ready
2022-04-02 09:37:34 [main] [32mINFO [m [AdminClientConfig:376] AdminClientConfig values: 
	bootstrap.servers = [192.168.49.2:30777]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-04-02 09:37:34 [main] [32mINFO [m [AppInfoParser:119] Kafka version: 3.1.0
2022-04-02 09:37:34 [main] [32mINFO [m [AppInfoParser:120] Kafka commitId: 37edeed0777bacb3
2022-04-02 09:37:34 [main] [32mINFO [m [AppInfoParser:121] Kafka startTimeMs: 1648892254136
2022-04-02 09:37:34 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-452248765-2091904895 in namespace topic-st
2022-04-02 09:37:34 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-452248765-2091904895 will have desired state: Ready
2022-04-02 09:37:35 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-452248765-2091904895 is in desired state: Ready
2022-04-02 09:37:35 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-452248765-2091904895 will have desired state: Ready
2022-04-02 09:37:35 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-452248765-2091904895 is in desired state: Ready
2022-04-02 09:37:37 [main] [32mINFO [m [TopicST:238] Iteration 0: Deleting my-topic-452248765-2091904895
2022-04-02 09:37:37 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic my-topic-452248765-2091904895 deletion
2022-04-02 09:37:40 [main] [32mINFO [m [TopicST:250] Iteration 0: Recreating my-topic-452248765-2091904895
2022-04-02 09:37:40 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-452248765-2091904895 in namespace topic-st
2022-04-02 09:37:40 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-452248765-2091904895 will have desired state: Ready
2022-04-02 09:37:41 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-452248765-2091904895 is in desired state: Ready
2022-04-02 09:37:41 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-452248765-2091904895 will have desired state: Ready
2022-04-02 09:37:41 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-452248765-2091904895 is in desired state: Ready
2022-04-02 09:37:43 [main] [32mINFO [m [TopicST:238] Iteration 1: Deleting my-topic-452248765-2091904895
2022-04-02 09:37:43 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic my-topic-452248765-2091904895 deletion
2022-04-02 09:37:46 [main] [32mINFO [m [TopicST:250] Iteration 1: Recreating my-topic-452248765-2091904895
2022-04-02 09:37:46 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-452248765-2091904895 in namespace topic-st
2022-04-02 09:37:46 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-452248765-2091904895 will have desired state: Ready
2022-04-02 09:37:47 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-452248765-2091904895 is in desired state: Ready
2022-04-02 09:37:47 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-452248765-2091904895 will have desired state: Ready
2022-04-02 09:37:47 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-452248765-2091904895 is in desired state: Ready
2022-04-02 09:37:49 [main] [32mINFO [m [TopicST:238] Iteration 2: Deleting my-topic-452248765-2091904895
2022-04-02 09:37:49 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic my-topic-452248765-2091904895 deletion
2022-04-02 09:37:52 [main] [32mINFO [m [TopicST:250] Iteration 2: Recreating my-topic-452248765-2091904895
2022-04-02 09:37:52 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-452248765-2091904895 in namespace topic-st
2022-04-02 09:37:52 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-452248765-2091904895 will have desired state: Ready
2022-04-02 09:37:53 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-452248765-2091904895 is in desired state: Ready
2022-04-02 09:37:53 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-452248765-2091904895 will have desired state: Ready
2022-04-02 09:37:53 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-452248765-2091904895 is in desired state: Ready
2022-04-02 09:37:55 [main] [32mINFO [m [TopicST:238] Iteration 3: Deleting my-topic-452248765-2091904895
2022-04-02 09:37:55 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic my-topic-452248765-2091904895 deletion
2022-04-02 09:37:58 [main] [32mINFO [m [TopicST:250] Iteration 3: Recreating my-topic-452248765-2091904895
2022-04-02 09:37:58 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-452248765-2091904895 in namespace topic-st
2022-04-02 09:37:58 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-452248765-2091904895 will have desired state: Ready
2022-04-02 09:37:59 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-452248765-2091904895 is in desired state: Ready
2022-04-02 09:37:59 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-452248765-2091904895 will have desired state: Ready
2022-04-02 09:37:59 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-452248765-2091904895 is in desired state: Ready
2022-04-02 09:38:01 [main] [32mINFO [m [TopicST:238] Iteration 4: Deleting my-topic-452248765-2091904895
2022-04-02 09:38:01 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic my-topic-452248765-2091904895 deletion
2022-04-02 09:38:04 [main] [32mINFO [m [TopicST:250] Iteration 4: Recreating my-topic-452248765-2091904895
2022-04-02 09:38:04 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-452248765-2091904895 in namespace topic-st
2022-04-02 09:38:04 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-452248765-2091904895 will have desired state: Ready
2022-04-02 09:38:05 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-452248765-2091904895 is in desired state: Ready
2022-04-02 09:38:05 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-452248765-2091904895 will have desired state: Ready
2022-04-02 09:38:05 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-452248765-2091904895 is in desired state: Ready
2022-04-02 09:38:07 [main] [32mINFO [m [TopicST:238] Iteration 5: Deleting my-topic-452248765-2091904895
2022-04-02 09:38:07 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic my-topic-452248765-2091904895 deletion
2022-04-02 09:38:10 [main] [32mINFO [m [TopicST:250] Iteration 5: Recreating my-topic-452248765-2091904895
2022-04-02 09:38:10 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-452248765-2091904895 in namespace topic-st
2022-04-02 09:38:10 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-452248765-2091904895 will have desired state: Ready
2022-04-02 09:38:11 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-452248765-2091904895 is in desired state: Ready
2022-04-02 09:38:11 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-452248765-2091904895 will have desired state: Ready
2022-04-02 09:38:11 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-452248765-2091904895 is in desired state: Ready
2022-04-02 09:38:13 [main] [32mINFO [m [TopicST:238] Iteration 6: Deleting my-topic-452248765-2091904895
2022-04-02 09:38:13 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic my-topic-452248765-2091904895 deletion
2022-04-02 09:38:16 [main] [32mINFO [m [TopicST:250] Iteration 6: Recreating my-topic-452248765-2091904895
2022-04-02 09:38:16 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-452248765-2091904895 in namespace topic-st
2022-04-02 09:38:16 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-452248765-2091904895 will have desired state: Ready
2022-04-02 09:38:17 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-452248765-2091904895 is in desired state: Ready
2022-04-02 09:38:17 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-452248765-2091904895 will have desired state: Ready
2022-04-02 09:38:17 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-452248765-2091904895 is in desired state: Ready
2022-04-02 09:38:19 [main] [32mINFO [m [TopicST:238] Iteration 7: Deleting my-topic-452248765-2091904895
2022-04-02 09:38:20 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic my-topic-452248765-2091904895 deletion
2022-04-02 09:38:23 [main] [32mINFO [m [TopicST:250] Iteration 7: Recreating my-topic-452248765-2091904895
2022-04-02 09:38:23 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-452248765-2091904895 in namespace topic-st
2022-04-02 09:38:23 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-452248765-2091904895 will have desired state: Ready
2022-04-02 09:38:24 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-452248765-2091904895 is in desired state: Ready
2022-04-02 09:38:24 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-452248765-2091904895 will have desired state: Ready
2022-04-02 09:38:24 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-452248765-2091904895 is in desired state: Ready
2022-04-02 09:38:26 [main] [32mINFO [m [TopicST:238] Iteration 8: Deleting my-topic-452248765-2091904895
2022-04-02 09:38:26 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic my-topic-452248765-2091904895 deletion
2022-04-02 09:38:29 [main] [32mINFO [m [TopicST:250] Iteration 8: Recreating my-topic-452248765-2091904895
2022-04-02 09:38:29 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-452248765-2091904895 in namespace topic-st
2022-04-02 09:38:29 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-452248765-2091904895 will have desired state: Ready
2022-04-02 09:38:30 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-452248765-2091904895 is in desired state: Ready
2022-04-02 09:38:30 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-452248765-2091904895 will have desired state: Ready
2022-04-02 09:38:30 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-452248765-2091904895 is in desired state: Ready
2022-04-02 09:38:32 [main] [32mINFO [m [TopicST:238] Iteration 9: Deleting my-topic-452248765-2091904895
2022-04-02 09:38:32 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic my-topic-452248765-2091904895 deletion
2022-04-02 09:38:35 [main] [32mINFO [m [TopicST:250] Iteration 9: Recreating my-topic-452248765-2091904895
2022-04-02 09:38:35 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-452248765-2091904895 in namespace topic-st
2022-04-02 09:38:35 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-452248765-2091904895 will have desired state: Ready
2022-04-02 09:38:36 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-452248765-2091904895 is in desired state: Ready
2022-04-02 09:38:36 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-452248765-2091904895 will have desired state: Ready
2022-04-02 09:38:36 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-452248765-2091904895 is in desired state: Ready
2022-04-02 09:38:36 [kafka-admin-client-thread | adminclient-2] [32mINFO [m [AppInfoParser:83] App info kafka.admin.client for adminclient-2 unregistered
2022-04-02 09:38:36 [kafka-admin-client-thread | adminclient-2] [32mINFO [m [Metrics:659] Metrics scheduler closed
2022-04-02 09:38:36 [kafka-admin-client-thread | adminclient-2] [32mINFO [m [Metrics:663] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-04-02 09:38:36 [kafka-admin-client-thread | adminclient-2] [32mINFO [m [Metrics:669] Metrics reporters closed
2022-04-02 09:38:36 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 09:38:36 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCreateDeleteCreate
2022-04-02 09:38:36 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-452248765-2091904895 in namespace topic-st
2022-04-02 09:38:36 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-452248765-2091904895 in namespace topic-st
2022-04-02 09:38:36 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-452248765-2091904895 in namespace topic-st
2022-04-02 09:38:36 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-5430efad in namespace topic-st
2022-04-02 09:38:36 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-452248765-2091904895 in namespace topic-st
2022-04-02 09:38:36 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-452248765-2091904895 in namespace topic-st
2022-04-02 09:38:36 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-452248765-2091904895 in namespace topic-st
2022-04-02 09:38:36 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-452248765-2091904895 in namespace topic-st
2022-04-02 09:38:46 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-452248765-2091904895 in namespace topic-st
2022-04-02 09:38:46 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-452248765-2091904895 in namespace topic-st
2022-04-02 09:38:46 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-452248765-2091904895 in namespace topic-st
2022-04-02 09:38:46 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-452248765-2091904895 in namespace topic-st
2022-04-02 09:38:46 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 09:38:46 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.topic.TopicST.testCreateDeleteCreate-FINISHED
2022-04-02 09:38:46 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 09:38:46 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 09:38:46 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.topic.TopicST.testTopicModificationOfReplicationFactor-STARTED
2022-04-02 09:38:46 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 09:38:46 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-163104142-1785019033 in namespace topic-st
2022-04-02 09:38:46 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-163104142-1785019033 will have desired state: Ready
2022-04-02 09:38:47 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-163104142-1785019033 is in desired state: Ready
2022-04-02 09:38:47 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-163104142-1785019033 will have desired state: NotReady
2022-04-02 09:38:48 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-163104142-1785019033 is in desired state: NotReady
2022-04-02 09:38:48 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic my-topic-163104142-1785019033 deletion
2022-04-02 09:38:48 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 09:38:48 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTopicModificationOfReplicationFactor
2022-04-02 09:38:48 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-163104142-1785019033 in namespace topic-st
2022-04-02 09:38:48 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 09:38:48 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.topic.TopicST.testTopicModificationOfReplicationFactor-FINISHED
2022-04-02 09:38:48 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 09:38:48 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 09:38:48 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.topic.TopicST.testDeleteTopicEnableFalse-STARTED
2022-04-02 09:38:48 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 09:38:48 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-d442b797-isolated in namespace topic-st
2022-04-02 09:38:48 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d442b797-isolated will have desired state: Ready
2022-04-02 09:39:55 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d442b797-isolated is in desired state: Ready
2022-04-02 09:39:55 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-d442b797-isolated-kafka-clients in namespace topic-st
2022-04-02 09:39:55 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-d442b797-isolated-kafka-clients will be ready
2022-04-02 09:39:56 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-d442b797-isolated-kafka-clients is ready
2022-04-02 09:39:56 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-67003713-1152150057 in namespace topic-st
2022-04-02 09:39:56 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-67003713-1152150057 will have desired state: Ready
2022-04-02 09:39:57 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-67003713-1152150057 is in desired state: Ready
2022-04-02 09:39:57 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-02 09:39:57 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@191f4faa, messages=[], arguments=[--max-messages, 100, --topic, my-topic-67003713-1152150057, --bootstrap-server, my-cluster-d442b797-isolated-kafka-bootstrap.topic-st.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-d442b797-isolated-kafka-clients-f8858c566-zwb86', podNamespace='topic-st', bootstrapServer='my-cluster-d442b797-isolated-kafka-bootstrap.topic-st.svc:9092', topicName='my-topic-67003713-1152150057', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@4123293e}
2022-04-02 09:39:57 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-d442b797-isolated-kafka-bootstrap.topic-st.svc:9092:my-topic-67003713-1152150057 from pod my-cluster-d442b797-isolated-kafka-clients-f8858c566-zwb86
2022-04-02 09:39:57 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-d442b797-isolated-kafka-clients-f8858c566-zwb86 -n topic-st -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-67003713-1152150057 --bootstrap-server my-cluster-d442b797-isolated-kafka-bootstrap.topic-st.svc:9092
2022-04-02 09:40:00 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-02 09:40:00 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-02 09:40:00 [main] [32mINFO [m [TopicST:395] Deleting KafkaTopic: my-topic-67003713-1152150057
2022-04-02 09:40:00 [main] [32mINFO [m [TopicST:397] KafkaTopic my-topic-67003713-1152150057 deleted
2022-04-02 09:41:40 [main] [32mINFO [m [TopicST:401] Wait KafkaTopic my-topic-67003713-1152150057 recreation
2022-04-02 09:41:40 [main] [32mINFO [m [KafkaTopicUtils:78] Waiting for KafkaTopic my-topic-67003713-1152150057 creation 
2022-04-02 09:41:40 [main] [32mINFO [m [TopicST:403] KafkaTopic my-topic-67003713-1152150057 recreated
2022-04-02 09:41:40 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@760d2d76, messages=[], arguments=[--max-messages, 100, --group-instance-id, instance1982945137, --group-id, my-consumer-group-1382316977, --topic, my-topic-67003713-1152150057, --bootstrap-server, my-cluster-d442b797-isolated-kafka-bootstrap.topic-st.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-d442b797-isolated-kafka-clients-f8858c566-zwb86', podNamespace='topic-st', bootstrapServer='my-cluster-d442b797-isolated-kafka-bootstrap.topic-st.svc:9092', topicName='my-topic-67003713-1152150057', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1382316977', consumerInstanceId='instance1982945137', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@158c4272}
2022-04-02 09:41:40 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-d442b797-isolated-kafka-bootstrap.topic-st.svc:9092#my-topic-67003713-1152150057 from pod my-cluster-d442b797-isolated-kafka-clients-f8858c566-zwb86
2022-04-02 09:41:40 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-d442b797-isolated-kafka-clients-f8858c566-zwb86 -n topic-st -- /opt/kafka/consumer.sh --max-messages 100 --group-instance-id instance1982945137 --group-id my-consumer-group-1382316977 --topic my-topic-67003713-1152150057 --bootstrap-server my-cluster-d442b797-isolated-kafka-bootstrap.topic-st.svc:9092
2022-04-02 09:41:46 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-02 09:41:46 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-02 09:41:46 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 09:41:46 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDeleteTopicEnableFalse
2022-04-02 09:41:46 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-d442b797-isolated-kafka-clients in namespace topic-st
2022-04-02 09:41:46 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-67003713-1152150057 in namespace topic-st
2022-04-02 09:41:46 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-d442b797-isolated in namespace topic-st
2022-04-02 09:42:36 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 09:42:36 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.topic.TopicST.testDeleteTopicEnableFalse-FINISHED
2022-04-02 09:42:36 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 09:42:36 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 09:42:36 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.topic.TopicST.testSendingMessagesToNonExistingTopic-STARTED
2022-04-02 09:42:36 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 09:42:36 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment topic-cluster-name-kafka-clients in namespace topic-st
2022-04-02 09:42:36 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: topic-cluster-name-kafka-clients will be ready
2022-04-02 09:42:38 [main] [32mINFO [m [DeploymentUtils:168] Deployment: topic-cluster-name-kafka-clients is ready
2022-04-02 09:42:38 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-02 09:42:38 [main] [32mINFO [m [TopicST:320] Checking if my-topic-106247208-1208080116 is on topic list
2022-04-02 09:42:38 [main] [32mINFO [m [TopicST:456] Checking topic my-topic-106247208-1208080116 in Kafka
2022-04-02 09:42:41 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace topic-st exec topic-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-02 09:42:41 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 09:42:41 [main] [32mINFO [m [TopicST:323] Topic with name my-topic-106247208-1208080116 is not created yet
2022-04-02 09:42:41 [main] [32mINFO [m [TopicST:325] Trying to send messages to non-existing topic my-topic-106247208-1208080116
2022-04-02 09:42:41 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@2ceba8a7, messages=[], arguments=[--max-messages, 100, --topic, my-topic-106247208-1208080116, --bootstrap-server, topic-cluster-name-kafka-bootstrap.topic-st.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='topic-cluster-name-kafka-clients-7dd7cb68d4-fnm8p', podNamespace='topic-st', bootstrapServer='topic-cluster-name-kafka-bootstrap.topic-st.svc:9092', topicName='my-topic-106247208-1208080116', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7a8f19ba}
2022-04-02 09:42:41 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to topic-cluster-name-kafka-bootstrap.topic-st.svc:9092:my-topic-106247208-1208080116 from pod topic-cluster-name-kafka-clients-7dd7cb68d4-fnm8p
2022-04-02 09:42:41 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec topic-cluster-name-kafka-clients-7dd7cb68d4-fnm8p -n topic-st -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-106247208-1208080116 --bootstrap-server topic-cluster-name-kafka-bootstrap.topic-st.svc:9092
2022-04-02 09:42:44 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-02 09:42:44 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-02 09:42:44 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@6a12b99e, messages=[], arguments=[--max-messages, 100, --group-instance-id, instance443418545, --group-id, my-consumer-group-981433022, --topic, my-topic-106247208-1208080116, --bootstrap-server, topic-cluster-name-kafka-bootstrap.topic-st.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='topic-cluster-name-kafka-clients-7dd7cb68d4-fnm8p', podNamespace='topic-st', bootstrapServer='topic-cluster-name-kafka-bootstrap.topic-st.svc:9092', topicName='my-topic-106247208-1208080116', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-981433022', consumerInstanceId='instance443418545', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@2e08d8c3}
2022-04-02 09:42:44 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from topic-cluster-name-kafka-bootstrap.topic-st.svc:9092#my-topic-106247208-1208080116 from pod topic-cluster-name-kafka-clients-7dd7cb68d4-fnm8p
2022-04-02 09:42:44 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec topic-cluster-name-kafka-clients-7dd7cb68d4-fnm8p -n topic-st -- /opt/kafka/consumer.sh --max-messages 100 --group-instance-id instance443418545 --group-id my-consumer-group-981433022 --topic my-topic-106247208-1208080116 --bootstrap-server topic-cluster-name-kafka-bootstrap.topic-st.svc:9092
2022-04-02 09:42:49 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-02 09:42:49 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-02 09:42:49 [main] [32mINFO [m [TopicST:341] Checking if my-topic-106247208-1208080116 is on topic list
2022-04-02 09:42:49 [main] [32mINFO [m [TopicST:456] Checking topic my-topic-106247208-1208080116 in Kafka
2022-04-02 09:42:52 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace topic-st exec topic-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-02 09:42:52 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 09:42:52 [main] [32mINFO [m [KafkaTopicUtils:78] Waiting for KafkaTopic my-topic-106247208-1208080116 creation 
2022-04-02 09:44:29 [main] [32mINFO [m [TopicST:353] Topic successfully created
2022-04-02 09:44:29 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 09:44:29 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSendingMessagesToNonExistingTopic
2022-04-02 09:44:29 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment topic-cluster-name-kafka-clients in namespace topic-st
2022-04-02 09:45:09 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 09:45:09 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.topic.TopicST.testSendingMessagesToNonExistingTopic-FINISHED
2022-04-02 09:45:09 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 09:45:09 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 09:45:09 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.topic.TopicST.testMoreReplicasThanAvailableBrokers-STARTED
2022-04-02 09:45:09 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 09:45:09 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-956215997-2052156598 in namespace topic-st
2022-04-02 09:45:09 [main] [32mINFO [m [TopicST:461] Checking in KafkaTopic CR that topic my-topic-956215997-2052156598 exists
2022-04-02 09:45:09 [main] [32mINFO [m [TopicST:456] Checking topic my-topic-956215997-2052156598 in Kafka
2022-04-02 09:45:12 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace topic-st exec topic-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-02 09:45:12 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 09:45:12 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-956215997-2052156598 will have desired state: NotReady
2022-04-02 09:45:12 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-956215997-2052156598 is in desired state: NotReady
2022-04-02 09:45:12 [main] [32mINFO [m [TopicST:90] Delete topic my-topic-956215997-2052156598
2022-04-02 09:45:12 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic my-topic-956215997-2052156598 deletion
2022-04-02 09:45:12 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic topic-example-new in namespace topic-st
2022-04-02 09:45:12 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: topic-example-new will have desired state: Ready
2022-04-02 09:45:14 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: topic-example-new is in desired state: Ready
2022-04-02 09:45:14 [main] [32mINFO [m [TopicST:456] Checking topic topic-example-new in Kafka
2022-04-02 09:45:17 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace topic-st exec topic-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-02 09:45:17 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 09:45:17 [main] [32mINFO [m [TopicST:461] Checking in KafkaTopic CR that topic topic-example-new exists
2022-04-02 09:45:17 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 09:45:17 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMoreReplicasThanAvailableBrokers
2022-04-02 09:45:17 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic topic-example-new in namespace topic-st
2022-04-02 09:45:17 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-956215997-2052156598 in namespace topic-st
2022-04-02 09:45:17 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 09:45:17 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.topic.TopicST.testMoreReplicasThanAvailableBrokers-FINISHED
2022-04-02 09:45:17 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 09:45:17 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 09:45:17 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.topic.TopicST.testCreateTopicViaKafka-STARTED
2022-04-02 09:45:17 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 09:45:20 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace topic-st exec topic-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --bootstrap-server localhost:9092 --create  --topic my-topic-1379952968-159895039 --replication-factor 3 --partitions 3
2022-04-02 09:45:20 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 09:45:20 [main] [32mINFO [m [KafkaTopicUtils:78] Waiting for KafkaTopic my-topic-1379952968-159895039 creation 
2022-04-02 09:45:21 [main] [32mINFO [m [TopicST:482] Checking in KafkaTopic CR that topic my-topic-1379952968-159895039 was created with expected settings
2022-04-02 09:45:23 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace topic-st exec topic-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-02 09:45:23 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 09:45:23 [main] [32mINFO [m [TopicST:121] Editing topic via Kafka, settings to partitions 5
2022-04-02 09:45:26 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace topic-st exec topic-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --bootstrap-server localhost:9092 --alter --topic my-topic-1379952968-159895039 --partitions 5
2022-04-02 09:45:26 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 09:45:26 [main] [32mINFO [m [KafkaTopicUtils:124] Waiting for KafkaTopic change my-topic-1379952968-159895039
2022-04-02 09:45:29 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace topic-st exec topic-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic my-topic-1379952968-159895039
2022-04-02 09:45:29 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 09:45:29 [main] [32mINFO [m [TopicST:470] Checking topic my-topic-1379952968-159895039 in Kafka topic-cluster-name
2022-04-02 09:45:29 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 09:45:29 [main] [32mINFO [m [ResourceManager:346] In context testCreateTopicViaKafka is everything deleted.
2022-04-02 09:45:29 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 09:45:29 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.topic.TopicST.testCreateTopicViaKafka-FINISHED
2022-04-02 09:45:29 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 09:45:29 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 09:45:29 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.topic.TopicST.testCreateTopicAfterUnsupportedOperation-STARTED
2022-04-02 09:45:29 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 09:45:29 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic topic-with-replication-to-change in namespace topic-st
2022-04-02 09:45:29 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: topic-with-replication-to-change will have desired state: Ready
2022-04-02 09:45:30 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: topic-with-replication-to-change is in desired state: Ready
2022-04-02 09:45:30 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: topic-with-replication-to-change will have desired state: NotReady
2022-04-02 09:45:31 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: topic-with-replication-to-change is in desired state: NotReady
2022-04-02 09:45:31 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic another-topic in namespace topic-st
2022-04-02 09:45:31 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: another-topic will have desired state: Ready
2022-04-02 09:45:32 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: another-topic is in desired state: Ready
2022-04-02 09:45:32 [main] [32mINFO [m [TopicST:456] Checking topic topic-with-replication-to-change in Kafka
2022-04-02 09:45:35 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace topic-st exec topic-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-02 09:45:35 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 09:45:35 [main] [32mINFO [m [TopicST:461] Checking in KafkaTopic CR that topic topic-with-replication-to-change exists
2022-04-02 09:45:35 [main] [32mINFO [m [TopicST:456] Checking topic another-topic in Kafka
2022-04-02 09:45:37 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace topic-st exec topic-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-02 09:45:37 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 09:45:37 [main] [32mINFO [m [TopicST:461] Checking in KafkaTopic CR that topic another-topic exists
2022-04-02 09:45:37 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic topic-with-replication-to-change deletion
2022-04-02 09:45:37 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic another-topic deletion
2022-04-02 09:45:37 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 09:45:37 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCreateTopicAfterUnsupportedOperation
2022-04-02 09:45:37 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic another-topic in namespace topic-st
2022-04-02 09:45:37 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic topic-with-replication-to-change in namespace topic-st
2022-04-02 09:45:37 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 09:45:37 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.topic.TopicST.testCreateTopicAfterUnsupportedOperation-FINISHED
2022-04-02 09:45:37 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 09:45:37 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 09:45:37 [main] [32mINFO [m [ResourceManager:348] Delete all resources for TopicST
2022-04-02 09:45:37 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka topic-cluster-name in namespace topic-st
2022-04-02 09:45:47 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 785.611 s - in io.strimzi.systemtest.operators.topic.TopicST
[[1;34mINFO[m] Running io.strimzi.systemtest.operators.ReconciliationST
2022-04-02 09:46:32 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: reconciliation-st
2022-04-02 09:46:32 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: reconciliation-st
2022-04-02 09:46:32 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: reconciliation-st
2022-04-02 09:46:32 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 09:46:32 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.ReconciliationST.testPauseReconciliationInKafkaAndKafkaConnectWithConnector-STARTED
2022-04-02 09:46:32 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 09:46:32 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-2 for test case:testPauseReconciliationInKafkaAndKafkaConnectWithConnector
2022-04-02 09:46:32 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-2
2022-04-02 09:46:32 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-2
2022-04-02 09:46:32 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-2
2022-04-02 09:46:32 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-4855cf13 in namespace namespace-2
2022-04-02 09:46:32 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-2
2022-04-02 09:46:32 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-4855cf13 will have desired state: Ready
2022-04-02 09:48:13 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-4855cf13 is in desired state: Ready
2022-04-02 09:48:13 [main] [32mINFO [m [ReconciliationST:80] Adding pause annotation into Kafka resource and also scaling replicas to 4, new pod should not appear
2022-04-02 09:48:13 [main] [32mINFO [m [ReconciliationST:86] Kafka should contain status with ReconciliationPaused
2022-04-02 09:48:13 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-4855cf13 will have desired state: ReconciliationPaused
2022-04-02 09:48:15 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-4855cf13 is in desired state: ReconciliationPaused
2022-04-02 09:48:15 [main] [32mINFO [m [PodUtils:209] Wait until Pod my-cluster-4855cf13-kafka will have stable 3 replicas
2022-04-02 09:48:15 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 19 polls
2022-04-02 09:48:16 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 18 polls
2022-04-02 09:48:17 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 17 polls
2022-04-02 09:48:18 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 16 polls
2022-04-02 09:48:19 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 15 polls
2022-04-02 09:48:20 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 14 polls
2022-04-02 09:48:21 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 13 polls
2022-04-02 09:48:22 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 12 polls
2022-04-02 09:48:23 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 11 polls
2022-04-02 09:48:24 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 10 polls
2022-04-02 09:48:25 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 9 polls
2022-04-02 09:48:26 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 8 polls
2022-04-02 09:48:27 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 7 polls
2022-04-02 09:48:28 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 6 polls
2022-04-02 09:48:29 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 5 polls
2022-04-02 09:48:30 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 4 polls
2022-04-02 09:48:31 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 3 polls
2022-04-02 09:48:32 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 2 polls
2022-04-02 09:48:33 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 1 polls
2022-04-02 09:48:34 [main] [32mINFO [m [PodUtils:217] Pod replicas are stable for 20 polls intervals
2022-04-02 09:48:34 [main] [32mINFO [m [PodUtils:228] Pod my-cluster-4855cf13-kafka has 3 replicas
2022-04-02 09:48:34 [main] [32mINFO [m [ReconciliationST:90] Setting annotation to "false", Kafka should be scaled to 4
2022-04-02 09:48:34 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 4 Pod(s) of my-cluster-4855cf13-kafka to be ready
2022-04-02 09:50:40 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-4855cf13 will have desired state: Ready
2022-04-02 09:50:40 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-4855cf13 is in desired state: Ready
2022-04-02 09:50:40 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-4855cf13 is ready
2022-04-02 09:50:40 [main] [32mINFO [m [ReconciliationST:94] Deploying KafkaConnect with pause annotation from the start, no pods should appear
2022-04-02 09:50:40 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-4855cf13-kafka-clients in namespace namespace-2
2022-04-02 09:50:40 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-2
2022-04-02 09:50:40 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-4855cf13-kafka-clients will be ready
2022-04-02 09:50:41 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-4855cf13-kafka-clients is ready
2022-04-02 09:50:41 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-4855cf13-scraper in namespace namespace-2
2022-04-02 09:50:41 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-2
2022-04-02 09:50:41 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-4855cf13-scraper will be ready
2022-04-02 09:50:42 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-4855cf13-scraper is ready
2022-04-02 09:50:42 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-4855cf13-scraper to be ready
2022-04-02 09:50:52 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-4855cf13-scraper is ready
2022-04-02 09:50:52 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-4855cf13-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-02 09:50:52 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-4855cf13-allow in namespace namespace-2
2022-04-02 09:50:52 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-2
2022-04-02 09:50:52 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-02 09:50:52 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-4855cf13 in namespace namespace-2
2022-04-02 09:50:52 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-2
2022-04-02 09:50:52 [main] [33mWARN [m [VersionUsageUtils:60] The client is using resource type 'kafkaconnects' with unstable version 'v1beta2'
2022-04-02 09:50:52 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-4855cf13 will have desired state: ReconciliationPaused
2022-04-02 09:50:53 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-4855cf13 is in desired state: ReconciliationPaused
2022-04-02 09:50:53 [main] [32mINFO [m [PodUtils:209] Wait until Pod my-cluster-4855cf13-connect will have stable 0 replicas
2022-04-02 09:50:53 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 19 polls
2022-04-02 09:50:54 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 18 polls
2022-04-02 09:50:55 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 17 polls
2022-04-02 09:50:56 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 16 polls
2022-04-02 09:50:57 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 15 polls
2022-04-02 09:50:58 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 14 polls
2022-04-02 09:50:59 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 13 polls
2022-04-02 09:51:00 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 12 polls
2022-04-02 09:51:01 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 11 polls
2022-04-02 09:51:02 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 10 polls
2022-04-02 09:51:03 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 9 polls
2022-04-02 09:51:04 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 8 polls
2022-04-02 09:51:05 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 7 polls
2022-04-02 09:51:06 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 6 polls
2022-04-02 09:51:07 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 5 polls
2022-04-02 09:51:08 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 4 polls
2022-04-02 09:51:09 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 3 polls
2022-04-02 09:51:10 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 2 polls
2022-04-02 09:51:11 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 1 polls
2022-04-02 09:51:12 [main] [32mINFO [m [PodUtils:217] Pod replicas are stable for 20 polls intervals
2022-04-02 09:51:12 [main] [32mINFO [m [PodUtils:228] Pod my-cluster-4855cf13-connect has 0 replicas
2022-04-02 09:51:12 [main] [32mINFO [m [ReconciliationST:108] Setting annotation to "false" and creating KafkaConnector
2022-04-02 09:51:12 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-4855cf13-connect will be ready
2022-04-02 09:52:15 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-4855cf13-connect is ready
2022-04-02 09:52:15 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-4855cf13-connect to be ready
2022-04-02 09:52:26 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-4855cf13-connect is ready
2022-04-02 09:52:26 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-4855cf13 in namespace namespace-2
2022-04-02 09:52:26 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-2
2022-04-02 09:52:26 [main] [33mWARN [m [VersionUsageUtils:60] The client is using resource type 'kafkaconnectors' with unstable version 'v1beta2'
2022-04-02 09:52:26 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-4855cf13 will have desired state: Ready
2022-04-02 09:52:27 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-4855cf13 is in desired state: Ready
2022-04-02 09:52:27 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-4855cf13-connect-7bd6c754cd-dvmw8 -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-4855cf13
2022-04-02 09:52:27 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 09:52:27 [main] [32mINFO [m [ReconciliationST:118] Adding pause annotation into the KafkaConnector and scaling taskMax to 4
2022-04-02 09:52:27 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-4855cf13 will have desired state: ReconciliationPaused
2022-04-02 09:52:28 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-4855cf13 is in desired state: ReconciliationPaused
2022-04-02 09:52:28 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-4855cf13-connect-7bd6c754cd-dvmw8 -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-4855cf13
2022-04-02 09:52:28 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 09:52:28 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 19 polls
2022-04-02 09:52:29 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-4855cf13-connect-7bd6c754cd-dvmw8 -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-4855cf13
2022-04-02 09:52:29 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 09:52:29 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 18 polls
2022-04-02 09:52:30 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-4855cf13-connect-7bd6c754cd-dvmw8 -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-4855cf13
2022-04-02 09:52:30 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 09:52:30 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 17 polls
2022-04-02 09:52:32 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-4855cf13-connect-7bd6c754cd-dvmw8 -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-4855cf13
2022-04-02 09:52:32 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 09:52:32 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 16 polls
2022-04-02 09:52:33 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-4855cf13-connect-7bd6c754cd-dvmw8 -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-4855cf13
2022-04-02 09:52:33 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 09:52:33 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 15 polls
2022-04-02 09:52:34 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-4855cf13-connect-7bd6c754cd-dvmw8 -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-4855cf13
2022-04-02 09:52:34 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 09:52:34 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 14 polls
2022-04-02 09:52:35 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-4855cf13-connect-7bd6c754cd-dvmw8 -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-4855cf13
2022-04-02 09:52:35 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 09:52:35 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 13 polls
2022-04-02 09:52:36 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-4855cf13-connect-7bd6c754cd-dvmw8 -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-4855cf13
2022-04-02 09:52:36 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 09:52:36 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 12 polls
2022-04-02 09:52:38 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-4855cf13-connect-7bd6c754cd-dvmw8 -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-4855cf13
2022-04-02 09:52:38 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 09:52:38 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 11 polls
2022-04-02 09:52:39 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-4855cf13-connect-7bd6c754cd-dvmw8 -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-4855cf13
2022-04-02 09:52:39 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 09:52:39 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 10 polls
2022-04-02 09:52:40 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-4855cf13-connect-7bd6c754cd-dvmw8 -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-4855cf13
2022-04-02 09:52:40 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 09:52:40 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 9 polls
2022-04-02 09:52:41 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-4855cf13-connect-7bd6c754cd-dvmw8 -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-4855cf13
2022-04-02 09:52:41 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 09:52:41 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 8 polls
2022-04-02 09:52:43 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-4855cf13-connect-7bd6c754cd-dvmw8 -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-4855cf13
2022-04-02 09:52:43 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 09:52:43 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 7 polls
2022-04-02 09:52:44 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-4855cf13-connect-7bd6c754cd-dvmw8 -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-4855cf13
2022-04-02 09:52:44 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 09:52:44 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 6 polls
2022-04-02 09:52:45 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-4855cf13-connect-7bd6c754cd-dvmw8 -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-4855cf13
2022-04-02 09:52:45 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 09:52:45 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 5 polls
2022-04-02 09:52:46 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-4855cf13-connect-7bd6c754cd-dvmw8 -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-4855cf13
2022-04-02 09:52:46 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 09:52:46 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 4 polls
2022-04-02 09:52:47 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-4855cf13-connect-7bd6c754cd-dvmw8 -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-4855cf13
2022-04-02 09:52:47 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 09:52:47 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 3 polls
2022-04-02 09:52:49 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-4855cf13-connect-7bd6c754cd-dvmw8 -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-4855cf13
2022-04-02 09:52:49 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 09:52:49 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 2 polls
2022-04-02 09:52:50 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-4855cf13-connect-7bd6c754cd-dvmw8 -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-4855cf13
2022-04-02 09:52:50 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 09:52:50 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 1 polls
2022-04-02 09:52:51 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-4855cf13-connect-7bd6c754cd-dvmw8 -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-4855cf13
2022-04-02 09:52:51 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 09:52:51 [main] [32mINFO [m [KafkaConnectorUtils:154] Connector's spec is stable for 20 polls intervals
2022-04-02 09:52:51 [main] [32mINFO [m [ReconciliationST:127] Setting annotation to "false", taskMax should be increased to 4
2022-04-02 09:52:51 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-4855cf13-connect-7bd6c754cd-dvmw8 -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-4855cf13/config
2022-04-02 09:52:51 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 09:52:51 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-4855cf13-connect-7bd6c754cd-dvmw8 -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-4855cf13/config
2022-04-02 09:52:51 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 09:52:51 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 09:52:51 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testPauseReconciliationInKafkaAndKafkaConnectWithConnector
2022-04-02 09:52:51 [main] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-4855cf13-allow in namespace namespace-2
2022-04-02 09:52:51 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-4855cf13 in namespace namespace-2
2022-04-02 09:52:51 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-4855cf13 in namespace namespace-2
2022-04-02 09:52:51 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-4855cf13 in namespace namespace-2
2022-04-02 09:52:51 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-4855cf13-scraper in namespace namespace-2
2022-04-02 09:52:51 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-4855cf13-kafka-clients in namespace namespace-2
2022-04-02 09:53:41 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 09:53:41 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-2 for test case:testPauseReconciliationInKafkaAndKafkaConnectWithConnector
2022-04-02 09:53:48 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.ReconciliationST.testPauseReconciliationInKafkaAndKafkaConnectWithConnector-FINISHED
2022-04-02 09:53:48 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 09:53:48 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 09:53:48 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.ReconciliationST.testPauseReconciliationInKafkaRebalanceAndTopic-STARTED
2022-04-02 09:53:48 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 09:53:48 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-3 for test case:testPauseReconciliationInKafkaRebalanceAndTopic
2022-04-02 09:53:48 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-3
2022-04-02 09:53:48 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-3
2022-04-02 09:53:48 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-3
2022-04-02 09:53:48 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-185223ef in namespace namespace-3
2022-04-02 09:53:48 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-3
2022-04-02 09:53:48 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-185223ef will have desired state: Ready
2022-04-02 09:55:27 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-185223ef is in desired state: Ready
2022-04-02 09:55:27 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1855060972-2087596290 in namespace namespace-3
2022-04-02 09:55:27 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-3
2022-04-02 09:55:27 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1855060972-2087596290 will have desired state: Ready
2022-04-02 09:55:28 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1855060972-2087596290 is in desired state: Ready
2022-04-02 09:55:28 [main] [32mINFO [m [ReconciliationST:147] Adding pause annotation into KafkaTopic resource and changing replication factor
2022-04-02 09:55:28 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1855060972-2087596290 will have desired state: ReconciliationPaused
2022-04-02 09:55:29 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1855060972-2087596290 is in desired state: ReconciliationPaused
2022-04-02 09:55:35 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-185223ef-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-1855060972-2087596290 --describe --bootstrap-server my-cluster-185223ef-kafka-bootstrap:9092
2022-04-02 09:55:35 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 09:55:38 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-185223ef-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-1855060972-2087596290 --describe --bootstrap-server my-cluster-185223ef-kafka-bootstrap:9092
2022-04-02 09:55:38 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 09:55:38 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 19 polls
2022-04-02 09:55:42 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-185223ef-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-1855060972-2087596290 --describe --bootstrap-server my-cluster-185223ef-kafka-bootstrap:9092
2022-04-02 09:55:42 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 09:55:42 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 18 polls
2022-04-02 09:55:45 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-185223ef-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-1855060972-2087596290 --describe --bootstrap-server my-cluster-185223ef-kafka-bootstrap:9092
2022-04-02 09:55:45 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 09:55:45 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 17 polls
2022-04-02 09:55:49 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-185223ef-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-1855060972-2087596290 --describe --bootstrap-server my-cluster-185223ef-kafka-bootstrap:9092
2022-04-02 09:55:49 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 09:55:49 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 16 polls
2022-04-02 09:55:54 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-185223ef-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-1855060972-2087596290 --describe --bootstrap-server my-cluster-185223ef-kafka-bootstrap:9092
2022-04-02 09:55:54 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 09:55:54 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 15 polls
2022-04-02 09:55:58 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-185223ef-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-1855060972-2087596290 --describe --bootstrap-server my-cluster-185223ef-kafka-bootstrap:9092
2022-04-02 09:55:58 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 09:55:58 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 14 polls
2022-04-02 09:56:16 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-185223ef-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-1855060972-2087596290 --describe --bootstrap-server my-cluster-185223ef-kafka-bootstrap:9092
2022-04-02 09:56:16 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 09:56:16 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 13 polls
2022-04-02 09:56:20 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-185223ef-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-1855060972-2087596290 --describe --bootstrap-server my-cluster-185223ef-kafka-bootstrap:9092
2022-04-02 09:56:20 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 09:56:20 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 12 polls
2022-04-02 09:56:35 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-185223ef-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-1855060972-2087596290 --describe --bootstrap-server my-cluster-185223ef-kafka-bootstrap:9092
2022-04-02 09:56:35 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 09:56:35 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 11 polls
2022-04-02 09:56:39 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-185223ef-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-1855060972-2087596290 --describe --bootstrap-server my-cluster-185223ef-kafka-bootstrap:9092
2022-04-02 09:56:39 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 09:56:39 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 10 polls
2022-04-02 09:56:52 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-185223ef-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-1855060972-2087596290 --describe --bootstrap-server my-cluster-185223ef-kafka-bootstrap:9092
2022-04-02 09:56:52 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 09:56:52 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 9 polls
2022-04-02 09:56:55 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-185223ef-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-1855060972-2087596290 --describe --bootstrap-server my-cluster-185223ef-kafka-bootstrap:9092
2022-04-02 09:56:55 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 09:56:55 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 8 polls
2022-04-02 09:56:59 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-185223ef-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-1855060972-2087596290 --describe --bootstrap-server my-cluster-185223ef-kafka-bootstrap:9092
2022-04-02 09:56:59 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 09:56:59 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 7 polls
2022-04-02 09:57:06 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-185223ef-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-1855060972-2087596290 --describe --bootstrap-server my-cluster-185223ef-kafka-bootstrap:9092
2022-04-02 09:57:06 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 09:57:06 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 6 polls
2022-04-02 09:57:10 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-185223ef-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-1855060972-2087596290 --describe --bootstrap-server my-cluster-185223ef-kafka-bootstrap:9092
2022-04-02 09:57:10 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 09:57:10 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 5 polls
2022-04-02 09:57:15 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-185223ef-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-1855060972-2087596290 --describe --bootstrap-server my-cluster-185223ef-kafka-bootstrap:9092
2022-04-02 09:57:15 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 09:57:15 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 4 polls
2022-04-02 09:57:18 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-185223ef-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-1855060972-2087596290 --describe --bootstrap-server my-cluster-185223ef-kafka-bootstrap:9092
2022-04-02 09:57:18 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 09:57:18 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 3 polls
2022-04-02 09:57:22 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-185223ef-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-1855060972-2087596290 --describe --bootstrap-server my-cluster-185223ef-kafka-bootstrap:9092
2022-04-02 09:57:22 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 09:57:22 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 2 polls
2022-04-02 09:57:29 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-185223ef-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-1855060972-2087596290 --describe --bootstrap-server my-cluster-185223ef-kafka-bootstrap:9092
2022-04-02 09:57:29 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 09:57:29 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 1 polls
2022-04-02 09:57:33 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-185223ef-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-1855060972-2087596290 --describe --bootstrap-server my-cluster-185223ef-kafka-bootstrap:9092
2022-04-02 09:57:33 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 09:57:33 [main] [32mINFO [m [KafkaTopicUtils:197] KafkaTopic's spec is stable for 20 polls intervals
2022-04-02 09:57:33 [main] [32mINFO [m [ReconciliationST:156] Setting annotation to "false", partitions should be scaled to 4
2022-04-02 09:57:33 [main] [32mINFO [m [KafkaTopicUtils:124] Waiting for KafkaTopic change my-topic-1855060972-2087596290
2022-04-02 09:57:33 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaRebalance my-cluster-185223ef in namespace namespace-3
2022-04-02 09:57:33 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-3
2022-04-02 09:57:33 [main] [33mWARN [m [VersionUsageUtils:60] The client is using resource type 'kafkarebalances' with unstable version 'v1beta2'
2022-04-02 09:57:33 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-185223ef will have desired state: PendingProposal
2022-04-02 09:57:34 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-185223ef is in desired state: PendingProposal
2022-04-02 09:57:34 [main] [32mINFO [m [ReconciliationST:164] Waiting for ProposalReady, then add pause and rebalance annotation, rebalancing should not be triggered
2022-04-02 09:57:34 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-185223ef will have desired state: ProposalReady
2022-04-02 10:01:18 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-185223ef is in desired state: ProposalReady
2022-04-02 10:01:18 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-185223ef will have desired state: ReconciliationPaused
2022-04-02 10:01:19 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-185223ef is in desired state: ReconciliationPaused
2022-04-02 10:01:19 [main] [32mINFO [m [KafkaRebalanceUtils:63] Reconciliation #1(test) KafkaRebalance(namespace-3/my-cluster-185223ef): Annotating KafkaRebalance:my-cluster-185223ef with annotation approve
2022-04-02 10:01:19 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-185223ef): KafkaRebalance status gonna be stable in 19 polls
2022-04-02 10:01:20 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-185223ef): KafkaRebalance status gonna be stable in 18 polls
2022-04-02 10:01:21 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-185223ef): KafkaRebalance status gonna be stable in 17 polls
2022-04-02 10:01:22 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-185223ef): KafkaRebalance status gonna be stable in 16 polls
2022-04-02 10:01:23 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-185223ef): KafkaRebalance status gonna be stable in 15 polls
2022-04-02 10:01:24 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-185223ef): KafkaRebalance status gonna be stable in 14 polls
2022-04-02 10:01:25 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-185223ef): KafkaRebalance status gonna be stable in 13 polls
2022-04-02 10:01:26 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-185223ef): KafkaRebalance status gonna be stable in 12 polls
2022-04-02 10:01:27 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-185223ef): KafkaRebalance status gonna be stable in 11 polls
2022-04-02 10:01:28 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-185223ef): KafkaRebalance status gonna be stable in 10 polls
2022-04-02 10:01:29 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-185223ef): KafkaRebalance status gonna be stable in 9 polls
2022-04-02 10:01:30 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-185223ef): KafkaRebalance status gonna be stable in 8 polls
2022-04-02 10:01:31 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-185223ef): KafkaRebalance status gonna be stable in 7 polls
2022-04-02 10:01:32 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-185223ef): KafkaRebalance status gonna be stable in 6 polls
2022-04-02 10:01:33 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-185223ef): KafkaRebalance status gonna be stable in 5 polls
2022-04-02 10:01:34 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-185223ef): KafkaRebalance status gonna be stable in 4 polls
2022-04-02 10:01:35 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-185223ef): KafkaRebalance status gonna be stable in 3 polls
2022-04-02 10:01:36 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-185223ef): KafkaRebalance status gonna be stable in 2 polls
2022-04-02 10:01:37 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-185223ef): KafkaRebalance status gonna be stable in 1 polls
2022-04-02 10:01:39 [main] [32mINFO [m [KafkaRebalanceUtils:118] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-185223ef): KafkaRebalance status is stable for 20 polls intervals
2022-04-02 10:01:39 [main] [32mINFO [m [ReconciliationST:178] Setting annotation to "false" and waiting for KafkaRebalance to be in Ready state
2022-04-02 10:01:39 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-185223ef will have desired state: ProposalReady
2022-04-02 10:01:40 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-185223ef is in desired state: ProposalReady
2022-04-02 10:01:40 [main] [32mINFO [m [KafkaRebalanceUtils:63] Reconciliation #3(test) KafkaRebalance(namespace-3/my-cluster-185223ef): Annotating KafkaRebalance:my-cluster-185223ef with annotation approve
2022-04-02 10:01:40 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-185223ef will have desired state: Ready
2022-04-02 10:03:05 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-185223ef is in desired state: Ready
2022-04-02 10:03:05 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 10:03:05 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testPauseReconciliationInKafkaRebalanceAndTopic
2022-04-02 10:03:05 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1855060972-2087596290 in namespace namespace-3
2022-04-02 10:03:05 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-185223ef in namespace namespace-3
2022-04-02 10:03:05 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaRebalance my-cluster-185223ef in namespace namespace-3
2022-04-02 10:03:05 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-3, for cruise control Kafka cluster my-cluster-185223ef
2022-04-02 10:03:15 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 10:03:15 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-3 for test case:testPauseReconciliationInKafkaRebalanceAndTopic
2022-04-02 10:03:58 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.ReconciliationST.testPauseReconciliationInKafkaRebalanceAndTopic-FINISHED
2022-04-02 10:03:58 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 10:03:58 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 10:03:58 [main] [32mINFO [m [ResourceManager:346] In context ReconciliationST is everything deleted.
2022-04-02 10:03:58 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1,052.039 s - in io.strimzi.systemtest.operators.ReconciliationST
[[1;34mINFO[m] Running io.strimzi.systemtest.bridge.HttpBridgeScramShaST
2022-04-02 10:04:04 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: http-bridge-scram-sha-st
2022-04-02 10:04:04 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: http-bridge-scram-sha-st
2022-04-02 10:04:04 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: http-bridge-scram-sha-st
2022-04-02 10:04:04 [main] [32mINFO [m [HttpBridgeScramShaST:123] Deploy Kafka and KafkaBridge before tests
2022-04-02 10:04:04 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka http-bridge-scram-sha-cluster-name in namespace http-bridge-scram-sha-st
2022-04-02 10:04:04 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: http-bridge-scram-sha-cluster-name will have desired state: Ready
2022-04-02 10:05:10 [main] [32mINFO [m [ResourceManager:444] Kafka: http-bridge-scram-sha-cluster-name is in desired state: Ready
2022-04-02 10:05:10 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-747685068-1146249779 in namespace http-bridge-scram-sha-st
2022-04-02 10:05:10 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-747685068-1146249779 will have desired state: Ready
2022-04-02 10:05:11 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-747685068-1146249779 is in desired state: Ready
2022-04-02 10:05:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment http-bridge-scram-sha-st-shared-kafka-clients in namespace http-bridge-scram-sha-st
2022-04-02 10:05:11 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: http-bridge-scram-sha-st-shared-kafka-clients will be ready
2022-04-02 10:05:12 [main] [32mINFO [m [DeploymentUtils:168] Deployment: http-bridge-scram-sha-st-shared-kafka-clients is ready
2022-04-02 10:05:12 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge http-bridge-scram-sha-cluster-name in namespace http-bridge-scram-sha-st
2022-04-02 10:05:12 [main] [33mWARN [m [VersionUsageUtils:60] The client is using resource type 'kafkabridges' with unstable version 'v1beta2'
2022-04-02 10:05:12 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: http-bridge-scram-sha-cluster-name will have desired state: Ready
2022-04-02 10:05:31 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: http-bridge-scram-sha-cluster-name is in desired state: Ready
2022-04-02 10:05:31 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-02 10:05:31 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 10:05:31 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeScramShaST.testSendSimpleMessageTlsScramSha-STARTED
2022-04-02 10:05:31 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 10:05:31 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-76715511-1719941989 in namespace http-bridge-scram-sha-st
2022-04-02 10:05:31 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-76715511-1719941989 will have desired state: Ready
2022-04-02 10:05:32 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-76715511-1719941989 is in desired state: Ready
2022-04-02 10:05:32 [main] [32mINFO [m [ResourceManager:155] Create/Update Job producer-1082898019 in namespace http-bridge-scram-sha-st
2022-04-02 10:05:32 [main] [32mINFO [m [JobUtils:81] Waiting for job: producer-1082898019 will be in active state
2022-04-02 10:05:33 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:producer-1082898019 to finished
2022-04-02 10:05:42 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-02 10:05:42 [main] [32mINFO [m [ResourceManager:155] Create/Update Job consumer-112532083 in namespace http-bridge-scram-sha-st
2022-04-02 10:05:42 [main] [32mINFO [m [JobUtils:81] Waiting for job: consumer-112532083 will be in active state
2022-04-02 10:05:43 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:consumer-112532083 to finished
2022-04-02 10:05:54 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 10:05:54 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSendSimpleMessageTlsScramSha
2022-04-02 10:05:54 [main] [32mINFO [m [ResourceManager:241] Delete of Job producer-1082898019 in namespace http-bridge-scram-sha-st
2022-04-02 10:05:54 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Job consumer-112532083 in namespace http-bridge-scram-sha-st
2022-04-02 10:05:54 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-76715511-1719941989 in namespace http-bridge-scram-sha-st
2022-04-02 10:06:04 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 10:06:04 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeScramShaST.testSendSimpleMessageTlsScramSha-FINISHED
2022-04-02 10:06:04 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 10:06:04 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 10:06:04 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeScramShaST.testReceiveSimpleMessageTlsScramSha-STARTED
2022-04-02 10:06:04 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 10:06:04 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-467311057-683530871 in namespace http-bridge-scram-sha-st
2022-04-02 10:06:04 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-467311057-683530871 will have desired state: Ready
2022-04-02 10:06:05 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-467311057-683530871 is in desired state: Ready
2022-04-02 10:06:05 [main] [32mINFO [m [ResourceManager:155] Create/Update Job consumer-383292724 in namespace http-bridge-scram-sha-st
2022-04-02 10:06:05 [main] [32mINFO [m [JobUtils:81] Waiting for job: consumer-383292724 will be in active state
2022-04-02 10:06:06 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-02 10:06:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Job producer-129094221 in namespace http-bridge-scram-sha-st
2022-04-02 10:06:06 [main] [32mINFO [m [JobUtils:81] Waiting for job: producer-129094221 will be in active state
2022-04-02 10:06:07 [main] [32mINFO [m [ClientUtils:61] Waiting till producer producer-129094221 and consumer consumer-383292724 finish
2022-04-02 10:06:22 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 10:06:22 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testReceiveSimpleMessageTlsScramSha
2022-04-02 10:06:22 [main] [32mINFO [m [ResourceManager:241] Delete of Job consumer-383292724 in namespace http-bridge-scram-sha-st
2022-04-02 10:06:22 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-467311057-683530871 in namespace http-bridge-scram-sha-st
2022-04-02 10:06:22 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Job producer-129094221 in namespace http-bridge-scram-sha-st
2022-04-02 10:06:32 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 10:06:32 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeScramShaST.testReceiveSimpleMessageTlsScramSha-FINISHED
2022-04-02 10:06:32 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 10:06:32 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 10:06:32 [main] [32mINFO [m [ResourceManager:348] Delete all resources for HttpBridgeScramShaST
2022-04-02 10:06:32 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment http-bridge-scram-sha-st-shared-kafka-clients in namespace http-bridge-scram-sha-st
2022-04-02 10:06:32 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge http-bridge-scram-sha-cluster-name in namespace http-bridge-scram-sha-st
2022-04-02 10:06:32 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-747685068-1146249779 in namespace http-bridge-scram-sha-st
2022-04-02 10:06:32 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka http-bridge-scram-sha-cluster-name in namespace http-bridge-scram-sha-st
2022-04-02 10:07:12 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 194.249 s - in io.strimzi.systemtest.bridge.HttpBridgeScramShaST
[[1;34mINFO[m] Running io.strimzi.systemtest.bridge.HttpBridgeTlsST
2022-04-02 10:07:18 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: http-bridge-tls-st
2022-04-02 10:07:18 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: http-bridge-tls-st
2022-04-02 10:07:18 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: http-bridge-tls-st
2022-04-02 10:07:18 [main] [32mINFO [m [HttpBridgeTlsST:129] Deploy Kafka and KafkaBridge before tests
2022-04-02 10:07:18 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka http-bridge-tls-cluster-name in namespace http-bridge-tls-st
2022-04-02 10:07:18 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: http-bridge-tls-cluster-name will have desired state: Ready
2022-04-02 10:08:23 [main] [32mINFO [m [ResourceManager:444] Kafka: http-bridge-tls-cluster-name is in desired state: Ready
2022-04-02 10:08:23 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-937644450-1579103840 in namespace http-bridge-tls-st
2022-04-02 10:08:23 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-937644450-1579103840 will have desired state: Ready
2022-04-02 10:08:24 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-937644450-1579103840 is in desired state: Ready
2022-04-02 10:08:24 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment http-bridge-tls-st-kafka-clients in namespace http-bridge-tls-st
2022-04-02 10:08:24 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: http-bridge-tls-st-kafka-clients will be ready
2022-04-02 10:08:26 [main] [32mINFO [m [DeploymentUtils:168] Deployment: http-bridge-tls-st-kafka-clients is ready
2022-04-02 10:08:26 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge http-bridge-tls-cluster-name in namespace http-bridge-tls-st
2022-04-02 10:08:26 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: http-bridge-tls-cluster-name will have desired state: Ready
2022-04-02 10:08:51 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: http-bridge-tls-cluster-name is in desired state: Ready
2022-04-02 10:08:51 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-02 10:08:51 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 10:08:51 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeTlsST.testReceiveSimpleMessageTls-STARTED
2022-04-02 10:08:51 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 10:08:51 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-716477747-1831407230 in namespace http-bridge-tls-st
2022-04-02 10:08:51 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-716477747-1831407230 will have desired state: Ready
2022-04-02 10:08:52 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-716477747-1831407230 is in desired state: Ready
2022-04-02 10:08:52 [main] [32mINFO [m [ResourceManager:155] Create/Update Job consumer-1680262520 in namespace http-bridge-tls-st
2022-04-02 10:08:52 [main] [32mINFO [m [JobUtils:81] Waiting for job: consumer-1680262520 will be in active state
2022-04-02 10:08:53 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-02 10:08:53 [main] [32mINFO [m [ResourceManager:155] Create/Update Job producer-832690256 in namespace http-bridge-tls-st
2022-04-02 10:08:53 [main] [32mINFO [m [JobUtils:81] Waiting for job: producer-832690256 will be in active state
2022-04-02 10:08:54 [main] [32mINFO [m [ClientUtils:61] Waiting till producer producer-832690256 and consumer consumer-1680262520 finish
2022-04-02 10:09:09 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 10:09:09 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testReceiveSimpleMessageTls
2022-04-02 10:09:09 [main] [32mINFO [m [ResourceManager:241] Delete of Job consumer-1680262520 in namespace http-bridge-tls-st
2022-04-02 10:09:09 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-716477747-1831407230 in namespace http-bridge-tls-st
2022-04-02 10:09:09 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job producer-832690256 in namespace http-bridge-tls-st
2022-04-02 10:09:19 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 10:09:19 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeTlsST.testReceiveSimpleMessageTls-FINISHED
2022-04-02 10:09:19 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 10:09:19 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 10:09:19 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeTlsST.testSendSimpleMessageTls-STARTED
2022-04-02 10:09:19 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 10:09:19 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-23125068-1802563835 in namespace http-bridge-tls-st
2022-04-02 10:09:19 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-23125068-1802563835 will have desired state: Ready
2022-04-02 10:09:20 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-23125068-1802563835 is in desired state: Ready
2022-04-02 10:09:20 [main] [32mINFO [m [ResourceManager:155] Create/Update Job producer-523148077 in namespace http-bridge-tls-st
2022-04-02 10:09:20 [main] [32mINFO [m [JobUtils:81] Waiting for job: producer-523148077 will be in active state
2022-04-02 10:09:21 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:producer-523148077 to finished
2022-04-02 10:09:30 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-02 10:09:30 [main] [32mINFO [m [ResourceManager:155] Create/Update Job consumer-862611506 in namespace http-bridge-tls-st
2022-04-02 10:09:30 [main] [32mINFO [m [JobUtils:81] Waiting for job: consumer-862611506 will be in active state
2022-04-02 10:09:31 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:consumer-862611506 to finished
2022-04-02 10:09:42 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 10:09:42 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSendSimpleMessageTls
2022-04-02 10:09:42 [main] [32mINFO [m [ResourceManager:241] Delete of Job producer-523148077 in namespace http-bridge-tls-st
2022-04-02 10:09:42 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-23125068-1802563835 in namespace http-bridge-tls-st
2022-04-02 10:09:42 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Job consumer-862611506 in namespace http-bridge-tls-st
2022-04-02 10:09:52 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 10:09:52 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeTlsST.testSendSimpleMessageTls-FINISHED
2022-04-02 10:09:52 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 10:09:52 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 10:09:52 [main] [32mINFO [m [ResourceManager:348] Delete all resources for HttpBridgeTlsST
2022-04-02 10:09:52 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment http-bridge-tls-st-kafka-clients in namespace http-bridge-tls-st
2022-04-02 10:09:52 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge http-bridge-tls-cluster-name in namespace http-bridge-tls-st
2022-04-02 10:09:52 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka http-bridge-tls-cluster-name in namespace http-bridge-tls-st
2022-04-02 10:09:52 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-937644450-1579103840 in namespace http-bridge-tls-st
2022-04-02 10:10:32 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 199.208 s - in io.strimzi.systemtest.bridge.HttpBridgeTlsST
[[1;34mINFO[m] Running io.strimzi.systemtest.tracing.TracingST
2022-04-02 10:10:37 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: tracing-st
2022-04-02 10:10:37 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: tracing-st
2022-04-02 10:10:37 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: tracing-st
2022-04-02 10:10:37 [main] [32mINFO [m [TracingST:497] === Applying jaeger operator install files ===
2022-04-02 10:10:37 [main] [32mINFO [m [TracingST:488] Creating jaeger-cluster-role-binding.yaml from /home/ec2-user/strimzi-kafka-operator/systemtest/../systemtest/src/test/resources/tracing/1.20/operator-files/jaeger-cluster-role-binding.yaml
2022-04-02 10:10:38 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st apply -f -
2022-04-02 10:10:38 [main] [32mINFO [m [Exec:417] Input: ---
kind: "ClusterRoleBinding"
apiVersion: "rbac.authorization.k8s.io/v1"
metadata:
  name: "jaeger-operator"
  namespace: "tracing-st"
subjects:
- kind: "ServiceAccount"
  name: "jaeger-operator"
  namespace: "tracing-st"
roleRef:
  kind: "ClusterRole"
  name: "jaeger-operator"
  apiGroup: "rbac.authorization.k8s.io"
2022-04-02 10:10:38 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 10:10:38 [main] [32mINFO [m [TracingST:488] Creating jaeger-cluster-role.yaml from /home/ec2-user/strimzi-kafka-operator/systemtest/../systemtest/src/test/resources/tracing/1.20/operator-files/jaeger-cluster-role.yaml
2022-04-02 10:10:38 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st apply -f -
2022-04-02 10:10:38 [main] [32mINFO [m [Exec:417] Input: ---
apiVersion: "rbac.authorization.k8s.io/v1"
kind: "ClusterRole"
metadata:
  name: "jaeger-operator"
  namespace: "tracing-st"
rules:
- apiGroups:
  - "jaegertracing.io"
  resources:
  - "*"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "apps"
  resourceNames:
  - "jaeger-operator"
  resources:
  - "deployments/finalizers"
  verbs:
  - "update"
- apiGroups:
  - ""
  resources:
  - "configmaps"
  - "persistentvolumeclaims"
  - "pods"
  - "secrets"
  - "serviceaccounts"
  - "services"
  - "services/finalizers"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "apps"
  resources:
  - "deployments"
  - "daemonsets"
  - "replicasets"
  - "statefulsets"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "extensions"
  resources:
  - "ingresses"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "networking.k8s.io"
  resources:
  - "ingresses"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "batch"
  resources:
  - "jobs"
  - "cronjobs"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "route.openshift.io"
  resources:
  - "routes"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "console.openshift.io"
  resources:
  - "consolelinks"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "autoscaling"
  resources:
  - "horizontalpodautoscalers"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "monitoring.coreos.com"
  resources:
  - "servicemonitors"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "logging.openshift.io"
  resources:
  - "elasticsearches"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "kafka.strimzi.io"
  resources:
  - "kafkas"
  - "kafkausers"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - ""
  resources:
  - "namespaces"
  verbs:
  - "get"
  - "list"
  - "watch"
- apiGroups:
  - "apps"
  resources:
  - "deployments"
  verbs:
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "rbac.authorization.k8s.io"
  resources:
  - "clusterrolebindings"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
2022-04-02 10:10:38 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 10:10:38 [main] [32mINFO [m [TracingST:488] Creating jaeger-crd.yaml from /home/ec2-user/strimzi-kafka-operator/systemtest/../systemtest/src/test/resources/tracing/1.20/operator-files/jaeger-crd.yaml
2022-04-02 10:10:38 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st apply -f -
2022-04-02 10:10:38 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 10:10:38 [main] [32mINFO [m [TracingST:488] Creating jaeger-operator.yaml from /home/ec2-user/strimzi-kafka-operator/systemtest/../systemtest/src/test/resources/tracing/1.20/operator-files/jaeger-operator.yaml
2022-04-02 10:10:38 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st apply -f -
2022-04-02 10:10:38 [main] [32mINFO [m [Exec:417] Input: ---
apiVersion: "apps/v1"
kind: "Deployment"
metadata:
  name: "jaeger-operator"
  namespace: "tracing-st"
spec:
  replicas: 1
  selector:
    matchLabels:
      name: "jaeger-operator"
  template:
    metadata:
      labels:
        name: "jaeger-operator"
    spec:
      serviceAccountName: "jaeger-operator"
      containers:
      - name: "jaeger-operator"
        image: "jaegertracing/jaeger-operator:1.20.0"
        ports:
        - containerPort: 8383
          name: "http-metrics"
        - containerPort: 8686
          name: "cr-metrics"
        args:
        - "start"
        - "--kafka-provision=no"
        imagePullPolicy: "Always"
        env:
        - name: "WATCH_NAMESPACE"
          value: ""
        - name: "POD_NAME"
          valueFrom:
            fieldRef:
              fieldPath: "metadata.name"
        - name: "POD_NAMESPACE"
          valueFrom:
            fieldRef:
              fieldPath: "metadata.namespace"
        - name: "OPERATOR_NAME"
          value: "jaeger-operator"
2022-04-02 10:10:38 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 10:10:38 [main] [32mINFO [m [TracingST:488] Creating jaeger-role-binding.yaml from /home/ec2-user/strimzi-kafka-operator/systemtest/../systemtest/src/test/resources/tracing/1.20/operator-files/jaeger-role-binding.yaml
2022-04-02 10:10:39 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st apply -f -
2022-04-02 10:10:39 [main] [32mINFO [m [Exec:417] Input: ---
kind: "RoleBinding"
apiVersion: "rbac.authorization.k8s.io/v1"
metadata:
  name: "jaeger-operator"
  namespace: "tracing-st"
subjects:
- kind: "ServiceAccount"
  name: "jaeger-operator"
roleRef:
  kind: "Role"
  name: "jaeger-operator"
  apiGroup: "rbac.authorization.k8s.io"
2022-04-02 10:10:39 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 10:10:39 [main] [32mINFO [m [TracingST:488] Creating jaeger-role.yaml from /home/ec2-user/strimzi-kafka-operator/systemtest/../systemtest/src/test/resources/tracing/1.20/operator-files/jaeger-role.yaml
2022-04-02 10:10:39 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st apply -f -
2022-04-02 10:10:39 [main] [32mINFO [m [Exec:417] Input: ---
apiVersion: "rbac.authorization.k8s.io/v1"
kind: "Role"
metadata:
  name: "jaeger-operator"
  namespace: "tracing-st"
rules:
- apiGroups:
  - "jaegertracing.io"
  resources:
  - "*"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "apps"
  resourceNames:
  - "jaeger-operator"
  resources:
  - "deployments/finalizers"
  verbs:
  - "update"
- apiGroups:
  - ""
  resources:
  - "configmaps"
  - "persistentvolumeclaims"
  - "pods"
  - "secrets"
  - "serviceaccounts"
  - "services"
  - "services/finalizers"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "apps"
  resources:
  - "deployments"
  - "daemonsets"
  - "replicasets"
  - "statefulsets"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "extensions"
  resources:
  - "ingresses"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "networking.k8s.io"
  resources:
  - "ingresses"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "batch"
  resources:
  - "jobs"
  - "cronjobs"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "route.openshift.io"
  resources:
  - "routes"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "image.openshift.io"
  resources:
  - "imagestreams"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "autoscaling"
  resources:
  - "horizontalpodautoscalers"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "monitoring.coreos.com"
  resources:
  - "servicemonitors"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "logging.openshift.io"
  resources:
  - "elasticsearches"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "kafka.strimzi.io"
  resources:
  - "kafkas"
  - "kafkausers"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
2022-04-02 10:10:39 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 10:10:39 [main] [32mINFO [m [TracingST:488] Creating jaeger-service-account.yaml from /home/ec2-user/strimzi-kafka-operator/systemtest/../systemtest/src/test/resources/tracing/1.20/operator-files/jaeger-service-account.yaml
2022-04-02 10:10:39 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st apply -f -
2022-04-02 10:10:39 [main] [32mINFO [m [Exec:417] Input: ---
apiVersion: "v1"
kind: "ServiceAccount"
metadata:
  name: "jaeger-operator"
  namespace: "tracing-st"
2022-04-02 10:10:39 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 10:10:39 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: jaeger-operator will be ready
2022-04-02 10:10:47 [main] [32mINFO [m [DeploymentUtils:168] Deployment: jaeger-operator is ready
2022-04-02 10:10:47 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment jaeger-operator to be ready
2022-04-02 10:10:57 [main] [32mINFO [m [DeploymentUtils:197] Deployment jaeger-operator is ready
2022-04-02 10:10:57 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy jaeger-allow in namespace tracing-st
2022-04-02 10:10:57 [main] [32mINFO [m [TracingST:524] Network policy for jaeger successfully created
2022-04-02 10:10:57 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 10:10:57 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.tracing.TracingST.testProducerConsumerStreamsConnectService-STARTED
2022-04-02 10:10:57 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 10:10:57 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-4 for test case:testProducerConsumerStreamsConnectService
2022-04-02 10:10:57 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-4
2022-04-02 10:10:57 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-4
2022-04-02 10:10:57 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-4
2022-04-02 10:10:57 [main] [32mINFO [m [TracingST:531] === Applying jaeger instance install file ===
2022-04-02 10:10:58 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-4 apply -f -
2022-04-02 10:10:58 [main] [32mINFO [m [Exec:417] Input: ---
apiVersion: "jaegertracing.io/v1"
kind: "Jaeger"
metadata:
  name: "my-jaeger"
spec:
  strategy: "allInOne"
  allInOne:
    image: "jaegertracing/all-in-one:1.20"
    options:
      log-level: "debug"
      query:
        base-path: "/jaeger"
  ingress:
    openshift: {}
    resources: {}
    security: "none"
  ui:
    options:
      dependencies:
        menuEnabled: false
      tracking:
        gaID: "UA-000000-2"
      menu:
      - label: "About Jaeger"
        items:
        - label: "Documentation"
          url: "https://www.jaegertracing.io/docs/latest"
  storage:
    options:
      memory:
        max-traces: 100000
2022-04-02 10:10:58 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 10:10:58 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-jaeger will be ready
2022-04-02 10:11:04 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-jaeger is ready
2022-04-02 10:11:04 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-jaeger to be ready
2022-04-02 10:11:14 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-jaeger is ready
2022-04-02 10:11:14 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-ee874091-kafka-clients in namespace namespace-4
2022-04-02 10:11:14 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-4
2022-04-02 10:11:14 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-ee874091-kafka-clients will be ready
2022-04-02 10:11:16 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-ee874091-kafka-clients is ready
2022-04-02 10:11:16 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-02 10:11:16 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-ee874091 in namespace namespace-4
2022-04-02 10:11:16 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-4
2022-04-02 10:11:16 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-ee874091 will have desired state: Ready
2022-04-02 10:12:38 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-ee874091 is in desired state: Ready
2022-04-02 10:12:38 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-826161369-1967799491 in namespace namespace-4
2022-04-02 10:12:38 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-4
2022-04-02 10:12:38 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-826161369-1967799491 will have desired state: Ready
2022-04-02 10:12:39 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-826161369-1967799491 is in desired state: Ready
2022-04-02 10:12:39 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-2081393180-386525849 in namespace namespace-4
2022-04-02 10:12:39 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-4
2022-04-02 10:12:39 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-2081393180-386525849 will have desired state: Ready
2022-04-02 10:12:40 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-2081393180-386525849 is in desired state: Ready
2022-04-02 10:12:40 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-ee874091-scraper in namespace namespace-4
2022-04-02 10:12:40 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-4
2022-04-02 10:12:40 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-ee874091-scraper will be ready
2022-04-02 10:12:42 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-ee874091-scraper is ready
2022-04-02 10:12:42 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-ee874091-scraper to be ready
2022-04-02 10:12:52 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-ee874091-scraper is ready
2022-04-02 10:12:52 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-ee874091-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-02 10:12:52 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-ee874091-allow in namespace namespace-4
2022-04-02 10:12:52 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-4
2022-04-02 10:12:52 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-02 10:12:52 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-ee874091 in namespace namespace-4
2022-04-02 10:12:52 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-4
2022-04-02 10:12:52 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-ee874091 will have desired state: Ready
2022-04-02 10:13:55 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-ee874091 is in desired state: Ready
2022-04-02 10:13:55 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-ee874091 in namespace namespace-4
2022-04-02 10:13:55 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-4
2022-04-02 10:13:55 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-ee874091 will have desired state: Ready
2022-04-02 10:13:56 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-ee874091 is in desired state: Ready
2022-04-02 10:13:56 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-ee874091-hello-world-producer in namespace namespace-4
2022-04-02 10:13:56 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-4
2022-04-02 10:13:56 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-ee874091-hello-world-producer will be in active state
2022-04-02 10:13:57 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-ee874091-hello-world-consumer in namespace namespace-4
2022-04-02 10:13:57 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-4
2022-04-02 10:13:57 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-ee874091-hello-world-consumer will be in active state
2022-04-02 10:13:58 [main] [32mINFO [m [ClientUtils:61] Waiting till producer my-cluster-ee874091-hello-world-producer and consumer my-cluster-ee874091-hello-world-consumer finish
2022-04-02 10:14:09 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-4 exec my-cluster-ee874091-kafka-clients-76f45b6846-xdxls -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-02 10:14:09 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 10:14:09 [main] [32mINFO [m [TracingUtils:47] Jaeger service hello-world-producer is present
2022-04-02 10:14:09 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-4 exec my-cluster-ee874091-kafka-clients-76f45b6846-xdxls -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=hello-world-producer&operation=To_my-topic-826161369-1967799491
2022-04-02 10:14:09 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 10:14:09 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-4 exec my-cluster-ee874091-kafka-clients-76f45b6846-xdxls -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-02 10:14:09 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 10:14:09 [main] [32mINFO [m [TracingUtils:47] Jaeger service hello-world-consumer is present
2022-04-02 10:14:09 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-4 exec my-cluster-ee874091-kafka-clients-76f45b6846-xdxls -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=hello-world-consumer&operation=From_my-topic-826161369-1967799491
2022-04-02 10:14:09 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 10:14:10 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-4 exec my-cluster-ee874091-kafka-clients-76f45b6846-xdxls -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-02 10:14:10 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 10:14:10 [main] [32mINFO [m [TracingUtils:47] Jaeger service my-connect is present
2022-04-02 10:14:10 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-4 exec my-cluster-ee874091-kafka-clients-76f45b6846-xdxls -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=my-connect&operation=From_my-topic-826161369-1967799491
2022-04-02 10:14:10 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 10:14:10 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 10:14:10 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumerStreamsConnectService
2022-04-02 10:14:10 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-ee874091 in namespace namespace-4
2022-04-02 10:14:10 [main] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-ee874091-allow in namespace namespace-4
2022-04-02 10:14:10 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-ee874091-kafka-clients in namespace namespace-4
2022-04-02 10:14:10 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-ee874091-hello-world-producer in namespace namespace-4
2022-04-02 10:14:10 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-ee874091 in namespace namespace-4
2022-04-02 10:14:10 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-2081393180-386525849 in namespace namespace-4
2022-04-02 10:14:10 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-ee874091-scraper in namespace namespace-4
2022-04-02 10:14:10 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-ee874091-hello-world-consumer in namespace namespace-4
2022-04-02 10:14:10 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-ee874091 in namespace namespace-4
2022-04-02 10:14:10 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-826161369-1967799491 in namespace namespace-4
2022-04-02 10:14:10 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-4 delete -f -
2022-04-02 10:14:10 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [Exec:417] Input: ---
apiVersion: "jaegertracing.io/v1"
kind: "Jaeger"
metadata:
  name: "my-jaeger"
spec:
  strategy: "allInOne"
  allInOne:
    image: "jaegertracing/all-in-one:1.20"
    options:
      log-level: "debug"
      query:
        base-path: "/jaeger"
  ingress:
    openshift: {}
    resources: {}
    security: "none"
  ui:
    options:
      dependencies:
        menuEnabled: false
      tracking:
        gaID: "UA-000000-2"
      menu:
      - label: "About Jaeger"
        items:
        - label: "Documentation"
          url: "https://www.jaegertracing.io/docs/latest"
  storage:
    options:
      memory:
        max-traces: 100000
2022-04-02 10:14:10 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 10:15:00 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 10:15:00 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-4 for test case:testProducerConsumerStreamsConnectService
2022-04-02 10:15:05 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.tracing.TracingST.testProducerConsumerStreamsConnectService-FINISHED
2022-04-02 10:15:05 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 10:15:05 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 10:15:05 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.tracing.TracingST.testKafkaBridgeService-STARTED
2022-04-02 10:15:05 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 10:15:05 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-5 for test case:testKafkaBridgeService
2022-04-02 10:15:05 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-5
2022-04-02 10:15:06 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-5
2022-04-02 10:15:06 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-5
2022-04-02 10:15:06 [main] [32mINFO [m [TracingST:531] === Applying jaeger instance install file ===
2022-04-02 10:15:06 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-5 apply -f -
2022-04-02 10:15:06 [main] [32mINFO [m [Exec:417] Input: ---
apiVersion: "jaegertracing.io/v1"
kind: "Jaeger"
metadata:
  name: "my-jaeger"
spec:
  strategy: "allInOne"
  allInOne:
    image: "jaegertracing/all-in-one:1.20"
    options:
      log-level: "debug"
      query:
        base-path: "/jaeger"
  ingress:
    openshift: {}
    resources: {}
    security: "none"
  ui:
    options:
      dependencies:
        menuEnabled: false
      tracking:
        gaID: "UA-000000-2"
      menu:
      - label: "About Jaeger"
        items:
        - label: "Documentation"
          url: "https://www.jaegertracing.io/docs/latest"
  storage:
    options:
      memory:
        max-traces: 100000
2022-04-02 10:15:06 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 10:15:06 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-jaeger will be ready
2022-04-02 10:15:16 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-jaeger is ready
2022-04-02 10:15:16 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-jaeger to be ready
2022-04-02 10:15:26 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-jaeger is ready
2022-04-02 10:15:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-cf69100c-kafka-clients in namespace namespace-5
2022-04-02 10:15:26 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-5
2022-04-02 10:15:26 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-cf69100c-kafka-clients will be ready
2022-04-02 10:15:28 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-cf69100c-kafka-clients is ready
2022-04-02 10:15:28 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-02 10:15:28 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-cf69100c in namespace namespace-5
2022-04-02 10:15:28 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-5
2022-04-02 10:15:28 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-cf69100c will have desired state: Ready
2022-04-02 10:16:33 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-cf69100c is in desired state: Ready
2022-04-02 10:16:33 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge my-cluster-cf69100c in namespace namespace-5
2022-04-02 10:16:33 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-5
2022-04-02 10:16:33 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: my-cluster-cf69100c will have desired state: Ready
2022-04-02 10:16:53 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: my-cluster-cf69100c is in desired state: Ready
2022-04-02 10:16:53 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-558194217-1771254233 in namespace namespace-5
2022-04-02 10:16:53 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-5
2022-04-02 10:16:53 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-558194217-1771254233 will have desired state: Ready
2022-04-02 10:16:55 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-558194217-1771254233 is in desired state: Ready
2022-04-02 10:16:55 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-02 10:16:55 [main] [32mINFO [m [ResourceManager:155] Create/Update Job bridge-producer in namespace namespace-5
2022-04-02 10:16:55 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-5
2022-04-02 10:16:55 [main] [32mINFO [m [JobUtils:81] Waiting for job: bridge-producer will be in active state
2022-04-02 10:16:56 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-cf69100c-hello-world-consumer in namespace namespace-5
2022-04-02 10:16:56 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-5
2022-04-02 10:16:56 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-cf69100c-hello-world-consumer will be in active state
2022-04-02 10:16:57 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:bridge-producer to finished
2022-04-02 10:18:45 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-5 exec my-cluster-cf69100c-kafka-clients-74c789f594-vxdrm -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-02 10:18:45 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 10:18:45 [main] [32mINFO [m [TracingUtils:47] Jaeger service my-kafka-bridge is present
2022-04-02 10:18:45 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-5 exec my-cluster-cf69100c-kafka-clients-74c789f594-vxdrm -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=my-kafka-bridge
2022-04-02 10:18:45 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 10:18:45 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 10:18:45 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaBridgeService
2022-04-02 10:18:45 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-558194217-1771254233 in namespace namespace-5
2022-04-02 10:18:45 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-cf69100c in namespace namespace-5
2022-04-02 10:18:45 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-cf69100c-kafka-clients in namespace namespace-5
2022-04-02 10:18:45 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge my-cluster-cf69100c in namespace namespace-5
2022-04-02 10:18:45 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-cf69100c-hello-world-consumer in namespace namespace-5
2022-04-02 10:18:45 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job bridge-producer in namespace namespace-5
2022-04-02 10:18:45 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-5 delete -f -
2022-04-02 10:18:45 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [Exec:417] Input: ---
apiVersion: "jaegertracing.io/v1"
kind: "Jaeger"
metadata:
  name: "my-jaeger"
spec:
  strategy: "allInOne"
  allInOne:
    image: "jaegertracing/all-in-one:1.20"
    options:
      log-level: "debug"
      query:
        base-path: "/jaeger"
  ingress:
    openshift: {}
    resources: {}
    security: "none"
  ui:
    options:
      dependencies:
        menuEnabled: false
      tracking:
        gaID: "UA-000000-2"
      menu:
      - label: "About Jaeger"
        items:
        - label: "Documentation"
          url: "https://www.jaegertracing.io/docs/latest"
  storage:
    options:
      memory:
        max-traces: 100000
2022-04-02 10:18:45 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 10:19:35 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 10:19:35 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-5 for test case:testKafkaBridgeService
2022-04-02 10:19:41 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.tracing.TracingST.testKafkaBridgeService-FINISHED
2022-04-02 10:19:41 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 10:19:41 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 10:19:41 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.tracing.TracingST.testProducerConsumerStreamsService-STARTED
2022-04-02 10:19:41 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 10:19:41 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-6 for test case:testProducerConsumerStreamsService
2022-04-02 10:19:41 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-6
2022-04-02 10:19:41 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-6
2022-04-02 10:19:41 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-6
2022-04-02 10:19:41 [main] [32mINFO [m [TracingST:531] === Applying jaeger instance install file ===
2022-04-02 10:19:41 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 apply -f -
2022-04-02 10:19:41 [main] [32mINFO [m [Exec:417] Input: ---
apiVersion: "jaegertracing.io/v1"
kind: "Jaeger"
metadata:
  name: "my-jaeger"
spec:
  strategy: "allInOne"
  allInOne:
    image: "jaegertracing/all-in-one:1.20"
    options:
      log-level: "debug"
      query:
        base-path: "/jaeger"
  ingress:
    openshift: {}
    resources: {}
    security: "none"
  ui:
    options:
      dependencies:
        menuEnabled: false
      tracking:
        gaID: "UA-000000-2"
      menu:
      - label: "About Jaeger"
        items:
        - label: "Documentation"
          url: "https://www.jaegertracing.io/docs/latest"
  storage:
    options:
      memory:
        max-traces: 100000
2022-04-02 10:19:41 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 10:19:41 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-jaeger will be ready
2022-04-02 10:19:44 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-jaeger is ready
2022-04-02 10:19:44 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-jaeger to be ready
2022-04-02 10:19:54 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-jaeger is ready
2022-04-02 10:19:54 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-9c0be7a7-kafka-clients in namespace namespace-6
2022-04-02 10:19:54 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-6
2022-04-02 10:19:54 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-9c0be7a7-kafka-clients will be ready
2022-04-02 10:19:56 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-9c0be7a7-kafka-clients is ready
2022-04-02 10:19:56 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-02 10:19:56 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-9c0be7a7 in namespace namespace-6
2022-04-02 10:19:56 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-6
2022-04-02 10:19:56 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-9c0be7a7 will have desired state: Ready
2022-04-02 10:21:07 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-9c0be7a7 is in desired state: Ready
2022-04-02 10:21:07 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-536689589-1288224663 in namespace namespace-6
2022-04-02 10:21:07 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-6
2022-04-02 10:21:07 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-536689589-1288224663 will have desired state: Ready
2022-04-02 10:21:08 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-536689589-1288224663 is in desired state: Ready
2022-04-02 10:21:08 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-595117903-311484123 in namespace namespace-6
2022-04-02 10:21:08 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-6
2022-04-02 10:21:08 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-595117903-311484123 will have desired state: Ready
2022-04-02 10:21:09 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-595117903-311484123 is in desired state: Ready
2022-04-02 10:21:09 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-9c0be7a7-hello-world-producer in namespace namespace-6
2022-04-02 10:21:09 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-6
2022-04-02 10:21:09 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-9c0be7a7-hello-world-producer will be in active state
2022-04-02 10:21:11 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 exec my-cluster-9c0be7a7-kafka-clients-55d46ffb4b-q9wpp -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-02 10:21:11 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 10:21:12 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 exec my-cluster-9c0be7a7-kafka-clients-55d46ffb4b-q9wpp -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-02 10:21:12 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 10:21:12 [main] [32mINFO [m [TracingUtils:50] Jaeger service hello-world-producer is not present. Present services are ["jaeger-query"].
2022-04-02 10:21:13 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 exec my-cluster-9c0be7a7-kafka-clients-55d46ffb4b-q9wpp -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-02 10:21:13 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 10:21:13 [main] [32mINFO [m [TracingUtils:47] Jaeger service hello-world-producer is present
2022-04-02 10:21:13 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 exec my-cluster-9c0be7a7-kafka-clients-55d46ffb4b-q9wpp -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=hello-world-producer
2022-04-02 10:21:13 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 10:21:13 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-9c0be7a7-hello-world-consumer in namespace namespace-6
2022-04-02 10:21:13 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-6
2022-04-02 10:21:13 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-9c0be7a7-hello-world-consumer will be in active state
2022-04-02 10:21:14 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 exec my-cluster-9c0be7a7-kafka-clients-55d46ffb4b-q9wpp -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-02 10:21:14 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 10:21:14 [main] [32mINFO [m [TracingUtils:50] Jaeger service hello-world-consumer is not present. Present services are ["jaeger-query","hello-world-producer"].
2022-04-02 10:21:16 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 exec my-cluster-9c0be7a7-kafka-clients-55d46ffb4b-q9wpp -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-02 10:21:16 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 10:21:16 [main] [32mINFO [m [TracingUtils:50] Jaeger service hello-world-consumer is not present. Present services are ["jaeger-query","hello-world-producer"].
2022-04-02 10:21:17 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 exec my-cluster-9c0be7a7-kafka-clients-55d46ffb4b-q9wpp -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-02 10:21:17 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 10:21:17 [main] [32mINFO [m [TracingUtils:50] Jaeger service hello-world-consumer is not present. Present services are ["hello-world-producer","jaeger-query"].
2022-04-02 10:21:18 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 exec my-cluster-9c0be7a7-kafka-clients-55d46ffb4b-q9wpp -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-02 10:21:18 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 10:21:18 [main] [32mINFO [m [TracingUtils:50] Jaeger service hello-world-consumer is not present. Present services are ["jaeger-query","hello-world-producer"].
2022-04-02 10:21:19 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 exec my-cluster-9c0be7a7-kafka-clients-55d46ffb4b-q9wpp -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-02 10:21:19 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 10:21:19 [main] [32mINFO [m [TracingUtils:47] Jaeger service hello-world-consumer is present
2022-04-02 10:21:19 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 exec my-cluster-9c0be7a7-kafka-clients-55d46ffb4b-q9wpp -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=hello-world-consumer
2022-04-02 10:21:19 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 10:21:19 [main] [32mINFO [m [ResourceManager:155] Create/Update Job hello-world-streams in namespace namespace-6
2022-04-02 10:21:19 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-6
2022-04-02 10:21:19 [main] [32mINFO [m [JobUtils:81] Waiting for job: hello-world-streams will be in active state
2022-04-02 10:21:20 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 10:21:20 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumerStreamsService
2022-04-02 10:21:20 [main] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-9c0be7a7-hello-world-producer in namespace namespace-6
2022-04-02 10:21:20 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-9c0be7a7 in namespace namespace-6
2022-04-02 10:21:20 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-595117903-311484123 in namespace namespace-6
2022-04-02 10:21:20 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job hello-world-streams in namespace namespace-6
2022-04-02 10:21:20 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-9c0be7a7-hello-world-consumer in namespace namespace-6
2022-04-02 10:21:20 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-9c0be7a7-kafka-clients in namespace namespace-6
2022-04-02 10:21:20 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-536689589-1288224663 in namespace namespace-6
2022-04-02 10:21:21 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 delete -f -
2022-04-02 10:21:21 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [Exec:417] Input: ---
apiVersion: "jaegertracing.io/v1"
kind: "Jaeger"
metadata:
  name: "my-jaeger"
spec:
  strategy: "allInOne"
  allInOne:
    image: "jaegertracing/all-in-one:1.20"
    options:
      log-level: "debug"
      query:
        base-path: "/jaeger"
  ingress:
    openshift: {}
    resources: {}
    security: "none"
  ui:
    options:
      dependencies:
        menuEnabled: false
      tracking:
        gaID: "UA-000000-2"
      menu:
      - label: "About Jaeger"
        items:
        - label: "Documentation"
          url: "https://www.jaegertracing.io/docs/latest"
  storage:
    options:
      memory:
        max-traces: 100000
2022-04-02 10:21:21 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 10:22:11 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 10:22:11 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-6 for test case:testProducerConsumerStreamsService
2022-04-02 10:22:16 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.tracing.TracingST.testProducerConsumerStreamsService-FINISHED
2022-04-02 10:22:16 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 10:22:16 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 10:22:16 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.tracing.TracingST.testProducerConsumerMirrorMakerService-STARTED
2022-04-02 10:22:16 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 10:22:16 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-7 for test case:testProducerConsumerMirrorMakerService
2022-04-02 10:22:16 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-7
2022-04-02 10:22:16 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-7
2022-04-02 10:22:16 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-7
2022-04-02 10:22:16 [main] [32mINFO [m [TracingST:531] === Applying jaeger instance install file ===
2022-04-02 10:22:16 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-7 apply -f -
2022-04-02 10:22:16 [main] [32mINFO [m [Exec:417] Input: ---
apiVersion: "jaegertracing.io/v1"
kind: "Jaeger"
metadata:
  name: "my-jaeger"
spec:
  strategy: "allInOne"
  allInOne:
    image: "jaegertracing/all-in-one:1.20"
    options:
      log-level: "debug"
      query:
        base-path: "/jaeger"
  ingress:
    openshift: {}
    resources: {}
    security: "none"
  ui:
    options:
      dependencies:
        menuEnabled: false
      tracking:
        gaID: "UA-000000-2"
      menu:
      - label: "About Jaeger"
        items:
        - label: "Documentation"
          url: "https://www.jaegertracing.io/docs/latest"
  storage:
    options:
      memory:
        max-traces: 100000
2022-04-02 10:22:16 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 10:22:16 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-jaeger will be ready
2022-04-02 10:22:25 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-jaeger is ready
2022-04-02 10:22:25 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-jaeger to be ready
2022-04-02 10:22:35 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-jaeger is ready
2022-04-02 10:22:35 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-6b9a6bc4-kafka-clients in namespace namespace-7
2022-04-02 10:22:35 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-7
2022-04-02 10:22:35 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-6b9a6bc4-kafka-clients will be ready
2022-04-02 10:22:37 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-6b9a6bc4-kafka-clients is ready
2022-04-02 10:22:37 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-02 10:22:37 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-6b9a6bc4 in namespace namespace-7
2022-04-02 10:22:37 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-7
2022-04-02 10:22:37 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-6b9a6bc4 will have desired state: Ready
2022-04-02 10:23:51 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-6b9a6bc4 is in desired state: Ready
2022-04-02 10:23:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-6b9a6bc4-target in namespace namespace-7
2022-04-02 10:23:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-7
2022-04-02 10:23:51 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-6b9a6bc4-target will have desired state: Ready
2022-04-02 10:25:04 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-6b9a6bc4-target is in desired state: Ready
2022-04-02 10:25:04 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1397612897-1971929773 in namespace namespace-7
2022-04-02 10:25:04 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-7
2022-04-02 10:25:04 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1397612897-1971929773 will have desired state: Ready
2022-04-02 10:25:05 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1397612897-1971929773 is in desired state: Ready
2022-04-02 10:25:05 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1397612897-1971929773-target in namespace namespace-7
2022-04-02 10:25:05 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-7
2022-04-02 10:25:05 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1397612897-1971929773-target will have desired state: Ready
2022-04-02 10:25:06 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1397612897-1971929773-target is in desired state: Ready
2022-04-02 10:25:06 [main] [32mINFO [m [TracingST:267] Setting for kafka source plain bootstrap:my-cluster-6b9a6bc4-kafka-bootstrap:9092
2022-04-02 10:25:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-6b9a6bc4-hello-world-producer in namespace namespace-7
2022-04-02 10:25:06 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-7
2022-04-02 10:25:06 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-6b9a6bc4-hello-world-producer will be in active state
2022-04-02 10:25:07 [main] [32mINFO [m [TracingST:276] Setting for kafka target plain bootstrap:my-cluster-6b9a6bc4-target-kafka-bootstrap:9092
2022-04-02 10:25:07 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-6b9a6bc4-hello-world-consumer in namespace namespace-7
2022-04-02 10:25:07 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-7
2022-04-02 10:25:07 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-6b9a6bc4-hello-world-consumer will be in active state
2022-04-02 10:25:08 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-6b9a6bc4 in namespace namespace-7
2022-04-02 10:25:08 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-7
2022-04-02 10:25:08 [main] [33mWARN [m [VersionUsageUtils:60] The client is using resource type 'kafkamirrormakers' with unstable version 'v1beta2'
2022-04-02 10:25:08 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-6b9a6bc4 will have desired state: Ready
2022-04-02 10:26:17 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-6b9a6bc4 is in desired state: Ready
2022-04-02 10:26:17 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-7 exec my-cluster-6b9a6bc4-kafka-clients-5c584fd8d8-f7ptj -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-02 10:26:17 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 10:26:17 [main] [32mINFO [m [TracingUtils:47] Jaeger service hello-world-producer is present
2022-04-02 10:26:18 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-7 exec my-cluster-6b9a6bc4-kafka-clients-5c584fd8d8-f7ptj -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=hello-world-producer&operation=To_my-topic-1397612897-1971929773
2022-04-02 10:26:18 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 10:26:18 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-7 exec my-cluster-6b9a6bc4-kafka-clients-5c584fd8d8-f7ptj -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-02 10:26:18 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 10:26:18 [main] [32mINFO [m [TracingUtils:47] Jaeger service hello-world-consumer is present
2022-04-02 10:26:18 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-7 exec my-cluster-6b9a6bc4-kafka-clients-5c584fd8d8-f7ptj -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=hello-world-consumer&operation=From_my-topic-1397612897-1971929773
2022-04-02 10:26:18 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 10:26:18 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-7 exec my-cluster-6b9a6bc4-kafka-clients-5c584fd8d8-f7ptj -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-02 10:26:18 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 10:26:18 [main] [32mINFO [m [TracingUtils:47] Jaeger service my-mirror-maker is present
2022-04-02 10:26:19 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-7 exec my-cluster-6b9a6bc4-kafka-clients-5c584fd8d8-f7ptj -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=my-mirror-maker&operation=From_my-topic-1397612897-1971929773
2022-04-02 10:26:19 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 10:26:19 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-7 exec my-cluster-6b9a6bc4-kafka-clients-5c584fd8d8-f7ptj -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-02 10:26:19 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 10:26:19 [main] [32mINFO [m [TracingUtils:47] Jaeger service my-mirror-maker is present
2022-04-02 10:26:19 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-7 exec my-cluster-6b9a6bc4-kafka-clients-5c584fd8d8-f7ptj -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=my-mirror-maker&operation=To_my-topic-1397612897-1971929773
2022-04-02 10:26:19 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 10:26:19 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 10:26:19 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumerMirrorMakerService
2022-04-02 10:26:19 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1397612897-1971929773-target in namespace namespace-7
2022-04-02 10:26:19 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-6b9a6bc4-hello-world-producer in namespace namespace-7
2022-04-02 10:26:19 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-6b9a6bc4-hello-world-consumer in namespace namespace-7
2022-04-02 10:26:19 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-6b9a6bc4 in namespace namespace-7
2022-04-02 10:26:19 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-6b9a6bc4 in namespace namespace-7
2022-04-02 10:26:19 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-6b9a6bc4-kafka-clients in namespace namespace-7
2022-04-02 10:26:19 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-6b9a6bc4-target in namespace namespace-7
2022-04-02 10:26:19 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1397612897-1971929773 in namespace namespace-7
2022-04-02 10:26:19 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-7 delete -f -
2022-04-02 10:26:19 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [Exec:417] Input: ---
apiVersion: "jaegertracing.io/v1"
kind: "Jaeger"
metadata:
  name: "my-jaeger"
spec:
  strategy: "allInOne"
  allInOne:
    image: "jaegertracing/all-in-one:1.20"
    options:
      log-level: "debug"
      query:
        base-path: "/jaeger"
  ingress:
    openshift: {}
    resources: {}
    security: "none"
  ui:
    options:
      dependencies:
        menuEnabled: false
      tracking:
        gaID: "UA-000000-2"
      menu:
      - label: "About Jaeger"
        items:
        - label: "Documentation"
          url: "https://www.jaegertracing.io/docs/latest"
  storage:
    options:
      memory:
        max-traces: 100000
2022-04-02 10:26:19 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 10:27:19 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 10:27:19 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-7 for test case:testProducerConsumerMirrorMakerService
2022-04-02 10:27:26 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.tracing.TracingST.testProducerConsumerMirrorMakerService-FINISHED
2022-04-02 10:27:26 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 10:27:26 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 10:27:26 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.tracing.TracingST.testProducerConsumerMirrorMaker2Service-STARTED
2022-04-02 10:27:26 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 10:27:26 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-8 for test case:testProducerConsumerMirrorMaker2Service
2022-04-02 10:27:26 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-8
2022-04-02 10:27:26 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-8
2022-04-02 10:27:26 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-8
2022-04-02 10:27:26 [main] [32mINFO [m [TracingST:531] === Applying jaeger instance install file ===
2022-04-02 10:27:26 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-8 apply -f -
2022-04-02 10:27:26 [main] [32mINFO [m [Exec:417] Input: ---
apiVersion: "jaegertracing.io/v1"
kind: "Jaeger"
metadata:
  name: "my-jaeger"
spec:
  strategy: "allInOne"
  allInOne:
    image: "jaegertracing/all-in-one:1.20"
    options:
      log-level: "debug"
      query:
        base-path: "/jaeger"
  ingress:
    openshift: {}
    resources: {}
    security: "none"
  ui:
    options:
      dependencies:
        menuEnabled: false
      tracking:
        gaID: "UA-000000-2"
      menu:
      - label: "About Jaeger"
        items:
        - label: "Documentation"
          url: "https://www.jaegertracing.io/docs/latest"
  storage:
    options:
      memory:
        max-traces: 100000
2022-04-02 10:27:26 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 10:27:26 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-jaeger will be ready
2022-04-02 10:27:31 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-jaeger is ready
2022-04-02 10:27:31 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-jaeger to be ready
2022-04-02 10:27:41 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-jaeger is ready
2022-04-02 10:27:41 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-a2b2aeef-kafka-clients in namespace namespace-8
2022-04-02 10:27:41 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-8
2022-04-02 10:27:41 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-a2b2aeef-kafka-clients will be ready
2022-04-02 10:27:43 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-a2b2aeef-kafka-clients is ready
2022-04-02 10:27:43 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-02 10:27:43 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-a2b2aeef in namespace namespace-8
2022-04-02 10:27:43 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-8
2022-04-02 10:27:43 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-a2b2aeef will have desired state: Ready
2022-04-02 10:28:59 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-a2b2aeef is in desired state: Ready
2022-04-02 10:28:59 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-a2b2aeef-target in namespace namespace-8
2022-04-02 10:28:59 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-8
2022-04-02 10:28:59 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-a2b2aeef-target will have desired state: Ready
2022-04-02 10:30:13 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-a2b2aeef-target is in desired state: Ready
2022-04-02 10:30:13 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-241112047-1079753945 in namespace namespace-8
2022-04-02 10:30:13 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-8
2022-04-02 10:30:13 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-241112047-1079753945 will have desired state: Ready
2022-04-02 10:30:14 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-241112047-1079753945 is in desired state: Ready
2022-04-02 10:30:14 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-cluster-a2b2aeef.my-topic-241112047-1079753945 in namespace namespace-8
2022-04-02 10:30:14 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-8
2022-04-02 10:30:14 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-cluster-a2b2aeef.my-topic-241112047-1079753945 will have desired state: Ready
2022-04-02 10:30:15 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-cluster-a2b2aeef.my-topic-241112047-1079753945 is in desired state: Ready
2022-04-02 10:30:15 [main] [32mINFO [m [TracingST:177] Setting for kafka source plain bootstrap:my-cluster-a2b2aeef-kafka-bootstrap:9092
2022-04-02 10:30:15 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-a2b2aeef-hello-world-producer in namespace namespace-8
2022-04-02 10:30:15 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-8
2022-04-02 10:30:15 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-a2b2aeef-hello-world-producer will be in active state
2022-04-02 10:30:16 [main] [32mINFO [m [TracingST:186] Setting for kafka target plain bootstrap:my-cluster-a2b2aeef-target-kafka-bootstrap:9092
2022-04-02 10:30:16 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-a2b2aeef-hello-world-consumer in namespace namespace-8
2022-04-02 10:30:16 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-8
2022-04-02 10:30:16 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-a2b2aeef-hello-world-consumer will be in active state
2022-04-02 10:30:17 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-a2b2aeef in namespace namespace-8
2022-04-02 10:30:17 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-8
2022-04-02 10:30:17 [main] [33mWARN [m [VersionUsageUtils:60] The client is using resource type 'kafkamirrormaker2s' with unstable version 'v1beta2'
2022-04-02 10:30:17 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-a2b2aeef will have desired state: Ready
2022-04-02 10:31:25 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-a2b2aeef is in desired state: Ready
2022-04-02 10:31:25 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-8 exec my-cluster-a2b2aeef-kafka-clients-6b9d4c7ddb-6ccbv -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-02 10:31:25 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 10:31:25 [main] [32mINFO [m [TracingUtils:47] Jaeger service hello-world-producer is present
2022-04-02 10:31:26 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-8 exec my-cluster-a2b2aeef-kafka-clients-6b9d4c7ddb-6ccbv -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=hello-world-producer&operation=To_my-topic-241112047-1079753945
2022-04-02 10:31:26 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 10:31:26 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-8 exec my-cluster-a2b2aeef-kafka-clients-6b9d4c7ddb-6ccbv -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-02 10:31:26 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 10:31:26 [main] [32mINFO [m [TracingUtils:47] Jaeger service hello-world-consumer is present
2022-04-02 10:31:26 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-8 exec my-cluster-a2b2aeef-kafka-clients-6b9d4c7ddb-6ccbv -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=hello-world-consumer&operation=From_my-cluster-a2b2aeef.my-topic-241112047-1079753945
2022-04-02 10:31:26 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 10:31:27 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-8 exec my-cluster-a2b2aeef-kafka-clients-6b9d4c7ddb-6ccbv -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-02 10:31:27 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 10:31:27 [main] [32mINFO [m [TracingUtils:47] Jaeger service my-mirror-maker2 is present
2022-04-02 10:31:27 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-8 exec my-cluster-a2b2aeef-kafka-clients-6b9d4c7ddb-6ccbv -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=my-mirror-maker2&operation=From_my-topic-241112047-1079753945
2022-04-02 10:31:27 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 10:31:27 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-8 exec my-cluster-a2b2aeef-kafka-clients-6b9d4c7ddb-6ccbv -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-02 10:31:27 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 10:31:27 [main] [32mINFO [m [TracingUtils:47] Jaeger service my-mirror-maker2 is present
2022-04-02 10:31:27 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-8 exec my-cluster-a2b2aeef-kafka-clients-6b9d4c7ddb-6ccbv -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=my-mirror-maker2&operation=To_my-cluster-a2b2aeef.my-topic-241112047-1079753945
2022-04-02 10:31:27 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 10:31:27 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 10:31:27 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumerMirrorMaker2Service
2022-04-02 10:31:27 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-cluster-a2b2aeef.my-topic-241112047-1079753945 in namespace namespace-8
2022-04-02 10:31:27 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-241112047-1079753945 in namespace namespace-8
2022-04-02 10:31:27 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-a2b2aeef-kafka-clients in namespace namespace-8
2022-04-02 10:31:27 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-a2b2aeef in namespace namespace-8
2022-04-02 10:31:27 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-a2b2aeef-hello-world-producer in namespace namespace-8
2022-04-02 10:31:27 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-a2b2aeef-target in namespace namespace-8
2022-04-02 10:31:27 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-a2b2aeef-hello-world-consumer in namespace namespace-8
2022-04-02 10:31:27 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-a2b2aeef in namespace namespace-8
2022-04-02 10:31:28 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-8 delete -f -
2022-04-02 10:31:28 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [Exec:417] Input: ---
apiVersion: "jaegertracing.io/v1"
kind: "Jaeger"
metadata:
  name: "my-jaeger"
spec:
  strategy: "allInOne"
  allInOne:
    image: "jaegertracing/all-in-one:1.20"
    options:
      log-level: "debug"
      query:
        base-path: "/jaeger"
  ingress:
    openshift: {}
    resources: {}
    security: "none"
  ui:
    options:
      dependencies:
        menuEnabled: false
      tracking:
        gaID: "UA-000000-2"
      menu:
      - label: "About Jaeger"
        items:
        - label: "Documentation"
          url: "https://www.jaegertracing.io/docs/latest"
  storage:
    options:
      memory:
        max-traces: 100000
2022-04-02 10:31:28 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 10:32:27 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 10:32:27 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-8 for test case:testProducerConsumerMirrorMaker2Service
2022-04-02 10:32:34 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.tracing.TracingST.testProducerConsumerMirrorMaker2Service-FINISHED
2022-04-02 10:32:34 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 10:32:34 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 10:32:34 [main] [32mINFO [m [ResourceManager:348] Delete all resources for TracingST
2022-04-02 10:32:34 [main] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy jaeger-allow in namespace tracing-st
2022-04-02 10:32:34 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st delete -f -
2022-04-02 10:32:34 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [Exec:417] Input: ---
apiVersion: "v1"
kind: "ServiceAccount"
metadata:
  name: "jaeger-operator"
  namespace: "tracing-st"
2022-04-02 10:32:34 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 10:32:34 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st delete -f -
2022-04-02 10:32:34 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [Exec:417] Input: ---
apiVersion: "rbac.authorization.k8s.io/v1"
kind: "Role"
metadata:
  name: "jaeger-operator"
  namespace: "tracing-st"
rules:
- apiGroups:
  - "jaegertracing.io"
  resources:
  - "*"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "apps"
  resourceNames:
  - "jaeger-operator"
  resources:
  - "deployments/finalizers"
  verbs:
  - "update"
- apiGroups:
  - ""
  resources:
  - "configmaps"
  - "persistentvolumeclaims"
  - "pods"
  - "secrets"
  - "serviceaccounts"
  - "services"
  - "services/finalizers"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "apps"
  resources:
  - "deployments"
  - "daemonsets"
  - "replicasets"
  - "statefulsets"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "extensions"
  resources:
  - "ingresses"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "networking.k8s.io"
  resources:
  - "ingresses"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "batch"
  resources:
  - "jobs"
  - "cronjobs"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "route.openshift.io"
  resources:
  - "routes"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "image.openshift.io"
  resources:
  - "imagestreams"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "autoscaling"
  resources:
  - "horizontalpodautoscalers"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "monitoring.coreos.com"
  resources:
  - "servicemonitors"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "logging.openshift.io"
  resources:
  - "elasticsearches"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "kafka.strimzi.io"
  resources:
  - "kafkas"
  - "kafkausers"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
2022-04-02 10:32:34 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 10:32:34 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st delete -f -
2022-04-02 10:32:34 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [Exec:417] Input: ---
kind: "RoleBinding"
apiVersion: "rbac.authorization.k8s.io/v1"
metadata:
  name: "jaeger-operator"
  namespace: "tracing-st"
subjects:
- kind: "ServiceAccount"
  name: "jaeger-operator"
roleRef:
  kind: "Role"
  name: "jaeger-operator"
  apiGroup: "rbac.authorization.k8s.io"
2022-04-02 10:32:34 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 10:32:34 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st delete -f -
2022-04-02 10:32:34 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [Exec:417] Input: ---
apiVersion: "apps/v1"
kind: "Deployment"
metadata:
  name: "jaeger-operator"
  namespace: "tracing-st"
spec:
  replicas: 1
  selector:
    matchLabels:
      name: "jaeger-operator"
  template:
    metadata:
      labels:
        name: "jaeger-operator"
    spec:
      serviceAccountName: "jaeger-operator"
      containers:
      - name: "jaeger-operator"
        image: "jaegertracing/jaeger-operator:1.20.0"
        ports:
        - containerPort: 8383
          name: "http-metrics"
        - containerPort: 8686
          name: "cr-metrics"
        args:
        - "start"
        - "--kafka-provision=no"
        imagePullPolicy: "Always"
        env:
        - name: "WATCH_NAMESPACE"
          value: ""
        - name: "POD_NAME"
          valueFrom:
            fieldRef:
              fieldPath: "metadata.name"
        - name: "POD_NAMESPACE"
          valueFrom:
            fieldRef:
              fieldPath: "metadata.namespace"
        - name: "OPERATOR_NAME"
          value: "jaeger-operator"
2022-04-02 10:32:34 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 10:32:35 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st delete -f -
2022-04-02 10:32:35 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 10:32:35 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st delete -f -
2022-04-02 10:32:35 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [Exec:417] Input: ---
apiVersion: "rbac.authorization.k8s.io/v1"
kind: "ClusterRole"
metadata:
  name: "jaeger-operator"
  namespace: "tracing-st"
rules:
- apiGroups:
  - "jaegertracing.io"
  resources:
  - "*"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "apps"
  resourceNames:
  - "jaeger-operator"
  resources:
  - "deployments/finalizers"
  verbs:
  - "update"
- apiGroups:
  - ""
  resources:
  - "configmaps"
  - "persistentvolumeclaims"
  - "pods"
  - "secrets"
  - "serviceaccounts"
  - "services"
  - "services/finalizers"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "apps"
  resources:
  - "deployments"
  - "daemonsets"
  - "replicasets"
  - "statefulsets"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "extensions"
  resources:
  - "ingresses"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "networking.k8s.io"
  resources:
  - "ingresses"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "batch"
  resources:
  - "jobs"
  - "cronjobs"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "route.openshift.io"
  resources:
  - "routes"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "console.openshift.io"
  resources:
  - "consolelinks"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "autoscaling"
  resources:
  - "horizontalpodautoscalers"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "monitoring.coreos.com"
  resources:
  - "servicemonitors"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "logging.openshift.io"
  resources:
  - "elasticsearches"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "kafka.strimzi.io"
  resources:
  - "kafkas"
  - "kafkausers"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - ""
  resources:
  - "namespaces"
  verbs:
  - "get"
  - "list"
  - "watch"
- apiGroups:
  - "apps"
  resources:
  - "deployments"
  verbs:
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "rbac.authorization.k8s.io"
  resources:
  - "clusterrolebindings"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
2022-04-02 10:32:35 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 10:32:35 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st delete -f -
2022-04-02 10:32:35 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [Exec:417] Input: ---
kind: "ClusterRoleBinding"
apiVersion: "rbac.authorization.k8s.io/v1"
metadata:
  name: "jaeger-operator"
  namespace: "tracing-st"
subjects:
- kind: "ServiceAccount"
  name: "jaeger-operator"
  namespace: "tracing-st"
roleRef:
  kind: "ClusterRole"
  name: "jaeger-operator"
  apiGroup: "rbac.authorization.k8s.io"
2022-04-02 10:32:35 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 10:32:35 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1,328.77 s - in io.strimzi.systemtest.tracing.TracingST
[[1;34mINFO[m] Running io.strimzi.systemtest.cruisecontrol.CruiseControlApiST
2022-04-02 10:32:46 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: cruise-control-api-st
2022-04-02 10:32:46 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: cruise-control-api-st
2022-04-02 10:32:46 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: cruise-control-api-st
2022-04-02 10:32:46 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 10:32:46 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlApiST.testCruiseControlBasicAPIRequests-STARTED
2022-04-02 10:32:46 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 10:32:46 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-9 for test case:testCruiseControlBasicAPIRequests
2022-04-02 10:32:46 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-9
2022-04-02 10:32:46 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-9
2022-04-02 10:32:46 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-9
2022-04-02 10:32:46 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-f6dbfa70 in namespace namespace-9
2022-04-02 10:32:46 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-9
2022-04-02 10:32:46 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-f6dbfa70 will have desired state: Ready
2022-04-02 10:34:22 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-f6dbfa70 is in desired state: Ready
2022-04-02 10:34:22 [main] [32mINFO [m [CruiseControlApiST:48] ----> CRUISE CONTROL DEPLOYMENT STATE ENDPOINT <----
2022-04-02 10:34:23 [main] [32mINFO [m [CruiseControlApiST:58] Verifying that Cruise Control REST API is available
2022-04-02 10:34:23 [main] [32mINFO [m [CruiseControlApiST:66] ----> KAFKA REBALANCE <----
2022-04-02 10:34:23 [main] [32mINFO [m [CruiseControlApiST:73] Waiting for CC will have for enough metrics to be recorded to make a proposal 
2022-04-02 10:36:14 [main] [32mINFO [m [CruiseControlApiST:97] ----> EXECUTION OF STOP PROPOSAL <----
2022-04-02 10:36:14 [main] [32mINFO [m [CruiseControlApiST:108] ----> USER TASKS <----
2022-04-02 10:36:15 [main] [32mINFO [m [CruiseControlApiST:126] Verifying that Cruise Control REST API doesn't allow HTTP requests
2022-04-02 10:36:15 [main] [32mINFO [m [CruiseControlApiST:132] Verifying that Cruise Control REST API doesn't allow unauthenticated requests
2022-04-02 10:36:15 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 10:36:15 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCruiseControlBasicAPIRequests
2022-04-02 10:36:15 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-f6dbfa70 in namespace namespace-9
2022-04-02 10:36:15 [main] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-9, for cruise control Kafka cluster my-cluster-f6dbfa70
2022-04-02 10:36:25 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 10:36:25 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-9 for test case:testCruiseControlBasicAPIRequests
2022-04-02 10:37:08 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlApiST.testCruiseControlBasicAPIRequests-FINISHED
2022-04-02 10:37:08 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 10:37:08 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 10:37:08 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlApiST.testCruiseControlBasicAPIRequestsWithSecurityDisabled-STARTED
2022-04-02 10:37:08 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 10:37:08 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-10 for test case:testCruiseControlBasicAPIRequestsWithSecurityDisabled
2022-04-02 10:37:08 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-10
2022-04-02 10:37:08 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-10
2022-04-02 10:37:08 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-10
2022-04-02 10:37:08 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka cruise-control-api-cluster-name in namespace namespace-10
2022-04-02 10:37:08 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-10
2022-04-02 10:37:08 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: cruise-control-api-cluster-name will have desired state: Ready
2022-04-02 10:38:51 [main] [32mINFO [m [ResourceManager:444] Kafka: cruise-control-api-cluster-name is in desired state: Ready
2022-04-02 10:38:51 [main] [32mINFO [m [CruiseControlApiST:153] ----> CRUISE CONTROL DEPLOYMENT STATE ENDPOINT <----
2022-04-02 10:38:52 [main] [32mINFO [m [CruiseControlApiST:157] Verifying that Cruise Control REST API is available using HTTP request without credentials
2022-04-02 10:38:52 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 10:38:52 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCruiseControlBasicAPIRequestsWithSecurityDisabled
2022-04-02 10:38:52 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka cruise-control-api-cluster-name in namespace namespace-10
2022-04-02 10:38:52 [main] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-10, for cruise control Kafka cluster cruise-control-api-cluster-name
2022-04-02 10:39:02 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 10:39:02 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-10 for test case:testCruiseControlBasicAPIRequestsWithSecurityDisabled
2022-04-02 10:39:45 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlApiST.testCruiseControlBasicAPIRequestsWithSecurityDisabled-FINISHED
2022-04-02 10:39:45 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 10:39:45 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 10:39:45 [main] [32mINFO [m [ResourceManager:346] In context CruiseControlApiST is everything deleted.
2022-04-02 10:39:45 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 424.447 s - in io.strimzi.systemtest.cruisecontrol.CruiseControlApiST
[[1;34mINFO[m] Running io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST
2022-04-02 10:39:50 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: cruise-control-configuration-st
2022-04-02 10:39:50 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: cruise-control-configuration-st
2022-04-02 10:39:50 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: cruise-control-configuration-st
2022-04-02 10:39:50 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 10:39:50 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testConfigurationFileIsCreated-STARTED
2022-04-02 10:39:50 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 10:39:50 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-11 for test case:testConfigurationFileIsCreated
2022-04-02 10:39:50 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-11
2022-04-02 10:39:50 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-11
2022-04-02 10:39:50 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-11
2022-04-02 10:39:50 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-2cfa2f61 in namespace namespace-11
2022-04-02 10:39:50 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-11
2022-04-02 10:39:51 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-2cfa2f61 will have desired state: Ready
2022-04-02 10:41:32 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-2cfa2f61 is in desired state: Ready
2022-04-02 10:41:32 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-11 exec my-cluster-2cfa2f61-cruise-control-747b7fffd9-6rftw -- /bin/bash -c cat /tmp/cruisecontrol.properties
2022-04-02 10:41:32 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 10:41:32 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 10:41:32 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testConfigurationFileIsCreated
2022-04-02 10:41:32 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-2cfa2f61 in namespace namespace-11
2022-04-02 10:41:32 [main] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-11, for cruise control Kafka cluster my-cluster-2cfa2f61
2022-04-02 10:41:42 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 10:41:42 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-11 for test case:testConfigurationFileIsCreated
2022-04-02 10:42:25 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testConfigurationFileIsCreated-FINISHED
2022-04-02 10:42:25 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 10:42:25 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 10:42:25 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testDeployAndUnDeployCruiseControl-STARTED
2022-04-02 10:42:25 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 10:42:25 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-12 for test case:testDeployAndUnDeployCruiseControl
2022-04-02 10:42:25 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-12
2022-04-02 10:42:25 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-12
2022-04-02 10:42:25 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-12
2022-04-02 10:42:25 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-75e60db2 in namespace namespace-12
2022-04-02 10:42:25 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-12
2022-04-02 10:42:25 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-75e60db2 will have desired state: Ready
2022-04-02 10:44:02 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-75e60db2 is in desired state: Ready
2022-04-02 10:44:02 [main] [32mINFO [m [CruiseControlConfigurationST:111] Removing Cruise Control to the classic Kafka.
2022-04-02 10:44:02 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-75e60db2-kafka rolling update
2022-04-02 10:45:27 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-75e60db2-kafka has been successfully rolled
2022-04-02 10:45:27 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-75e60db2-kafka to be ready
2022-04-02 10:45:50 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-75e60db2 will have desired state: Ready
2022-04-02 10:45:50 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-75e60db2 is in desired state: Ready
2022-04-02 10:45:50 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-75e60db2 is ready
2022-04-02 10:45:50 [main] [32mINFO [m [CruiseControlConfigurationST:117] Verifying that in Cruise Control is not present in the Kafka cluster
2022-04-02 10:45:50 [main] [32mINFO [m [CruiseControlConfigurationST:120] Verifying that my-cluster-75e60db2-cruise-control- pod is not present
2022-04-02 10:45:50 [main] [32mINFO [m [PodUtils:209] Wait until Pod my-cluster-75e60db2-cruise-control- will have stable 0 replicas
2022-04-02 10:45:50 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 19 polls
2022-04-02 10:45:51 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 18 polls
2022-04-02 10:45:52 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 17 polls
2022-04-02 10:45:53 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 16 polls
2022-04-02 10:45:54 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 15 polls
2022-04-02 10:45:55 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 14 polls
2022-04-02 10:45:56 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 13 polls
2022-04-02 10:45:57 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 12 polls
2022-04-02 10:45:58 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 11 polls
2022-04-02 10:45:59 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 10 polls
2022-04-02 10:46:00 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 9 polls
2022-04-02 10:46:01 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 8 polls
2022-04-02 10:46:02 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 7 polls
2022-04-02 10:46:03 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 6 polls
2022-04-02 10:46:04 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 5 polls
2022-04-02 10:46:05 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 4 polls
2022-04-02 10:46:06 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 3 polls
2022-04-02 10:46:07 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 2 polls
2022-04-02 10:46:08 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 1 polls
2022-04-02 10:46:09 [main] [32mINFO [m [PodUtils:217] Pod replicas are stable for 20 polls intervals
2022-04-02 10:46:09 [main] [32mINFO [m [PodUtils:228] Pod my-cluster-75e60db2-cruise-control- has 0 replicas
2022-04-02 10:46:09 [main] [32mINFO [m [CruiseControlConfigurationST:123] Verifying that in Kafka config map there is no configuration to cruise control metric reporter
2022-04-02 10:48:09 [main] [1;31mERROR[m [TestUtils:162] Exception waiting for Verify that kafka configuration {cluster-name=my-cluster-75e60db2} has correct cruise control metric reporter properties, null
2022-04-02 10:48:09 [main] [32mINFO [m [CruiseControlConfigurationST:126] Cruise Control topics will not be deleted and will stay in the Kafka cluster
2022-04-02 10:48:09 [main] [32mINFO [m [CruiseControlConfigurationST:130] Adding Cruise Control to the classic Kafka.
2022-04-02 10:48:09 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-75e60db2-kafka rolling update
2022-04-02 10:49:34 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-75e60db2-kafka has been successfully rolled
2022-04-02 10:49:34 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-75e60db2-kafka to be ready
2022-04-02 10:50:00 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-75e60db2 will have desired state: Ready
2022-04-02 10:50:00 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-75e60db2 is in desired state: Ready
2022-04-02 10:50:00 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-75e60db2 is ready
2022-04-02 10:50:00 [main] [32mINFO [m [CruiseControlConfigurationST:136] Verifying that in Kafka config map there is configuration to cruise control metric reporter
2022-04-02 10:50:00 [main] [32mINFO [m [CruiseControlConfigurationST:139] Verifying that Cruise Control topics are created after CC is instantiated.
2022-04-02 10:50:00 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 10:50:00 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDeployAndUnDeployCruiseControl
2022-04-02 10:50:00 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-75e60db2 in namespace namespace-12
2022-04-02 10:50:00 [main] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-12, for cruise control Kafka cluster my-cluster-75e60db2
2022-04-02 10:50:10 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 10:50:10 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-12 for test case:testDeployAndUnDeployCruiseControl
2022-04-02 10:50:54 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testDeployAndUnDeployCruiseControl-FINISHED
2022-04-02 10:50:54 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 10:50:54 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 10:50:54 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testConfigurationPerformanceOptions-STARTED
2022-04-02 10:50:54 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 10:50:54 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-13 for test case:testConfigurationPerformanceOptions
2022-04-02 10:50:54 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-13
2022-04-02 10:50:54 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-13
2022-04-02 10:50:54 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-13
2022-04-02 10:50:54 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-cdd0d513 in namespace namespace-13
2022-04-02 10:50:54 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-13
2022-04-02 10:50:54 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-cdd0d513 will have desired state: Ready
2022-04-02 10:52:28 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-cdd0d513 is in desired state: Ready
2022-04-02 10:52:28 [main] [32mINFO [m [CruiseControlConfigurationST:271] Changing cruise control performance tuning options
2022-04-02 10:52:28 [main] [32mINFO [m [CruiseControlConfigurationST:277] Verifying that CC pod is rolling, after changing options
2022-04-02 10:52:28 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-cdd0d513-cruise-control rolling update
2022-04-02 10:53:03 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-cdd0d513-cruise-control will be ready
2022-04-02 10:53:03 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-cdd0d513-cruise-control is ready
2022-04-02 10:53:13 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-cdd0d513-cruise-control rolling update finished
2022-04-02 10:53:13 [main] [32mINFO [m [CruiseControlConfigurationST:280] Verifying that Kafka pods did not roll
2022-04-02 10:53:13 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-cdd0d513-kafka-2=9630e42a-015b-459d-9426-7c2e337741d9, my-cluster-cdd0d513-kafka-1=6e868b9a-0247-4706-bb11-161272279cde, my-cluster-cdd0d513-kafka-0=6bdd74c6-5b2d-46f6-975b-651b25606453} pods didn't roll. Remaining seconds for stability: 50
2022-04-02 10:53:14 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-cdd0d513-kafka-2=9630e42a-015b-459d-9426-7c2e337741d9, my-cluster-cdd0d513-kafka-1=6e868b9a-0247-4706-bb11-161272279cde, my-cluster-cdd0d513-kafka-0=6bdd74c6-5b2d-46f6-975b-651b25606453} pods didn't roll. Remaining seconds for stability: 49
2022-04-02 10:53:15 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-cdd0d513-kafka-2=9630e42a-015b-459d-9426-7c2e337741d9, my-cluster-cdd0d513-kafka-1=6e868b9a-0247-4706-bb11-161272279cde, my-cluster-cdd0d513-kafka-0=6bdd74c6-5b2d-46f6-975b-651b25606453} pods didn't roll. Remaining seconds for stability: 48
2022-04-02 10:53:16 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-cdd0d513-kafka-2=9630e42a-015b-459d-9426-7c2e337741d9, my-cluster-cdd0d513-kafka-1=6e868b9a-0247-4706-bb11-161272279cde, my-cluster-cdd0d513-kafka-0=6bdd74c6-5b2d-46f6-975b-651b25606453} pods didn't roll. Remaining seconds for stability: 47
2022-04-02 10:53:17 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-cdd0d513-kafka-2=9630e42a-015b-459d-9426-7c2e337741d9, my-cluster-cdd0d513-kafka-1=6e868b9a-0247-4706-bb11-161272279cde, my-cluster-cdd0d513-kafka-0=6bdd74c6-5b2d-46f6-975b-651b25606453} pods didn't roll. Remaining seconds for stability: 46
2022-04-02 10:53:18 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-cdd0d513-kafka-2=9630e42a-015b-459d-9426-7c2e337741d9, my-cluster-cdd0d513-kafka-1=6e868b9a-0247-4706-bb11-161272279cde, my-cluster-cdd0d513-kafka-0=6bdd74c6-5b2d-46f6-975b-651b25606453} pods didn't roll. Remaining seconds for stability: 45
2022-04-02 10:53:19 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-cdd0d513-kafka-2=9630e42a-015b-459d-9426-7c2e337741d9, my-cluster-cdd0d513-kafka-1=6e868b9a-0247-4706-bb11-161272279cde, my-cluster-cdd0d513-kafka-0=6bdd74c6-5b2d-46f6-975b-651b25606453} pods didn't roll. Remaining seconds for stability: 44
2022-04-02 10:53:20 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-cdd0d513-kafka-2=9630e42a-015b-459d-9426-7c2e337741d9, my-cluster-cdd0d513-kafka-1=6e868b9a-0247-4706-bb11-161272279cde, my-cluster-cdd0d513-kafka-0=6bdd74c6-5b2d-46f6-975b-651b25606453} pods didn't roll. Remaining seconds for stability: 43
2022-04-02 10:53:21 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-cdd0d513-kafka-2=9630e42a-015b-459d-9426-7c2e337741d9, my-cluster-cdd0d513-kafka-1=6e868b9a-0247-4706-bb11-161272279cde, my-cluster-cdd0d513-kafka-0=6bdd74c6-5b2d-46f6-975b-651b25606453} pods didn't roll. Remaining seconds for stability: 42
2022-04-02 10:53:22 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-cdd0d513-kafka-2=9630e42a-015b-459d-9426-7c2e337741d9, my-cluster-cdd0d513-kafka-1=6e868b9a-0247-4706-bb11-161272279cde, my-cluster-cdd0d513-kafka-0=6bdd74c6-5b2d-46f6-975b-651b25606453} pods didn't roll. Remaining seconds for stability: 41
2022-04-02 10:53:23 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-cdd0d513-kafka-2=9630e42a-015b-459d-9426-7c2e337741d9, my-cluster-cdd0d513-kafka-1=6e868b9a-0247-4706-bb11-161272279cde, my-cluster-cdd0d513-kafka-0=6bdd74c6-5b2d-46f6-975b-651b25606453} pods didn't roll. Remaining seconds for stability: 40
2022-04-02 10:53:24 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-cdd0d513-kafka-2=9630e42a-015b-459d-9426-7c2e337741d9, my-cluster-cdd0d513-kafka-1=6e868b9a-0247-4706-bb11-161272279cde, my-cluster-cdd0d513-kafka-0=6bdd74c6-5b2d-46f6-975b-651b25606453} pods didn't roll. Remaining seconds for stability: 39
2022-04-02 10:53:25 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-cdd0d513-kafka-2=9630e42a-015b-459d-9426-7c2e337741d9, my-cluster-cdd0d513-kafka-1=6e868b9a-0247-4706-bb11-161272279cde, my-cluster-cdd0d513-kafka-0=6bdd74c6-5b2d-46f6-975b-651b25606453} pods didn't roll. Remaining seconds for stability: 38
2022-04-02 10:53:26 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-cdd0d513-kafka-2=9630e42a-015b-459d-9426-7c2e337741d9, my-cluster-cdd0d513-kafka-1=6e868b9a-0247-4706-bb11-161272279cde, my-cluster-cdd0d513-kafka-0=6bdd74c6-5b2d-46f6-975b-651b25606453} pods didn't roll. Remaining seconds for stability: 37
2022-04-02 10:53:27 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-cdd0d513-kafka-2=9630e42a-015b-459d-9426-7c2e337741d9, my-cluster-cdd0d513-kafka-1=6e868b9a-0247-4706-bb11-161272279cde, my-cluster-cdd0d513-kafka-0=6bdd74c6-5b2d-46f6-975b-651b25606453} pods didn't roll. Remaining seconds for stability: 36
2022-04-02 10:53:28 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-cdd0d513-kafka-2=9630e42a-015b-459d-9426-7c2e337741d9, my-cluster-cdd0d513-kafka-1=6e868b9a-0247-4706-bb11-161272279cde, my-cluster-cdd0d513-kafka-0=6bdd74c6-5b2d-46f6-975b-651b25606453} pods didn't roll. Remaining seconds for stability: 35
2022-04-02 10:53:29 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-cdd0d513-kafka-2=9630e42a-015b-459d-9426-7c2e337741d9, my-cluster-cdd0d513-kafka-1=6e868b9a-0247-4706-bb11-161272279cde, my-cluster-cdd0d513-kafka-0=6bdd74c6-5b2d-46f6-975b-651b25606453} pods didn't roll. Remaining seconds for stability: 34
2022-04-02 10:53:30 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-cdd0d513-kafka-2=9630e42a-015b-459d-9426-7c2e337741d9, my-cluster-cdd0d513-kafka-1=6e868b9a-0247-4706-bb11-161272279cde, my-cluster-cdd0d513-kafka-0=6bdd74c6-5b2d-46f6-975b-651b25606453} pods didn't roll. Remaining seconds for stability: 33
2022-04-02 10:53:31 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-cdd0d513-kafka-2=9630e42a-015b-459d-9426-7c2e337741d9, my-cluster-cdd0d513-kafka-1=6e868b9a-0247-4706-bb11-161272279cde, my-cluster-cdd0d513-kafka-0=6bdd74c6-5b2d-46f6-975b-651b25606453} pods didn't roll. Remaining seconds for stability: 32
2022-04-02 10:53:32 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-cdd0d513-kafka-2=9630e42a-015b-459d-9426-7c2e337741d9, my-cluster-cdd0d513-kafka-1=6e868b9a-0247-4706-bb11-161272279cde, my-cluster-cdd0d513-kafka-0=6bdd74c6-5b2d-46f6-975b-651b25606453} pods didn't roll. Remaining seconds for stability: 31
2022-04-02 10:53:33 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-cdd0d513-kafka-2=9630e42a-015b-459d-9426-7c2e337741d9, my-cluster-cdd0d513-kafka-1=6e868b9a-0247-4706-bb11-161272279cde, my-cluster-cdd0d513-kafka-0=6bdd74c6-5b2d-46f6-975b-651b25606453} pods didn't roll. Remaining seconds for stability: 30
2022-04-02 10:53:34 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-cdd0d513-kafka-2=9630e42a-015b-459d-9426-7c2e337741d9, my-cluster-cdd0d513-kafka-1=6e868b9a-0247-4706-bb11-161272279cde, my-cluster-cdd0d513-kafka-0=6bdd74c6-5b2d-46f6-975b-651b25606453} pods didn't roll. Remaining seconds for stability: 29
2022-04-02 10:53:35 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-cdd0d513-kafka-2=9630e42a-015b-459d-9426-7c2e337741d9, my-cluster-cdd0d513-kafka-1=6e868b9a-0247-4706-bb11-161272279cde, my-cluster-cdd0d513-kafka-0=6bdd74c6-5b2d-46f6-975b-651b25606453} pods didn't roll. Remaining seconds for stability: 28
2022-04-02 10:53:36 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-cdd0d513-kafka-2=9630e42a-015b-459d-9426-7c2e337741d9, my-cluster-cdd0d513-kafka-1=6e868b9a-0247-4706-bb11-161272279cde, my-cluster-cdd0d513-kafka-0=6bdd74c6-5b2d-46f6-975b-651b25606453} pods didn't roll. Remaining seconds for stability: 27
2022-04-02 10:53:37 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-cdd0d513-kafka-2=9630e42a-015b-459d-9426-7c2e337741d9, my-cluster-cdd0d513-kafka-1=6e868b9a-0247-4706-bb11-161272279cde, my-cluster-cdd0d513-kafka-0=6bdd74c6-5b2d-46f6-975b-651b25606453} pods didn't roll. Remaining seconds for stability: 26
2022-04-02 10:53:38 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-cdd0d513-kafka-2=9630e42a-015b-459d-9426-7c2e337741d9, my-cluster-cdd0d513-kafka-1=6e868b9a-0247-4706-bb11-161272279cde, my-cluster-cdd0d513-kafka-0=6bdd74c6-5b2d-46f6-975b-651b25606453} pods didn't roll. Remaining seconds for stability: 25
2022-04-02 10:53:39 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-cdd0d513-kafka-2=9630e42a-015b-459d-9426-7c2e337741d9, my-cluster-cdd0d513-kafka-1=6e868b9a-0247-4706-bb11-161272279cde, my-cluster-cdd0d513-kafka-0=6bdd74c6-5b2d-46f6-975b-651b25606453} pods didn't roll. Remaining seconds for stability: 24
2022-04-02 10:53:40 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-cdd0d513-kafka-2=9630e42a-015b-459d-9426-7c2e337741d9, my-cluster-cdd0d513-kafka-1=6e868b9a-0247-4706-bb11-161272279cde, my-cluster-cdd0d513-kafka-0=6bdd74c6-5b2d-46f6-975b-651b25606453} pods didn't roll. Remaining seconds for stability: 23
2022-04-02 10:53:41 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-cdd0d513-kafka-2=9630e42a-015b-459d-9426-7c2e337741d9, my-cluster-cdd0d513-kafka-1=6e868b9a-0247-4706-bb11-161272279cde, my-cluster-cdd0d513-kafka-0=6bdd74c6-5b2d-46f6-975b-651b25606453} pods didn't roll. Remaining seconds for stability: 22
2022-04-02 10:53:42 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-cdd0d513-kafka-2=9630e42a-015b-459d-9426-7c2e337741d9, my-cluster-cdd0d513-kafka-1=6e868b9a-0247-4706-bb11-161272279cde, my-cluster-cdd0d513-kafka-0=6bdd74c6-5b2d-46f6-975b-651b25606453} pods didn't roll. Remaining seconds for stability: 21
2022-04-02 10:53:43 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-cdd0d513-kafka-2=9630e42a-015b-459d-9426-7c2e337741d9, my-cluster-cdd0d513-kafka-1=6e868b9a-0247-4706-bb11-161272279cde, my-cluster-cdd0d513-kafka-0=6bdd74c6-5b2d-46f6-975b-651b25606453} pods didn't roll. Remaining seconds for stability: 20
2022-04-02 10:53:44 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-cdd0d513-kafka-2=9630e42a-015b-459d-9426-7c2e337741d9, my-cluster-cdd0d513-kafka-1=6e868b9a-0247-4706-bb11-161272279cde, my-cluster-cdd0d513-kafka-0=6bdd74c6-5b2d-46f6-975b-651b25606453} pods didn't roll. Remaining seconds for stability: 19
2022-04-02 10:53:45 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-cdd0d513-kafka-2=9630e42a-015b-459d-9426-7c2e337741d9, my-cluster-cdd0d513-kafka-1=6e868b9a-0247-4706-bb11-161272279cde, my-cluster-cdd0d513-kafka-0=6bdd74c6-5b2d-46f6-975b-651b25606453} pods didn't roll. Remaining seconds for stability: 18
2022-04-02 10:53:46 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-cdd0d513-kafka-2=9630e42a-015b-459d-9426-7c2e337741d9, my-cluster-cdd0d513-kafka-1=6e868b9a-0247-4706-bb11-161272279cde, my-cluster-cdd0d513-kafka-0=6bdd74c6-5b2d-46f6-975b-651b25606453} pods didn't roll. Remaining seconds for stability: 17
2022-04-02 10:53:47 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-cdd0d513-kafka-2=9630e42a-015b-459d-9426-7c2e337741d9, my-cluster-cdd0d513-kafka-1=6e868b9a-0247-4706-bb11-161272279cde, my-cluster-cdd0d513-kafka-0=6bdd74c6-5b2d-46f6-975b-651b25606453} pods didn't roll. Remaining seconds for stability: 16
2022-04-02 10:53:48 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-cdd0d513-kafka-2=9630e42a-015b-459d-9426-7c2e337741d9, my-cluster-cdd0d513-kafka-1=6e868b9a-0247-4706-bb11-161272279cde, my-cluster-cdd0d513-kafka-0=6bdd74c6-5b2d-46f6-975b-651b25606453} pods didn't roll. Remaining seconds for stability: 15
2022-04-02 10:53:49 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-cdd0d513-kafka-2=9630e42a-015b-459d-9426-7c2e337741d9, my-cluster-cdd0d513-kafka-1=6e868b9a-0247-4706-bb11-161272279cde, my-cluster-cdd0d513-kafka-0=6bdd74c6-5b2d-46f6-975b-651b25606453} pods didn't roll. Remaining seconds for stability: 14
2022-04-02 10:53:50 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-cdd0d513-kafka-2=9630e42a-015b-459d-9426-7c2e337741d9, my-cluster-cdd0d513-kafka-1=6e868b9a-0247-4706-bb11-161272279cde, my-cluster-cdd0d513-kafka-0=6bdd74c6-5b2d-46f6-975b-651b25606453} pods didn't roll. Remaining seconds for stability: 13
2022-04-02 10:53:51 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-cdd0d513-kafka-2=9630e42a-015b-459d-9426-7c2e337741d9, my-cluster-cdd0d513-kafka-1=6e868b9a-0247-4706-bb11-161272279cde, my-cluster-cdd0d513-kafka-0=6bdd74c6-5b2d-46f6-975b-651b25606453} pods didn't roll. Remaining seconds for stability: 12
2022-04-02 10:53:52 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-cdd0d513-kafka-2=9630e42a-015b-459d-9426-7c2e337741d9, my-cluster-cdd0d513-kafka-1=6e868b9a-0247-4706-bb11-161272279cde, my-cluster-cdd0d513-kafka-0=6bdd74c6-5b2d-46f6-975b-651b25606453} pods didn't roll. Remaining seconds for stability: 11
2022-04-02 10:53:53 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-cdd0d513-kafka-2=9630e42a-015b-459d-9426-7c2e337741d9, my-cluster-cdd0d513-kafka-1=6e868b9a-0247-4706-bb11-161272279cde, my-cluster-cdd0d513-kafka-0=6bdd74c6-5b2d-46f6-975b-651b25606453} pods didn't roll. Remaining seconds for stability: 10
2022-04-02 10:53:54 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-cdd0d513-kafka-2=9630e42a-015b-459d-9426-7c2e337741d9, my-cluster-cdd0d513-kafka-1=6e868b9a-0247-4706-bb11-161272279cde, my-cluster-cdd0d513-kafka-0=6bdd74c6-5b2d-46f6-975b-651b25606453} pods didn't roll. Remaining seconds for stability: 9
2022-04-02 10:53:55 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-cdd0d513-kafka-2=9630e42a-015b-459d-9426-7c2e337741d9, my-cluster-cdd0d513-kafka-1=6e868b9a-0247-4706-bb11-161272279cde, my-cluster-cdd0d513-kafka-0=6bdd74c6-5b2d-46f6-975b-651b25606453} pods didn't roll. Remaining seconds for stability: 8
2022-04-02 10:53:56 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-cdd0d513-kafka-2=9630e42a-015b-459d-9426-7c2e337741d9, my-cluster-cdd0d513-kafka-1=6e868b9a-0247-4706-bb11-161272279cde, my-cluster-cdd0d513-kafka-0=6bdd74c6-5b2d-46f6-975b-651b25606453} pods didn't roll. Remaining seconds for stability: 7
2022-04-02 10:53:57 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-cdd0d513-kafka-2=9630e42a-015b-459d-9426-7c2e337741d9, my-cluster-cdd0d513-kafka-1=6e868b9a-0247-4706-bb11-161272279cde, my-cluster-cdd0d513-kafka-0=6bdd74c6-5b2d-46f6-975b-651b25606453} pods didn't roll. Remaining seconds for stability: 6
2022-04-02 10:53:58 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-cdd0d513-kafka-2=9630e42a-015b-459d-9426-7c2e337741d9, my-cluster-cdd0d513-kafka-1=6e868b9a-0247-4706-bb11-161272279cde, my-cluster-cdd0d513-kafka-0=6bdd74c6-5b2d-46f6-975b-651b25606453} pods didn't roll. Remaining seconds for stability: 5
2022-04-02 10:53:59 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-cdd0d513-kafka-2=9630e42a-015b-459d-9426-7c2e337741d9, my-cluster-cdd0d513-kafka-1=6e868b9a-0247-4706-bb11-161272279cde, my-cluster-cdd0d513-kafka-0=6bdd74c6-5b2d-46f6-975b-651b25606453} pods didn't roll. Remaining seconds for stability: 4
2022-04-02 10:54:00 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-cdd0d513-kafka-2=9630e42a-015b-459d-9426-7c2e337741d9, my-cluster-cdd0d513-kafka-1=6e868b9a-0247-4706-bb11-161272279cde, my-cluster-cdd0d513-kafka-0=6bdd74c6-5b2d-46f6-975b-651b25606453} pods didn't roll. Remaining seconds for stability: 3
2022-04-02 10:54:01 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-cdd0d513-kafka-2=9630e42a-015b-459d-9426-7c2e337741d9, my-cluster-cdd0d513-kafka-1=6e868b9a-0247-4706-bb11-161272279cde, my-cluster-cdd0d513-kafka-0=6bdd74c6-5b2d-46f6-975b-651b25606453} pods didn't roll. Remaining seconds for stability: 2
2022-04-02 10:54:02 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-cdd0d513-kafka-2=9630e42a-015b-459d-9426-7c2e337741d9, my-cluster-cdd0d513-kafka-1=6e868b9a-0247-4706-bb11-161272279cde, my-cluster-cdd0d513-kafka-0=6bdd74c6-5b2d-46f6-975b-651b25606453} pods didn't roll. Remaining seconds for stability: 1
2022-04-02 10:54:03 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-cdd0d513-kafka-2=9630e42a-015b-459d-9426-7c2e337741d9, my-cluster-cdd0d513-kafka-1=6e868b9a-0247-4706-bb11-161272279cde, my-cluster-cdd0d513-kafka-0=6bdd74c6-5b2d-46f6-975b-651b25606453} pods didn't roll. Remaining seconds for stability: 0
2022-04-02 10:54:03 [main] [32mINFO [m [CruiseControlConfigurationST:283] Verifying new configuration in the Kafka CR
2022-04-02 10:54:03 [main] [32mINFO [m [CruiseControlConfigurationST:300] Verifying Cruise control performance options are set in Kafka CR
2022-04-02 10:54:03 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 10:54:03 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testConfigurationPerformanceOptions
2022-04-02 10:54:03 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-cdd0d513 in namespace namespace-13
2022-04-02 10:54:03 [main] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-13, for cruise control Kafka cluster my-cluster-cdd0d513
2022-04-02 10:54:13 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 10:54:13 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-13 for test case:testConfigurationPerformanceOptions
2022-04-02 10:54:57 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testConfigurationPerformanceOptions-FINISHED
2022-04-02 10:54:57 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 10:54:57 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 10:54:57 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testConfigurationReflection-STARTED
2022-04-02 10:54:57 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 10:54:57 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-14 for test case:testConfigurationReflection
2022-04-02 10:54:57 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-14
2022-04-02 10:54:57 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-14
2022-04-02 10:54:57 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-14
2022-04-02 10:54:57 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-64dbb741 in namespace namespace-14
2022-04-02 10:54:57 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-14
2022-04-02 10:54:57 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-64dbb741 will have desired state: Ready
2022-04-02 10:56:36 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-64dbb741 is in desired state: Ready
2022-04-02 10:56:36 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-14 exec my-cluster-64dbb741-cruise-control-689965f95b-g5jm5 -- /bin/bash -c cat /tmp/cruisecontrol.properties
2022-04-02 10:56:36 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 10:56:36 [main] [32mINFO [m [CruiseControlConfigurationST:221] Verifying that all configuration in the cruise control container matching the cruise control file /tmp/cruisecontrol.properties properties
2022-04-02 10:56:36 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 10:56:36 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testConfigurationReflection
2022-04-02 10:56:36 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-64dbb741 in namespace namespace-14
2022-04-02 10:56:36 [main] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-14, for cruise control Kafka cluster my-cluster-64dbb741
2022-04-02 10:56:46 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 10:56:46 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-14 for test case:testConfigurationReflection
2022-04-02 10:57:29 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testConfigurationReflection-FINISHED
2022-04-02 10:57:29 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 10:57:29 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 10:57:29 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testConfigurationDiskChangeDoNotTriggersRollingUpdateOfKafkaPods-STARTED
2022-04-02 10:57:29 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 10:57:29 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-15 for test case:testConfigurationDiskChangeDoNotTriggersRollingUpdateOfKafkaPods
2022-04-02 10:57:29 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-15
2022-04-02 10:57:29 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-15
2022-04-02 10:57:29 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-15
2022-04-02 10:57:29 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-0cf7a15d in namespace namespace-15
2022-04-02 10:57:29 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-15
2022-04-02 10:57:29 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-0cf7a15d will have desired state: Ready
2022-04-02 10:59:10 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-0cf7a15d is in desired state: Ready
2022-04-02 10:59:10 [main] [32mINFO [m [CruiseControlConfigurationST:157] Changing the broker capacity of the cruise control
2022-04-02 10:59:10 [main] [32mINFO [m [CruiseControlConfigurationST:168] Verifying that CC pod is rolling, because of change size of disk
2022-04-02 10:59:10 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-0cf7a15d-cruise-control rolling update
2022-04-02 10:59:45 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-0cf7a15d-cruise-control will be ready
2022-04-02 10:59:45 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-0cf7a15d-cruise-control is ready
2022-04-02 10:59:55 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-0cf7a15d-cruise-control rolling update finished
2022-04-02 10:59:55 [main] [32mINFO [m [CruiseControlConfigurationST:171] Verifying that Kafka pods did not roll
2022-04-02 10:59:55 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0cf7a15d-kafka-0=e6c98f34-73c8-40bc-864e-fcd106c01076, my-cluster-0cf7a15d-kafka-2=95ed9cdf-626d-48a0-b625-de9005e6f310, my-cluster-0cf7a15d-kafka-1=4fdeecdc-f37f-4606-b43c-28cc0bd82583} pods didn't roll. Remaining seconds for stability: 50
2022-04-02 10:59:56 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0cf7a15d-kafka-0=e6c98f34-73c8-40bc-864e-fcd106c01076, my-cluster-0cf7a15d-kafka-2=95ed9cdf-626d-48a0-b625-de9005e6f310, my-cluster-0cf7a15d-kafka-1=4fdeecdc-f37f-4606-b43c-28cc0bd82583} pods didn't roll. Remaining seconds for stability: 49
2022-04-02 10:59:57 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0cf7a15d-kafka-0=e6c98f34-73c8-40bc-864e-fcd106c01076, my-cluster-0cf7a15d-kafka-2=95ed9cdf-626d-48a0-b625-de9005e6f310, my-cluster-0cf7a15d-kafka-1=4fdeecdc-f37f-4606-b43c-28cc0bd82583} pods didn't roll. Remaining seconds for stability: 48
2022-04-02 10:59:58 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0cf7a15d-kafka-0=e6c98f34-73c8-40bc-864e-fcd106c01076, my-cluster-0cf7a15d-kafka-2=95ed9cdf-626d-48a0-b625-de9005e6f310, my-cluster-0cf7a15d-kafka-1=4fdeecdc-f37f-4606-b43c-28cc0bd82583} pods didn't roll. Remaining seconds for stability: 47
2022-04-02 10:59:59 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0cf7a15d-kafka-0=e6c98f34-73c8-40bc-864e-fcd106c01076, my-cluster-0cf7a15d-kafka-2=95ed9cdf-626d-48a0-b625-de9005e6f310, my-cluster-0cf7a15d-kafka-1=4fdeecdc-f37f-4606-b43c-28cc0bd82583} pods didn't roll. Remaining seconds for stability: 46
2022-04-02 11:00:00 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0cf7a15d-kafka-0=e6c98f34-73c8-40bc-864e-fcd106c01076, my-cluster-0cf7a15d-kafka-2=95ed9cdf-626d-48a0-b625-de9005e6f310, my-cluster-0cf7a15d-kafka-1=4fdeecdc-f37f-4606-b43c-28cc0bd82583} pods didn't roll. Remaining seconds for stability: 45
2022-04-02 11:00:01 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0cf7a15d-kafka-0=e6c98f34-73c8-40bc-864e-fcd106c01076, my-cluster-0cf7a15d-kafka-2=95ed9cdf-626d-48a0-b625-de9005e6f310, my-cluster-0cf7a15d-kafka-1=4fdeecdc-f37f-4606-b43c-28cc0bd82583} pods didn't roll. Remaining seconds for stability: 44
2022-04-02 11:00:02 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0cf7a15d-kafka-0=e6c98f34-73c8-40bc-864e-fcd106c01076, my-cluster-0cf7a15d-kafka-2=95ed9cdf-626d-48a0-b625-de9005e6f310, my-cluster-0cf7a15d-kafka-1=4fdeecdc-f37f-4606-b43c-28cc0bd82583} pods didn't roll. Remaining seconds for stability: 43
2022-04-02 11:00:03 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0cf7a15d-kafka-0=e6c98f34-73c8-40bc-864e-fcd106c01076, my-cluster-0cf7a15d-kafka-2=95ed9cdf-626d-48a0-b625-de9005e6f310, my-cluster-0cf7a15d-kafka-1=4fdeecdc-f37f-4606-b43c-28cc0bd82583} pods didn't roll. Remaining seconds for stability: 42
2022-04-02 11:00:04 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0cf7a15d-kafka-0=e6c98f34-73c8-40bc-864e-fcd106c01076, my-cluster-0cf7a15d-kafka-2=95ed9cdf-626d-48a0-b625-de9005e6f310, my-cluster-0cf7a15d-kafka-1=4fdeecdc-f37f-4606-b43c-28cc0bd82583} pods didn't roll. Remaining seconds for stability: 41
2022-04-02 11:00:05 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0cf7a15d-kafka-0=e6c98f34-73c8-40bc-864e-fcd106c01076, my-cluster-0cf7a15d-kafka-2=95ed9cdf-626d-48a0-b625-de9005e6f310, my-cluster-0cf7a15d-kafka-1=4fdeecdc-f37f-4606-b43c-28cc0bd82583} pods didn't roll. Remaining seconds for stability: 40
2022-04-02 11:00:06 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0cf7a15d-kafka-0=e6c98f34-73c8-40bc-864e-fcd106c01076, my-cluster-0cf7a15d-kafka-2=95ed9cdf-626d-48a0-b625-de9005e6f310, my-cluster-0cf7a15d-kafka-1=4fdeecdc-f37f-4606-b43c-28cc0bd82583} pods didn't roll. Remaining seconds for stability: 39
2022-04-02 11:00:07 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0cf7a15d-kafka-0=e6c98f34-73c8-40bc-864e-fcd106c01076, my-cluster-0cf7a15d-kafka-2=95ed9cdf-626d-48a0-b625-de9005e6f310, my-cluster-0cf7a15d-kafka-1=4fdeecdc-f37f-4606-b43c-28cc0bd82583} pods didn't roll. Remaining seconds for stability: 38
2022-04-02 11:00:08 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0cf7a15d-kafka-0=e6c98f34-73c8-40bc-864e-fcd106c01076, my-cluster-0cf7a15d-kafka-2=95ed9cdf-626d-48a0-b625-de9005e6f310, my-cluster-0cf7a15d-kafka-1=4fdeecdc-f37f-4606-b43c-28cc0bd82583} pods didn't roll. Remaining seconds for stability: 37
2022-04-02 11:00:09 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0cf7a15d-kafka-0=e6c98f34-73c8-40bc-864e-fcd106c01076, my-cluster-0cf7a15d-kafka-2=95ed9cdf-626d-48a0-b625-de9005e6f310, my-cluster-0cf7a15d-kafka-1=4fdeecdc-f37f-4606-b43c-28cc0bd82583} pods didn't roll. Remaining seconds for stability: 36
2022-04-02 11:00:10 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0cf7a15d-kafka-0=e6c98f34-73c8-40bc-864e-fcd106c01076, my-cluster-0cf7a15d-kafka-2=95ed9cdf-626d-48a0-b625-de9005e6f310, my-cluster-0cf7a15d-kafka-1=4fdeecdc-f37f-4606-b43c-28cc0bd82583} pods didn't roll. Remaining seconds for stability: 35
2022-04-02 11:00:11 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0cf7a15d-kafka-0=e6c98f34-73c8-40bc-864e-fcd106c01076, my-cluster-0cf7a15d-kafka-2=95ed9cdf-626d-48a0-b625-de9005e6f310, my-cluster-0cf7a15d-kafka-1=4fdeecdc-f37f-4606-b43c-28cc0bd82583} pods didn't roll. Remaining seconds for stability: 34
2022-04-02 11:00:12 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0cf7a15d-kafka-0=e6c98f34-73c8-40bc-864e-fcd106c01076, my-cluster-0cf7a15d-kafka-2=95ed9cdf-626d-48a0-b625-de9005e6f310, my-cluster-0cf7a15d-kafka-1=4fdeecdc-f37f-4606-b43c-28cc0bd82583} pods didn't roll. Remaining seconds for stability: 33
2022-04-02 11:00:13 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0cf7a15d-kafka-0=e6c98f34-73c8-40bc-864e-fcd106c01076, my-cluster-0cf7a15d-kafka-2=95ed9cdf-626d-48a0-b625-de9005e6f310, my-cluster-0cf7a15d-kafka-1=4fdeecdc-f37f-4606-b43c-28cc0bd82583} pods didn't roll. Remaining seconds for stability: 32
2022-04-02 11:00:14 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0cf7a15d-kafka-0=e6c98f34-73c8-40bc-864e-fcd106c01076, my-cluster-0cf7a15d-kafka-2=95ed9cdf-626d-48a0-b625-de9005e6f310, my-cluster-0cf7a15d-kafka-1=4fdeecdc-f37f-4606-b43c-28cc0bd82583} pods didn't roll. Remaining seconds for stability: 31
2022-04-02 11:00:15 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0cf7a15d-kafka-0=e6c98f34-73c8-40bc-864e-fcd106c01076, my-cluster-0cf7a15d-kafka-2=95ed9cdf-626d-48a0-b625-de9005e6f310, my-cluster-0cf7a15d-kafka-1=4fdeecdc-f37f-4606-b43c-28cc0bd82583} pods didn't roll. Remaining seconds for stability: 30
2022-04-02 11:00:16 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0cf7a15d-kafka-0=e6c98f34-73c8-40bc-864e-fcd106c01076, my-cluster-0cf7a15d-kafka-2=95ed9cdf-626d-48a0-b625-de9005e6f310, my-cluster-0cf7a15d-kafka-1=4fdeecdc-f37f-4606-b43c-28cc0bd82583} pods didn't roll. Remaining seconds for stability: 29
2022-04-02 11:00:17 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0cf7a15d-kafka-0=e6c98f34-73c8-40bc-864e-fcd106c01076, my-cluster-0cf7a15d-kafka-2=95ed9cdf-626d-48a0-b625-de9005e6f310, my-cluster-0cf7a15d-kafka-1=4fdeecdc-f37f-4606-b43c-28cc0bd82583} pods didn't roll. Remaining seconds for stability: 28
2022-04-02 11:00:18 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0cf7a15d-kafka-0=e6c98f34-73c8-40bc-864e-fcd106c01076, my-cluster-0cf7a15d-kafka-2=95ed9cdf-626d-48a0-b625-de9005e6f310, my-cluster-0cf7a15d-kafka-1=4fdeecdc-f37f-4606-b43c-28cc0bd82583} pods didn't roll. Remaining seconds for stability: 27
2022-04-02 11:00:19 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0cf7a15d-kafka-0=e6c98f34-73c8-40bc-864e-fcd106c01076, my-cluster-0cf7a15d-kafka-2=95ed9cdf-626d-48a0-b625-de9005e6f310, my-cluster-0cf7a15d-kafka-1=4fdeecdc-f37f-4606-b43c-28cc0bd82583} pods didn't roll. Remaining seconds for stability: 26
2022-04-02 11:00:20 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0cf7a15d-kafka-0=e6c98f34-73c8-40bc-864e-fcd106c01076, my-cluster-0cf7a15d-kafka-2=95ed9cdf-626d-48a0-b625-de9005e6f310, my-cluster-0cf7a15d-kafka-1=4fdeecdc-f37f-4606-b43c-28cc0bd82583} pods didn't roll. Remaining seconds for stability: 25
2022-04-02 11:00:21 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0cf7a15d-kafka-0=e6c98f34-73c8-40bc-864e-fcd106c01076, my-cluster-0cf7a15d-kafka-2=95ed9cdf-626d-48a0-b625-de9005e6f310, my-cluster-0cf7a15d-kafka-1=4fdeecdc-f37f-4606-b43c-28cc0bd82583} pods didn't roll. Remaining seconds for stability: 24
2022-04-02 11:00:22 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0cf7a15d-kafka-0=e6c98f34-73c8-40bc-864e-fcd106c01076, my-cluster-0cf7a15d-kafka-2=95ed9cdf-626d-48a0-b625-de9005e6f310, my-cluster-0cf7a15d-kafka-1=4fdeecdc-f37f-4606-b43c-28cc0bd82583} pods didn't roll. Remaining seconds for stability: 23
2022-04-02 11:00:23 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0cf7a15d-kafka-0=e6c98f34-73c8-40bc-864e-fcd106c01076, my-cluster-0cf7a15d-kafka-2=95ed9cdf-626d-48a0-b625-de9005e6f310, my-cluster-0cf7a15d-kafka-1=4fdeecdc-f37f-4606-b43c-28cc0bd82583} pods didn't roll. Remaining seconds for stability: 22
2022-04-02 11:00:24 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0cf7a15d-kafka-0=e6c98f34-73c8-40bc-864e-fcd106c01076, my-cluster-0cf7a15d-kafka-2=95ed9cdf-626d-48a0-b625-de9005e6f310, my-cluster-0cf7a15d-kafka-1=4fdeecdc-f37f-4606-b43c-28cc0bd82583} pods didn't roll. Remaining seconds for stability: 21
2022-04-02 11:00:25 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0cf7a15d-kafka-0=e6c98f34-73c8-40bc-864e-fcd106c01076, my-cluster-0cf7a15d-kafka-2=95ed9cdf-626d-48a0-b625-de9005e6f310, my-cluster-0cf7a15d-kafka-1=4fdeecdc-f37f-4606-b43c-28cc0bd82583} pods didn't roll. Remaining seconds for stability: 20
2022-04-02 11:00:26 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0cf7a15d-kafka-0=e6c98f34-73c8-40bc-864e-fcd106c01076, my-cluster-0cf7a15d-kafka-2=95ed9cdf-626d-48a0-b625-de9005e6f310, my-cluster-0cf7a15d-kafka-1=4fdeecdc-f37f-4606-b43c-28cc0bd82583} pods didn't roll. Remaining seconds for stability: 19
2022-04-02 11:00:27 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0cf7a15d-kafka-0=e6c98f34-73c8-40bc-864e-fcd106c01076, my-cluster-0cf7a15d-kafka-2=95ed9cdf-626d-48a0-b625-de9005e6f310, my-cluster-0cf7a15d-kafka-1=4fdeecdc-f37f-4606-b43c-28cc0bd82583} pods didn't roll. Remaining seconds for stability: 18
2022-04-02 11:00:28 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0cf7a15d-kafka-0=e6c98f34-73c8-40bc-864e-fcd106c01076, my-cluster-0cf7a15d-kafka-2=95ed9cdf-626d-48a0-b625-de9005e6f310, my-cluster-0cf7a15d-kafka-1=4fdeecdc-f37f-4606-b43c-28cc0bd82583} pods didn't roll. Remaining seconds for stability: 17
2022-04-02 11:00:29 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0cf7a15d-kafka-0=e6c98f34-73c8-40bc-864e-fcd106c01076, my-cluster-0cf7a15d-kafka-2=95ed9cdf-626d-48a0-b625-de9005e6f310, my-cluster-0cf7a15d-kafka-1=4fdeecdc-f37f-4606-b43c-28cc0bd82583} pods didn't roll. Remaining seconds for stability: 16
2022-04-02 11:00:30 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0cf7a15d-kafka-0=e6c98f34-73c8-40bc-864e-fcd106c01076, my-cluster-0cf7a15d-kafka-2=95ed9cdf-626d-48a0-b625-de9005e6f310, my-cluster-0cf7a15d-kafka-1=4fdeecdc-f37f-4606-b43c-28cc0bd82583} pods didn't roll. Remaining seconds for stability: 15
2022-04-02 11:00:31 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0cf7a15d-kafka-0=e6c98f34-73c8-40bc-864e-fcd106c01076, my-cluster-0cf7a15d-kafka-2=95ed9cdf-626d-48a0-b625-de9005e6f310, my-cluster-0cf7a15d-kafka-1=4fdeecdc-f37f-4606-b43c-28cc0bd82583} pods didn't roll. Remaining seconds for stability: 14
2022-04-02 11:00:32 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0cf7a15d-kafka-0=e6c98f34-73c8-40bc-864e-fcd106c01076, my-cluster-0cf7a15d-kafka-2=95ed9cdf-626d-48a0-b625-de9005e6f310, my-cluster-0cf7a15d-kafka-1=4fdeecdc-f37f-4606-b43c-28cc0bd82583} pods didn't roll. Remaining seconds for stability: 13
2022-04-02 11:00:33 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0cf7a15d-kafka-0=e6c98f34-73c8-40bc-864e-fcd106c01076, my-cluster-0cf7a15d-kafka-2=95ed9cdf-626d-48a0-b625-de9005e6f310, my-cluster-0cf7a15d-kafka-1=4fdeecdc-f37f-4606-b43c-28cc0bd82583} pods didn't roll. Remaining seconds for stability: 12
2022-04-02 11:00:34 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0cf7a15d-kafka-0=e6c98f34-73c8-40bc-864e-fcd106c01076, my-cluster-0cf7a15d-kafka-2=95ed9cdf-626d-48a0-b625-de9005e6f310, my-cluster-0cf7a15d-kafka-1=4fdeecdc-f37f-4606-b43c-28cc0bd82583} pods didn't roll. Remaining seconds for stability: 11
2022-04-02 11:00:35 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0cf7a15d-kafka-0=e6c98f34-73c8-40bc-864e-fcd106c01076, my-cluster-0cf7a15d-kafka-2=95ed9cdf-626d-48a0-b625-de9005e6f310, my-cluster-0cf7a15d-kafka-1=4fdeecdc-f37f-4606-b43c-28cc0bd82583} pods didn't roll. Remaining seconds for stability: 10
2022-04-02 11:00:36 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0cf7a15d-kafka-0=e6c98f34-73c8-40bc-864e-fcd106c01076, my-cluster-0cf7a15d-kafka-2=95ed9cdf-626d-48a0-b625-de9005e6f310, my-cluster-0cf7a15d-kafka-1=4fdeecdc-f37f-4606-b43c-28cc0bd82583} pods didn't roll. Remaining seconds for stability: 9
2022-04-02 11:00:37 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0cf7a15d-kafka-0=e6c98f34-73c8-40bc-864e-fcd106c01076, my-cluster-0cf7a15d-kafka-2=95ed9cdf-626d-48a0-b625-de9005e6f310, my-cluster-0cf7a15d-kafka-1=4fdeecdc-f37f-4606-b43c-28cc0bd82583} pods didn't roll. Remaining seconds for stability: 8
2022-04-02 11:00:38 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0cf7a15d-kafka-0=e6c98f34-73c8-40bc-864e-fcd106c01076, my-cluster-0cf7a15d-kafka-2=95ed9cdf-626d-48a0-b625-de9005e6f310, my-cluster-0cf7a15d-kafka-1=4fdeecdc-f37f-4606-b43c-28cc0bd82583} pods didn't roll. Remaining seconds for stability: 7
2022-04-02 11:00:39 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0cf7a15d-kafka-0=e6c98f34-73c8-40bc-864e-fcd106c01076, my-cluster-0cf7a15d-kafka-2=95ed9cdf-626d-48a0-b625-de9005e6f310, my-cluster-0cf7a15d-kafka-1=4fdeecdc-f37f-4606-b43c-28cc0bd82583} pods didn't roll. Remaining seconds for stability: 6
2022-04-02 11:00:40 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0cf7a15d-kafka-0=e6c98f34-73c8-40bc-864e-fcd106c01076, my-cluster-0cf7a15d-kafka-2=95ed9cdf-626d-48a0-b625-de9005e6f310, my-cluster-0cf7a15d-kafka-1=4fdeecdc-f37f-4606-b43c-28cc0bd82583} pods didn't roll. Remaining seconds for stability: 5
2022-04-02 11:00:41 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0cf7a15d-kafka-0=e6c98f34-73c8-40bc-864e-fcd106c01076, my-cluster-0cf7a15d-kafka-2=95ed9cdf-626d-48a0-b625-de9005e6f310, my-cluster-0cf7a15d-kafka-1=4fdeecdc-f37f-4606-b43c-28cc0bd82583} pods didn't roll. Remaining seconds for stability: 4
2022-04-02 11:00:42 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0cf7a15d-kafka-0=e6c98f34-73c8-40bc-864e-fcd106c01076, my-cluster-0cf7a15d-kafka-2=95ed9cdf-626d-48a0-b625-de9005e6f310, my-cluster-0cf7a15d-kafka-1=4fdeecdc-f37f-4606-b43c-28cc0bd82583} pods didn't roll. Remaining seconds for stability: 3
2022-04-02 11:00:43 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0cf7a15d-kafka-0=e6c98f34-73c8-40bc-864e-fcd106c01076, my-cluster-0cf7a15d-kafka-2=95ed9cdf-626d-48a0-b625-de9005e6f310, my-cluster-0cf7a15d-kafka-1=4fdeecdc-f37f-4606-b43c-28cc0bd82583} pods didn't roll. Remaining seconds for stability: 2
2022-04-02 11:00:44 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0cf7a15d-kafka-0=e6c98f34-73c8-40bc-864e-fcd106c01076, my-cluster-0cf7a15d-kafka-2=95ed9cdf-626d-48a0-b625-de9005e6f310, my-cluster-0cf7a15d-kafka-1=4fdeecdc-f37f-4606-b43c-28cc0bd82583} pods didn't roll. Remaining seconds for stability: 1
2022-04-02 11:00:45 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0cf7a15d-kafka-0=e6c98f34-73c8-40bc-864e-fcd106c01076, my-cluster-0cf7a15d-kafka-2=95ed9cdf-626d-48a0-b625-de9005e6f310, my-cluster-0cf7a15d-kafka-1=4fdeecdc-f37f-4606-b43c-28cc0bd82583} pods didn't roll. Remaining seconds for stability: 0
2022-04-02 11:00:45 [main] [32mINFO [m [CruiseControlConfigurationST:174] Verifying new configuration in the Kafka CR
2022-04-02 11:00:45 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 11:00:45 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testConfigurationDiskChangeDoNotTriggersRollingUpdateOfKafkaPods
2022-04-02 11:00:45 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-0cf7a15d in namespace namespace-15
2022-04-02 11:00:45 [main] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-15, for cruise control Kafka cluster my-cluster-0cf7a15d
2022-04-02 11:00:55 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 11:00:55 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-15 for test case:testConfigurationDiskChangeDoNotTriggersRollingUpdateOfKafkaPods
2022-04-02 11:01:32 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testConfigurationDiskChangeDoNotTriggersRollingUpdateOfKafkaPods-FINISHED
2022-04-02 11:01:32 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 11:01:32 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 11:01:32 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testCapacityFile-STARTED
2022-04-02 11:01:32 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 11:01:32 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-16 for test case:testCapacityFile
2022-04-02 11:01:32 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-16
2022-04-02 11:01:32 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-16
2022-04-02 11:01:32 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-16
2022-04-02 11:01:32 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-f6a64b1f in namespace namespace-16
2022-04-02 11:01:32 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-16
2022-04-02 11:01:32 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-f6a64b1f will have desired state: Ready
2022-04-02 11:03:16 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-f6a64b1f is in desired state: Ready
2022-04-02 11:03:16 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-16 exec my-cluster-f6a64b1f-cruise-control-9ddb74f8f-p5s6h -- /bin/bash -c cat /tmp/capacity.json
2022-04-02 11:03:16 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 11:03:16 [main] [32mINFO [m [CruiseControlConfigurationST:80] We got only one configuration of broker-capacities
2022-04-02 11:03:16 [main] [32mINFO [m [CruiseControlConfigurationST:83] Verifying cruise control configuration.
2022-04-02 11:03:16 [main] [32mINFO [m [CruiseControlConfigurationST:92] Verifying default cruise control capacities
2022-04-02 11:03:16 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 11:03:16 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCapacityFile
2022-04-02 11:03:16 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-f6a64b1f in namespace namespace-16
2022-04-02 11:03:16 [main] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-16, for cruise control Kafka cluster my-cluster-f6a64b1f
2022-04-02 11:03:27 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 11:03:27 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-16 for test case:testCapacityFile
2022-04-02 11:04:10 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testCapacityFile-FINISHED
2022-04-02 11:04:10 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 11:04:10 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 11:04:10 [main] [32mINFO [m [ResourceManager:346] In context CruiseControlConfigurationST is everything deleted.
2022-04-02 11:04:10 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1,464.904 s - in io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST
[[1;34mINFO[m] Running io.strimzi.systemtest.cruisecontrol.CruiseControlST
2022-04-02 11:04:15 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: cruise-control-st
2022-04-02 11:04:15 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: cruise-control-st
2022-04-02 11:04:15 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: cruise-control-st
2022-04-02 11:04:15 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 11:04:15 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlTopicExclusion-STARTED
2022-04-02 11:04:15 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 11:04:15 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-17 for test case:testCruiseControlTopicExclusion
2022-04-02 11:04:15 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-17
2022-04-02 11:04:15 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-17
2022-04-02 11:04:15 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-17
2022-04-02 11:04:15 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-1c29fbc5 in namespace namespace-17
2022-04-02 11:04:15 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-17
2022-04-02 11:04:15 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-1c29fbc5 will have desired state: Ready
2022-04-02 11:06:00 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-1c29fbc5 is in desired state: Ready
2022-04-02 11:06:00 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic excluded-topic-1 in namespace namespace-17
2022-04-02 11:06:00 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-17
2022-04-02 11:06:00 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: excluded-topic-1 will have desired state: Ready
2022-04-02 11:06:01 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: excluded-topic-1 is in desired state: Ready
2022-04-02 11:06:01 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic excluded-topic-2 in namespace namespace-17
2022-04-02 11:06:01 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-17
2022-04-02 11:06:01 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: excluded-topic-2 will have desired state: Ready
2022-04-02 11:06:02 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: excluded-topic-2 is in desired state: Ready
2022-04-02 11:06:02 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic included-topic in namespace namespace-17
2022-04-02 11:06:02 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-17
2022-04-02 11:06:02 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: included-topic will have desired state: Ready
2022-04-02 11:06:03 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: included-topic is in desired state: Ready
2022-04-02 11:06:03 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaRebalance my-cluster-1c29fbc5 in namespace namespace-17
2022-04-02 11:06:03 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-17
2022-04-02 11:06:03 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-1c29fbc5 will have desired state: PendingProposal
2022-04-02 11:06:04 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-1c29fbc5 is in desired state: PendingProposal
2022-04-02 11:06:04 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-1c29fbc5 will have desired state: ProposalReady
2022-04-02 11:11:49 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-1c29fbc5 is in desired state: ProposalReady
2022-04-02 11:11:49 [main] [32mINFO [m [CruiseControlST:208] Checking status of KafkaRebalance
2022-04-02 11:11:49 [main] [32mINFO [m [KafkaRebalanceUtils:63] Reconciliation #4(test) KafkaRebalance(cruise-control-st/my-cluster-1c29fbc5): Annotating KafkaRebalance:my-cluster-1c29fbc5 with annotation approve
2022-04-02 11:11:49 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-1c29fbc5 will have desired state: Ready
2022-04-02 11:13:24 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-1c29fbc5 is in desired state: Ready
2022-04-02 11:13:24 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 11:13:24 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCruiseControlTopicExclusion
2022-04-02 11:13:24 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic excluded-topic-2 in namespace namespace-17
2022-04-02 11:13:24 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaRebalance my-cluster-1c29fbc5 in namespace namespace-17
2022-04-02 11:13:24 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-1c29fbc5 in namespace namespace-17
2022-04-02 11:13:24 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic excluded-topic-1 in namespace namespace-17
2022-04-02 11:13:24 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-17, for cruise control Kafka cluster my-cluster-1c29fbc5
2022-04-02 11:13:24 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic included-topic in namespace namespace-17
2022-04-02 11:13:34 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 11:13:34 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-17 for test case:testCruiseControlTopicExclusion
2022-04-02 11:14:17 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlTopicExclusion-FINISHED
2022-04-02 11:14:17 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 11:14:17 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 11:14:17 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlIntraBrokerBalancingWithoutSpecifyingJBODStorage-STARTED
2022-04-02 11:14:17 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 11:14:17 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-18 for test case:testCruiseControlIntraBrokerBalancingWithoutSpecifyingJBODStorage
2022-04-02 11:14:17 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-18
2022-04-02 11:14:17 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-18
2022-04-02 11:14:17 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-18
2022-04-02 11:14:17 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-d6e18ab7 in namespace namespace-18
2022-04-02 11:14:17 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-18
2022-04-02 11:14:17 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d6e18ab7 will have desired state: Ready
2022-04-02 11:15:57 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d6e18ab7 is in desired state: Ready
2022-04-02 11:15:57 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaRebalance my-cluster-d6e18ab7 in namespace namespace-18
2022-04-02 11:15:57 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-18
2022-04-02 11:15:57 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-d6e18ab7 will have desired state: NotReady
2022-04-02 11:15:58 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-d6e18ab7 is in desired state: NotReady
2022-04-02 11:15:58 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 11:15:58 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCruiseControlIntraBrokerBalancingWithoutSpecifyingJBODStorage
2022-04-02 11:15:58 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaRebalance my-cluster-d6e18ab7 in namespace namespace-18
2022-04-02 11:15:58 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-d6e18ab7 in namespace namespace-18
2022-04-02 11:15:58 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-18, for cruise control Kafka cluster my-cluster-d6e18ab7
2022-04-02 11:16:08 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 11:16:08 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-18 for test case:testCruiseControlIntraBrokerBalancingWithoutSpecifyingJBODStorage
2022-04-02 11:16:51 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlIntraBrokerBalancingWithoutSpecifyingJBODStorage-FINISHED
2022-04-02 11:16:51 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 11:16:51 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 11:16:51 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testAutoCreationOfCruiseControlTopics-STARTED
2022-04-02 11:16:51 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 11:16:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-be1c0202 in namespace cruise-control-st
2022-04-02 11:16:51 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-be1c0202 will have desired state: Ready
2022-04-02 11:18:31 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-be1c0202 is in desired state: Ready
2022-04-02 11:18:31 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: strimzi.cruisecontrol.metrics will have desired state: Ready
2022-04-02 11:18:31 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: strimzi.cruisecontrol.metrics is in desired state: Ready
2022-04-02 11:18:31 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: strimzi.cruisecontrol.modeltrainingsamples will have desired state: Ready
2022-04-02 11:18:31 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: strimzi.cruisecontrol.modeltrainingsamples is in desired state: Ready
2022-04-02 11:18:31 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: strimzi.cruisecontrol.partitionmetricsamples will have desired state: Ready
2022-04-02 11:18:31 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: strimzi.cruisecontrol.partitionmetricsamples is in desired state: Ready
2022-04-02 11:18:31 [main] [32mINFO [m [CruiseControlST:96] Checking partitions and replicas for strimzi.cruisecontrol.metrics
2022-04-02 11:18:31 [main] [32mINFO [m [CruiseControlST:100] Checking partitions and replicas for strimzi.cruisecontrol.modeltrainingsamples
2022-04-02 11:18:31 [main] [32mINFO [m [CruiseControlST:104] Checking partitions and replicas for strimzi.cruisecontrol.partitionmetricsamples
2022-04-02 11:18:31 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 11:18:31 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAutoCreationOfCruiseControlTopics
2022-04-02 11:18:31 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-be1c0202 in namespace cruise-control-st
2022-04-02 11:18:31 [main] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace cruise-control-st, for cruise control Kafka cluster my-cluster-be1c0202
2022-04-02 11:18:41 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 11:18:41 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testAutoCreationOfCruiseControlTopics-FINISHED
2022-04-02 11:18:41 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 11:18:41 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 11:18:41 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlReplicaMovementStrategy-STARTED
2022-04-02 11:18:41 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 11:18:41 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-19 for test case:testCruiseControlReplicaMovementStrategy
2022-04-02 11:18:41 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-19
2022-04-02 11:18:41 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-19
2022-04-02 11:18:41 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-19
2022-04-02 11:18:41 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-e200c2be in namespace namespace-19
2022-04-02 11:18:41 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-19
2022-04-02 11:18:41 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-e200c2be will have desired state: Ready
2022-04-02 11:21:18 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-e200c2be is in desired state: Ready
2022-04-02 11:21:18 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-e200c2be-kafka-clients in namespace namespace-19
2022-04-02 11:21:18 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-19
2022-04-02 11:21:18 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-e200c2be-kafka-clients will be ready
2022-04-02 11:21:20 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-e200c2be-kafka-clients is ready
2022-04-02 11:21:20 [main] [32mINFO [m [CruiseControlST:234] Check for default CruiseControl replicaMovementStrategy in pod configuration file.
2022-04-02 11:21:20 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-19 exec my-cluster-e200c2be-cruise-control-75c4b748c7-5kfzn -c cruise-control -- cat /tmp/cruisecontrol.properties
2022-04-02 11:21:20 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 11:21:20 [main] [32mINFO [m [CruiseControlST:248] Set non-default CruiseControl replicaMovementStrategies to KafkaRebalance resource.
2022-04-02 11:21:20 [main] [32mINFO [m [CruiseControlST:252] Verifying that CC pod is rolling, because of change size of disk
2022-04-02 11:21:20 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-e200c2be-cruise-control rolling update
2022-04-02 11:21:55 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-e200c2be-cruise-control will be ready
2022-04-02 11:21:55 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-e200c2be-cruise-control is ready
2022-04-02 11:22:05 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-e200c2be-cruise-control rolling update finished
2022-04-02 11:22:05 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-19 exec my-cluster-e200c2be-cruise-control-679cc8dd89-d97rp -c cruise-control -- cat /tmp/cruisecontrol.properties
2022-04-02 11:22:05 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 11:22:05 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 11:22:05 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCruiseControlReplicaMovementStrategy
2022-04-02 11:22:05 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-e200c2be-kafka-clients in namespace namespace-19
2022-04-02 11:22:05 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-e200c2be in namespace namespace-19
2022-04-02 11:22:05 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-19, for cruise control Kafka cluster my-cluster-e200c2be
2022-04-02 11:22:55 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 11:22:55 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-19 for test case:testCruiseControlReplicaMovementStrategy
2022-04-02 11:23:01 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlReplicaMovementStrategy-FINISHED
2022-04-02 11:23:01 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 11:23:01 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 11:23:01 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlWithSingleNodeKafka-STARTED
2022-04-02 11:23:01 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 11:23:01 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-20 for test case:testCruiseControlWithSingleNodeKafka
2022-04-02 11:23:01 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-20
2022-04-02 11:23:01 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-20
2022-04-02 11:23:01 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-20
2022-04-02 11:23:01 [main] [32mINFO [m [CruiseControlST:169] Deploying single node Kafka with CruiseControl
2022-04-02 11:23:01 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-ac0ad488 in namespace namespace-20
2022-04-02 11:23:01 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-20
2022-04-02 11:23:03 [main] [32mINFO [m [CruiseControlST:178] Increasing Kafka nodes to 3
2022-04-02 11:23:03 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-ac0ad488 will have desired state: Ready
2022-04-02 11:24:34 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-ac0ad488 is in desired state: Ready
2022-04-02 11:24:34 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 11:24:34 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCruiseControlWithSingleNodeKafka
2022-04-02 11:24:34 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-ac0ad488 in namespace namespace-20
2022-04-02 11:24:34 [main] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-20, for cruise control Kafka cluster my-cluster-ac0ad488
2022-04-02 11:24:44 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 11:24:44 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-20 for test case:testCruiseControlWithSingleNodeKafka
2022-04-02 11:25:28 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlWithSingleNodeKafka-FINISHED
2022-04-02 11:25:28 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 11:25:28 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 11:25:28 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlWithRebalanceResourceAndRefreshAnnotation-STARTED
2022-04-02 11:25:28 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 11:25:28 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-003effe3 in namespace cruise-control-st
2022-04-02 11:25:28 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-003effe3 will have desired state: Ready
2022-04-02 11:27:09 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-003effe3 is in desired state: Ready
2022-04-02 11:27:09 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaRebalance my-cluster-003effe3 in namespace cruise-control-st
2022-04-02 11:27:09 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-003effe3 will have desired state: PendingProposal
2022-04-02 11:27:10 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-003effe3 is in desired state: PendingProposal
2022-04-02 11:27:10 [main] [32mINFO [m [KafkaRebalanceUtils:75] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-003effe3): ============================================================================
2022-04-02 11:27:10 [main] [32mINFO [m [KafkaRebalanceUtils:76] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-003effe3): PendingProposal
2022-04-02 11:27:10 [main] [32mINFO [m [KafkaRebalanceUtils:77] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-003effe3): ============================================================================
2022-04-02 11:27:10 [main] [32mINFO [m [KafkaRebalanceUtils:81] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-003effe3): Verifying that KafkaRebalance resource is in PendingProposal state
2022-04-02 11:27:10 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-003effe3 will have desired state: PendingProposal
2022-04-02 11:27:10 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-003effe3 is in desired state: PendingProposal
2022-04-02 11:27:10 [main] [32mINFO [m [KafkaRebalanceUtils:85] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-003effe3): Verifying that KafkaRebalance resource is in ProposalReady state
2022-04-02 11:27:10 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-003effe3 will have desired state: ProposalReady
2022-04-02 11:31:00 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-003effe3 is in desired state: ProposalReady
2022-04-02 11:31:00 [main] [32mINFO [m [KafkaRebalanceUtils:90] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-003effe3): ============================================================================
2022-04-02 11:31:00 [main] [32mINFO [m [KafkaRebalanceUtils:91] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-003effe3): ProposalReady
2022-04-02 11:31:00 [main] [32mINFO [m [KafkaRebalanceUtils:92] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-003effe3): ============================================================================
2022-04-02 11:31:00 [main] [32mINFO [m [KafkaRebalanceUtils:94] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-003effe3): Triggering the rebalance with annotation strimzi.io/rebalance=approve of KafkaRebalance resource
2022-04-02 11:31:00 [main] [32mINFO [m [KafkaRebalanceUtils:63] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-003effe3): Annotating KafkaRebalance:my-cluster-003effe3 with annotation approve
2022-04-02 11:31:00 [main] [32mINFO [m [KafkaRebalanceUtils:98] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-003effe3): Response from the annotation process kafkarebalance.kafka.strimzi.io/my-cluster-003effe3 annotated
2022-04-02 11:31:00 [main] [32mINFO [m [KafkaRebalanceUtils:100] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-003effe3): Verifying that annotation triggers the Rebalancing state
2022-04-02 11:31:00 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-003effe3 will have desired state: Rebalancing
2022-04-02 11:31:01 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-003effe3 is in desired state: Rebalancing
2022-04-02 11:31:01 [main] [32mINFO [m [KafkaRebalanceUtils:104] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-003effe3): Verifying that KafkaRebalance is in the Ready state
2022-04-02 11:31:01 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-003effe3 will have desired state: Ready
2022-04-02 11:32:06 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-003effe3 is in desired state: Ready
2022-04-02 11:32:06 [main] [32mINFO [m [CruiseControlST:152] Annotating KafkaRebalance: my-cluster-003effe3 with 'refresh' anno
2022-04-02 11:32:06 [main] [32mINFO [m [KafkaRebalanceUtils:63] Reconciliation #6(test) KafkaRebalance(cruise-control-st/my-cluster-003effe3): Annotating KafkaRebalance:my-cluster-003effe3 with annotation refresh
2022-04-02 11:32:06 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-003effe3 will have desired state: ProposalReady
2022-04-02 11:32:07 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-003effe3 is in desired state: ProposalReady
2022-04-02 11:32:07 [main] [32mINFO [m [CruiseControlST:156] Trying rebalancing process again
2022-04-02 11:32:07 [main] [32mINFO [m [KafkaRebalanceUtils:75] Reconciliation #7(test) KafkaRebalance(cruise-control-st/my-cluster-003effe3): ============================================================================
2022-04-02 11:32:07 [main] [32mINFO [m [KafkaRebalanceUtils:76] Reconciliation #7(test) KafkaRebalance(cruise-control-st/my-cluster-003effe3): ProposalReady
2022-04-02 11:32:07 [main] [32mINFO [m [KafkaRebalanceUtils:77] Reconciliation #7(test) KafkaRebalance(cruise-control-st/my-cluster-003effe3): ============================================================================
2022-04-02 11:32:07 [main] [32mINFO [m [KafkaRebalanceUtils:90] Reconciliation #7(test) KafkaRebalance(cruise-control-st/my-cluster-003effe3): ============================================================================
2022-04-02 11:32:07 [main] [32mINFO [m [KafkaRebalanceUtils:91] Reconciliation #7(test) KafkaRebalance(cruise-control-st/my-cluster-003effe3): ProposalReady
2022-04-02 11:32:07 [main] [32mINFO [m [KafkaRebalanceUtils:92] Reconciliation #7(test) KafkaRebalance(cruise-control-st/my-cluster-003effe3): ============================================================================
2022-04-02 11:32:07 [main] [32mINFO [m [KafkaRebalanceUtils:94] Reconciliation #7(test) KafkaRebalance(cruise-control-st/my-cluster-003effe3): Triggering the rebalance with annotation strimzi.io/rebalance=approve of KafkaRebalance resource
2022-04-02 11:32:07 [main] [32mINFO [m [KafkaRebalanceUtils:63] Reconciliation #7(test) KafkaRebalance(cruise-control-st/my-cluster-003effe3): Annotating KafkaRebalance:my-cluster-003effe3 with annotation approve
2022-04-02 11:32:07 [main] [32mINFO [m [KafkaRebalanceUtils:98] Reconciliation #7(test) KafkaRebalance(cruise-control-st/my-cluster-003effe3): Response from the annotation process kafkarebalance.kafka.strimzi.io/my-cluster-003effe3 annotated
2022-04-02 11:32:07 [main] [32mINFO [m [KafkaRebalanceUtils:100] Reconciliation #7(test) KafkaRebalance(cruise-control-st/my-cluster-003effe3): Verifying that annotation triggers the Rebalancing state
2022-04-02 11:32:07 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-003effe3 will have desired state: Rebalancing
2022-04-02 11:32:08 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-003effe3 is in desired state: Rebalancing
2022-04-02 11:32:08 [main] [32mINFO [m [KafkaRebalanceUtils:104] Reconciliation #7(test) KafkaRebalance(cruise-control-st/my-cluster-003effe3): Verifying that KafkaRebalance is in the Ready state
2022-04-02 11:32:08 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-003effe3 will have desired state: Ready
2022-04-02 11:32:13 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-003effe3 is in desired state: Ready
2022-04-02 11:32:13 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 11:32:13 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCruiseControlWithRebalanceResourceAndRefreshAnnotation
2022-04-02 11:32:13 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaRebalance my-cluster-003effe3 in namespace cruise-control-st
2022-04-02 11:32:13 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-003effe3 in namespace cruise-control-st
2022-04-02 11:32:13 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace cruise-control-st, for cruise control Kafka cluster my-cluster-003effe3
2022-04-02 11:32:23 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 11:32:23 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlWithRebalanceResourceAndRefreshAnnotation-FINISHED
2022-04-02 11:32:23 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 11:32:23 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 11:32:23 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlWithApiSecurityDisabled-STARTED
2022-04-02 11:32:23 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 11:32:23 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-9c7fde26 in namespace cruise-control-st
2022-04-02 11:32:23 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-9c7fde26 will have desired state: Ready
2022-04-02 11:35:08 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-9c7fde26 is in desired state: Ready
2022-04-02 11:35:08 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaRebalance my-cluster-9c7fde26 in namespace cruise-control-st
2022-04-02 11:35:08 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-9c7fde26 will have desired state: PendingProposal
2022-04-02 11:35:09 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-9c7fde26 is in desired state: PendingProposal
2022-04-02 11:35:09 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-9c7fde26 will have desired state: ProposalReady
2022-04-02 11:36:58 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-9c7fde26 is in desired state: ProposalReady
2022-04-02 11:36:58 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 11:36:58 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCruiseControlWithApiSecurityDisabled
2022-04-02 11:36:58 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaRebalance my-cluster-9c7fde26 in namespace cruise-control-st
2022-04-02 11:36:58 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-9c7fde26 in namespace cruise-control-st
2022-04-02 11:36:58 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace cruise-control-st, for cruise control Kafka cluster my-cluster-9c7fde26
2022-04-02 11:37:08 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 11:37:08 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlWithApiSecurityDisabled-FINISHED
2022-04-02 11:37:08 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 11:37:08 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 11:37:08 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlIntraBrokerBalancing-STARTED
2022-04-02 11:37:08 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 11:37:08 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-21 for test case:testCruiseControlIntraBrokerBalancing
2022-04-02 11:37:08 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-21
2022-04-02 11:37:08 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-21
2022-04-02 11:37:08 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-21
2022-04-02 11:37:08 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-149c013c in namespace namespace-21
2022-04-02 11:37:08 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-21
2022-04-02 11:37:08 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-149c013c will have desired state: Ready
2022-04-02 11:38:44 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-149c013c is in desired state: Ready
2022-04-02 11:38:44 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaRebalance my-cluster-149c013c in namespace namespace-21
2022-04-02 11:38:44 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-21
2022-04-02 11:38:44 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-149c013c will have desired state: PendingProposal
2022-04-02 11:38:45 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-149c013c is in desired state: PendingProposal
2022-04-02 11:38:45 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-149c013c will have desired state: ProposalReady
2022-04-02 11:41:36 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-149c013c is in desired state: ProposalReady
2022-04-02 11:41:36 [main] [32mINFO [m [CruiseControlST:292] Checking status of KafkaRebalance
2022-04-02 11:41:36 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 11:41:36 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCruiseControlIntraBrokerBalancing
2022-04-02 11:41:36 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaRebalance my-cluster-149c013c in namespace namespace-21
2022-04-02 11:41:36 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-149c013c in namespace namespace-21
2022-04-02 11:41:36 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-21, for cruise control Kafka cluster my-cluster-149c013c
2022-04-02 11:41:46 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 11:41:46 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-21 for test case:testCruiseControlIntraBrokerBalancing
2022-04-02 11:42:29 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlIntraBrokerBalancing-FINISHED
2022-04-02 11:42:29 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 11:42:29 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 11:42:29 [main] [32mINFO [m [ResourceManager:346] In context CruiseControlST is everything deleted.
2022-04-02 11:42:29 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2,300.403 s - in io.strimzi.systemtest.cruisecontrol.CruiseControlST
[[1;34mINFO[m] Running io.strimzi.systemtest.kafka.listeners.ListenersST
2022-04-02 11:42:38 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: listeners-st
2022-04-02 11:42:38 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: listeners-st
2022-04-02 11:42:38 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: listeners-st
2022-04-02 11:42:38 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 11:42:38 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesTlsAuthenticated-STARTED
2022-04-02 11:42:38 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 11:42:38 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-22 for test case:testSendMessagesTlsAuthenticated
2022-04-02 11:42:38 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-22
2022-04-02 11:42:38 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-22
2022-04-02 11:42:38 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-22
2022-04-02 11:42:38 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-955ad68d in namespace namespace-22
2022-04-02 11:42:38 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-22
2022-04-02 11:42:38 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-955ad68d will have desired state: Ready
2022-04-02 11:43:58 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-955ad68d is in desired state: Ready
2022-04-02 11:43:58 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-2091869696-1879811571 in namespace namespace-22
2022-04-02 11:43:58 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-22
2022-04-02 11:43:58 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-2091869696-1879811571 will have desired state: Ready
2022-04-02 11:43:59 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-2091869696-1879811571 is in desired state: Ready
2022-04-02 11:43:59 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1551231335-1487279756 in namespace namespace-22
2022-04-02 11:43:59 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-22
2022-04-02 11:43:59 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1551231335-1487279756 will have desired state: Ready
2022-04-02 11:44:00 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1551231335-1487279756 is in desired state: Ready
2022-04-02 11:44:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-955ad68d-kafka-clients in namespace namespace-22
2022-04-02 11:44:00 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-22
2022-04-02 11:44:00 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-955ad68d-kafka-clients will be ready
2022-04-02 11:44:02 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-955ad68d-kafka-clients is ready
2022-04-02 11:44:02 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-02 11:44:02 [main] [32mINFO [m [ListenersST:221] Checking produced and consumed messages to pod:my-cluster-955ad68d-kafka-clients-577c5947b-bbz47
2022-04-02 11:44:02 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@57ab442e, messages=[], arguments=[USER=my_user_1551231335_1487279756, --max-messages, 100, --topic, my-topic-2091869696-1879811571, --bootstrap-server, my-cluster-955ad68d-kafka-bootstrap.namespace-22.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-955ad68d-kafka-clients-577c5947b-bbz47', podNamespace='namespace-22', bootstrapServer='my-cluster-955ad68d-kafka-bootstrap.namespace-22.svc:9093', topicName='my-topic-2091869696-1879811571', maxMessages=100, kafkaUsername='my-user-1551231335-1487279756', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1a35fde7}
2022-04-02 11:44:02 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-955ad68d-kafka-bootstrap.namespace-22.svc:9093:my-topic-2091869696-1879811571 from pod my-cluster-955ad68d-kafka-clients-577c5947b-bbz47
2022-04-02 11:44:02 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-955ad68d-kafka-clients-577c5947b-bbz47 -n namespace-22 -- /opt/kafka/producer.sh USER=my_user_1551231335_1487279756 --max-messages 100 --topic my-topic-2091869696-1879811571 --bootstrap-server my-cluster-955ad68d-kafka-bootstrap.namespace-22.svc:9093
2022-04-02 11:44:06 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-02 11:44:06 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-02 11:44:06 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@5d2ca126, messages=[], arguments=[USER=my_user_1551231335_1487279756, --max-messages, 100, --group-instance-id, instance1018076647, --group-id, my-consumer-group-1913811299, --topic, my-topic-2091869696-1879811571, --bootstrap-server, my-cluster-955ad68d-kafka-bootstrap.namespace-22.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-955ad68d-kafka-clients-577c5947b-bbz47', podNamespace='namespace-22', bootstrapServer='my-cluster-955ad68d-kafka-bootstrap.namespace-22.svc:9093', topicName='my-topic-2091869696-1879811571', maxMessages=100, kafkaUsername='my-user-1551231335-1487279756', consumerGroupName='my-consumer-group-1913811299', consumerInstanceId='instance1018076647', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@68c3b31c}
2022-04-02 11:44:06 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-955ad68d-kafka-bootstrap.namespace-22.svc:9093:my-topic-2091869696-1879811571 from pod my-cluster-955ad68d-kafka-clients-577c5947b-bbz47
2022-04-02 11:44:06 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-955ad68d-kafka-clients-577c5947b-bbz47 -n namespace-22 -- /opt/kafka/consumer.sh USER=my_user_1551231335_1487279756 --max-messages 100 --group-instance-id instance1018076647 --group-id my-consumer-group-1913811299 --topic my-topic-2091869696-1879811571 --bootstrap-server my-cluster-955ad68d-kafka-bootstrap.namespace-22.svc:9093
2022-04-02 11:44:13 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-02 11:44:13 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-02 11:44:13 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 11:44:13 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSendMessagesTlsAuthenticated
2022-04-02 11:44:13 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1551231335-1487279756 in namespace namespace-22
2022-04-02 11:44:13 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-955ad68d-kafka-clients in namespace namespace-22
2022-04-02 11:44:13 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-955ad68d in namespace namespace-22
2022-04-02 11:44:13 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-2091869696-1879811571 in namespace namespace-22
2022-04-02 11:45:03 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 11:45:03 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-22 for test case:testSendMessagesTlsAuthenticated
2022-04-02 11:45:08 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesTlsAuthenticated-FINISHED
2022-04-02 11:45:08 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 11:45:08 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 11:45:08 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesCustomListenerTlsScramSha-STARTED
2022-04-02 11:45:08 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 11:45:08 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-23 for test case:testSendMessagesCustomListenerTlsScramSha
2022-04-02 11:45:08 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-23
2022-04-02 11:45:08 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-23
2022-04-02 11:45:08 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-23
2022-04-02 11:45:08 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-27dda461 in namespace namespace-23
2022-04-02 11:45:08 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-23
2022-04-02 11:45:08 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-27dda461 will have desired state: Ready
2022-04-02 11:46:28 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-27dda461 is in desired state: Ready
2022-04-02 11:46:28 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1767087777-1889831242 in namespace namespace-23
2022-04-02 11:46:28 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-23
2022-04-02 11:46:28 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1767087777-1889831242 will have desired state: Ready
2022-04-02 11:46:29 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1767087777-1889831242 is in desired state: Ready
2022-04-02 11:46:29 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-220169969-157866767 in namespace namespace-23
2022-04-02 11:46:29 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-23
2022-04-02 11:46:29 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-220169969-157866767 will have desired state: Ready
2022-04-02 11:46:30 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-220169969-157866767 is in desired state: Ready
2022-04-02 11:46:30 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-27dda461-kafka-clients in namespace namespace-23
2022-04-02 11:46:30 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-23
2022-04-02 11:46:30 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-27dda461-kafka-clients will be ready
2022-04-02 11:46:32 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-27dda461-kafka-clients is ready
2022-04-02 11:46:32 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-02 11:46:32 [main] [32mINFO [m [ListenersST:442] Checking produced and consumed messages to pod:my-cluster-27dda461-kafka-clients-84ff78d449-szxsj
2022-04-02 11:46:32 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@57b55853, messages=[], arguments=[USER=my_user_220169969_157866767, --max-messages, 100, --topic, my-topic-1767087777-1889831242, --bootstrap-server, my-cluster-27dda461-kafka-bootstrap.namespace-23.svc:9122], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-27dda461-kafka-clients-84ff78d449-szxsj', podNamespace='namespace-23', bootstrapServer='my-cluster-27dda461-kafka-bootstrap.namespace-23.svc:9122', topicName='my-topic-1767087777-1889831242', maxMessages=100, kafkaUsername='my-user-220169969-157866767', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@33d66aef}
2022-04-02 11:46:32 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-27dda461-kafka-bootstrap.namespace-23.svc:9122:my-topic-1767087777-1889831242 from pod my-cluster-27dda461-kafka-clients-84ff78d449-szxsj
2022-04-02 11:46:32 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-27dda461-kafka-clients-84ff78d449-szxsj -n namespace-23 -- /opt/kafka/producer.sh USER=my_user_220169969_157866767 --max-messages 100 --topic my-topic-1767087777-1889831242 --bootstrap-server my-cluster-27dda461-kafka-bootstrap.namespace-23.svc:9122
2022-04-02 11:46:35 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-02 11:46:35 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-02 11:46:35 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@2d847621, messages=[], arguments=[USER=my_user_220169969_157866767, --max-messages, 100, --group-instance-id, instance790242752, --group-id, my-consumer-group-208355084, --topic, my-topic-1767087777-1889831242, --bootstrap-server, my-cluster-27dda461-kafka-bootstrap.namespace-23.svc:9122], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-27dda461-kafka-clients-84ff78d449-szxsj', podNamespace='namespace-23', bootstrapServer='my-cluster-27dda461-kafka-bootstrap.namespace-23.svc:9122', topicName='my-topic-1767087777-1889831242', maxMessages=100, kafkaUsername='my-user-220169969-157866767', consumerGroupName='my-consumer-group-208355084', consumerInstanceId='instance790242752', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@2d05e07c}
2022-04-02 11:46:35 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-27dda461-kafka-bootstrap.namespace-23.svc:9122:my-topic-1767087777-1889831242 from pod my-cluster-27dda461-kafka-clients-84ff78d449-szxsj
2022-04-02 11:46:35 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-27dda461-kafka-clients-84ff78d449-szxsj -n namespace-23 -- /opt/kafka/consumer.sh USER=my_user_220169969_157866767 --max-messages 100 --group-instance-id instance790242752 --group-id my-consumer-group-208355084 --topic my-topic-1767087777-1889831242 --bootstrap-server my-cluster-27dda461-kafka-bootstrap.namespace-23.svc:9122
2022-04-02 11:46:42 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-02 11:46:42 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-02 11:46:42 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 11:46:42 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSendMessagesCustomListenerTlsScramSha
2022-04-02 11:46:42 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-220169969-157866767 in namespace namespace-23
2022-04-02 11:46:42 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1767087777-1889831242 in namespace namespace-23
2022-04-02 11:46:42 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-27dda461-kafka-clients in namespace namespace-23
2022-04-02 11:46:42 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-27dda461 in namespace namespace-23
2022-04-02 11:47:32 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 11:47:32 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-23 for test case:testSendMessagesCustomListenerTlsScramSha
2022-04-02 11:47:38 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesCustomListenerTlsScramSha-FINISHED
2022-04-02 11:47:38 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 11:47:38 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 11:47:38 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.ListenersST.testCertificateWithNonExistingDataCrt-STARTED
2022-04-02 11:47:38 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 11:47:38 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-24 for test case:testCertificateWithNonExistingDataCrt
2022-04-02 11:47:38 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-24
2022-04-02 11:47:38 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-24
2022-04-02 11:47:38 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-24
2022-04-02 11:47:38 [main] [32mINFO [m [SecretUtils:46] Waiting for Secret my-cluster-485e28ae-custom-certificate-server-1
2022-04-02 11:47:38 [main] [32mINFO [m [SecretUtils:50] Secret my-cluster-485e28ae-custom-certificate-server-1 created
2022-04-02 11:47:38 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-485e28ae in namespace namespace-24
2022-04-02 11:47:38 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-24
2022-04-02 11:48:12 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 11:48:12 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCertificateWithNonExistingDataCrt
2022-04-02 11:48:12 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-485e28ae in namespace namespace-24
2022-04-02 11:48:12 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 11:48:12 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-24 for test case:testCertificateWithNonExistingDataCrt
2022-04-02 11:48:23 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.ListenersST.testCertificateWithNonExistingDataCrt-FINISHED
2022-04-02 11:48:23 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 11:48:23 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 11:48:23 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.ListenersST.testCertificateWithNonExistingDataKey-STARTED
2022-04-02 11:48:23 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 11:48:23 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-25 for test case:testCertificateWithNonExistingDataKey
2022-04-02 11:48:23 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-25
2022-04-02 11:48:23 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-25
2022-04-02 11:48:23 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-25
2022-04-02 11:48:23 [main] [32mINFO [m [SecretUtils:46] Waiting for Secret my-cluster-5af88e48-custom-certificate-server-1
2022-04-02 11:48:23 [main] [32mINFO [m [SecretUtils:50] Secret my-cluster-5af88e48-custom-certificate-server-1 created
2022-04-02 11:48:23 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-5af88e48 in namespace namespace-25
2022-04-02 11:48:23 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-25
2022-04-02 11:48:59 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 11:48:59 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCertificateWithNonExistingDataKey
2022-04-02 11:48:59 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-5af88e48 in namespace namespace-25
2022-04-02 11:48:59 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 11:48:59 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-25 for test case:testCertificateWithNonExistingDataKey
2022-04-02 11:49:26 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.ListenersST.testCertificateWithNonExistingDataKey-FINISHED
2022-04-02 11:49:26 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 11:49:26 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 11:49:26 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesPlainAnonymous-STARTED
2022-04-02 11:49:26 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 11:49:26 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-26 for test case:testSendMessagesPlainAnonymous
2022-04-02 11:49:26 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-26
2022-04-02 11:49:26 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-26
2022-04-02 11:49:26 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-26
2022-04-02 11:49:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-fa70f482 in namespace namespace-26
2022-04-02 11:49:26 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-26
2022-04-02 11:49:26 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-fa70f482 will have desired state: Ready
2022-04-02 11:50:46 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-fa70f482 is in desired state: Ready
2022-04-02 11:50:46 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1611048153-1086230695 in namespace namespace-26
2022-04-02 11:50:46 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-26
2022-04-02 11:50:46 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1611048153-1086230695 will have desired state: Ready
2022-04-02 11:50:47 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1611048153-1086230695 is in desired state: Ready
2022-04-02 11:50:47 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-fa70f482-kafka-clients in namespace namespace-26
2022-04-02 11:50:47 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-26
2022-04-02 11:50:47 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-fa70f482-kafka-clients will be ready
2022-04-02 11:50:49 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-fa70f482-kafka-clients is ready
2022-04-02 11:50:49 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-02 11:50:49 [main] [32mINFO [m [ListenersST:152] Checking produced and consumed messages to pod:my-cluster-fa70f482-kafka-clients-86869cdb9c-7xxf5
2022-04-02 11:50:49 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@d7deef3, messages=[], arguments=[--max-messages, 100, --topic, my-topic-1611048153-1086230695, --bootstrap-server, my-cluster-fa70f482-kafka-bootstrap.namespace-26.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-fa70f482-kafka-clients-86869cdb9c-7xxf5', podNamespace='namespace-26', bootstrapServer='my-cluster-fa70f482-kafka-bootstrap.namespace-26.svc:9092', topicName='my-topic-1611048153-1086230695', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@286806ad}
2022-04-02 11:50:49 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-fa70f482-kafka-bootstrap.namespace-26.svc:9092:my-topic-1611048153-1086230695 from pod my-cluster-fa70f482-kafka-clients-86869cdb9c-7xxf5
2022-04-02 11:50:49 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-fa70f482-kafka-clients-86869cdb9c-7xxf5 -n namespace-26 -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-1611048153-1086230695 --bootstrap-server my-cluster-fa70f482-kafka-bootstrap.namespace-26.svc:9092
2022-04-02 11:50:51 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-02 11:50:51 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-02 11:50:51 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@2ac1c945, messages=[], arguments=[--max-messages, 100, --group-instance-id, instance1227496313, --group-id, my-consumer-group-1580179250, --topic, my-topic-1611048153-1086230695, --bootstrap-server, my-cluster-fa70f482-kafka-bootstrap.namespace-26.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-fa70f482-kafka-clients-86869cdb9c-7xxf5', podNamespace='namespace-26', bootstrapServer='my-cluster-fa70f482-kafka-bootstrap.namespace-26.svc:9092', topicName='my-topic-1611048153-1086230695', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1580179250', consumerInstanceId='instance1227496313', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@42f4f2d8}
2022-04-02 11:50:51 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-fa70f482-kafka-bootstrap.namespace-26.svc:9092#my-topic-1611048153-1086230695 from pod my-cluster-fa70f482-kafka-clients-86869cdb9c-7xxf5
2022-04-02 11:50:51 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-fa70f482-kafka-clients-86869cdb9c-7xxf5 -n namespace-26 -- /opt/kafka/consumer.sh --max-messages 100 --group-instance-id instance1227496313 --group-id my-consumer-group-1580179250 --topic my-topic-1611048153-1086230695 --bootstrap-server my-cluster-fa70f482-kafka-bootstrap.namespace-26.svc:9092
2022-04-02 11:50:57 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-02 11:50:57 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-02 11:50:57 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 11:50:57 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSendMessagesPlainAnonymous
2022-04-02 11:50:57 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-fa70f482 in namespace namespace-26
2022-04-02 11:50:57 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1611048153-1086230695 in namespace namespace-26
2022-04-02 11:50:57 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-fa70f482-kafka-clients in namespace namespace-26
2022-04-02 11:51:47 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 11:51:47 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-26 for test case:testSendMessagesPlainAnonymous
2022-04-02 11:51:52 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesPlainAnonymous-FINISHED
2022-04-02 11:51:52 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 11:51:52 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 11:51:52 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesPlainScramSha-STARTED
2022-04-02 11:51:52 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 11:51:52 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-27 for test case:testSendMessagesPlainScramSha
2022-04-02 11:51:52 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-27
2022-04-02 11:51:52 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-27
2022-04-02 11:51:52 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-27
2022-04-02 11:51:52 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-a0e2bc9b in namespace namespace-27
2022-04-02 11:51:52 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-27
2022-04-02 11:51:52 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-a0e2bc9b will have desired state: Ready
2022-04-02 11:53:15 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-a0e2bc9b is in desired state: Ready
2022-04-02 11:53:15 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-805798417-1258357216 in namespace namespace-27
2022-04-02 11:53:15 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-27
2022-04-02 11:53:15 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-805798417-1258357216 will have desired state: Ready
2022-04-02 11:53:16 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-805798417-1258357216 is in desired state: Ready
2022-04-02 11:53:16 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1584965935-772641642 in namespace namespace-27
2022-04-02 11:53:16 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-27
2022-04-02 11:53:16 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1584965935-772641642 will have desired state: Ready
2022-04-02 11:53:17 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1584965935-772641642 is in desired state: Ready
2022-04-02 11:53:17 [main] [32mINFO [m [ListenersST:273] Broker pod log line about user my-user-1584965935-772641642: 2022-04-02 11:53:16,481 INFO Processing override for entityPath: users/my-user-1584965935-772641642 with config: HashMap(SCRAM-SHA-512 -> [hidden]) (kafka.server.DynamicConfigManager) [/config/changes-event-process-thread]
2022-04-02 11:53:17 [main] [32mINFO [m [ListenersST:273] Broker pod log line about user my-user-1584965935-772641642: 2022-04-02 11:53:16,485 INFO Removing PRODUCE quota for user my-user-1584965935-772641642 (kafka.server.ClientQuotaManager) [/config/changes-event-process-thread]
2022-04-02 11:53:17 [main] [32mINFO [m [ListenersST:273] Broker pod log line about user my-user-1584965935-772641642: 2022-04-02 11:53:16,487 INFO Removing FETCH quota for user my-user-1584965935-772641642 (kafka.server.ClientQuotaManager) [/config/changes-event-process-thread]
2022-04-02 11:53:17 [main] [32mINFO [m [ListenersST:273] Broker pod log line about user my-user-1584965935-772641642: 2022-04-02 11:53:16,488 INFO Removing REQUEST quota for user my-user-1584965935-772641642 (kafka.server.ClientRequestQuotaManager) [/config/changes-event-process-thread]
2022-04-02 11:53:17 [main] [32mINFO [m [ListenersST:273] Broker pod log line about user my-user-1584965935-772641642: 2022-04-02 11:53:16,488 INFO Removing CONTROLLER_MUTATION quota for user my-user-1584965935-772641642 (kafka.server.ControllerMutationQuotaManager) [/config/changes-event-process-thread]
2022-04-02 11:53:17 [main] [32mINFO [m [ListenersST:273] Broker pod log line about user my-user-1584965935-772641642: 2022-04-02 11:53:16,671 INFO Processing override for entityPath: users/my-user-1584965935-772641642 with config: HashMap(SCRAM-SHA-512 -> [hidden]) (kafka.server.DynamicConfigManager) [/config/changes-event-process-thread]
2022-04-02 11:53:17 [main] [32mINFO [m [ListenersST:273] Broker pod log line about user my-user-1584965935-772641642: 2022-04-02 11:53:16,671 INFO Removing PRODUCE quota for user my-user-1584965935-772641642 (kafka.server.ClientQuotaManager) [/config/changes-event-process-thread]
2022-04-02 11:53:17 [main] [32mINFO [m [ListenersST:273] Broker pod log line about user my-user-1584965935-772641642: 2022-04-02 11:53:16,671 INFO Removing FETCH quota for user my-user-1584965935-772641642 (kafka.server.ClientQuotaManager) [/config/changes-event-process-thread]
2022-04-02 11:53:17 [main] [32mINFO [m [ListenersST:273] Broker pod log line about user my-user-1584965935-772641642: 2022-04-02 11:53:16,671 INFO Removing REQUEST quota for user my-user-1584965935-772641642 (kafka.server.ClientRequestQuotaManager) [/config/changes-event-process-thread]
2022-04-02 11:53:17 [main] [32mINFO [m [ListenersST:273] Broker pod log line about user my-user-1584965935-772641642: 2022-04-02 11:53:16,672 INFO Removing CONTROLLER_MUTATION quota for user my-user-1584965935-772641642 (kafka.server.ControllerMutationQuotaManager) [/config/changes-event-process-thread]
2022-04-02 11:53:17 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-a0e2bc9b-kafka-clients in namespace namespace-27
2022-04-02 11:53:17 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-27
2022-04-02 11:53:17 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-a0e2bc9b-kafka-clients will be ready
2022-04-02 11:53:19 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-a0e2bc9b-kafka-clients is ready
2022-04-02 11:53:19 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-02 11:53:19 [main] [32mINFO [m [ListenersST:296] Checking produced and consumed messages to pod:my-cluster-a0e2bc9b-kafka-clients-6bdc4c4ff5-bmkvg
2022-04-02 11:53:19 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@25ce0fb2, messages=[], arguments=[USER=my_user_1584965935_772641642, --max-messages, 100, --topic, my-topic-805798417-1258357216, --bootstrap-server, my-cluster-a0e2bc9b-kafka-bootstrap.namespace-27.svc:9095], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-a0e2bc9b-kafka-clients-6bdc4c4ff5-bmkvg', podNamespace='namespace-27', bootstrapServer='my-cluster-a0e2bc9b-kafka-bootstrap.namespace-27.svc:9095', topicName='my-topic-805798417-1258357216', maxMessages=100, kafkaUsername='my-user-1584965935-772641642', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3713d89a}
2022-04-02 11:53:19 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-a0e2bc9b-kafka-bootstrap.namespace-27.svc:9095:my-topic-805798417-1258357216 from pod my-cluster-a0e2bc9b-kafka-clients-6bdc4c4ff5-bmkvg
2022-04-02 11:53:19 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-a0e2bc9b-kafka-clients-6bdc4c4ff5-bmkvg -n namespace-27 -- /opt/kafka/producer.sh USER=my_user_1584965935_772641642 --max-messages 100 --topic my-topic-805798417-1258357216 --bootstrap-server my-cluster-a0e2bc9b-kafka-bootstrap.namespace-27.svc:9095
2022-04-02 11:53:21 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-02 11:53:21 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-02 11:53:21 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@7753c77e, messages=[], arguments=[USER=my_user_1584965935_772641642, --max-messages, 100, --group-instance-id, instance2042673058, --group-id, my-consumer-group-293143822, --topic, my-topic-805798417-1258357216, --bootstrap-server, my-cluster-a0e2bc9b-kafka-bootstrap.namespace-27.svc:9095], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-a0e2bc9b-kafka-clients-6bdc4c4ff5-bmkvg', podNamespace='namespace-27', bootstrapServer='my-cluster-a0e2bc9b-kafka-bootstrap.namespace-27.svc:9095', topicName='my-topic-805798417-1258357216', maxMessages=100, kafkaUsername='my-user-1584965935-772641642', consumerGroupName='my-consumer-group-293143822', consumerInstanceId='instance2042673058', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5ead1339}
2022-04-02 11:53:21 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-a0e2bc9b-kafka-bootstrap.namespace-27.svc:9095#my-topic-805798417-1258357216 from pod my-cluster-a0e2bc9b-kafka-clients-6bdc4c4ff5-bmkvg
2022-04-02 11:53:21 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-a0e2bc9b-kafka-clients-6bdc4c4ff5-bmkvg -n namespace-27 -- /opt/kafka/consumer.sh USER=my_user_1584965935_772641642 --max-messages 100 --group-instance-id instance2042673058 --group-id my-consumer-group-293143822 --topic my-topic-805798417-1258357216 --bootstrap-server my-cluster-a0e2bc9b-kafka-bootstrap.namespace-27.svc:9095
2022-04-02 11:53:27 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-02 11:53:27 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-02 11:53:27 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 11:53:27 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSendMessagesPlainScramSha
2022-04-02 11:53:27 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1584965935-772641642 in namespace namespace-27
2022-04-02 11:53:27 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-a0e2bc9b-kafka-clients in namespace namespace-27
2022-04-02 11:53:27 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-805798417-1258357216 in namespace namespace-27
2022-04-02 11:53:27 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-a0e2bc9b in namespace namespace-27
2022-04-02 11:54:17 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 11:54:17 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-27 for test case:testSendMessagesPlainScramSha
2022-04-02 11:54:23 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesPlainScramSha-FINISHED
2022-04-02 11:54:23 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 11:54:23 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 11:54:23 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesTlsScramSha-STARTED
2022-04-02 11:54:23 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 11:54:23 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-28 for test case:testSendMessagesTlsScramSha
2022-04-02 11:54:23 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-28
2022-04-02 11:54:23 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-28
2022-04-02 11:54:23 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-28
2022-04-02 11:54:23 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-d15f7dac in namespace namespace-28
2022-04-02 11:54:23 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-28
2022-04-02 11:54:23 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d15f7dac will have desired state: Ready
2022-04-02 11:55:48 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d15f7dac is in desired state: Ready
2022-04-02 11:55:48 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1130233466-1884464494 in namespace namespace-28
2022-04-02 11:55:48 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-28
2022-04-02 11:55:48 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1130233466-1884464494 will have desired state: Ready
2022-04-02 11:55:49 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1130233466-1884464494 is in desired state: Ready
2022-04-02 11:55:49 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-221709780-2073511947 in namespace namespace-28
2022-04-02 11:55:49 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-28
2022-04-02 11:55:49 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-221709780-2073511947 will have desired state: Ready
2022-04-02 11:55:50 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-221709780-2073511947 is in desired state: Ready
2022-04-02 11:55:50 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-d15f7dac-kafka-clients in namespace namespace-28
2022-04-02 11:55:50 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-28
2022-04-02 11:55:50 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-d15f7dac-kafka-clients will be ready
2022-04-02 11:55:52 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-d15f7dac-kafka-clients is ready
2022-04-02 11:55:52 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-02 11:55:52 [main] [32mINFO [m [ListenersST:370] Checking produced and consumed messages to pod:my-cluster-d15f7dac-kafka-clients-74587d5f7b-gdbxp
2022-04-02 11:55:52 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@35283a40, messages=[], arguments=[USER=my_user_221709780_2073511947, --max-messages, 100, --topic, my-topic-1130233466-1884464494, --bootstrap-server, my-cluster-d15f7dac-kafka-bootstrap.namespace-28.svc:9096], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-d15f7dac-kafka-clients-74587d5f7b-gdbxp', podNamespace='namespace-28', bootstrapServer='my-cluster-d15f7dac-kafka-bootstrap.namespace-28.svc:9096', topicName='my-topic-1130233466-1884464494', maxMessages=100, kafkaUsername='my-user-221709780-2073511947', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@560b198}
2022-04-02 11:55:52 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-d15f7dac-kafka-bootstrap.namespace-28.svc:9096:my-topic-1130233466-1884464494 from pod my-cluster-d15f7dac-kafka-clients-74587d5f7b-gdbxp
2022-04-02 11:55:52 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-d15f7dac-kafka-clients-74587d5f7b-gdbxp -n namespace-28 -- /opt/kafka/producer.sh USER=my_user_221709780_2073511947 --max-messages 100 --topic my-topic-1130233466-1884464494 --bootstrap-server my-cluster-d15f7dac-kafka-bootstrap.namespace-28.svc:9096
2022-04-02 11:55:56 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-02 11:55:56 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-02 11:55:56 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@1065a15c, messages=[], arguments=[USER=my_user_221709780_2073511947, --max-messages, 100, --group-instance-id, instance2063175044, --group-id, my-consumer-group-649797768, --topic, my-topic-1130233466-1884464494, --bootstrap-server, my-cluster-d15f7dac-kafka-bootstrap.namespace-28.svc:9096], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-d15f7dac-kafka-clients-74587d5f7b-gdbxp', podNamespace='namespace-28', bootstrapServer='my-cluster-d15f7dac-kafka-bootstrap.namespace-28.svc:9096', topicName='my-topic-1130233466-1884464494', maxMessages=100, kafkaUsername='my-user-221709780-2073511947', consumerGroupName='my-consumer-group-649797768', consumerInstanceId='instance2063175044', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@10893ea4}
2022-04-02 11:55:56 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-d15f7dac-kafka-bootstrap.namespace-28.svc:9096:my-topic-1130233466-1884464494 from pod my-cluster-d15f7dac-kafka-clients-74587d5f7b-gdbxp
2022-04-02 11:55:56 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-d15f7dac-kafka-clients-74587d5f7b-gdbxp -n namespace-28 -- /opt/kafka/consumer.sh USER=my_user_221709780_2073511947 --max-messages 100 --group-instance-id instance2063175044 --group-id my-consumer-group-649797768 --topic my-topic-1130233466-1884464494 --bootstrap-server my-cluster-d15f7dac-kafka-bootstrap.namespace-28.svc:9096
2022-04-02 11:56:03 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-02 11:56:03 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-02 11:56:03 [main] [32mINFO [m [ListenersST:377] Checking if generated password has 25 characters
2022-04-02 11:56:03 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 11:56:03 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSendMessagesTlsScramSha
2022-04-02 11:56:03 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-221709780-2073511947 in namespace namespace-28
2022-04-02 11:56:03 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-d15f7dac-kafka-clients in namespace namespace-28
2022-04-02 11:56:03 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1130233466-1884464494 in namespace namespace-28
2022-04-02 11:56:03 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-d15f7dac in namespace namespace-28
2022-04-02 11:56:53 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 11:56:53 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-28 for test case:testSendMessagesTlsScramSha
2022-04-02 11:56:59 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesTlsScramSha-FINISHED
2022-04-02 11:56:59 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 11:56:59 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 11:56:59 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.ListenersST.testNonExistingCustomCertificate-STARTED
2022-04-02 11:56:59 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 11:56:59 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-29 for test case:testNonExistingCustomCertificate
2022-04-02 11:56:59 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-29
2022-04-02 11:56:59 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-29
2022-04-02 11:56:59 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-29
2022-04-02 11:56:59 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-9707317a in namespace namespace-29
2022-04-02 11:56:59 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-29
2022-04-02 11:57:36 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 11:57:36 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testNonExistingCustomCertificate
2022-04-02 11:57:36 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-9707317a in namespace namespace-29
2022-04-02 11:57:36 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 11:57:36 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-29 for test case:testNonExistingCustomCertificate
2022-04-02 11:57:41 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.ListenersST.testNonExistingCustomCertificate-FINISHED
2022-04-02 11:57:41 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 11:57:41 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 11:57:41 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.ListenersST.testAdvertisedHostNamesAppearsInBrokerCerts-STARTED
2022-04-02 11:57:41 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 11:57:41 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-30 for test case:testAdvertisedHostNamesAppearsInBrokerCerts
2022-04-02 11:57:41 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-30
2022-04-02 11:57:42 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-30
2022-04-02 11:57:42 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-30
2022-04-02 11:57:42 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-2a020208 in namespace namespace-30
2022-04-02 11:57:42 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-30
2022-04-02 11:57:42 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-2a020208 will have desired state: Ready
2022-04-02 11:58:58 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-2a020208 is in desired state: Ready
2022-04-02 11:58:58 [main] [32mINFO [m [ListenersST:2338] Encoding my-cluster-2a020208-kafka-0.crt
2022-04-02 11:58:58 [main] [32mINFO [m [ListenersST:2338] Encoding my-cluster-2a020208-kafka-1.crt
2022-04-02 11:58:58 [main] [32mINFO [m [ListenersST:2338] Encoding my-cluster-2a020208-kafka-2.crt
2022-04-02 11:58:58 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 11:58:58 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAdvertisedHostNamesAppearsInBrokerCerts
2022-04-02 11:58:58 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-2a020208 in namespace namespace-30
2022-04-02 11:59:08 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 11:59:08 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-30 for test case:testAdvertisedHostNamesAppearsInBrokerCerts
2022-04-02 11:59:51 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.ListenersST.testAdvertisedHostNamesAppearsInBrokerCerts-FINISHED
2022-04-02 11:59:51 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 11:59:51 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 11:59:51 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.ListenersST.testMessagesTlsScramShaWithPredefinedPassword-STARTED
2022-04-02 11:59:51 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 11:59:51 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-31 for test case:testMessagesTlsScramShaWithPredefinedPassword
2022-04-02 11:59:51 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-31
2022-04-02 11:59:51 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-31
2022-04-02 11:59:51 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-31
2022-04-02 11:59:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-7c7a7fbb in namespace namespace-31
2022-04-02 11:59:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-31
2022-04-02 11:59:51 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-942369981-440777853 in namespace namespace-31
2022-04-02 11:59:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-31
2022-04-02 11:59:51 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-304216267-356166708 in namespace namespace-31
2022-04-02 11:59:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-31
2022-04-02 11:59:51 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-7c7a7fbb will have desired state: Ready
2022-04-02 12:01:07 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-7c7a7fbb is in desired state: Ready
2022-04-02 12:01:07 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-942369981-440777853 will have desired state: Ready
2022-04-02 12:01:07 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-942369981-440777853 is in desired state: Ready
2022-04-02 12:01:07 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-304216267-356166708 will have desired state: Ready
2022-04-02 12:01:07 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-304216267-356166708 is in desired state: Ready
2022-04-02 12:01:07 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-7c7a7fbb-kafka-clients in namespace namespace-31
2022-04-02 12:01:07 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-31
2022-04-02 12:01:07 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-7c7a7fbb-kafka-clients will be ready
2022-04-02 12:01:09 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-7c7a7fbb-kafka-clients is ready
2022-04-02 12:01:09 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-02 12:01:09 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@604398c7, messages=[], arguments=[USER=my_user_942369981_440777853, --max-messages, 100, --topic, my-topic-304216267-356166708, --bootstrap-server, my-cluster-7c7a7fbb-kafka-bootstrap.namespace-31.svc:9096], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-7c7a7fbb-kafka-clients-77dc688b86-6tbws', podNamespace='namespace-31', bootstrapServer='my-cluster-7c7a7fbb-kafka-bootstrap.namespace-31.svc:9096', topicName='my-topic-304216267-356166708', maxMessages=100, kafkaUsername='my-user-942369981-440777853', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@35ea6baa}
2022-04-02 12:01:09 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-7c7a7fbb-kafka-bootstrap.namespace-31.svc:9096:my-topic-304216267-356166708 from pod my-cluster-7c7a7fbb-kafka-clients-77dc688b86-6tbws
2022-04-02 12:01:09 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-7c7a7fbb-kafka-clients-77dc688b86-6tbws -n namespace-31 -- /opt/kafka/producer.sh USER=my_user_942369981_440777853 --max-messages 100 --topic my-topic-304216267-356166708 --bootstrap-server my-cluster-7c7a7fbb-kafka-bootstrap.namespace-31.svc:9096
2022-04-02 12:01:13 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-02 12:01:13 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-02 12:01:13 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@10b0d0a4, messages=[], arguments=[USER=my_user_942369981_440777853, --max-messages, 100, --group-instance-id, instance1891470192, --group-id, my-consumer-group-187779397, --topic, my-topic-304216267-356166708, --bootstrap-server, my-cluster-7c7a7fbb-kafka-bootstrap.namespace-31.svc:9096], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-7c7a7fbb-kafka-clients-77dc688b86-6tbws', podNamespace='namespace-31', bootstrapServer='my-cluster-7c7a7fbb-kafka-bootstrap.namespace-31.svc:9096', topicName='my-topic-304216267-356166708', maxMessages=100, kafkaUsername='my-user-942369981-440777853', consumerGroupName='my-consumer-group-187779397', consumerInstanceId='instance1891470192', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@76e142e9}
2022-04-02 12:01:13 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-7c7a7fbb-kafka-bootstrap.namespace-31.svc:9096:my-topic-304216267-356166708 from pod my-cluster-7c7a7fbb-kafka-clients-77dc688b86-6tbws
2022-04-02 12:01:13 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-7c7a7fbb-kafka-clients-77dc688b86-6tbws -n namespace-31 -- /opt/kafka/consumer.sh USER=my_user_942369981_440777853 --max-messages 100 --group-instance-id instance1891470192 --group-id my-consumer-group-187779397 --topic my-topic-304216267-356166708 --bootstrap-server my-cluster-7c7a7fbb-kafka-bootstrap.namespace-31.svc:9096
2022-04-02 12:01:20 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-02 12:01:20 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-02 12:01:20 [main] [32mINFO [m [ListenersST:2213] Changing password in secret: my-cluster-7c7a7fbb-secret, we should be able to send/receive messages
2022-04-02 12:01:20 [main] [32mINFO [m [SecretUtils:171] Waiting for user password will be changed to Y29tcGxldGVseV9kaWZmZXJlbnRfc2VjcmV0X3Bhc3N3b3Jk in secret: my-user-942369981-440777853
2022-04-02 12:02:50 [main] [32mINFO [m [ListenersST:2222] We need to recreate Kafka Clients deployment, so the correct password from secret will be taken
2022-04-02 12:02:50 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-7c7a7fbb-kafka-clients in namespace namespace-31
2022-04-02 12:03:30 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-7c7a7fbb-kafka-clients in namespace namespace-31
2022-04-02 12:03:30 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-31
2022-04-02 12:03:30 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-7c7a7fbb-kafka-clients will be ready
2022-04-02 12:03:32 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-7c7a7fbb-kafka-clients is ready
2022-04-02 12:03:32 [main] [32mINFO [m [ListenersST:2226] Receiving messages with new password
2022-04-02 12:03:32 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@7a7b5cbb, messages=[], arguments=[USER=my_user_942369981_440777853, --max-messages, 100, --group-instance-id, instance1051095172, --group-id, my-consumer-group-1040284831, --topic, my-topic-304216267-356166708, --bootstrap-server, my-cluster-7c7a7fbb-kafka-bootstrap.namespace-31.svc:9096], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-7c7a7fbb-kafka-clients-7b5d7bb798-8xnxf', podNamespace='namespace-31', bootstrapServer='my-cluster-7c7a7fbb-kafka-bootstrap.namespace-31.svc:9096', topicName='my-topic-304216267-356166708', maxMessages=100, kafkaUsername='my-user-942369981-440777853', consumerGroupName='my-consumer-group-1040284831', consumerInstanceId='instance1051095172', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@671b096}
2022-04-02 12:03:32 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-7c7a7fbb-kafka-bootstrap.namespace-31.svc:9096:my-topic-304216267-356166708 from pod my-cluster-7c7a7fbb-kafka-clients-7b5d7bb798-8xnxf
2022-04-02 12:03:32 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-7c7a7fbb-kafka-clients-7b5d7bb798-8xnxf -n namespace-31 -- /opt/kafka/consumer.sh USER=my_user_942369981_440777853 --max-messages 100 --group-instance-id instance1051095172 --group-id my-consumer-group-1040284831 --topic my-topic-304216267-356166708 --bootstrap-server my-cluster-7c7a7fbb-kafka-bootstrap.namespace-31.svc:9096
2022-04-02 12:03:40 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-02 12:03:40 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-02 12:03:40 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 12:03:40 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMessagesTlsScramShaWithPredefinedPassword
2022-04-02 12:03:40 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-304216267-356166708 in namespace namespace-31
2022-04-02 12:03:40 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-7c7a7fbb in namespace namespace-31
2022-04-02 12:03:40 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-942369981-440777853 in namespace namespace-31
2022-04-02 12:03:40 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-7c7a7fbb-kafka-clients in namespace namespace-31
2022-04-02 12:03:40 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-7c7a7fbb-kafka-clients in namespace namespace-31
2022-04-02 12:04:30 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 12:04:30 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-31 for test case:testMessagesTlsScramShaWithPredefinedPassword
2022-04-02 12:04:35 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.ListenersST.testMessagesTlsScramShaWithPredefinedPassword-FINISHED
2022-04-02 12:04:35 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 12:04:35 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 12:04:35 [main] [32mINFO [m [ResourceManager:346] In context ListenersST is everything deleted.
2022-04-02 12:04:35 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1,324.994 s - in io.strimzi.systemtest.kafka.listeners.ListenersST
[[1;34mINFO[m] Running io.strimzi.systemtest.kafka.listeners.MultipleListenersST
2022-04-02 12:04:41 [main] [32mINFO [m [MultipleListenersST:294] Starting to generate test cases for multiple listeners
2022-04-02 12:04:41 [main] [32mINFO [m [MultipleListenersST:300] Generating INTERNAL listener
2022-04-02 12:04:41 [main] [32mINFO [m [MultipleListenersST:363] Generating listeners with type INTERNAL -> [io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@cc506a52, io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@da8566e, io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@5c00647c]
2022-04-02 12:04:41 [main] [32mINFO [m [MultipleListenersST:300] Generating ROUTE listener
2022-04-02 12:04:41 [main] [32mINFO [m [MultipleListenersST:363] Generating listeners with type ROUTE -> [io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@6e69b0cb]
2022-04-02 12:04:41 [main] [32mINFO [m [MultipleListenersST:300] Generating LOADBALANCER listener
2022-04-02 12:04:41 [main] [32mINFO [m [MultipleListenersST:363] Generating listeners with type LOADBALANCER -> [io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@5d16f586, io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@9e6ee1a2]
2022-04-02 12:04:41 [main] [32mINFO [m [MultipleListenersST:300] Generating NODEPORT listener
2022-04-02 12:04:41 [main] [32mINFO [m [MultipleListenersST:363] Generating listeners with type NODEPORT -> [io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@4cdd63cf, io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@8e354feb, io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@dc8d5df9]
2022-04-02 12:04:41 [main] [32mINFO [m [MultipleListenersST:300] Generating INGRESS listener
2022-04-02 12:04:41 [main] [32mINFO [m [MultipleListenersST:363] Generating listeners with type INGRESS -> []
2022-04-02 12:04:41 [main] [32mINFO [m [MultipleListenersST:367] Finished with generation of test cases for multiple listeners
2022-04-02 12:04:41 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: multiple-listeners-st
2022-04-02 12:04:41 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: multiple-listeners-st
2022-04-02 12:04:41 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: multiple-listeners-st
2022-04-02 12:04:41 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 12:04:41 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.MultipleListenersST.testMultipleInternal-STARTED
2022-04-02 12:04:41 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 12:04:41 [main] [32mINFO [m [MultipleListenersST:163] This is listeners [io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@cc506a52, io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@da8566e, io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@5c00647c], which will verified.
2022-04-02 12:04:41 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-89059ac5 in namespace multiple-listeners-st
2022-04-02 12:04:41 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-89059ac5 will have desired state: Ready
2022-04-02 12:05:59 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-89059ac5 is in desired state: Ready
2022-04-02 12:05:59 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1260803127-21296579 in namespace multiple-listeners-st
2022-04-02 12:05:59 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1260803127-21296579 will have desired state: Ready
2022-04-02 12:06:00 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1260803127-21296579 is in desired state: Ready
2022-04-02 12:06:00 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-50817194-2060743814 in namespace multiple-listeners-st
2022-04-02 12:06:00 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-50817194-2060743814 will have desired state: Ready
2022-04-02 12:06:01 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-50817194-2060743814 is in desired state: Ready
2022-04-02 12:06:01 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-89059ac5-kafka-clients-tls in namespace multiple-listeners-st
2022-04-02 12:06:01 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-89059ac5-kafka-clients-tls will be ready
2022-04-02 12:06:03 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-89059ac5-kafka-clients-tls is ready
2022-04-02 12:06:03 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-02 12:06:03 [main] [32mINFO [m [MultipleListenersST:252] Checking produced and consumed messages to pod:my-cluster-89059ac5-kafka-clients-tls-84cc4879fc-qjkjt
2022-04-02 12:06:03 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1372956169-1826307302 in namespace multiple-listeners-st
2022-04-02 12:06:03 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1372956169-1826307302 will have desired state: Ready
2022-04-02 12:06:04 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1372956169-1826307302 is in desired state: Ready
2022-04-02 12:06:04 [main] [32mINFO [m [ClientUtils:127] Sending messages to - topic my-topic-50817194-2060743814, cluster my-cluster-89059ac5 and message count of 100
2022-04-02 12:06:04 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@3e803119, messages=[], arguments=[USER=my_user_1260803127_21296579, --max-messages, 100, --topic, my-topic-1372956169-1826307302, --bootstrap-server, my-cluster-89059ac5-kafka-bootstrap.multiple-listeners-st.svc:13900], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-89059ac5-kafka-clients-tls-84cc4879fc-qjkjt', podNamespace='multiple-listeners-st', bootstrapServer='my-cluster-89059ac5-kafka-bootstrap.multiple-listeners-st.svc:13900', topicName='my-topic-1372956169-1826307302', maxMessages=100, kafkaUsername='my-user-1260803127-21296579', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@498b91ba}
2022-04-02 12:06:04 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-89059ac5-kafka-bootstrap.multiple-listeners-st.svc:13900:my-topic-1372956169-1826307302 from pod my-cluster-89059ac5-kafka-clients-tls-84cc4879fc-qjkjt
2022-04-02 12:06:04 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-89059ac5-kafka-clients-tls-84cc4879fc-qjkjt -n multiple-listeners-st -- /opt/kafka/producer.sh USER=my_user_1260803127_21296579 --max-messages 100 --topic my-topic-1372956169-1826307302 --bootstrap-server my-cluster-89059ac5-kafka-bootstrap.multiple-listeners-st.svc:13900
2022-04-02 12:06:08 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-02 12:06:08 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-02 12:06:08 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@272b2cce, messages=[], arguments=[USER=my_user_1260803127_21296579, --max-messages, 100, --group-instance-id, instance1077019891, --group-id, my-consumer-group-1379696494, --topic, my-topic-1372956169-1826307302, --bootstrap-server, my-cluster-89059ac5-kafka-bootstrap.multiple-listeners-st.svc:13900], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-89059ac5-kafka-clients-tls-84cc4879fc-qjkjt', podNamespace='multiple-listeners-st', bootstrapServer='my-cluster-89059ac5-kafka-bootstrap.multiple-listeners-st.svc:13900', topicName='my-topic-1372956169-1826307302', maxMessages=100, kafkaUsername='my-user-1260803127-21296579', consumerGroupName='my-consumer-group-1379696494', consumerInstanceId='instance1077019891', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@32386d72}
2022-04-02 12:06:08 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-89059ac5-kafka-bootstrap.multiple-listeners-st.svc:13900:my-topic-1372956169-1826307302 from pod my-cluster-89059ac5-kafka-clients-tls-84cc4879fc-qjkjt
2022-04-02 12:06:08 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-89059ac5-kafka-clients-tls-84cc4879fc-qjkjt -n multiple-listeners-st -- /opt/kafka/consumer.sh USER=my_user_1260803127_21296579 --max-messages 100 --group-instance-id instance1077019891 --group-id my-consumer-group-1379696494 --topic my-topic-1372956169-1826307302 --bootstrap-server my-cluster-89059ac5-kafka-bootstrap.multiple-listeners-st.svc:13900
2022-04-02 12:06:14 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-02 12:06:14 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-02 12:06:14 [main] [32mINFO [m [ClientUtils:133] Sent 100 and received 100
2022-04-02 12:06:14 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1837188209-1084770269 in namespace multiple-listeners-st
2022-04-02 12:06:14 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1837188209-1084770269 will have desired state: Ready
2022-04-02 12:06:15 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1837188209-1084770269 is in desired state: Ready
2022-04-02 12:06:15 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-89059ac5-kafka-clients-tls in namespace multiple-listeners-st
2022-04-02 12:06:15 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-89059ac5-kafka-clients-tls will be ready
2022-04-02 12:06:15 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-89059ac5-kafka-clients-tls is ready
2022-04-02 12:06:15 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-02 12:06:15 [main] [32mINFO [m [MultipleListenersST:252] Checking produced and consumed messages to pod:my-cluster-89059ac5-kafka-clients-tls-84cc4879fc-qjkjt
2022-04-02 12:06:15 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1944259727-1752840508 in namespace multiple-listeners-st
2022-04-02 12:06:16 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1944259727-1752840508 will have desired state: Ready
2022-04-02 12:06:17 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1944259727-1752840508 is in desired state: Ready
2022-04-02 12:06:17 [main] [32mINFO [m [ClientUtils:127] Sending messages to - topic my-topic-1837188209-1084770269, cluster my-cluster-89059ac5 and message count of 100
2022-04-02 12:06:17 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@238511ec, messages=[], arguments=[USER=my_user_1260803127_21296579, --max-messages, 100, --topic, my-topic-1944259727-1752840508, --bootstrap-server, my-cluster-89059ac5-kafka-bootstrap.multiple-listeners-st.svc:13901], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-89059ac5-kafka-clients-tls-84cc4879fc-qjkjt', podNamespace='multiple-listeners-st', bootstrapServer='my-cluster-89059ac5-kafka-bootstrap.multiple-listeners-st.svc:13901', topicName='my-topic-1944259727-1752840508', maxMessages=100, kafkaUsername='my-user-1260803127-21296579', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@189cd9cb}
2022-04-02 12:06:17 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-89059ac5-kafka-bootstrap.multiple-listeners-st.svc:13901:my-topic-1944259727-1752840508 from pod my-cluster-89059ac5-kafka-clients-tls-84cc4879fc-qjkjt
2022-04-02 12:06:17 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-89059ac5-kafka-clients-tls-84cc4879fc-qjkjt -n multiple-listeners-st -- /opt/kafka/producer.sh USER=my_user_1260803127_21296579 --max-messages 100 --topic my-topic-1944259727-1752840508 --bootstrap-server my-cluster-89059ac5-kafka-bootstrap.multiple-listeners-st.svc:13901
2022-04-02 12:06:20 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-02 12:06:20 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-02 12:06:20 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@2c14b0c5, messages=[], arguments=[USER=my_user_1260803127_21296579, --max-messages, 100, --group-instance-id, instance1373223590, --group-id, my-consumer-group-1230001797, --topic, my-topic-1944259727-1752840508, --bootstrap-server, my-cluster-89059ac5-kafka-bootstrap.multiple-listeners-st.svc:13901], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-89059ac5-kafka-clients-tls-84cc4879fc-qjkjt', podNamespace='multiple-listeners-st', bootstrapServer='my-cluster-89059ac5-kafka-bootstrap.multiple-listeners-st.svc:13901', topicName='my-topic-1944259727-1752840508', maxMessages=100, kafkaUsername='my-user-1260803127-21296579', consumerGroupName='my-consumer-group-1230001797', consumerInstanceId='instance1373223590', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5227ab13}
2022-04-02 12:06:20 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-89059ac5-kafka-bootstrap.multiple-listeners-st.svc:13901:my-topic-1944259727-1752840508 from pod my-cluster-89059ac5-kafka-clients-tls-84cc4879fc-qjkjt
2022-04-02 12:06:20 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-89059ac5-kafka-clients-tls-84cc4879fc-qjkjt -n multiple-listeners-st -- /opt/kafka/consumer.sh USER=my_user_1260803127_21296579 --max-messages 100 --group-instance-id instance1373223590 --group-id my-consumer-group-1230001797 --topic my-topic-1944259727-1752840508 --bootstrap-server my-cluster-89059ac5-kafka-bootstrap.multiple-listeners-st.svc:13901
2022-04-02 12:06:27 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-02 12:06:27 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-02 12:06:27 [main] [32mINFO [m [ClientUtils:133] Sent 100 and received 100
2022-04-02 12:06:27 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-767988424-1437432814 in namespace multiple-listeners-st
2022-04-02 12:06:27 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-767988424-1437432814 will have desired state: Ready
2022-04-02 12:06:28 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-767988424-1437432814 is in desired state: Ready
2022-04-02 12:06:28 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-89059ac5-kafka-clients-plain in namespace multiple-listeners-st
2022-04-02 12:06:28 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-89059ac5-kafka-clients-plain will be ready
2022-04-02 12:06:30 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-89059ac5-kafka-clients-plain is ready
2022-04-02 12:06:30 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-02 12:06:30 [main] [32mINFO [m [MultipleListenersST:274] Checking produced and consumed messages to pod:my-cluster-89059ac5-kafka-clients-plain-899876bd5-97bds
2022-04-02 12:06:30 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@59b917d7, messages=[], arguments=[--max-messages, 100, --topic, my-topic-767988424-1437432814, --bootstrap-server, my-cluster-89059ac5-kafka-bootstrap.multiple-listeners-st.svc:13902], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-89059ac5-kafka-clients-plain-899876bd5-97bds', podNamespace='multiple-listeners-st', bootstrapServer='my-cluster-89059ac5-kafka-bootstrap.multiple-listeners-st.svc:13902', topicName='my-topic-767988424-1437432814', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5238660d}
2022-04-02 12:06:30 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-89059ac5-kafka-bootstrap.multiple-listeners-st.svc:13902:my-topic-767988424-1437432814 from pod my-cluster-89059ac5-kafka-clients-plain-899876bd5-97bds
2022-04-02 12:06:30 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-89059ac5-kafka-clients-plain-899876bd5-97bds -n multiple-listeners-st -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-767988424-1437432814 --bootstrap-server my-cluster-89059ac5-kafka-bootstrap.multiple-listeners-st.svc:13902
2022-04-02 12:06:32 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-02 12:06:32 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-02 12:06:32 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@3fb25c48, messages=[], arguments=[--max-messages, 100, --group-instance-id, instance1456108752, --group-id, my-consumer-group-1208906571, --topic, my-topic-767988424-1437432814, --bootstrap-server, my-cluster-89059ac5-kafka-bootstrap.multiple-listeners-st.svc:13902], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-89059ac5-kafka-clients-plain-899876bd5-97bds', podNamespace='multiple-listeners-st', bootstrapServer='my-cluster-89059ac5-kafka-bootstrap.multiple-listeners-st.svc:13902', topicName='my-topic-767988424-1437432814', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1208906571', consumerInstanceId='instance1456108752', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@36a940c0}
2022-04-02 12:06:32 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-89059ac5-kafka-bootstrap.multiple-listeners-st.svc:13902#my-topic-767988424-1437432814 from pod my-cluster-89059ac5-kafka-clients-plain-899876bd5-97bds
2022-04-02 12:06:32 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-89059ac5-kafka-clients-plain-899876bd5-97bds -n multiple-listeners-st -- /opt/kafka/consumer.sh --max-messages 100 --group-instance-id instance1456108752 --group-id my-consumer-group-1208906571 --topic my-topic-767988424-1437432814 --bootstrap-server my-cluster-89059ac5-kafka-bootstrap.multiple-listeners-st.svc:13902
2022-04-02 12:06:38 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-02 12:06:38 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-02 12:06:38 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 12:06:38 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMultipleInternal
2022-04-02 12:06:38 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-89059ac5-kafka-clients-tls in namespace multiple-listeners-st
2022-04-02 12:06:38 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1837188209-1084770269 in namespace multiple-listeners-st
2022-04-02 12:06:38 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1944259727-1752840508 in namespace multiple-listeners-st
2022-04-02 12:06:38 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-50817194-2060743814 in namespace multiple-listeners-st
2022-04-02 12:06:38 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1260803127-21296579 in namespace multiple-listeners-st
2022-04-02 12:06:38 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-89059ac5 in namespace multiple-listeners-st
2022-04-02 12:06:38 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-767988424-1437432814 in namespace multiple-listeners-st
2022-04-02 12:06:38 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-89059ac5-kafka-clients-plain in namespace multiple-listeners-st
2022-04-02 12:06:48 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1372956169-1826307302 in namespace multiple-listeners-st
2022-04-02 12:06:48 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-89059ac5-kafka-clients-tls in namespace multiple-listeners-st
2022-04-02 12:07:18 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 12:07:18 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.MultipleListenersST.testMultipleInternal-FINISHED
2022-04-02 12:07:18 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 12:07:18 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 12:07:18 [main] [32mINFO [m [ResourceManager:346] In context MultipleListenersST is everything deleted.
2022-04-02 12:07:18 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 162.814 s - in io.strimzi.systemtest.kafka.listeners.MultipleListenersST
[[1;34mINFO[m] Running io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfST
2022-04-02 12:07:23 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: dynamic-conf-st
2022-04-02 12:07:24 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: dynamic-conf-st
2022-04-02 12:07:24 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: dynamic-conf-st
2022-04-02 12:07:24 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 12:07:24 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfST.testSimpleDynamicConfiguration-STARTED
2022-04-02 12:07:24 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 12:07:24 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-fac0ec9f in namespace dynamic-conf-st
2022-04-02 12:07:24 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-fac0ec9f will have desired state: Ready
2022-04-02 12:08:38 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-fac0ec9f is in desired state: Ready
2022-04-02 12:08:41 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-st exec my-cluster-fac0ec9f-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-02 12:08:41 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 12:08:41 [main] [32mINFO [m [DynamicConfST:380] Updating configuration of Kafka cluster
2022-04-02 12:08:41 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-fac0ec9f-kafka are stable
2022-04-02 12:08:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-02 12:08:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-02 12:08:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-02 12:08:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-02 12:08:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-02 12:08:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-02 12:08:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-02 12:08:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-02 12:08:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-02 12:08:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-02 12:08:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-02 12:08:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-02 12:08:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-02 12:08:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-02 12:08:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-02 12:08:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-02 12:08:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-02 12:08:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-02 12:08:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-02 12:08:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-02 12:08:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-02 12:08:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-02 12:08:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-02 12:08:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-02 12:08:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-02 12:08:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-02 12:08:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-02 12:08:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-02 12:08:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-02 12:08:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-02 12:08:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-02 12:08:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-02 12:08:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-02 12:08:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-02 12:08:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-02 12:08:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-02 12:08:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-02 12:08:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-02 12:08:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-02 12:08:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-02 12:08:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-02 12:08:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-02 12:08:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-02 12:08:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-02 12:08:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-02 12:08:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-02 12:08:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-02 12:08:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-02 12:08:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-02 12:08:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-02 12:08:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-02 12:08:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-02 12:08:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-02 12:08:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-02 12:08:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-02 12:08:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-02 12:08:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-02 12:09:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-02 12:09:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-02 12:09:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-02 12:09:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-02 12:09:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-02 12:09:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-02 12:09:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-02 12:09:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-02 12:09:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-02 12:09:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-02 12:09:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-02 12:09:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-02 12:09:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-02 12:09:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-02 12:09:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-02 12:09:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-02 12:09:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-02 12:09:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-02 12:09:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-02 12:09:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-02 12:09:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-02 12:09:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-02 12:09:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-02 12:09:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-02 12:09:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-02 12:09:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-02 12:09:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-02 12:09:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-02 12:09:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-02 12:09:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-02 12:09:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-02 12:09:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-02 12:09:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-02 12:09:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-02 12:09:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-02 12:09:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-02 12:09:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-02 12:09:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-02 12:09:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-02 12:09:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-02 12:09:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-02 12:09:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-02 12:09:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-02 12:09:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-02 12:09:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-02 12:09:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-02 12:09:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-02 12:09:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-02 12:09:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-02 12:09:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-02 12:09:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-02 12:09:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-02 12:09:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-02 12:09:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-02 12:09:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-02 12:09:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-02 12:09:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-02 12:09:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-02 12:09:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-02 12:09:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-02 12:09:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-02 12:09:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-02 12:09:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-02 12:09:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-02 12:09:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-02 12:09:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-02 12:09:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-02 12:09:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-02 12:09:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-02 12:09:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-02 12:09:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-02 12:09:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-02 12:09:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-02 12:09:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-02 12:09:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-02 12:09:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-02 12:09:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-02 12:09:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-02 12:09:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-02 12:09:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-02 12:09:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-02 12:09:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-02 12:09:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-02 12:09:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-02 12:09:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-02 12:09:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-02 12:09:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-02 12:09:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-02 12:09:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-02 12:09:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-02 12:09:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-02 12:09:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-02 12:09:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fac0ec9f-kafka-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-02 12:09:30 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-fac0ec9f-kafka-0 ,my-cluster-fac0ec9f-kafka-1 ,my-cluster-fac0ec9f-kafka-2
2022-04-02 12:09:33 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-st exec my-cluster-fac0ec9f-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-02 12:09:33 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 12:09:33 [main] [32mINFO [m [DynamicConfST:102] Verify values after update
2022-04-02 12:09:33 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 12:09:33 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSimpleDynamicConfiguration
2022-04-02 12:09:33 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-fac0ec9f in namespace dynamic-conf-st
2022-04-02 12:09:43 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 12:09:43 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfST.testSimpleDynamicConfiguration-FINISHED
2022-04-02 12:09:43 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 12:09:43 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 12:09:43 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfST.testUpdateToExternalListenerCausesRollingRestart-STARTED
2022-04-02 12:09:43 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 12:09:43 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-ab56a09b in namespace dynamic-conf-st
2022-04-02 12:09:43 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-ab56a09b will have desired state: Ready
2022-04-02 12:11:03 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-ab56a09b is in desired state: Ready
2022-04-02 12:11:06 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-st exec my-cluster-ab56a09b-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-02 12:11:06 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 12:11:06 [main] [32mINFO [m [DynamicConfST:380] Updating configuration of Kafka cluster
2022-04-02 12:11:06 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-ab56a09b-kafka are stable
2022-04-02 12:11:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-02 12:11:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-02 12:11:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-02 12:11:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-02 12:11:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-02 12:11:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-02 12:11:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-02 12:11:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-02 12:11:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-02 12:11:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-02 12:11:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-02 12:11:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-02 12:11:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-02 12:11:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-02 12:11:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-02 12:11:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-02 12:11:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-02 12:11:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-02 12:11:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-02 12:11:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-02 12:11:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-02 12:11:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-02 12:11:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-02 12:11:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-02 12:11:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-02 12:11:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-02 12:11:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-02 12:11:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-02 12:11:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-02 12:11:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-02 12:11:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-02 12:11:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-02 12:11:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-02 12:11:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-02 12:11:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-02 12:11:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-02 12:11:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-02 12:11:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-02 12:11:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-02 12:11:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-02 12:11:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-02 12:11:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-02 12:11:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-02 12:11:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-02 12:11:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-02 12:11:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-02 12:11:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-02 12:11:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-02 12:11:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-02 12:11:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-02 12:11:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-02 12:11:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-02 12:11:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-02 12:11:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-02 12:11:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-02 12:11:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-02 12:11:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-02 12:11:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-02 12:11:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-02 12:11:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-02 12:11:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-02 12:11:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-02 12:11:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-02 12:11:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-02 12:11:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-02 12:11:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-02 12:11:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-02 12:11:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-02 12:11:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-02 12:11:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-02 12:11:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-02 12:11:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-02 12:11:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-02 12:11:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-02 12:11:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-02 12:11:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-02 12:11:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-02 12:11:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-02 12:11:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-02 12:11:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-02 12:11:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-02 12:11:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-02 12:11:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-02 12:11:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-02 12:11:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-02 12:11:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-02 12:11:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-02 12:11:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-02 12:11:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-02 12:11:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-02 12:11:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-02 12:11:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-02 12:11:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-02 12:11:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-02 12:11:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-02 12:11:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-02 12:11:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-02 12:11:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-02 12:11:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-02 12:11:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-02 12:11:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-02 12:11:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-02 12:11:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-02 12:11:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-02 12:11:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-02 12:11:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-02 12:11:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-02 12:11:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-02 12:11:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-02 12:11:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-02 12:11:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-02 12:11:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-02 12:11:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-02 12:11:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-02 12:11:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-02 12:11:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-02 12:11:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-02 12:11:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-02 12:11:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-02 12:11:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-02 12:11:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-02 12:11:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-02 12:11:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-02 12:11:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-02 12:11:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-02 12:11:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-02 12:11:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-02 12:11:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-02 12:11:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-02 12:11:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-02 12:11:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-02 12:11:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-02 12:11:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-02 12:11:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-02 12:11:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-02 12:11:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-02 12:11:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-02 12:11:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-02 12:11:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-02 12:11:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-02 12:11:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-02 12:11:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-02 12:11:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-02 12:11:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-02 12:11:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-02 12:11:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-02 12:11:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-02 12:11:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-02 12:11:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-02 12:11:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-02 12:11:55 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-ab56a09b-kafka-0 ,my-cluster-ab56a09b-kafka-1 ,my-cluster-ab56a09b-kafka-2
2022-04-02 12:11:58 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-st exec my-cluster-ab56a09b-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-02 12:11:58 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 12:11:58 [main] [32mINFO [m [DynamicConfST:163] Updating listeners of Kafka cluster
2022-04-02 12:11:58 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-ab56a09b-kafka rolling update
2022-04-02 12:13:13 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-ab56a09b-kafka has been successfully rolled
2022-04-02 12:13:13 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-ab56a09b-kafka to be ready
2022-04-02 12:13:44 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-ab56a09b will have desired state: Ready
2022-04-02 12:13:44 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-ab56a09b is in desired state: Ready
2022-04-02 12:13:44 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-ab56a09b is ready
2022-04-02 12:13:47 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-st exec my-cluster-ab56a09b-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-02 12:13:47 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 12:13:47 [main] [32mINFO [m [DynamicConfST:380] Updating configuration of Kafka cluster
2022-04-02 12:13:47 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-ab56a09b-kafka are stable
2022-04-02 12:13:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-02 12:13:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-02 12:13:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-02 12:13:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-02 12:13:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-02 12:13:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-02 12:13:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-02 12:13:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-02 12:13:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-02 12:13:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-02 12:13:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-02 12:13:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-02 12:13:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-02 12:13:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-02 12:13:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-02 12:13:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-02 12:13:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-02 12:13:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-02 12:13:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-02 12:13:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-02 12:13:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-02 12:13:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-02 12:13:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-02 12:13:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-02 12:13:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-02 12:13:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-02 12:13:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-02 12:13:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-02 12:13:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-02 12:13:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-02 12:13:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-02 12:13:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-02 12:13:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-02 12:13:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-02 12:13:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-02 12:13:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-02 12:13:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-02 12:13:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-02 12:13:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-02 12:14:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-02 12:14:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-02 12:14:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-02 12:14:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-02 12:14:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-02 12:14:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-02 12:14:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-02 12:14:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-02 12:14:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-02 12:14:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-02 12:14:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-02 12:14:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-02 12:14:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-02 12:14:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-02 12:14:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-02 12:14:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-02 12:14:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-02 12:14:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-02 12:14:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-02 12:14:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-02 12:14:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-02 12:14:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-02 12:14:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-02 12:14:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-02 12:14:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-02 12:14:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-02 12:14:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-02 12:14:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-02 12:14:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-02 12:14:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-02 12:14:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-02 12:14:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-02 12:14:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-02 12:14:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-02 12:14:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-02 12:14:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-02 12:14:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-02 12:14:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-02 12:14:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-02 12:14:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-02 12:14:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-02 12:14:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-02 12:14:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-02 12:14:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-02 12:14:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-02 12:14:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-02 12:14:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-02 12:14:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-02 12:14:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-02 12:14:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-02 12:14:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-02 12:14:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-02 12:14:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-02 12:14:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-02 12:14:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-02 12:14:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-02 12:14:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-02 12:14:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-02 12:14:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-02 12:14:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-02 12:14:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-02 12:14:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-02 12:14:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-02 12:14:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-02 12:14:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-02 12:14:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-02 12:14:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-02 12:14:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-02 12:14:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-02 12:14:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-02 12:14:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-02 12:14:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-02 12:14:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-02 12:14:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-02 12:14:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-02 12:14:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-02 12:14:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-02 12:14:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-02 12:14:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-02 12:14:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-02 12:14:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-02 12:14:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-02 12:14:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-02 12:14:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-02 12:14:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-02 12:14:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-02 12:14:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-02 12:14:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-02 12:14:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-02 12:14:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-02 12:14:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-02 12:14:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-02 12:14:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-02 12:14:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-02 12:14:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-02 12:14:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-02 12:14:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-02 12:14:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-02 12:14:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-02 12:14:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-02 12:14:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-02 12:14:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-02 12:14:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-02 12:14:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-02 12:14:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-02 12:14:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-02 12:14:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-02 12:14:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-02 12:14:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-02 12:14:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-02 12:14:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-02 12:14:36 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-ab56a09b-kafka-0 ,my-cluster-ab56a09b-kafka-1 ,my-cluster-ab56a09b-kafka-2
2022-04-02 12:14:39 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-st exec my-cluster-ab56a09b-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-02 12:14:39 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 12:14:42 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-st exec my-cluster-ab56a09b-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-02 12:14:42 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 12:14:42 [main] [32mINFO [m [DynamicConfST:380] Updating configuration of Kafka cluster
2022-04-02 12:14:42 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-ab56a09b-kafka are stable
2022-04-02 12:14:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-02 12:14:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-02 12:14:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-02 12:14:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-02 12:14:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-02 12:14:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-02 12:14:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-02 12:14:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-02 12:14:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-02 12:14:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-02 12:14:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-02 12:14:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-02 12:14:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-02 12:14:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-02 12:14:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-02 12:14:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-02 12:14:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-02 12:14:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-02 12:14:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-02 12:14:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-02 12:14:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-02 12:14:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-02 12:14:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-02 12:14:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-02 12:14:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-02 12:14:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-02 12:14:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-02 12:14:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-02 12:14:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-02 12:14:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-02 12:14:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-02 12:14:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-02 12:14:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-02 12:14:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-02 12:14:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-02 12:14:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-02 12:14:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-02 12:14:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-02 12:14:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-02 12:14:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-02 12:14:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-02 12:14:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-02 12:14:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-02 12:14:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-02 12:14:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-02 12:14:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-02 12:14:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-02 12:14:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-02 12:14:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-02 12:14:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-02 12:14:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-02 12:14:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-02 12:14:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-02 12:14:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-02 12:15:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-02 12:15:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-02 12:15:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-02 12:15:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-02 12:15:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-02 12:15:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-02 12:15:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-02 12:15:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-02 12:15:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-02 12:15:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-02 12:15:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-02 12:15:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-02 12:15:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-02 12:15:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-02 12:15:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-02 12:15:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-02 12:15:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-02 12:15:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-02 12:15:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-02 12:15:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-02 12:15:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-02 12:15:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-02 12:15:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-02 12:15:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-02 12:15:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-02 12:15:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-02 12:15:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-02 12:15:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-02 12:15:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-02 12:15:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-02 12:15:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-02 12:15:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-02 12:15:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-02 12:15:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-02 12:15:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-02 12:15:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-02 12:15:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-02 12:15:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-02 12:15:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-02 12:15:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-02 12:15:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-02 12:15:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-02 12:15:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-02 12:15:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-02 12:15:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-02 12:15:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-02 12:15:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-02 12:15:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-02 12:15:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-02 12:15:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-02 12:15:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-02 12:15:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-02 12:15:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-02 12:15:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-02 12:15:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-02 12:15:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-02 12:15:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-02 12:15:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-02 12:15:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-02 12:15:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-02 12:15:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-02 12:15:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-02 12:15:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-02 12:15:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-02 12:15:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-02 12:15:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-02 12:15:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-02 12:15:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-02 12:15:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-02 12:15:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-02 12:15:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-02 12:15:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-02 12:15:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-02 12:15:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-02 12:15:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-02 12:15:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-02 12:15:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-02 12:15:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-02 12:15:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-02 12:15:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-02 12:15:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-02 12:15:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-02 12:15:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-02 12:15:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-02 12:15:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-02 12:15:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-02 12:15:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-02 12:15:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-02 12:15:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-02 12:15:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-02 12:15:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-02 12:15:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-02 12:15:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-02 12:15:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-02 12:15:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-02 12:15:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-02 12:15:31 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-ab56a09b-kafka-0 ,my-cluster-ab56a09b-kafka-1 ,my-cluster-ab56a09b-kafka-2
2022-04-02 12:15:34 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-st exec my-cluster-ab56a09b-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-02 12:15:34 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 12:15:34 [main] [32mINFO [m [DynamicConfST:214] Updating listeners of Kafka cluster
2022-04-02 12:15:34 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-ab56a09b-kafka rolling update
2022-04-02 12:16:54 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-ab56a09b-kafka has been successfully rolled
2022-04-02 12:16:54 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-ab56a09b-kafka to be ready
2022-04-02 12:17:25 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-ab56a09b will have desired state: Ready
2022-04-02 12:17:25 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-ab56a09b is in desired state: Ready
2022-04-02 12:17:25 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-ab56a09b is ready
2022-04-02 12:17:28 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-st exec my-cluster-ab56a09b-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-02 12:17:28 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 12:17:28 [main] [32mINFO [m [DynamicConfST:380] Updating configuration of Kafka cluster
2022-04-02 12:17:28 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-ab56a09b-kafka are stable
2022-04-02 12:17:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-02 12:17:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-02 12:17:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-02 12:17:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-02 12:17:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-02 12:17:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-02 12:17:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-02 12:17:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-02 12:17:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-02 12:17:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-02 12:17:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-02 12:17:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-02 12:17:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-02 12:17:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-02 12:17:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-02 12:17:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-02 12:17:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-02 12:17:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-02 12:17:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-02 12:17:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-02 12:17:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-02 12:17:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-02 12:17:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-02 12:17:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-02 12:17:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-02 12:17:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-02 12:17:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-02 12:17:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-02 12:17:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-02 12:17:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-02 12:17:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-02 12:17:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-02 12:17:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-02 12:17:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-02 12:17:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-02 12:17:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-02 12:17:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-02 12:17:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-02 12:17:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-02 12:17:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-02 12:17:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-02 12:17:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-02 12:17:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-02 12:17:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-02 12:17:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-02 12:17:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-02 12:17:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-02 12:17:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-02 12:17:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-02 12:17:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-02 12:17:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-02 12:17:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-02 12:17:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-02 12:17:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-02 12:17:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-02 12:17:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-02 12:17:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-02 12:17:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-02 12:17:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-02 12:17:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-02 12:17:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-02 12:17:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-02 12:17:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-02 12:17:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-02 12:17:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-02 12:17:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-02 12:17:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-02 12:17:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-02 12:17:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-02 12:17:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-02 12:17:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-02 12:17:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-02 12:17:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-02 12:17:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-02 12:17:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-02 12:17:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-02 12:17:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-02 12:17:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-02 12:17:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-02 12:17:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-02 12:17:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-02 12:17:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-02 12:17:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-02 12:17:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-02 12:17:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-02 12:17:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-02 12:17:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-02 12:17:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-02 12:17:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-02 12:17:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-02 12:17:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-02 12:17:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-02 12:17:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-02 12:17:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-02 12:17:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-02 12:17:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-02 12:18:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-02 12:18:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-02 12:18:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-02 12:18:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-02 12:18:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-02 12:18:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-02 12:18:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-02 12:18:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-02 12:18:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-02 12:18:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-02 12:18:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-02 12:18:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-02 12:18:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-02 12:18:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-02 12:18:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-02 12:18:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-02 12:18:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-02 12:18:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-02 12:18:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-02 12:18:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-02 12:18:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-02 12:18:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-02 12:18:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-02 12:18:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-02 12:18:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-02 12:18:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-02 12:18:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-02 12:18:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-02 12:18:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-02 12:18:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-02 12:18:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-02 12:18:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-02 12:18:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-02 12:18:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-02 12:18:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-02 12:18:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-02 12:18:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-02 12:18:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-02 12:18:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-02 12:18:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-02 12:18:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-02 12:18:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-02 12:18:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-02 12:18:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-02 12:18:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-02 12:18:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-02 12:18:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-02 12:18:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-02 12:18:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-02 12:18:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-02 12:18:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-02 12:18:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-02 12:18:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-02 12:18:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ab56a09b-kafka-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-02 12:18:17 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-ab56a09b-kafka-0 ,my-cluster-ab56a09b-kafka-1 ,my-cluster-ab56a09b-kafka-2
2022-04-02 12:18:20 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-st exec my-cluster-ab56a09b-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-02 12:18:20 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 12:18:20 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 12:18:20 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testUpdateToExternalListenerCausesRollingRestart
2022-04-02 12:18:20 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-ab56a09b in namespace dynamic-conf-st
2022-04-02 12:18:30 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 12:18:30 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfST.testUpdateToExternalListenerCausesRollingRestart-FINISHED
2022-04-02 12:18:30 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 12:18:30 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 12:18:30 [main] [32mINFO [m [ResourceManager:346] In context DynamicConfST is everything deleted.
2022-04-02 12:18:30 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 710.067 s - in io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfST
[[1;34mINFO[m] Running io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfSharedST
2022-04-02 12:19:14 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: dynamic-conf-shared-st
2022-04-02 12:19:14 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: dynamic-conf-shared-st
2022-04-02 12:19:14 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: dynamic-conf-shared-st
2022-04-02 12:19:14 [main] [32mINFO [m [DynamicConfSharedST:218] Deploying shared Kafka across all test cases!
2022-04-02 12:19:14 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka dynamic-configuration-shared-cluster-name in namespace dynamic-conf-shared-st
2022-04-02 12:19:14 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: dynamic-configuration-shared-cluster-name will have desired state: Ready
2022-04-02 12:21:02 [main] [32mINFO [m [ResourceManager:444] Kafka: dynamic-configuration-shared-cluster-name is in desired state: Ready
2022-04-02 12:21:02 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 12:21:02 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfSharedST.testDynConfiguration-STARTED
2022-04-02 12:21:02 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 12:21:02 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 12:21:02 [main] [32mINFO [m [ResourceManager:346] In context testDynConfiguration is everything deleted.
2022-04-02 12:21:02 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 12:21:02 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfSharedST.testDynConfiguration-FINISHED
2022-04-02 12:21:02 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 12:21:02 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 12:21:02 [main] [32mINFO [m [ResourceManager:348] Delete all resources for DynamicConfSharedST
2022-04-02 12:21:02 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka dynamic-configuration-shared-cluster-name in namespace dynamic-conf-shared-st
2022-04-02 12:21:12 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;31mERROR[m] Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 161.539 s <<< FAILURE! - in io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfSharedST
[[1;31mERROR[m] io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfSharedST.testDynConfiguration  Time elapsed: 108.458 s  <<< ERROR!
java.lang.RuntimeException: Error reading from classpath resource /home/ec2-user/strimzi-kafka-operator/systemtest/../cluster-operator/src/main/resources/kafka-3.1.0-config-model.json
	at io.strimzi.systemtest.utils.kafkaUtils.KafkaUtils.readConfigModel(KafkaUtils.java:320)
	at io.strimzi.systemtest.utils.kafkaUtils.KafkaUtils.getDynamicConfigurationProperties(KafkaUtils.java:332)
	at io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfSharedST.generateTestCases(DynamicConfSharedST.java:84)
	at io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfSharedST.testDynConfiguration(DynamicConfSharedST.java:57)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestFactoryMethod(TimeoutExtension.java:100)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestFactoryTestDescriptor.lambda$invokeTestMethod$1(TestFactoryTestDescriptor.java:97)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestFactoryTestDescriptor.invokeTestMethod(TestFactoryTestDescriptor.java:95)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
Caused by: java.io.FileNotFoundException: /home/ec2-user/strimzi-kafka-operator/systemtest/../cluster-operator/src/main/resources/kafka-3.1.0-config-model.json (No such file or directory)
	at java.base/java.io.FileInputStream.open0(Native Method)
	at java.base/java.io.FileInputStream.open(FileInputStream.java:219)
	at java.base/java.io.FileInputStream.<init>(FileInputStream.java:157)
	at java.base/java.io.FileInputStream.<init>(FileInputStream.java:112)
	at io.strimzi.systemtest.utils.kafkaUtils.KafkaUtils.readConfigModel(KafkaUtils.java:312)
	... 102 more

[[1;34mINFO[m] Running io.strimzi.systemtest.kafka.KafkaST
2022-04-02 12:21:55 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: kafka-st
2022-04-02 12:21:55 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: kafka-st
2022-04-02 12:21:55 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: kafka-st
2022-04-02 12:21:55 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 12:21:55 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testKafkaOffsetsReplicationFactorHigherThanReplicas-STARTED
2022-04-02 12:21:55 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 12:21:55 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-32 for test case:testKafkaOffsetsReplicationFactorHigherThanReplicas
2022-04-02 12:21:55 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-32
2022-04-02 12:21:55 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-32
2022-04-02 12:21:55 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-32
2022-04-02 12:21:55 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-5e02217b in namespace namespace-32
2022-04-02 12:21:55 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-32
2022-04-02 12:21:57 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 12:21:57 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaOffsetsReplicationFactorHigherThanReplicas
2022-04-02 12:21:57 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-5e02217b in namespace namespace-32
2022-04-02 12:22:07 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 12:22:07 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testKafkaOffsetsReplicationFactorHigherThanReplicas-FINISHED
2022-04-02 12:22:07 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 12:22:07 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 12:22:07 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testEntityOperatorWithoutUserOperator-STARTED
2022-04-02 12:22:07 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 12:22:07 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-33 for test case:testEntityOperatorWithoutUserOperator
2022-04-02 12:22:07 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-33
2022-04-02 12:22:07 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-33
2022-04-02 12:22:07 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-33
2022-04-02 12:22:07 [main] [32mINFO [m [KafkaST:787] Deploying Kafka cluster without UO in EO
2022-04-02 12:22:07 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-e5568e73 in namespace namespace-33
2022-04-02 12:22:07 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-33
2022-04-02 12:22:07 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-e5568e73 will have desired state: Ready
2022-04-02 12:23:25 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-e5568e73 is in desired state: Ready
2022-04-02 12:23:25 [main] [32mINFO [m [AbstractST:478] Search in strimzi-cluster-operator log for errors in last 77 seconds
2022-04-02 12:23:25 [main] [32mINFO [m [BaseCmdKubeClient:481] Exception not found
2022-04-02 12:23:25 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 12:23:25 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testEntityOperatorWithoutUserOperator
2022-04-02 12:23:25 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-e5568e73 in namespace namespace-33
2022-04-02 12:23:35 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 12:23:35 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testEntityOperatorWithoutUserOperator-FINISHED
2022-04-02 12:23:35 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 12:23:35 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 12:23:35 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testEntityOperatorWithoutTopicOperator-STARTED
2022-04-02 12:23:35 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 12:23:35 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-34 for test case:testEntityOperatorWithoutTopicOperator
2022-04-02 12:23:35 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-34
2022-04-02 12:23:35 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-34
2022-04-02 12:23:35 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-34
2022-04-02 12:23:35 [main] [32mINFO [m [KafkaST:757] Deploying Kafka cluster without TO in EO
2022-04-02 12:23:35 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-dcc0cd9d in namespace namespace-34
2022-04-02 12:23:35 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-34
2022-04-02 12:23:35 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-dcc0cd9d will have desired state: Ready
2022-04-02 12:25:14 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-dcc0cd9d is in desired state: Ready
2022-04-02 12:25:14 [main] [32mINFO [m [AbstractST:478] Search in strimzi-cluster-operator log for errors in last 99 seconds
2022-04-02 12:25:14 [main] [32mINFO [m [BaseCmdKubeClient:481] Exception not found
2022-04-02 12:25:14 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 12:25:14 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testEntityOperatorWithoutTopicOperator
2022-04-02 12:25:14 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-dcc0cd9d in namespace namespace-34
2022-04-02 12:25:24 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 12:25:24 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testEntityOperatorWithoutTopicOperator-FINISHED
2022-04-02 12:25:24 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 12:25:24 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 12:25:24 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testTopicWithoutLabels-STARTED
2022-04-02 12:25:24 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 12:25:24 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-35 for test case:testTopicWithoutLabels
2022-04-02 12:25:24 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-35
2022-04-02 12:25:24 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-35
2022-04-02 12:25:24 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-35
2022-04-02 12:25:24 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-8c55d614 in namespace namespace-35
2022-04-02 12:25:24 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-35
2022-04-02 12:25:24 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-8c55d614 will have desired state: Ready
2022-04-02 12:26:40 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-8c55d614 is in desired state: Ready
2022-04-02 12:26:40 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic topic-without-labels in namespace namespace-35
2022-04-02 12:26:40 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-35
2022-04-02 12:26:42 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-35 exec my-cluster-8c55d614-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-02 12:26:42 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 12:26:43 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic topic-without-labels deletion
2022-04-02 12:26:45 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-35 exec my-cluster-8c55d614-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-02 12:26:45 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 12:26:45 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 12:26:45 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTopicWithoutLabels
2022-04-02 12:26:45 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic topic-without-labels in namespace namespace-35
2022-04-02 12:26:45 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-8c55d614 in namespace namespace-35
2022-04-02 12:26:55 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 12:26:55 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testTopicWithoutLabels-FINISHED
2022-04-02 12:26:55 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 12:26:55 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 12:26:55 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testRemoveTopicOperatorFromEntityOperator-STARTED
2022-04-02 12:26:55 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 12:26:55 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-36 for test case:testRemoveTopicOperatorFromEntityOperator
2022-04-02 12:26:55 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-36
2022-04-02 12:26:55 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-36
2022-04-02 12:26:55 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-36
2022-04-02 12:26:55 [main] [32mINFO [m [KafkaST:623] Deploying Kafka cluster my-cluster-d6d4baa7
2022-04-02 12:26:55 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-d6d4baa7 in namespace namespace-36
2022-04-02 12:26:55 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-36
2022-04-02 12:26:55 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d6d4baa7 will have desired state: Ready
2022-04-02 12:28:18 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d6d4baa7 is in desired state: Ready
2022-04-02 12:28:18 [main] [32mINFO [m [PodUtils:154] Waiting when Pod my-cluster-d6d4baa7-entity-operator-bb9fcf8bd-79bdd will be deleted
2022-04-02 12:28:33 [main] [32mINFO [m [PodUtils:171] Pod my-cluster-d6d4baa7-entity-operator-bb9fcf8bd-79bdd deleted
2022-04-02 12:28:33 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-d6d4baa7-entity-operator will be ready
2022-04-02 12:28:51 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-d6d4baa7-entity-operator is ready
2022-04-02 12:28:51 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-d6d4baa7-entity-operator to be ready
2022-04-02 12:29:01 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-d6d4baa7-entity-operator is ready
2022-04-02 12:29:01 [main] [32mINFO [m [PodUtils:201] Wait until Pod my-cluster-d6d4baa7-entity-operator will have 1 containers
2022-04-02 12:29:01 [main] [32mINFO [m [PodUtils:205] Pod my-cluster-d6d4baa7-entity-operator has 1 containers
2022-04-02 12:29:01 [main] [32mINFO [m [PodUtils:154] Waiting when Pod my-cluster-d6d4baa7-entity-operator-64b64df9cc-7wnbb will be deleted
2022-04-02 12:29:06 [main] [32mINFO [m [PodUtils:171] Pod my-cluster-d6d4baa7-entity-operator-64b64df9cc-7wnbb deleted
2022-04-02 12:29:06 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-d6d4baa7-entity-operator will be ready
2022-04-02 12:29:29 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-d6d4baa7-entity-operator is ready
2022-04-02 12:29:29 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-d6d4baa7-entity-operator to be ready
2022-04-02 12:29:39 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-d6d4baa7-entity-operator is ready
2022-04-02 12:29:39 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 12:29:39 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRemoveTopicOperatorFromEntityOperator
2022-04-02 12:29:39 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-d6d4baa7 in namespace namespace-36
2022-04-02 12:29:49 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 12:29:49 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testRemoveTopicOperatorFromEntityOperator-FINISHED
2022-04-02 12:29:49 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 12:29:49 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 12:29:49 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testEntityOperatorWithoutUserAndTopicOperators-STARTED
2022-04-02 12:29:49 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 12:29:49 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-37 for test case:testEntityOperatorWithoutUserAndTopicOperators
2022-04-02 12:29:49 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-37
2022-04-02 12:29:49 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-37
2022-04-02 12:29:49 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-37
2022-04-02 12:29:49 [main] [32mINFO [m [KafkaST:814] Deploying Kafka cluster without UO and TO in EO
2022-04-02 12:29:49 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-4626cdb0 in namespace namespace-37
2022-04-02 12:29:49 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-37
2022-04-02 12:29:49 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-4626cdb0 will have desired state: Ready
2022-04-02 12:31:35 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-4626cdb0 is in desired state: Ready
2022-04-02 12:31:35 [main] [32mINFO [m [AbstractST:478] Search in strimzi-cluster-operator log for errors in last 105 seconds
2022-04-02 12:31:35 [main] [32mINFO [m [BaseCmdKubeClient:481] Exception not found
2022-04-02 12:31:35 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 12:31:35 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testEntityOperatorWithoutUserAndTopicOperators
2022-04-02 12:31:35 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-4626cdb0 in namespace namespace-37
2022-04-02 12:31:45 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 12:31:45 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testEntityOperatorWithoutUserAndTopicOperators-FINISHED
2022-04-02 12:31:45 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 12:31:45 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 12:31:45 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testRemoveUserAndTopicOperatorsFromEntityOperator-STARTED
2022-04-02 12:31:45 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 12:31:45 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-38 for test case:testRemoveUserAndTopicOperatorsFromEntityOperator
2022-04-02 12:31:45 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-38
2022-04-02 12:31:45 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-38
2022-04-02 12:31:45 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-38
2022-04-02 12:31:45 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-8776e1d2 in namespace namespace-38
2022-04-02 12:31:45 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-38
2022-04-02 12:31:45 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-8776e1d2 will have desired state: Ready
2022-04-02 12:33:02 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-8776e1d2 is in desired state: Ready
2022-04-02 12:33:02 [main] [32mINFO [m [PodUtils:209] Wait until Pod my-cluster-8776e1d2-entity-operator will have stable 0 replicas
2022-04-02 12:33:02 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-02 12:33:03 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-02 12:33:04 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-02 12:33:05 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-02 12:33:06 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-02 12:33:07 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-02 12:33:08 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-02 12:33:09 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 19 polls
2022-04-02 12:33:10 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 18 polls
2022-04-02 12:33:11 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 17 polls
2022-04-02 12:33:12 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 16 polls
2022-04-02 12:33:13 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 15 polls
2022-04-02 12:33:14 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 14 polls
2022-04-02 12:33:15 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 13 polls
2022-04-02 12:33:16 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 12 polls
2022-04-02 12:33:17 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 11 polls
2022-04-02 12:33:18 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 10 polls
2022-04-02 12:33:19 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 9 polls
2022-04-02 12:33:20 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 8 polls
2022-04-02 12:33:21 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 7 polls
2022-04-02 12:33:22 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 6 polls
2022-04-02 12:33:23 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 5 polls
2022-04-02 12:33:24 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 4 polls
2022-04-02 12:33:25 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 3 polls
2022-04-02 12:33:26 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 2 polls
2022-04-02 12:33:27 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 1 polls
2022-04-02 12:33:28 [main] [32mINFO [m [PodUtils:217] Pod replicas are stable for 20 polls intervals
2022-04-02 12:33:28 [main] [32mINFO [m [PodUtils:228] Pod my-cluster-8776e1d2-entity-operator has 0 replicas
2022-04-02 12:33:28 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-8776e1d2-entity-operator will be ready
2022-04-02 12:34:01 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-8776e1d2-entity-operator is ready
2022-04-02 12:34:01 [main] [32mINFO [m [AbstractST:478] Search in strimzi-cluster-operator log for errors in last 136 seconds
2022-04-02 12:34:01 [main] [32mINFO [m [BaseCmdKubeClient:481] Exception not found
2022-04-02 12:34:01 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 12:34:01 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRemoveUserAndTopicOperatorsFromEntityOperator
2022-04-02 12:34:01 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-8776e1d2 in namespace namespace-38
2022-04-02 12:34:11 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 12:34:11 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testRemoveUserAndTopicOperatorsFromEntityOperator-FINISHED
2022-04-02 12:34:11 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 12:34:11 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 12:34:11 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testConsumerOffsetFiles-STARTED
2022-04-02 12:34:11 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 12:34:11 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-39 for test case:testConsumerOffsetFiles
2022-04-02 12:34:11 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-39
2022-04-02 12:34:12 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-39
2022-04-02 12:34:12 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-39
2022-04-02 12:34:12 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-83b46a7d in namespace namespace-39
2022-04-02 12:34:12 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-39
2022-04-02 12:34:12 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-83b46a7d will have desired state: Ready
2022-04-02 12:35:25 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-83b46a7d is in desired state: Ready
2022-04-02 12:35:25 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-722056079-1203034697 in namespace namespace-39
2022-04-02 12:35:25 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-39
2022-04-02 12:35:25 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-722056079-1203034697 will have desired state: Ready
2022-04-02 12:35:26 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-722056079-1203034697 is in desired state: Ready
2022-04-02 12:35:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-83b46a7d-kafka-clients in namespace namespace-39
2022-04-02 12:35:26 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-39
2022-04-02 12:35:26 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-83b46a7d-kafka-clients will be ready
2022-04-02 12:35:28 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-83b46a7d-kafka-clients is ready
2022-04-02 12:35:28 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-02 12:35:28 [main] [32mINFO [m [KafkaST:1415] Executing command cd /var/lib/kafka/data/kafka-log0/;ls -1 | sed -n "s#__consumer_offsets-\([0-9]*\)#\1#p" | sort -V in my-cluster-83b46a7d-kafka-0
2022-04-02 12:35:28 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-39 exec my-cluster-83b46a7d-kafka-0 -- /bin/bash -c cd /var/lib/kafka/data/kafka-log0/;ls -1 | sed -n "s#__consumer_offsets-\([0-9]*\)#\1#p" | sort -V
2022-04-02 12:35:28 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 12:35:28 [main] [32mINFO [m [KafkaST:1422] Result: 
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99

2022-04-02 12:35:28 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@72887150, messages=[], arguments=[--max-messages, 100, --topic, my-topic-722056079-1203034697, --bootstrap-server, my-cluster-83b46a7d-kafka-bootstrap.namespace-39.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-83b46a7d-kafka-clients-58655fcf54-k2hm2', podNamespace='namespace-39', bootstrapServer='my-cluster-83b46a7d-kafka-bootstrap.namespace-39.svc:9092', topicName='my-topic-722056079-1203034697', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7d4aea56}
2022-04-02 12:35:28 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-83b46a7d-kafka-bootstrap.namespace-39.svc:9092:my-topic-722056079-1203034697 from pod my-cluster-83b46a7d-kafka-clients-58655fcf54-k2hm2
2022-04-02 12:35:28 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-83b46a7d-kafka-clients-58655fcf54-k2hm2 -n namespace-39 -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-722056079-1203034697 --bootstrap-server my-cluster-83b46a7d-kafka-bootstrap.namespace-39.svc:9092
2022-04-02 12:35:30 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-02 12:35:30 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-02 12:35:30 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@217627c, messages=[], arguments=[--max-messages, 100, --group-instance-id, instance1020448775, --group-id, my-consumer-group-2062736251, --topic, my-topic-722056079-1203034697, --bootstrap-server, my-cluster-83b46a7d-kafka-bootstrap.namespace-39.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-83b46a7d-kafka-clients-58655fcf54-k2hm2', podNamespace='namespace-39', bootstrapServer='my-cluster-83b46a7d-kafka-bootstrap.namespace-39.svc:9092', topicName='my-topic-722056079-1203034697', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-2062736251', consumerInstanceId='instance1020448775', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6bc3ad01}
2022-04-02 12:35:30 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-83b46a7d-kafka-bootstrap.namespace-39.svc:9092#my-topic-722056079-1203034697 from pod my-cluster-83b46a7d-kafka-clients-58655fcf54-k2hm2
2022-04-02 12:35:30 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-83b46a7d-kafka-clients-58655fcf54-k2hm2 -n namespace-39 -- /opt/kafka/consumer.sh --max-messages 100 --group-instance-id instance1020448775 --group-id my-consumer-group-2062736251 --topic my-topic-722056079-1203034697 --bootstrap-server my-cluster-83b46a7d-kafka-bootstrap.namespace-39.svc:9092
2022-04-02 12:35:36 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-02 12:35:36 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-02 12:35:36 [main] [32mINFO [m [KafkaST:1429] Executing command cd /var/lib/kafka/data/kafka-log0/;ls -1 | sed -n "s#__consumer_offsets-\([0-9]*\)#\1#p" | sort -V in my-cluster-83b46a7d-kafka-0
2022-04-02 12:35:36 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-39 exec my-cluster-83b46a7d-kafka-0 -- /bin/bash -c cd /var/lib/kafka/data/kafka-log0/;ls -1 | sed -n "s#__consumer_offsets-\([0-9]*\)#\1#p" | sort -V
2022-04-02 12:35:36 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 12:35:36 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 12:35:36 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testConsumerOffsetFiles
2022-04-02 12:35:36 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-722056079-1203034697 in namespace namespace-39
2022-04-02 12:35:36 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-83b46a7d in namespace namespace-39
2022-04-02 12:35:36 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-83b46a7d-kafka-clients in namespace namespace-39
2022-04-02 12:36:26 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 12:36:26 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testConsumerOffsetFiles-FINISHED
2022-04-02 12:36:26 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 12:36:26 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 12:36:26 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testAppDomainLabels-STARTED
2022-04-02 12:36:26 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 12:36:26 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-40 for test case:testAppDomainLabels
2022-04-02 12:36:26 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-40
2022-04-02 12:36:26 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-40
2022-04-02 12:36:26 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-40
2022-04-02 12:36:27 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-c528fa54 in namespace namespace-40
2022-04-02 12:36:27 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-40
2022-04-02 12:36:27 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-c528fa54 will have desired state: Ready
2022-04-02 12:37:39 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-c528fa54 is in desired state: Ready
2022-04-02 12:37:39 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1281397986-1401714669 in namespace namespace-40
2022-04-02 12:37:39 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-40
2022-04-02 12:37:39 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1281397986-1401714669 will have desired state: Ready
2022-04-02 12:37:40 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1281397986-1401714669 is in desired state: Ready
2022-04-02 12:37:40 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-c528fa54-kafka-clients in namespace namespace-40
2022-04-02 12:37:40 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-40
2022-04-02 12:37:40 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-c528fa54-kafka-clients will be ready
2022-04-02 12:37:41 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-c528fa54-kafka-clients is ready
2022-04-02 12:37:41 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-02 12:37:41 [main] [32mINFO [m [KafkaST:1220] ---> PODS <---
2022-04-02 12:37:41 [main] [32mINFO [m [KafkaST:1232] ---> STATEFUL SETS <---
2022-04-02 12:37:41 [main] [32mINFO [m [KafkaST:1236] Getting labels from stateful set of kafka resource
2022-04-02 12:37:41 [main] [32mINFO [m [KafkaST:1765] Verifying labels {app.kubernetes.io/instance=my-cluster-c528fa54, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-c528fa54, strimzi.io/cluster=my-cluster-c528fa54, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-c528fa54-kafka, test.case=testAppDomainLabels}
2022-04-02 12:37:41 [main] [32mINFO [m [KafkaST:1241] Getting labels from stateful set of zookeeper resource
2022-04-02 12:37:41 [main] [32mINFO [m [KafkaST:1765] Verifying labels {app.kubernetes.io/instance=my-cluster-c528fa54, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=zookeeper, app.kubernetes.io/part-of=strimzi-my-cluster-c528fa54, strimzi.io/cluster=my-cluster-c528fa54, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-c528fa54-zookeeper, test.case=testAppDomainLabels}
2022-04-02 12:37:41 [main] [32mINFO [m [KafkaST:1244] ---> SERVICES <---
2022-04-02 12:37:41 [main] [32mINFO [m [KafkaST:1251] Getting labels from my-cluster-c528fa54-kafka-bootstrap service
2022-04-02 12:37:41 [main] [32mINFO [m [KafkaST:1765] Verifying labels {app.kubernetes.io/instance=my-cluster-c528fa54, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-c528fa54, strimzi.io/cluster=my-cluster-c528fa54, strimzi.io/discovery=true, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-c528fa54-kafka, test.case=testAppDomainLabels}
2022-04-02 12:37:41 [main] [32mINFO [m [KafkaST:1251] Getting labels from my-cluster-c528fa54-kafka-brokers service
2022-04-02 12:37:41 [main] [32mINFO [m [KafkaST:1765] Verifying labels {app.kubernetes.io/instance=my-cluster-c528fa54, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-c528fa54, strimzi.io/cluster=my-cluster-c528fa54, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-c528fa54-kafka, test.case=testAppDomainLabels}
2022-04-02 12:37:41 [main] [32mINFO [m [KafkaST:1251] Getting labels from my-cluster-c528fa54-zookeeper-client service
2022-04-02 12:37:41 [main] [32mINFO [m [KafkaST:1765] Verifying labels {app.kubernetes.io/instance=my-cluster-c528fa54, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=zookeeper, app.kubernetes.io/part-of=strimzi-my-cluster-c528fa54, strimzi.io/cluster=my-cluster-c528fa54, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-c528fa54-zookeeper-client, test.case=testAppDomainLabels}
2022-04-02 12:37:41 [main] [32mINFO [m [KafkaST:1251] Getting labels from my-cluster-c528fa54-zookeeper-nodes service
2022-04-02 12:37:41 [main] [32mINFO [m [KafkaST:1765] Verifying labels {app.kubernetes.io/instance=my-cluster-c528fa54, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=zookeeper, app.kubernetes.io/part-of=strimzi-my-cluster-c528fa54, strimzi.io/cluster=my-cluster-c528fa54, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-c528fa54-zookeeper, test.case=testAppDomainLabels}
2022-04-02 12:37:41 [main] [32mINFO [m [KafkaST:1255] ---> SECRETS <---
2022-04-02 12:37:41 [main] [32mINFO [m [KafkaST:1262] Getting labels from my-cluster-c528fa54-clients-ca secret
2022-04-02 12:37:41 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-c528fa54, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=strimzi, app.kubernetes.io/part-of=strimzi-my-cluster-c528fa54, strimzi.io/cluster=my-cluster-c528fa54, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testAppDomainLabels}
2022-04-02 12:37:41 [main] [32mINFO [m [KafkaST:1262] Getting labels from my-cluster-c528fa54-clients-ca-cert secret
2022-04-02 12:37:41 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-c528fa54, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=strimzi, app.kubernetes.io/part-of=strimzi-my-cluster-c528fa54, strimzi.io/cluster=my-cluster-c528fa54, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testAppDomainLabels}
2022-04-02 12:37:41 [main] [32mINFO [m [KafkaST:1262] Getting labels from my-cluster-c528fa54-cluster-ca secret
2022-04-02 12:37:41 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-c528fa54, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=strimzi, app.kubernetes.io/part-of=strimzi-my-cluster-c528fa54, strimzi.io/cluster=my-cluster-c528fa54, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testAppDomainLabels}
2022-04-02 12:37:41 [main] [32mINFO [m [KafkaST:1262] Getting labels from my-cluster-c528fa54-cluster-ca-cert secret
2022-04-02 12:37:41 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-c528fa54, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=strimzi, app.kubernetes.io/part-of=strimzi-my-cluster-c528fa54, strimzi.io/cluster=my-cluster-c528fa54, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testAppDomainLabels}
2022-04-02 12:37:41 [main] [32mINFO [m [KafkaST:1262] Getting labels from my-cluster-c528fa54-cluster-operator-certs secret
2022-04-02 12:37:41 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-c528fa54, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=strimzi, app.kubernetes.io/part-of=strimzi-my-cluster-c528fa54, strimzi.io/cluster=my-cluster-c528fa54, strimzi.io/kind=Kafka, test.case=testAppDomainLabels}
2022-04-02 12:37:41 [main] [32mINFO [m [KafkaST:1262] Getting labels from my-cluster-c528fa54-entity-topic-operator-certs secret
2022-04-02 12:37:41 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-c528fa54, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=entity-topic-operator, app.kubernetes.io/part-of=strimzi-my-cluster-c528fa54, strimzi.io/cluster=my-cluster-c528fa54, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testAppDomainLabels}
2022-04-02 12:37:41 [main] [32mINFO [m [KafkaST:1262] Getting labels from my-cluster-c528fa54-entity-user-operator-certs secret
2022-04-02 12:37:41 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-c528fa54, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=entity-user-operator, app.kubernetes.io/part-of=strimzi-my-cluster-c528fa54, strimzi.io/cluster=my-cluster-c528fa54, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testAppDomainLabels}
2022-04-02 12:37:41 [main] [32mINFO [m [KafkaST:1262] Getting labels from my-cluster-c528fa54-kafka-brokers secret
2022-04-02 12:37:41 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-c528fa54, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-c528fa54, strimzi.io/cluster=my-cluster-c528fa54, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testAppDomainLabels}
2022-04-02 12:37:41 [main] [32mINFO [m [KafkaST:1262] Getting labels from my-cluster-c528fa54-zookeeper-nodes secret
2022-04-02 12:37:41 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-c528fa54, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=zookeeper, app.kubernetes.io/part-of=strimzi-my-cluster-c528fa54, strimzi.io/cluster=my-cluster-c528fa54, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testAppDomainLabels}
2022-04-02 12:37:41 [main] [32mINFO [m [KafkaST:1266] ---> CONFIG MAPS <---
2022-04-02 12:37:41 [main] [32mINFO [m [KafkaST:1271] Getting labels from my-cluster-c528fa54-entity-topic-operator-config config map
2022-04-02 12:37:41 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-c528fa54, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=entity-topic-operator, app.kubernetes.io/part-of=strimzi-my-cluster-c528fa54, strimzi.io/cluster=my-cluster-c528fa54, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testAppDomainLabels}
2022-04-02 12:37:41 [main] [32mINFO [m [KafkaST:1271] Getting labels from my-cluster-c528fa54-entity-user-operator-config config map
2022-04-02 12:37:41 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-c528fa54, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=entity-user-operator, app.kubernetes.io/part-of=strimzi-my-cluster-c528fa54, strimzi.io/cluster=my-cluster-c528fa54, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testAppDomainLabels}
2022-04-02 12:37:41 [main] [32mINFO [m [KafkaST:1271] Getting labels from my-cluster-c528fa54-kafka-config config map
2022-04-02 12:37:41 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-c528fa54, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-c528fa54, strimzi.io/cluster=my-cluster-c528fa54, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-c528fa54-kafka, test.case=testAppDomainLabels}
2022-04-02 12:37:41 [main] [32mINFO [m [KafkaST:1271] Getting labels from my-cluster-c528fa54-zookeeper-config config map
2022-04-02 12:37:41 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-c528fa54, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=zookeeper, app.kubernetes.io/part-of=strimzi-my-cluster-c528fa54, strimzi.io/cluster=my-cluster-c528fa54, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testAppDomainLabels}
2022-04-02 12:37:41 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@778e6b9f, messages=[], arguments=[--max-messages, 100, --topic, my-topic-1281397986-1401714669, --bootstrap-server, my-cluster-c528fa54-kafka-bootstrap.namespace-40.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-c528fa54-kafka-clients-5f66c897bd-ws76s', podNamespace='namespace-40', bootstrapServer='my-cluster-c528fa54-kafka-bootstrap.namespace-40.svc:9092', topicName='my-topic-1281397986-1401714669', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@2141a658}
2022-04-02 12:37:41 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-c528fa54-kafka-bootstrap.namespace-40.svc:9092:my-topic-1281397986-1401714669 from pod my-cluster-c528fa54-kafka-clients-5f66c897bd-ws76s
2022-04-02 12:37:41 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-c528fa54-kafka-clients-5f66c897bd-ws76s -n namespace-40 -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-1281397986-1401714669 --bootstrap-server my-cluster-c528fa54-kafka-bootstrap.namespace-40.svc:9092
2022-04-02 12:37:43 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-02 12:37:43 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-02 12:37:43 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@5b785561, messages=[], arguments=[--max-messages, 100, --group-instance-id, instance163366475, --group-id, my-consumer-group-1176896034, --topic, my-topic-1281397986-1401714669, --bootstrap-server, my-cluster-c528fa54-kafka-bootstrap.namespace-40.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-c528fa54-kafka-clients-5f66c897bd-ws76s', podNamespace='namespace-40', bootstrapServer='my-cluster-c528fa54-kafka-bootstrap.namespace-40.svc:9092', topicName='my-topic-1281397986-1401714669', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1176896034', consumerInstanceId='instance163366475', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@77a74eab}
2022-04-02 12:37:43 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-c528fa54-kafka-bootstrap.namespace-40.svc:9092#my-topic-1281397986-1401714669 from pod my-cluster-c528fa54-kafka-clients-5f66c897bd-ws76s
2022-04-02 12:37:43 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-c528fa54-kafka-clients-5f66c897bd-ws76s -n namespace-40 -- /opt/kafka/consumer.sh --max-messages 100 --group-instance-id instance163366475 --group-id my-consumer-group-1176896034 --topic my-topic-1281397986-1401714669 --bootstrap-server my-cluster-c528fa54-kafka-bootstrap.namespace-40.svc:9092
2022-04-02 12:37:49 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-02 12:37:49 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-02 12:37:49 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 12:37:49 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAppDomainLabels
2022-04-02 12:37:49 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1281397986-1401714669 in namespace namespace-40
2022-04-02 12:37:49 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-c528fa54-kafka-clients in namespace namespace-40
2022-04-02 12:37:49 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-c528fa54 in namespace namespace-40
2022-04-02 12:38:29 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 12:38:29 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testAppDomainLabels-FINISHED
2022-04-02 12:38:29 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 12:38:29 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 12:38:29 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testRemoveUserOperatorFromEntityOperator-STARTED
2022-04-02 12:38:29 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 12:38:29 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-41 for test case:testRemoveUserOperatorFromEntityOperator
2022-04-02 12:38:29 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-41
2022-04-02 12:38:29 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-41
2022-04-02 12:38:29 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-41
2022-04-02 12:38:29 [main] [32mINFO [m [KafkaST:669] Deploying Kafka cluster my-cluster-bfa7e00b
2022-04-02 12:38:29 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-bfa7e00b in namespace namespace-41
2022-04-02 12:38:29 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-41
2022-04-02 12:38:29 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-bfa7e00b will have desired state: Ready
2022-04-02 12:39:37 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-bfa7e00b is in desired state: Ready
2022-04-02 12:39:37 [main] [32mINFO [m [PodUtils:154] Waiting when Pod my-cluster-bfa7e00b-entity-operator-8548d8c5d8-jrxmb will be deleted
2022-04-02 12:39:52 [main] [32mINFO [m [PodUtils:171] Pod my-cluster-bfa7e00b-entity-operator-8548d8c5d8-jrxmb deleted
2022-04-02 12:39:52 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-bfa7e00b-entity-operator will be ready
2022-04-02 12:43:51 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-bfa7e00b-entity-operator is ready
2022-04-02 12:43:51 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-bfa7e00b-entity-operator to be ready
2022-04-02 12:44:01 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-bfa7e00b-entity-operator is ready
2022-04-02 12:44:01 [main] [32mINFO [m [PodUtils:201] Wait until Pod my-cluster-bfa7e00b-entity-operator will have 2 containers
2022-04-02 12:44:01 [main] [32mINFO [m [PodUtils:205] Pod my-cluster-bfa7e00b-entity-operator has 2 containers
2022-04-02 12:44:01 [main] [32mINFO [m [PodUtils:154] Waiting when Pod my-cluster-bfa7e00b-entity-operator-6bc48488d7-lqbz9 will be deleted
2022-04-02 12:44:11 [main] [32mINFO [m [PodUtils:171] Pod my-cluster-bfa7e00b-entity-operator-6bc48488d7-lqbz9 deleted
2022-04-02 12:44:11 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-bfa7e00b-entity-operator will be ready
2022-04-02 12:48:14 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-bfa7e00b-entity-operator is ready
2022-04-02 12:48:14 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-bfa7e00b-entity-operator to be ready
2022-04-02 12:48:24 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-bfa7e00b-entity-operator is ready
2022-04-02 12:48:24 [main] [32mINFO [m [AbstractST:478] Search in strimzi-cluster-operator log for errors in last 594 seconds
2022-04-02 12:48:24 [main] [32mINFO [m [BaseCmdKubeClient:481] Exception not found
2022-04-02 12:48:24 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 12:48:24 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRemoveUserOperatorFromEntityOperator
2022-04-02 12:48:24 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-bfa7e00b in namespace namespace-41
2022-04-02 12:48:34 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 12:48:34 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testRemoveUserOperatorFromEntityOperator-FINISHED
2022-04-02 12:48:34 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 12:48:34 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 12:48:34 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testUOListeningOnlyUsersInSameCluster-STARTED
2022-04-02 12:48:34 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 12:48:34 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-42 for test case:testUOListeningOnlyUsersInSameCluster
2022-04-02 12:48:34 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-42
2022-04-02 12:48:34 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-42
2022-04-02 12:48:34 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-42
2022-04-02 12:48:34 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-1 in namespace namespace-42
2022-04-02 12:48:34 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-42
2022-04-02 12:48:34 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-1 will have desired state: Ready
2022-04-02 12:49:48 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-1 is in desired state: Ready
2022-04-02 12:49:48 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-2 in namespace namespace-42
2022-04-02 12:49:48 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-42
2022-04-02 12:49:48 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-2 will have desired state: Ready
2022-04-02 12:50:59 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-2 is in desired state: Ready
2022-04-02 12:50:59 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-783256452-1625236729 in namespace namespace-42
2022-04-02 12:50:59 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-42
2022-04-02 12:50:59 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-783256452-1625236729 will have desired state: Ready
2022-04-02 12:51:00 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-783256452-1625236729 is in desired state: Ready
2022-04-02 12:51:00 [main] [32mINFO [m [KafkaST:1292] Verifying that user my-user-783256452-1625236729 in cluster my-cluster-1 is created
2022-04-02 12:51:00 [main] [32mINFO [m [KafkaST:1297] Verifying that user my-user-783256452-1625236729 in cluster my-cluster-2 is not created
2022-04-02 12:51:00 [main] [32mINFO [m [KafkaST:1302] Verifying that user belongs to my-cluster-1 cluster
2022-04-02 12:51:00 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 12:51:00 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testUOListeningOnlyUsersInSameCluster
2022-04-02 12:51:00 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-2 in namespace namespace-42
2022-04-02 12:51:00 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-1 in namespace namespace-42
2022-04-02 12:51:00 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-783256452-1625236729 in namespace namespace-42
2022-04-02 12:51:20 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 12:51:20 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testUOListeningOnlyUsersInSameCluster-FINISHED
2022-04-02 12:51:20 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 12:51:20 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 12:51:20 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testKafkaJBODDeleteClaimsTrueFalse-STARTED
2022-04-02 12:51:20 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 12:51:20 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-43 for test case:testKafkaJBODDeleteClaimsTrueFalse
2022-04-02 12:51:20 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-43
2022-04-02 12:51:20 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-43
2022-04-02 12:51:20 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-43
2022-04-02 12:51:20 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-febc1f52 in namespace namespace-43
2022-04-02 12:51:20 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-43
2022-04-02 12:51:20 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-febc1f52 will have desired state: Ready
2022-04-02 12:53:25 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-febc1f52 is in desired state: Ready
2022-04-02 12:53:25 [main] [32mINFO [m [KafkaST:1710] Checking labels for volume:data-0-my-cluster-febc1f52-kafka-0
2022-04-02 12:53:25 [main] [32mINFO [m [KafkaST:1710] Checking labels for volume:data-0-my-cluster-febc1f52-kafka-1
2022-04-02 12:53:25 [main] [32mINFO [m [KafkaST:1710] Checking labels for volume:data-1-my-cluster-febc1f52-kafka-0
2022-04-02 12:53:25 [main] [32mINFO [m [KafkaST:1710] Checking labels for volume:data-1-my-cluster-febc1f52-kafka-1
2022-04-02 12:53:25 [main] [32mINFO [m [KafkaST:1717] Checking PVC names included in JBOD array
2022-04-02 12:53:25 [main] [32mINFO [m [KafkaST:1724] Checking PVC on Kafka pods
2022-04-02 12:53:25 [main] [32mINFO [m [KafkaST:1729] Getting list of mounted data sources and PVCs on Kafka pod 0
2022-04-02 12:53:25 [main] [32mINFO [m [KafkaST:1737] Verifying mounted data sources and PVCs on Kafka pod 0
2022-04-02 12:53:25 [main] [32mINFO [m [KafkaST:1729] Getting list of mounted data sources and PVCs on Kafka pod 1
2022-04-02 12:53:25 [main] [32mINFO [m [KafkaST:1737] Verifying mounted data sources and PVCs on Kafka pod 1
2022-04-02 12:53:25 [main] [32mINFO [m [KafkaST:882] Deleting cluster
2022-04-02 12:53:26 [main] [32mINFO [m [KafkaST:885] Waiting for PVC deletion
2022-04-02 12:53:46 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 12:53:46 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaJBODDeleteClaimsTrueFalse
2022-04-02 12:53:46 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-febc1f52 in namespace namespace-43
2022-04-02 12:53:46 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 12:53:46 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testKafkaJBODDeleteClaimsTrueFalse-FINISHED
2022-04-02 12:53:46 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 12:53:46 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 12:53:46 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testLabelsAndAnnotationForPVC-STARTED
2022-04-02 12:53:46 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 12:53:46 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-44 for test case:testLabelsAndAnnotationForPVC
2022-04-02 12:53:46 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-44
2022-04-02 12:53:46 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-44
2022-04-02 12:53:46 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-44
2022-04-02 12:53:46 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-fd1b7516 in namespace namespace-44
2022-04-02 12:53:46 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-44
2022-04-02 12:53:46 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-fd1b7516 will have desired state: Ready
2022-04-02 12:55:03 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-fd1b7516 is in desired state: Ready
2022-04-02 12:55:03 [main] [32mINFO [m [KafkaST:1510] Check if Kubernetes labels are applied
2022-04-02 12:55:03 [main] [32mINFO [m [KafkaST:1517] Kubernetes labels are correctly set and present
2022-04-02 12:55:03 [main] [32mINFO [m [KafkaST:1525] Verifying that PVC label data-0-my-cluster-fd1b7516-kafka-0 - testValue = testValue
2022-04-02 12:55:03 [main] [32mINFO [m [KafkaST:1525] Verifying that PVC label data-0-my-cluster-fd1b7516-kafka-1 - testValue = testValue
2022-04-02 12:55:03 [main] [32mINFO [m [KafkaST:1525] Verifying that PVC label data-0-my-cluster-fd1b7516-kafka-2 - testValue = testValue
2022-04-02 12:55:03 [main] [32mINFO [m [KafkaST:1525] Verifying that PVC label data-1-my-cluster-fd1b7516-kafka-0 - testValue = testValue
2022-04-02 12:55:03 [main] [32mINFO [m [KafkaST:1525] Verifying that PVC label data-1-my-cluster-fd1b7516-kafka-1 - testValue = testValue
2022-04-02 12:55:03 [main] [32mINFO [m [KafkaST:1525] Verifying that PVC label data-1-my-cluster-fd1b7516-kafka-2 - testValue = testValue
2022-04-02 12:55:03 [main] [32mINFO [m [KafkaST:1525] Verifying that PVC label data-my-cluster-fd1b7516-zookeeper-0 - testValue = testValue
2022-04-02 12:55:03 [main] [32mINFO [m [KafkaST:1535] Replacing kafka && zookeeper labels and annotations from testKey to editedTestValue
2022-04-02 12:55:03 [main] [32mINFO [m [PersistentVolumeClaimUtils:30] Wait until PVC labels will change {testKey=editedTestValue}
2022-04-02 12:55:06 [main] [32mINFO [m [PersistentVolumeClaimUtils:46] PVC labels has changed {testKey=editedTestValue}
2022-04-02 12:55:06 [main] [32mINFO [m [PersistentVolumeClaimUtils:50] Wait until PVC annotation will change {testKey=editedTestValue}
2022-04-02 12:55:06 [main] [32mINFO [m [PersistentVolumeClaimUtils:66] PVC annotation has changed {testKey=editedTestValue}
2022-04-02 12:55:06 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-fd1b7516 will have desired state: Ready
2022-04-02 12:55:06 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-fd1b7516 is in desired state: Ready
2022-04-02 12:55:06 [main] [32mINFO [m [KafkaST:1549] [PersistentVolumeClaim(apiVersion=v1, kind=PersistentVolumeClaim, metadata=ObjectMeta(annotations={pv.kubernetes.io/bind-completed=yes, strimzi.io/delete-claim=false, testKey=editedTestValue}, clusterName=null, creationTimestamp=2022-04-02T12:54:15Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[kubernetes.io/pvc-protection], generateName=null, generation=null, labels={app.kubernetes.io/instance=my-cluster-fd1b7516, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-fd1b7516, strimzi.io/cluster=my-cluster-fd1b7516, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-fd1b7516-kafka, test.case=testLabelsAndAnnotationForPVC, testKey=editedTestValue}, managedFields=[], name=data-0-my-cluster-fd1b7516-kafka-0, namespace=namespace-44, ownerReferences=[], resourceVersion=356019, selfLink=/api/v1/namespaces/namespace-44/persistentvolumeclaims/data-0-my-cluster-fd1b7516-kafka-0, uid=b0f02790-23f2-4fa8-ae42-f2a8f1ecd5b4, additionalProperties={}), spec=PersistentVolumeClaimSpec(accessModes=[ReadWriteOnce], dataSource=null, dataSourceRef=null, resources=ResourceRequirements(limits=null, requests={storage=20Gi}, additionalProperties={}), selector=null, storageClassName=standard, volumeMode=Filesystem, volumeName=pvc-b0f02790-23f2-4fa8-ae42-f2a8f1ecd5b4, additionalProperties={}), status=PersistentVolumeClaimStatus(accessModes=[ReadWriteOnce], allocatedResources=null, capacity={storage=20Gi}, conditions=[], phase=Bound, resizeStatus=null, additionalProperties={}), additionalProperties={}), PersistentVolumeClaim(apiVersion=v1, kind=PersistentVolumeClaim, metadata=ObjectMeta(annotations={pv.kubernetes.io/bind-completed=yes, strimzi.io/delete-claim=false, testKey=editedTestValue}, clusterName=null, creationTimestamp=2022-04-02T12:54:15Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[kubernetes.io/pvc-protection], generateName=null, generation=null, labels={app.kubernetes.io/instance=my-cluster-fd1b7516, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-fd1b7516, strimzi.io/cluster=my-cluster-fd1b7516, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-fd1b7516-kafka, test.case=testLabelsAndAnnotationForPVC, testKey=editedTestValue}, managedFields=[], name=data-0-my-cluster-fd1b7516-kafka-1, namespace=namespace-44, ownerReferences=[], resourceVersion=356022, selfLink=/api/v1/namespaces/namespace-44/persistentvolumeclaims/data-0-my-cluster-fd1b7516-kafka-1, uid=2c4391c3-ea49-4cd6-99b7-52229f2ddfdc, additionalProperties={}), spec=PersistentVolumeClaimSpec(accessModes=[ReadWriteOnce], dataSource=null, dataSourceRef=null, resources=ResourceRequirements(limits=null, requests={storage=20Gi}, additionalProperties={}), selector=null, storageClassName=standard, volumeMode=Filesystem, volumeName=pvc-2c4391c3-ea49-4cd6-99b7-52229f2ddfdc, additionalProperties={}), status=PersistentVolumeClaimStatus(accessModes=[ReadWriteOnce], allocatedResources=null, capacity={storage=20Gi}, conditions=[], phase=Bound, resizeStatus=null, additionalProperties={}), additionalProperties={}), PersistentVolumeClaim(apiVersion=v1, kind=PersistentVolumeClaim, metadata=ObjectMeta(annotations={pv.kubernetes.io/bind-completed=yes, strimzi.io/delete-claim=false, testKey=editedTestValue}, clusterName=null, creationTimestamp=2022-04-02T12:54:15Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[kubernetes.io/pvc-protection], generateName=null, generation=null, labels={app.kubernetes.io/instance=my-cluster-fd1b7516, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-fd1b7516, strimzi.io/cluster=my-cluster-fd1b7516, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-fd1b7516-kafka, test.case=testLabelsAndAnnotationForPVC, testKey=editedTestValue}, managedFields=[], name=data-0-my-cluster-fd1b7516-kafka-2, namespace=namespace-44, ownerReferences=[], resourceVersion=356016, selfLink=/api/v1/namespaces/namespace-44/persistentvolumeclaims/data-0-my-cluster-fd1b7516-kafka-2, uid=452035b3-8b41-4b01-bc54-dff32e94429c, additionalProperties={}), spec=PersistentVolumeClaimSpec(accessModes=[ReadWriteOnce], dataSource=null, dataSourceRef=null, resources=ResourceRequirements(limits=null, requests={storage=20Gi}, additionalProperties={}), selector=null, storageClassName=standard, volumeMode=Filesystem, volumeName=pvc-452035b3-8b41-4b01-bc54-dff32e94429c, additionalProperties={}), status=PersistentVolumeClaimStatus(accessModes=[ReadWriteOnce], allocatedResources=null, capacity={storage=20Gi}, conditions=[], phase=Bound, resizeStatus=null, additionalProperties={}), additionalProperties={}), PersistentVolumeClaim(apiVersion=v1, kind=PersistentVolumeClaim, metadata=ObjectMeta(annotations={pv.kubernetes.io/bind-completed=yes, strimzi.io/delete-claim=true, testKey=editedTestValue}, clusterName=null, creationTimestamp=2022-04-02T12:54:15Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[kubernetes.io/pvc-protection], generateName=null, generation=null, labels={app.kubernetes.io/instance=my-cluster-fd1b7516, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-fd1b7516, strimzi.io/cluster=my-cluster-fd1b7516, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-fd1b7516-kafka, test.case=testLabelsAndAnnotationForPVC, testKey=editedTestValue}, managedFields=[], name=data-1-my-cluster-fd1b7516-kafka-0, namespace=namespace-44, ownerReferences=[OwnerReference(apiVersion=kafka.strimzi.io/v1beta2, blockOwnerDeletion=false, controller=false, kind=Kafka, name=my-cluster-fd1b7516, uid=26605f6d-f402-4afa-9994-266337f31611, additionalProperties={})], resourceVersion=356021, selfLink=/api/v1/namespaces/namespace-44/persistentvolumeclaims/data-1-my-cluster-fd1b7516-kafka-0, uid=ee541487-b49e-4c31-9513-aaf4d6ca6ddf, additionalProperties={}), spec=PersistentVolumeClaimSpec(accessModes=[ReadWriteOnce], dataSource=null, dataSourceRef=null, resources=ResourceRequirements(limits=null, requests={storage=10Gi}, additionalProperties={}), selector=null, storageClassName=standard, volumeMode=Filesystem, volumeName=pvc-ee541487-b49e-4c31-9513-aaf4d6ca6ddf, additionalProperties={}), status=PersistentVolumeClaimStatus(accessModes=[ReadWriteOnce], allocatedResources=null, capacity={storage=10Gi}, conditions=[], phase=Bound, resizeStatus=null, additionalProperties={}), additionalProperties={}), PersistentVolumeClaim(apiVersion=v1, kind=PersistentVolumeClaim, metadata=ObjectMeta(annotations={pv.kubernetes.io/bind-completed=yes, strimzi.io/delete-claim=true, testKey=editedTestValue}, clusterName=null, creationTimestamp=2022-04-02T12:54:15Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[kubernetes.io/pvc-protection], generateName=null, generation=null, labels={app.kubernetes.io/instance=my-cluster-fd1b7516, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-fd1b7516, strimzi.io/cluster=my-cluster-fd1b7516, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-fd1b7516-kafka, test.case=testLabelsAndAnnotationForPVC, testKey=editedTestValue}, managedFields=[], name=data-1-my-cluster-fd1b7516-kafka-1, namespace=namespace-44, ownerReferences=[OwnerReference(apiVersion=kafka.strimzi.io/v1beta2, blockOwnerDeletion=false, controller=false, kind=Kafka, name=my-cluster-fd1b7516, uid=26605f6d-f402-4afa-9994-266337f31611, additionalProperties={})], resourceVersion=356023, selfLink=/api/v1/namespaces/namespace-44/persistentvolumeclaims/data-1-my-cluster-fd1b7516-kafka-1, uid=6f0f063f-c719-4f3a-abb6-aac66f5ba310, additionalProperties={}), spec=PersistentVolumeClaimSpec(accessModes=[ReadWriteOnce], dataSource=null, dataSourceRef=null, resources=ResourceRequirements(limits=null, requests={storage=10Gi}, additionalProperties={}), selector=null, storageClassName=standard, volumeMode=Filesystem, volumeName=pvc-6f0f063f-c719-4f3a-abb6-aac66f5ba310, additionalProperties={}), status=PersistentVolumeClaimStatus(accessModes=[ReadWriteOnce], allocatedResources=null, capacity={storage=10Gi}, conditions=[], phase=Bound, resizeStatus=null, additionalProperties={}), additionalProperties={}), PersistentVolumeClaim(apiVersion=v1, kind=PersistentVolumeClaim, metadata=ObjectMeta(annotations={pv.kubernetes.io/bind-completed=yes, strimzi.io/delete-claim=true, testKey=editedTestValue}, clusterName=null, creationTimestamp=2022-04-02T12:54:15Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[kubernetes.io/pvc-protection], generateName=null, generation=null, labels={app.kubernetes.io/instance=my-cluster-fd1b7516, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-fd1b7516, strimzi.io/cluster=my-cluster-fd1b7516, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-fd1b7516-kafka, test.case=testLabelsAndAnnotationForPVC, testKey=editedTestValue}, managedFields=[], name=data-1-my-cluster-fd1b7516-kafka-2, namespace=namespace-44, ownerReferences=[OwnerReference(apiVersion=kafka.strimzi.io/v1beta2, blockOwnerDeletion=false, controller=false, kind=Kafka, name=my-cluster-fd1b7516, uid=26605f6d-f402-4afa-9994-266337f31611, additionalProperties={})], resourceVersion=356024, selfLink=/api/v1/namespaces/namespace-44/persistentvolumeclaims/data-1-my-cluster-fd1b7516-kafka-2, uid=70bfefde-0cbe-4d10-a67d-2db3ff6fbf19, additionalProperties={}), spec=PersistentVolumeClaimSpec(accessModes=[ReadWriteOnce], dataSource=null, dataSourceRef=null, resources=ResourceRequirements(limits=null, requests={storage=10Gi}, additionalProperties={}), selector=null, storageClassName=standard, volumeMode=Filesystem, volumeName=pvc-70bfefde-0cbe-4d10-a67d-2db3ff6fbf19, additionalProperties={}), status=PersistentVolumeClaimStatus(accessModes=[ReadWriteOnce], allocatedResources=null, capacity={storage=10Gi}, conditions=[], phase=Bound, resizeStatus=null, additionalProperties={}), additionalProperties={}), PersistentVolumeClaim(apiVersion=v1, kind=PersistentVolumeClaim, metadata=ObjectMeta(annotations={pv.kubernetes.io/bind-completed=yes, strimzi.io/delete-claim=false, testKey=editedTestValue}, clusterName=null, creationTimestamp=2022-04-02T12:53:48Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[kubernetes.io/pvc-protection], generateName=null, generation=null, labels={app.kubernetes.io/instance=my-cluster-fd1b7516, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=zookeeper, app.kubernetes.io/part-of=strimzi-my-cluster-fd1b7516, strimzi.io/cluster=my-cluster-fd1b7516, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-fd1b7516-zookeeper, test.case=testLabelsAndAnnotationForPVC, testKey=editedTestValue}, managedFields=[], name=data-my-cluster-fd1b7516-zookeeper-0, namespace=namespace-44, ownerReferences=[], resourceVersion=356006, selfLink=/api/v1/namespaces/namespace-44/persistentvolumeclaims/data-my-cluster-fd1b7516-zookeeper-0, uid=f55ecadc-6e1a-4fea-9961-15e7c0d80237, additionalProperties={}), spec=PersistentVolumeClaimSpec(accessModes=[ReadWriteOnce], dataSource=null, dataSourceRef=null, resources=ResourceRequirements(limits=null, requests={storage=3Gi}, additionalProperties={}), selector=null, storageClassName=standard, volumeMode=Filesystem, volumeName=pvc-f55ecadc-6e1a-4fea-9961-15e7c0d80237, additionalProperties={}), status=PersistentVolumeClaimStatus(accessModes=[ReadWriteOnce], allocatedResources=null, capacity={storage=3Gi}, conditions=[], phase=Bound, resizeStatus=null, additionalProperties={}), additionalProperties={})]
2022-04-02 12:55:06 [main] [32mINFO [m [KafkaST:1554] Verifying replaced PVC label data-0-my-cluster-fd1b7516-kafka-0 - testValue = editedTestValue
2022-04-02 12:55:06 [main] [32mINFO [m [KafkaST:1554] Verifying replaced PVC label data-0-my-cluster-fd1b7516-kafka-1 - testValue = editedTestValue
2022-04-02 12:55:06 [main] [32mINFO [m [KafkaST:1554] Verifying replaced PVC label data-0-my-cluster-fd1b7516-kafka-2 - testValue = editedTestValue
2022-04-02 12:55:06 [main] [32mINFO [m [KafkaST:1554] Verifying replaced PVC label data-1-my-cluster-fd1b7516-kafka-0 - testValue = editedTestValue
2022-04-02 12:55:06 [main] [32mINFO [m [KafkaST:1554] Verifying replaced PVC label data-1-my-cluster-fd1b7516-kafka-1 - testValue = editedTestValue
2022-04-02 12:55:06 [main] [32mINFO [m [KafkaST:1554] Verifying replaced PVC label data-1-my-cluster-fd1b7516-kafka-2 - testValue = editedTestValue
2022-04-02 12:55:06 [main] [32mINFO [m [KafkaST:1554] Verifying replaced PVC label data-my-cluster-fd1b7516-zookeeper-0 - testValue = editedTestValue
2022-04-02 12:55:06 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 12:55:06 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testLabelsAndAnnotationForPVC
2022-04-02 12:55:06 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-fd1b7516 in namespace namespace-44
2022-04-02 12:55:16 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 12:55:16 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testLabelsAndAnnotationForPVC-FINISHED
2022-04-02 12:55:16 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 12:55:16 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 12:55:16 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testMessagesAreStoredInDisk-STARTED
2022-04-02 12:55:16 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 12:55:16 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-45 for test case:testMessagesAreStoredInDisk
2022-04-02 12:55:16 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-45
2022-04-02 12:55:16 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-45
2022-04-02 12:55:16 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-45
2022-04-02 12:55:16 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-7a45a4ec in namespace namespace-45
2022-04-02 12:55:16 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-45
2022-04-02 12:55:16 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-7a45a4ec will have desired state: Ready
2022-04-02 12:56:19 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-7a45a4ec is in desired state: Ready
2022-04-02 12:56:19 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1915143877-1149560305 in namespace namespace-45
2022-04-02 12:56:19 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-45
2022-04-02 12:56:19 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1915143877-1149560305 will have desired state: Ready
2022-04-02 12:56:20 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1915143877-1149560305 is in desired state: Ready
2022-04-02 12:56:20 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-7a45a4ec-kafka-clients in namespace namespace-45
2022-04-02 12:56:20 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-45
2022-04-02 12:56:20 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-7a45a4ec-kafka-clients will be ready
2022-04-02 12:56:22 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-7a45a4ec-kafka-clients is ready
2022-04-02 12:56:22 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-02 12:56:22 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-45 exec my-cluster-7a45a4ec-kafka-0 -- /bin/bash -c cd /var/lib/kafka/data/kafka-log0; ls -1
2022-04-02 12:56:22 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 12:56:22 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-45 exec my-cluster-7a45a4ec-kafka-0 -- /bin/bash -c cd /var/lib/kafka/data/kafka-log0; ls -1 | sed -n '/my-topic-1915143877-1149560305/p'
2022-04-02 12:56:22 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 12:56:22 [main] [32mINFO [m [KafkaST:1344] Executing command cd /var/lib/kafka/data/kafka-log0/my-topic-1915143877-1149560305-0
/;cat 00000000000000000000.log in my-cluster-7a45a4ec-kafka-0
2022-04-02 12:56:22 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-45 exec my-cluster-7a45a4ec-kafka-0 -- /bin/bash -c cd /var/lib/kafka/data/kafka-log0/my-topic-1915143877-1149560305-0
/;cat 00000000000000000000.log
2022-04-02 12:56:22 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 12:56:22 [main] [32mINFO [m [KafkaST:1348] Topic my-topic-1915143877-1149560305 is present in kafka broker my-cluster-7a45a4ec-kafka-0 with no data
2022-04-02 12:56:22 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@7f95d303, messages=[], arguments=[--max-messages, 100, --topic, my-topic-1915143877-1149560305, --bootstrap-server, my-cluster-7a45a4ec-kafka-bootstrap.namespace-45.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-7a45a4ec-kafka-clients-686547dd9-bmn9h', podNamespace='namespace-45', bootstrapServer='my-cluster-7a45a4ec-kafka-bootstrap.namespace-45.svc:9092', topicName='my-topic-1915143877-1149560305', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@4628a7da}
2022-04-02 12:56:22 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-7a45a4ec-kafka-bootstrap.namespace-45.svc:9092:my-topic-1915143877-1149560305 from pod my-cluster-7a45a4ec-kafka-clients-686547dd9-bmn9h
2022-04-02 12:56:22 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-7a45a4ec-kafka-clients-686547dd9-bmn9h -n namespace-45 -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-1915143877-1149560305 --bootstrap-server my-cluster-7a45a4ec-kafka-bootstrap.namespace-45.svc:9092
2022-04-02 12:56:25 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-02 12:56:25 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-02 12:56:25 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@4e086b0a, messages=[], arguments=[--max-messages, 100, --group-instance-id, instance292182182, --group-id, my-consumer-group-1712823236, --topic, my-topic-1915143877-1149560305, --bootstrap-server, my-cluster-7a45a4ec-kafka-bootstrap.namespace-45.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-7a45a4ec-kafka-clients-686547dd9-bmn9h', podNamespace='namespace-45', bootstrapServer='my-cluster-7a45a4ec-kafka-bootstrap.namespace-45.svc:9092', topicName='my-topic-1915143877-1149560305', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1712823236', consumerInstanceId='instance292182182', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@362f3159}
2022-04-02 12:56:25 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-7a45a4ec-kafka-bootstrap.namespace-45.svc:9092#my-topic-1915143877-1149560305 from pod my-cluster-7a45a4ec-kafka-clients-686547dd9-bmn9h
2022-04-02 12:56:25 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-7a45a4ec-kafka-clients-686547dd9-bmn9h -n namespace-45 -- /opt/kafka/consumer.sh --max-messages 100 --group-instance-id instance292182182 --group-id my-consumer-group-1712823236 --topic my-topic-1915143877-1149560305 --bootstrap-server my-cluster-7a45a4ec-kafka-bootstrap.namespace-45.svc:9092
2022-04-02 12:56:30 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-02 12:56:30 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-02 12:56:30 [main] [32mINFO [m [KafkaST:1355] Executing command cd /var/lib/kafka/data/kafka-log0/my-topic-1915143877-1149560305-0
/;cat 00000000000000000000.log in my-cluster-7a45a4ec-kafka-0
2022-04-02 12:56:30 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-45 exec my-cluster-7a45a4ec-kafka-0 -- /bin/bash -c cd /var/lib/kafka/data/kafka-log0/my-topic-1915143877-1149560305-0
/;cat 00000000000000000000.log
2022-04-02 12:56:30 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 12:56:30 [main] [32mINFO [m [KafkaST:1364] Deleting kafka pod my-cluster-7a45a4ec-kafka-0
2022-04-02 12:56:30 [main] [32mINFO [m [KafkaST:1364] Deleting kafka pod my-cluster-7a45a4ec-kafka-clients-686547dd9-bmn9h
2022-04-02 12:56:31 [main] [32mINFO [m [KafkaST:1368] Wait for kafka to rolling restart ...
2022-04-02 12:56:31 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-7a45a4ec-kafka rolling update
2022-04-02 12:56:36 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-7a45a4ec-kafka has been successfully rolled
2022-04-02 12:56:36 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 1 Pod(s) of my-cluster-7a45a4ec-kafka to be ready
2022-04-02 12:57:05 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-7a45a4ec will have desired state: Ready
2022-04-02 12:57:05 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-7a45a4ec is in desired state: Ready
2022-04-02 12:57:05 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-7a45a4ec is ready
2022-04-02 12:57:05 [main] [32mINFO [m [KafkaST:1371] Executing command cd /var/lib/kafka/data/kafka-log0/my-topic-1915143877-1149560305-0
/;cat 00000000000000000000.log in my-cluster-7a45a4ec-kafka-0
2022-04-02 12:57:05 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-45 exec my-cluster-7a45a4ec-kafka-0 -- /bin/bash -c cd /var/lib/kafka/data/kafka-log0/my-topic-1915143877-1149560305-0
/;cat 00000000000000000000.log
2022-04-02 12:57:05 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 12:57:05 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 12:57:05 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMessagesAreStoredInDisk
2022-04-02 12:57:05 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1915143877-1149560305 in namespace namespace-45
2022-04-02 12:57:05 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-7a45a4ec in namespace namespace-45
2022-04-02 12:57:05 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-7a45a4ec-kafka-clients in namespace namespace-45
2022-04-02 12:57:55 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 12:57:55 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testMessagesAreStoredInDisk-FINISHED
2022-04-02 12:57:55 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 12:57:55 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 12:57:55 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testLabelModificationDoesNotBreakCluster-STARTED
2022-04-02 12:57:55 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 12:57:55 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-46 for test case:testLabelModificationDoesNotBreakCluster
2022-04-02 12:57:55 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-46
2022-04-02 12:57:55 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-46
2022-04-02 12:57:55 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-46
2022-04-02 12:57:55 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-4ce5bae1 in namespace namespace-46
2022-04-02 12:57:55 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-46
2022-04-02 12:57:55 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-4ce5bae1 will have desired state: Ready
2022-04-02 12:59:11 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-4ce5bae1 is in desired state: Ready
2022-04-02 12:59:11 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-598940274-691467854 in namespace namespace-46
2022-04-02 12:59:11 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-46
2022-04-02 12:59:11 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-598940274-691467854 will have desired state: Ready
2022-04-02 12:59:12 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-598940274-691467854 is in desired state: Ready
2022-04-02 12:59:12 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-4ce5bae1-kafka-clients in namespace namespace-46
2022-04-02 12:59:12 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-46
2022-04-02 12:59:12 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-4ce5bae1-kafka-clients will be ready
2022-04-02 12:59:14 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-4ce5bae1-kafka-clients is ready
2022-04-02 12:59:14 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-02 12:59:14 [main] [32mINFO [m [KafkaST:1078] Waiting for kafka stateful set labels changed {label-name-1=name-of-the-label-1, label-name-2=name-of-the-label-2}
2022-04-02 12:59:14 [main] [32mINFO [m [StatefulSetUtils:85] Waiting for Stateful set label change label-name-1 -> name-of-the-label-1
2022-04-02 12:59:14 [main] [32mINFO [m [StatefulSetUtils:85] Waiting for Stateful set label change label-name-2 -> name-of-the-label-2
2022-04-02 12:59:14 [main] [32mINFO [m [KafkaST:1081] Getting labels from stateful set resource
2022-04-02 12:59:14 [main] [32mINFO [m [KafkaST:1084] Verifying default labels in the Kafka CR
2022-04-02 12:59:14 [main] [32mINFO [m [KafkaST:1095] Setting new values of labels from name-of-the-label-1 to new-name-of-the-label-1 | from name-of-the-label-2 to new-name-of-the-label-2 and adding one label-name-3 with value name-of-the-label-3
2022-04-02 12:59:14 [main] [32mINFO [m [KafkaST:1098] Edit kafka labels in Kafka CR
2022-04-02 12:59:14 [main] [32mINFO [m [KafkaST:1109] Waiting for kafka service labels changed {label-name-1=new-name-of-the-label-1, label-name-2=new-name-of-the-label-2, label-name-3=name-of-the-label-3}
2022-04-02 12:59:14 [main] [32mINFO [m [ServiceUtils:33] Waiting for Service label change label-name-1 -> new-name-of-the-label-1
2022-04-02 12:59:40 [main] [32mINFO [m [ServiceUtils:33] Waiting for Service label change label-name-2 -> new-name-of-the-label-2
2022-04-02 12:59:40 [main] [32mINFO [m [ServiceUtils:33] Waiting for Service label change label-name-3 -> name-of-the-label-3
2022-04-02 12:59:40 [main] [32mINFO [m [KafkaST:1112] Verifying kafka labels via services
2022-04-02 12:59:40 [main] [32mINFO [m [KafkaST:1118] Waiting for Kafka ConfigMap my-cluster-4ce5bae1-kafka-config in namespace namespace-46 to have new labels: {label-name-1=new-name-of-the-label-1, label-name-2=new-name-of-the-label-2, label-name-3=name-of-the-label-3}
2022-04-02 12:59:40 [main] [32mINFO [m [ConfigMapUtils:42] Waiting for ConfigMap my-cluster-4ce5bae1-kafka-config label change label-name-1 -> new-name-of-the-label-1
2022-04-02 12:59:40 [main] [32mINFO [m [ConfigMapUtils:42] Waiting for ConfigMap my-cluster-4ce5bae1-kafka-config label change label-name-2 -> new-name-of-the-label-2
2022-04-02 12:59:41 [main] [32mINFO [m [ConfigMapUtils:42] Waiting for ConfigMap my-cluster-4ce5bae1-kafka-config label change label-name-3 -> name-of-the-label-3
2022-04-02 12:59:41 [main] [32mINFO [m [KafkaST:1121] Verifying Kafka labels on ConfigMap my-cluster-4ce5bae1-kafka-config in namespace namespace-46
2022-04-02 12:59:41 [main] [32mINFO [m [KafkaST:1127] Waiting for kafka stateful set labels changed {label-name-1=new-name-of-the-label-1, label-name-2=new-name-of-the-label-2, label-name-3=name-of-the-label-3}
2022-04-02 12:59:41 [main] [32mINFO [m [StatefulSetUtils:85] Waiting for Stateful set label change label-name-1 -> new-name-of-the-label-1
2022-04-02 12:59:41 [main] [32mINFO [m [StatefulSetUtils:85] Waiting for Stateful set label change label-name-2 -> new-name-of-the-label-2
2022-04-02 12:59:41 [main] [32mINFO [m [StatefulSetUtils:85] Waiting for Stateful set label change label-name-3 -> name-of-the-label-3
2022-04-02 12:59:41 [main] [32mINFO [m [KafkaST:1130] Verifying kafka labels via stateful set
2022-04-02 12:59:41 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-4ce5bae1-kafka rolling update
2022-04-02 13:00:46 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-4ce5bae1-kafka has been successfully rolled
2022-04-02 13:00:46 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-4ce5bae1-kafka to be ready
2022-04-02 13:01:20 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-4ce5bae1 will have desired state: Ready
2022-04-02 13:01:20 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-4ce5bae1 is in desired state: Ready
2022-04-02 13:01:20 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-4ce5bae1 is ready
2022-04-02 13:01:20 [main] [32mINFO [m [KafkaST:1136] Verifying via kafka pods
2022-04-02 13:01:20 [main] [32mINFO [m [KafkaST:1143] Removing labels: label-name-1 -> new-name-of-the-label-1, label-name-2 -> new-name-of-the-label-2, label-name-3 -> name-of-the-label-3
2022-04-02 13:01:20 [main] [32mINFO [m [KafkaST:1155] Waiting for kafka service labels deletion {app.kubernetes.io/instance=my-cluster-4ce5bae1, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-4ce5bae1, controller-revision-hash=my-cluster-4ce5bae1-kafka-9d9c96bf6, statefulset.kubernetes.io/pod-name=my-cluster-4ce5bae1-kafka-0, strimzi.io/cluster=my-cluster-4ce5bae1, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-4ce5bae1-kafka, test.case=testLabelModificationDoesNotBreakCluster}
2022-04-02 13:01:20 [main] [32mINFO [m [ServiceUtils:44] Service label label-name-1 change to null
2022-04-02 13:04:20 [main] [1;31mERROR[m [TestExecutionWatcher:28] KafkaST - Exception Timeout after 180000 ms waiting for Service labellabel-name-1 change to null has been thrown in @Test. Going to collect logs from components.
2022-04-02 13:04:20 [main] [32mINFO [m [LogCollector:252] Collecting events in Namespace infra-namespace
2022-04-02 13:04:20 [main] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace infra-namespace
2022-04-02 13:04:20 [main] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace infra-namespace
2022-04-02 13:04:26 [main] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace infra-namespace
2022-04-02 13:04:26 [main] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace infra-namespace
2022-04-02 13:04:26 [main] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace infra-namespace
2022-04-02 13:04:26 [main] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace infra-namespace
2022-04-02 13:04:27 [main] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-04-02 13:04:27 [main] [32mINFO [m [LogCollector:252] Collecting events in Namespace kafka-st
2022-04-02 13:04:27 [main] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace kafka-st
2022-04-02 13:04:27 [main] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace kafka-st
2022-04-02 13:04:27 [main] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace kafka-st
2022-04-02 13:04:27 [main] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace kafka-st
2022-04-02 13:04:27 [main] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace kafka-st
2022-04-02 13:04:27 [main] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace kafka-st
2022-04-02 13:04:27 [main] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-04-02 13:04:27 [main] [32mINFO [m [LogCollector:252] Collecting events in Namespace namespace-46
2022-04-02 13:04:27 [main] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace namespace-46
2022-04-02 13:04:27 [main] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace namespace-46
2022-04-02 13:04:29 [main] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace namespace-46
2022-04-02 13:04:29 [main] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace namespace-46
2022-04-02 13:04:29 [main] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace namespace-46
2022-04-02 13:04:29 [main] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace namespace-46
2022-04-02 13:04:29 [main] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-04-02 13:04:29 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 13:04:29 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testLabelModificationDoesNotBreakCluster
2022-04-02 13:04:29 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-598940274-691467854 in namespace namespace-46
2022-04-02 13:04:29 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-4ce5bae1 in namespace namespace-46
2022-04-02 13:04:29 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-4ce5bae1-kafka-clients in namespace namespace-46
2022-04-02 13:05:09 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 13:05:10 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testLabelModificationDoesNotBreakCluster-FINISHED
2022-04-02 13:05:10 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 13:05:10 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 13:05:10 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testEODeletion-STARTED
2022-04-02 13:05:10 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 13:05:10 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-47 for test case:testEODeletion
2022-04-02 13:05:10 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-47
2022-04-02 13:05:10 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-47
2022-04-02 13:05:10 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-47
2022-04-02 13:05:10 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-3fa4732c in namespace namespace-47
2022-04-02 13:05:10 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-47
2022-04-02 13:05:10 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-3fa4732c will have desired state: Ready
2022-04-02 13:06:19 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-3fa4732c is in desired state: Ready
2022-04-02 13:06:19 [main] [32mINFO [m [KafkaST:122] Setting entity operator to null
2022-04-02 13:06:19 [main] [33mWARN [m [DeploymentUtils:213] Deployment my-cluster-3fa4732c-entity-operator is not deleted yet! Triggering force delete by cmd client!
2022-04-02 13:06:24 [main] [33mWARN [m [DeploymentUtils:213] Deployment my-cluster-3fa4732c-entity-operator is not deleted yet! Triggering force delete by cmd client!
2022-04-02 13:06:29 [main] [32mINFO [m [PodUtils:154] Waiting when Pod my-cluster-3fa4732c-entity-operator-6cf6f45dcb-pdfvn will be deleted
2022-04-02 13:06:34 [main] [32mINFO [m [PodUtils:171] Pod my-cluster-3fa4732c-entity-operator-6cf6f45dcb-pdfvn deleted
2022-04-02 13:06:34 [main] [32mINFO [m [KafkaST:130] Entity operator was deleted
2022-04-02 13:06:34 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 13:06:34 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testEODeletion
2022-04-02 13:06:34 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-3fa4732c in namespace namespace-47
2022-04-02 13:06:44 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 13:06:44 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testEODeletion-FINISHED
2022-04-02 13:06:44 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 13:06:44 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 13:06:44 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testJvmAndResources-STARTED
2022-04-02 13:06:44 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 13:06:44 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-48 for test case:testJvmAndResources
2022-04-02 13:06:44 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-48
2022-04-02 13:06:44 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-48
2022-04-02 13:06:44 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-48
2022-04-02 13:06:44 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-a2cac51a in namespace namespace-48
2022-04-02 13:06:44 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-48
2022-04-02 13:06:44 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-a2cac51a will have desired state: Ready
2022-04-02 13:08:09 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-a2cac51a is in desired state: Ready
2022-04-02 13:08:10 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-48 exec my-cluster-a2cac51a-kafka-0 -c kafka -- /bin/bash -c for proc in $(ls -1 /proc/ | grep [0-9]); do if echo "$(ls -lh /proc/$proc/exe 2>/dev/null || true)" | grep -q java; then cat /proc/$proc/cmdline; fi; done
2022-04-02 13:08:10 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 13:08:10 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-48 exec my-cluster-a2cac51a-zookeeper-0 -c zookeeper -- /bin/bash -c for proc in $(ls -1 /proc/ | grep [0-9]); do if echo "$(ls -lh /proc/$proc/exe 2>/dev/null || true)" | grep -q java; then cat /proc/$proc/cmdline; fi; done
2022-04-02 13:08:10 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 13:08:10 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-48 exec my-cluster-a2cac51a-entity-operator-555968cc87-kn6dw -c topic-operator -- /bin/bash -c for proc in $(ls -1 /proc/ | grep [0-9]); do if echo "$(ls -lh /proc/$proc/exe 2>/dev/null || true)" | grep -q java; then cat /proc/$proc/cmdline; fi; done
2022-04-02 13:08:10 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 13:08:10 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-48 exec my-cluster-a2cac51a-entity-operator-555968cc87-kn6dw -c user-operator -- /bin/bash -c for proc in $(ls -1 /proc/ | grep [0-9]); do if echo "$(ls -lh /proc/$proc/exe 2>/dev/null || true)" | grep -q java; then cat /proc/$proc/cmdline; fi; done
2022-04-02 13:08:10 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 13:08:10 [main] [32mINFO [m [KafkaST:533] Check if -D java options are present in topic-operator
2022-04-02 13:08:10 [main] [32mINFO [m [KafkaST:533] Check if -D java options are present in user-operator
2022-04-02 13:08:10 [main] [32mINFO [m [KafkaST:552] Checking no rolling update for Kafka cluster
2022-04-02 13:08:10 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-zookeeper-0=1e612677-ed5e-4be2-94c5-a3166d62b72d} pods didn't roll. Remaining seconds for stability: 50
2022-04-02 13:08:11 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-zookeeper-0=1e612677-ed5e-4be2-94c5-a3166d62b72d} pods didn't roll. Remaining seconds for stability: 49
2022-04-02 13:08:12 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-zookeeper-0=1e612677-ed5e-4be2-94c5-a3166d62b72d} pods didn't roll. Remaining seconds for stability: 48
2022-04-02 13:08:13 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-zookeeper-0=1e612677-ed5e-4be2-94c5-a3166d62b72d} pods didn't roll. Remaining seconds for stability: 47
2022-04-02 13:08:14 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-zookeeper-0=1e612677-ed5e-4be2-94c5-a3166d62b72d} pods didn't roll. Remaining seconds for stability: 46
2022-04-02 13:08:16 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-zookeeper-0=1e612677-ed5e-4be2-94c5-a3166d62b72d} pods didn't roll. Remaining seconds for stability: 45
2022-04-02 13:08:17 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-zookeeper-0=1e612677-ed5e-4be2-94c5-a3166d62b72d} pods didn't roll. Remaining seconds for stability: 44
2022-04-02 13:08:18 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-zookeeper-0=1e612677-ed5e-4be2-94c5-a3166d62b72d} pods didn't roll. Remaining seconds for stability: 43
2022-04-02 13:08:19 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-zookeeper-0=1e612677-ed5e-4be2-94c5-a3166d62b72d} pods didn't roll. Remaining seconds for stability: 42
2022-04-02 13:08:20 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-zookeeper-0=1e612677-ed5e-4be2-94c5-a3166d62b72d} pods didn't roll. Remaining seconds for stability: 41
2022-04-02 13:08:21 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-zookeeper-0=1e612677-ed5e-4be2-94c5-a3166d62b72d} pods didn't roll. Remaining seconds for stability: 40
2022-04-02 13:08:22 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-zookeeper-0=1e612677-ed5e-4be2-94c5-a3166d62b72d} pods didn't roll. Remaining seconds for stability: 39
2022-04-02 13:08:23 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-zookeeper-0=1e612677-ed5e-4be2-94c5-a3166d62b72d} pods didn't roll. Remaining seconds for stability: 38
2022-04-02 13:08:24 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-zookeeper-0=1e612677-ed5e-4be2-94c5-a3166d62b72d} pods didn't roll. Remaining seconds for stability: 37
2022-04-02 13:08:25 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-zookeeper-0=1e612677-ed5e-4be2-94c5-a3166d62b72d} pods didn't roll. Remaining seconds for stability: 36
2022-04-02 13:08:26 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-zookeeper-0=1e612677-ed5e-4be2-94c5-a3166d62b72d} pods didn't roll. Remaining seconds for stability: 35
2022-04-02 13:08:27 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-zookeeper-0=1e612677-ed5e-4be2-94c5-a3166d62b72d} pods didn't roll. Remaining seconds for stability: 34
2022-04-02 13:08:28 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-zookeeper-0=1e612677-ed5e-4be2-94c5-a3166d62b72d} pods didn't roll. Remaining seconds for stability: 33
2022-04-02 13:08:29 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-zookeeper-0=1e612677-ed5e-4be2-94c5-a3166d62b72d} pods didn't roll. Remaining seconds for stability: 32
2022-04-02 13:08:30 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-zookeeper-0=1e612677-ed5e-4be2-94c5-a3166d62b72d} pods didn't roll. Remaining seconds for stability: 31
2022-04-02 13:08:31 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-zookeeper-0=1e612677-ed5e-4be2-94c5-a3166d62b72d} pods didn't roll. Remaining seconds for stability: 30
2022-04-02 13:08:32 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-zookeeper-0=1e612677-ed5e-4be2-94c5-a3166d62b72d} pods didn't roll. Remaining seconds for stability: 29
2022-04-02 13:08:33 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-zookeeper-0=1e612677-ed5e-4be2-94c5-a3166d62b72d} pods didn't roll. Remaining seconds for stability: 28
2022-04-02 13:08:34 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-zookeeper-0=1e612677-ed5e-4be2-94c5-a3166d62b72d} pods didn't roll. Remaining seconds for stability: 27
2022-04-02 13:08:35 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-zookeeper-0=1e612677-ed5e-4be2-94c5-a3166d62b72d} pods didn't roll. Remaining seconds for stability: 26
2022-04-02 13:08:36 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-zookeeper-0=1e612677-ed5e-4be2-94c5-a3166d62b72d} pods didn't roll. Remaining seconds for stability: 25
2022-04-02 13:08:37 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-zookeeper-0=1e612677-ed5e-4be2-94c5-a3166d62b72d} pods didn't roll. Remaining seconds for stability: 24
2022-04-02 13:08:38 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-zookeeper-0=1e612677-ed5e-4be2-94c5-a3166d62b72d} pods didn't roll. Remaining seconds for stability: 23
2022-04-02 13:08:39 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-zookeeper-0=1e612677-ed5e-4be2-94c5-a3166d62b72d} pods didn't roll. Remaining seconds for stability: 22
2022-04-02 13:08:40 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-zookeeper-0=1e612677-ed5e-4be2-94c5-a3166d62b72d} pods didn't roll. Remaining seconds for stability: 21
2022-04-02 13:08:41 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-zookeeper-0=1e612677-ed5e-4be2-94c5-a3166d62b72d} pods didn't roll. Remaining seconds for stability: 20
2022-04-02 13:08:42 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-zookeeper-0=1e612677-ed5e-4be2-94c5-a3166d62b72d} pods didn't roll. Remaining seconds for stability: 19
2022-04-02 13:08:43 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-zookeeper-0=1e612677-ed5e-4be2-94c5-a3166d62b72d} pods didn't roll. Remaining seconds for stability: 18
2022-04-02 13:08:44 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-zookeeper-0=1e612677-ed5e-4be2-94c5-a3166d62b72d} pods didn't roll. Remaining seconds for stability: 17
2022-04-02 13:08:45 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-zookeeper-0=1e612677-ed5e-4be2-94c5-a3166d62b72d} pods didn't roll. Remaining seconds for stability: 16
2022-04-02 13:08:46 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-zookeeper-0=1e612677-ed5e-4be2-94c5-a3166d62b72d} pods didn't roll. Remaining seconds for stability: 15
2022-04-02 13:08:47 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-zookeeper-0=1e612677-ed5e-4be2-94c5-a3166d62b72d} pods didn't roll. Remaining seconds for stability: 14
2022-04-02 13:08:48 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-zookeeper-0=1e612677-ed5e-4be2-94c5-a3166d62b72d} pods didn't roll. Remaining seconds for stability: 13
2022-04-02 13:08:49 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-zookeeper-0=1e612677-ed5e-4be2-94c5-a3166d62b72d} pods didn't roll. Remaining seconds for stability: 12
2022-04-02 13:08:50 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-zookeeper-0=1e612677-ed5e-4be2-94c5-a3166d62b72d} pods didn't roll. Remaining seconds for stability: 11
2022-04-02 13:08:51 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-zookeeper-0=1e612677-ed5e-4be2-94c5-a3166d62b72d} pods didn't roll. Remaining seconds for stability: 10
2022-04-02 13:08:52 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-zookeeper-0=1e612677-ed5e-4be2-94c5-a3166d62b72d} pods didn't roll. Remaining seconds for stability: 9
2022-04-02 13:08:53 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-zookeeper-0=1e612677-ed5e-4be2-94c5-a3166d62b72d} pods didn't roll. Remaining seconds for stability: 8
2022-04-02 13:08:54 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-zookeeper-0=1e612677-ed5e-4be2-94c5-a3166d62b72d} pods didn't roll. Remaining seconds for stability: 7
2022-04-02 13:08:55 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-zookeeper-0=1e612677-ed5e-4be2-94c5-a3166d62b72d} pods didn't roll. Remaining seconds for stability: 6
2022-04-02 13:08:56 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-zookeeper-0=1e612677-ed5e-4be2-94c5-a3166d62b72d} pods didn't roll. Remaining seconds for stability: 5
2022-04-02 13:08:57 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-zookeeper-0=1e612677-ed5e-4be2-94c5-a3166d62b72d} pods didn't roll. Remaining seconds for stability: 4
2022-04-02 13:08:58 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-zookeeper-0=1e612677-ed5e-4be2-94c5-a3166d62b72d} pods didn't roll. Remaining seconds for stability: 3
2022-04-02 13:08:59 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-zookeeper-0=1e612677-ed5e-4be2-94c5-a3166d62b72d} pods didn't roll. Remaining seconds for stability: 2
2022-04-02 13:09:00 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-zookeeper-0=1e612677-ed5e-4be2-94c5-a3166d62b72d} pods didn't roll. Remaining seconds for stability: 1
2022-04-02 13:09:01 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-zookeeper-0=1e612677-ed5e-4be2-94c5-a3166d62b72d} pods didn't roll. Remaining seconds for stability: 0
2022-04-02 13:09:01 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-kafka-0=2f5280a3-e8e8-417b-9e34-d1610c6b7a7f} pods didn't roll. Remaining seconds for stability: 50
2022-04-02 13:09:02 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-kafka-0=2f5280a3-e8e8-417b-9e34-d1610c6b7a7f} pods didn't roll. Remaining seconds for stability: 49
2022-04-02 13:09:03 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-kafka-0=2f5280a3-e8e8-417b-9e34-d1610c6b7a7f} pods didn't roll. Remaining seconds for stability: 48
2022-04-02 13:09:04 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-kafka-0=2f5280a3-e8e8-417b-9e34-d1610c6b7a7f} pods didn't roll. Remaining seconds for stability: 47
2022-04-02 13:09:05 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-kafka-0=2f5280a3-e8e8-417b-9e34-d1610c6b7a7f} pods didn't roll. Remaining seconds for stability: 46
2022-04-02 13:09:06 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-kafka-0=2f5280a3-e8e8-417b-9e34-d1610c6b7a7f} pods didn't roll. Remaining seconds for stability: 45
2022-04-02 13:09:07 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-kafka-0=2f5280a3-e8e8-417b-9e34-d1610c6b7a7f} pods didn't roll. Remaining seconds for stability: 44
2022-04-02 13:09:08 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-kafka-0=2f5280a3-e8e8-417b-9e34-d1610c6b7a7f} pods didn't roll. Remaining seconds for stability: 43
2022-04-02 13:09:09 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-kafka-0=2f5280a3-e8e8-417b-9e34-d1610c6b7a7f} pods didn't roll. Remaining seconds for stability: 42
2022-04-02 13:09:10 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-kafka-0=2f5280a3-e8e8-417b-9e34-d1610c6b7a7f} pods didn't roll. Remaining seconds for stability: 41
2022-04-02 13:09:11 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-kafka-0=2f5280a3-e8e8-417b-9e34-d1610c6b7a7f} pods didn't roll. Remaining seconds for stability: 40
2022-04-02 13:09:12 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-kafka-0=2f5280a3-e8e8-417b-9e34-d1610c6b7a7f} pods didn't roll. Remaining seconds for stability: 39
2022-04-02 13:09:13 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-kafka-0=2f5280a3-e8e8-417b-9e34-d1610c6b7a7f} pods didn't roll. Remaining seconds for stability: 38
2022-04-02 13:09:14 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-kafka-0=2f5280a3-e8e8-417b-9e34-d1610c6b7a7f} pods didn't roll. Remaining seconds for stability: 37
2022-04-02 13:09:15 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-kafka-0=2f5280a3-e8e8-417b-9e34-d1610c6b7a7f} pods didn't roll. Remaining seconds for stability: 36
2022-04-02 13:09:16 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-kafka-0=2f5280a3-e8e8-417b-9e34-d1610c6b7a7f} pods didn't roll. Remaining seconds for stability: 35
2022-04-02 13:09:17 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-kafka-0=2f5280a3-e8e8-417b-9e34-d1610c6b7a7f} pods didn't roll. Remaining seconds for stability: 34
2022-04-02 13:09:18 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-kafka-0=2f5280a3-e8e8-417b-9e34-d1610c6b7a7f} pods didn't roll. Remaining seconds for stability: 33
2022-04-02 13:09:19 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-kafka-0=2f5280a3-e8e8-417b-9e34-d1610c6b7a7f} pods didn't roll. Remaining seconds for stability: 32
2022-04-02 13:09:20 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-kafka-0=2f5280a3-e8e8-417b-9e34-d1610c6b7a7f} pods didn't roll. Remaining seconds for stability: 31
2022-04-02 13:09:21 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-kafka-0=2f5280a3-e8e8-417b-9e34-d1610c6b7a7f} pods didn't roll. Remaining seconds for stability: 30
2022-04-02 13:09:22 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-kafka-0=2f5280a3-e8e8-417b-9e34-d1610c6b7a7f} pods didn't roll. Remaining seconds for stability: 29
2022-04-02 13:09:23 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-kafka-0=2f5280a3-e8e8-417b-9e34-d1610c6b7a7f} pods didn't roll. Remaining seconds for stability: 28
2022-04-02 13:09:24 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-kafka-0=2f5280a3-e8e8-417b-9e34-d1610c6b7a7f} pods didn't roll. Remaining seconds for stability: 27
2022-04-02 13:09:25 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-kafka-0=2f5280a3-e8e8-417b-9e34-d1610c6b7a7f} pods didn't roll. Remaining seconds for stability: 26
2022-04-02 13:09:26 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-kafka-0=2f5280a3-e8e8-417b-9e34-d1610c6b7a7f} pods didn't roll. Remaining seconds for stability: 25
2022-04-02 13:09:27 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-kafka-0=2f5280a3-e8e8-417b-9e34-d1610c6b7a7f} pods didn't roll. Remaining seconds for stability: 24
2022-04-02 13:09:28 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-kafka-0=2f5280a3-e8e8-417b-9e34-d1610c6b7a7f} pods didn't roll. Remaining seconds for stability: 23
2022-04-02 13:09:29 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-kafka-0=2f5280a3-e8e8-417b-9e34-d1610c6b7a7f} pods didn't roll. Remaining seconds for stability: 22
2022-04-02 13:09:30 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-kafka-0=2f5280a3-e8e8-417b-9e34-d1610c6b7a7f} pods didn't roll. Remaining seconds for stability: 21
2022-04-02 13:09:31 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-kafka-0=2f5280a3-e8e8-417b-9e34-d1610c6b7a7f} pods didn't roll. Remaining seconds for stability: 20
2022-04-02 13:09:32 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-kafka-0=2f5280a3-e8e8-417b-9e34-d1610c6b7a7f} pods didn't roll. Remaining seconds for stability: 19
2022-04-02 13:09:33 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-kafka-0=2f5280a3-e8e8-417b-9e34-d1610c6b7a7f} pods didn't roll. Remaining seconds for stability: 18
2022-04-02 13:09:34 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-kafka-0=2f5280a3-e8e8-417b-9e34-d1610c6b7a7f} pods didn't roll. Remaining seconds for stability: 17
2022-04-02 13:09:35 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-kafka-0=2f5280a3-e8e8-417b-9e34-d1610c6b7a7f} pods didn't roll. Remaining seconds for stability: 16
2022-04-02 13:09:36 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-kafka-0=2f5280a3-e8e8-417b-9e34-d1610c6b7a7f} pods didn't roll. Remaining seconds for stability: 15
2022-04-02 13:09:37 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-kafka-0=2f5280a3-e8e8-417b-9e34-d1610c6b7a7f} pods didn't roll. Remaining seconds for stability: 14
2022-04-02 13:09:38 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-kafka-0=2f5280a3-e8e8-417b-9e34-d1610c6b7a7f} pods didn't roll. Remaining seconds for stability: 13
2022-04-02 13:09:39 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-kafka-0=2f5280a3-e8e8-417b-9e34-d1610c6b7a7f} pods didn't roll. Remaining seconds for stability: 12
2022-04-02 13:09:40 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-kafka-0=2f5280a3-e8e8-417b-9e34-d1610c6b7a7f} pods didn't roll. Remaining seconds for stability: 11
2022-04-02 13:09:41 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-kafka-0=2f5280a3-e8e8-417b-9e34-d1610c6b7a7f} pods didn't roll. Remaining seconds for stability: 10
2022-04-02 13:09:42 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-kafka-0=2f5280a3-e8e8-417b-9e34-d1610c6b7a7f} pods didn't roll. Remaining seconds for stability: 9
2022-04-02 13:09:43 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-kafka-0=2f5280a3-e8e8-417b-9e34-d1610c6b7a7f} pods didn't roll. Remaining seconds for stability: 8
2022-04-02 13:09:44 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-kafka-0=2f5280a3-e8e8-417b-9e34-d1610c6b7a7f} pods didn't roll. Remaining seconds for stability: 7
2022-04-02 13:09:45 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-kafka-0=2f5280a3-e8e8-417b-9e34-d1610c6b7a7f} pods didn't roll. Remaining seconds for stability: 6
2022-04-02 13:09:46 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-kafka-0=2f5280a3-e8e8-417b-9e34-d1610c6b7a7f} pods didn't roll. Remaining seconds for stability: 5
2022-04-02 13:09:47 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-kafka-0=2f5280a3-e8e8-417b-9e34-d1610c6b7a7f} pods didn't roll. Remaining seconds for stability: 4
2022-04-02 13:09:48 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-kafka-0=2f5280a3-e8e8-417b-9e34-d1610c6b7a7f} pods didn't roll. Remaining seconds for stability: 3
2022-04-02 13:09:49 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-kafka-0=2f5280a3-e8e8-417b-9e34-d1610c6b7a7f} pods didn't roll. Remaining seconds for stability: 2
2022-04-02 13:09:50 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-kafka-0=2f5280a3-e8e8-417b-9e34-d1610c6b7a7f} pods didn't roll. Remaining seconds for stability: 1
2022-04-02 13:09:51 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-a2cac51a-kafka-0=2f5280a3-e8e8-417b-9e34-d1610c6b7a7f} pods didn't roll. Remaining seconds for stability: 0
2022-04-02 13:09:51 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-a2cac51a-entity-operator-555968cc87-kn6dw=b0ac7f9c-a5c6-4a27-af0a-2ef72b4303b0} pods not rolling waiting, remaining seconds for stability 50
2022-04-02 13:09:52 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-a2cac51a-entity-operator-555968cc87-kn6dw=b0ac7f9c-a5c6-4a27-af0a-2ef72b4303b0} pods not rolling waiting, remaining seconds for stability 49
2022-04-02 13:09:53 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-a2cac51a-entity-operator-555968cc87-kn6dw=b0ac7f9c-a5c6-4a27-af0a-2ef72b4303b0} pods not rolling waiting, remaining seconds for stability 48
2022-04-02 13:09:54 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-a2cac51a-entity-operator-555968cc87-kn6dw=b0ac7f9c-a5c6-4a27-af0a-2ef72b4303b0} pods not rolling waiting, remaining seconds for stability 47
2022-04-02 13:09:55 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-a2cac51a-entity-operator-555968cc87-kn6dw=b0ac7f9c-a5c6-4a27-af0a-2ef72b4303b0} pods not rolling waiting, remaining seconds for stability 46
2022-04-02 13:09:56 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-a2cac51a-entity-operator-555968cc87-kn6dw=b0ac7f9c-a5c6-4a27-af0a-2ef72b4303b0} pods not rolling waiting, remaining seconds for stability 45
2022-04-02 13:09:57 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-a2cac51a-entity-operator-555968cc87-kn6dw=b0ac7f9c-a5c6-4a27-af0a-2ef72b4303b0} pods not rolling waiting, remaining seconds for stability 44
2022-04-02 13:09:58 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-a2cac51a-entity-operator-555968cc87-kn6dw=b0ac7f9c-a5c6-4a27-af0a-2ef72b4303b0} pods not rolling waiting, remaining seconds for stability 43
2022-04-02 13:09:59 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-a2cac51a-entity-operator-555968cc87-kn6dw=b0ac7f9c-a5c6-4a27-af0a-2ef72b4303b0} pods not rolling waiting, remaining seconds for stability 42
2022-04-02 13:10:00 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-a2cac51a-entity-operator-555968cc87-kn6dw=b0ac7f9c-a5c6-4a27-af0a-2ef72b4303b0} pods not rolling waiting, remaining seconds for stability 41
2022-04-02 13:10:01 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-a2cac51a-entity-operator-555968cc87-kn6dw=b0ac7f9c-a5c6-4a27-af0a-2ef72b4303b0} pods not rolling waiting, remaining seconds for stability 40
2022-04-02 13:10:02 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-a2cac51a-entity-operator-555968cc87-kn6dw=b0ac7f9c-a5c6-4a27-af0a-2ef72b4303b0} pods not rolling waiting, remaining seconds for stability 39
2022-04-02 13:10:03 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-a2cac51a-entity-operator-555968cc87-kn6dw=b0ac7f9c-a5c6-4a27-af0a-2ef72b4303b0} pods not rolling waiting, remaining seconds for stability 38
2022-04-02 13:10:04 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-a2cac51a-entity-operator-555968cc87-kn6dw=b0ac7f9c-a5c6-4a27-af0a-2ef72b4303b0} pods not rolling waiting, remaining seconds for stability 37
2022-04-02 13:10:05 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-a2cac51a-entity-operator-555968cc87-kn6dw=b0ac7f9c-a5c6-4a27-af0a-2ef72b4303b0} pods not rolling waiting, remaining seconds for stability 36
2022-04-02 13:10:06 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-a2cac51a-entity-operator-555968cc87-kn6dw=b0ac7f9c-a5c6-4a27-af0a-2ef72b4303b0} pods not rolling waiting, remaining seconds for stability 35
2022-04-02 13:10:07 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-a2cac51a-entity-operator-555968cc87-kn6dw=b0ac7f9c-a5c6-4a27-af0a-2ef72b4303b0} pods not rolling waiting, remaining seconds for stability 34
2022-04-02 13:10:08 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-a2cac51a-entity-operator-555968cc87-kn6dw=b0ac7f9c-a5c6-4a27-af0a-2ef72b4303b0} pods not rolling waiting, remaining seconds for stability 33
2022-04-02 13:10:09 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-a2cac51a-entity-operator-555968cc87-kn6dw=b0ac7f9c-a5c6-4a27-af0a-2ef72b4303b0} pods not rolling waiting, remaining seconds for stability 32
2022-04-02 13:10:10 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-a2cac51a-entity-operator-555968cc87-kn6dw=b0ac7f9c-a5c6-4a27-af0a-2ef72b4303b0} pods not rolling waiting, remaining seconds for stability 31
2022-04-02 13:10:11 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-a2cac51a-entity-operator-555968cc87-kn6dw=b0ac7f9c-a5c6-4a27-af0a-2ef72b4303b0} pods not rolling waiting, remaining seconds for stability 30
2022-04-02 13:10:12 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-a2cac51a-entity-operator-555968cc87-kn6dw=b0ac7f9c-a5c6-4a27-af0a-2ef72b4303b0} pods not rolling waiting, remaining seconds for stability 29
2022-04-02 13:10:13 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-a2cac51a-entity-operator-555968cc87-kn6dw=b0ac7f9c-a5c6-4a27-af0a-2ef72b4303b0} pods not rolling waiting, remaining seconds for stability 28
2022-04-02 13:10:14 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-a2cac51a-entity-operator-555968cc87-kn6dw=b0ac7f9c-a5c6-4a27-af0a-2ef72b4303b0} pods not rolling waiting, remaining seconds for stability 27
2022-04-02 13:10:15 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-a2cac51a-entity-operator-555968cc87-kn6dw=b0ac7f9c-a5c6-4a27-af0a-2ef72b4303b0} pods not rolling waiting, remaining seconds for stability 26
2022-04-02 13:10:16 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-a2cac51a-entity-operator-555968cc87-kn6dw=b0ac7f9c-a5c6-4a27-af0a-2ef72b4303b0} pods not rolling waiting, remaining seconds for stability 25
2022-04-02 13:10:17 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-a2cac51a-entity-operator-555968cc87-kn6dw=b0ac7f9c-a5c6-4a27-af0a-2ef72b4303b0} pods not rolling waiting, remaining seconds for stability 24
2022-04-02 13:10:18 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-a2cac51a-entity-operator-555968cc87-kn6dw=b0ac7f9c-a5c6-4a27-af0a-2ef72b4303b0} pods not rolling waiting, remaining seconds for stability 23
2022-04-02 13:10:19 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-a2cac51a-entity-operator-555968cc87-kn6dw=b0ac7f9c-a5c6-4a27-af0a-2ef72b4303b0} pods not rolling waiting, remaining seconds for stability 22
2022-04-02 13:10:20 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-a2cac51a-entity-operator-555968cc87-kn6dw=b0ac7f9c-a5c6-4a27-af0a-2ef72b4303b0} pods not rolling waiting, remaining seconds for stability 21
2022-04-02 13:10:21 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-a2cac51a-entity-operator-555968cc87-kn6dw=b0ac7f9c-a5c6-4a27-af0a-2ef72b4303b0} pods not rolling waiting, remaining seconds for stability 20
2022-04-02 13:10:22 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-a2cac51a-entity-operator-555968cc87-kn6dw=b0ac7f9c-a5c6-4a27-af0a-2ef72b4303b0} pods not rolling waiting, remaining seconds for stability 19
2022-04-02 13:10:23 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-a2cac51a-entity-operator-555968cc87-kn6dw=b0ac7f9c-a5c6-4a27-af0a-2ef72b4303b0} pods not rolling waiting, remaining seconds for stability 18
2022-04-02 13:10:24 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-a2cac51a-entity-operator-555968cc87-kn6dw=b0ac7f9c-a5c6-4a27-af0a-2ef72b4303b0} pods not rolling waiting, remaining seconds for stability 17
2022-04-02 13:10:25 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-a2cac51a-entity-operator-555968cc87-kn6dw=b0ac7f9c-a5c6-4a27-af0a-2ef72b4303b0} pods not rolling waiting, remaining seconds for stability 16
2022-04-02 13:10:26 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-a2cac51a-entity-operator-555968cc87-kn6dw=b0ac7f9c-a5c6-4a27-af0a-2ef72b4303b0} pods not rolling waiting, remaining seconds for stability 15
2022-04-02 13:10:27 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-a2cac51a-entity-operator-555968cc87-kn6dw=b0ac7f9c-a5c6-4a27-af0a-2ef72b4303b0} pods not rolling waiting, remaining seconds for stability 14
2022-04-02 13:10:28 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-a2cac51a-entity-operator-555968cc87-kn6dw=b0ac7f9c-a5c6-4a27-af0a-2ef72b4303b0} pods not rolling waiting, remaining seconds for stability 13
2022-04-02 13:10:29 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-a2cac51a-entity-operator-555968cc87-kn6dw=b0ac7f9c-a5c6-4a27-af0a-2ef72b4303b0} pods not rolling waiting, remaining seconds for stability 12
2022-04-02 13:10:30 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-a2cac51a-entity-operator-555968cc87-kn6dw=b0ac7f9c-a5c6-4a27-af0a-2ef72b4303b0} pods not rolling waiting, remaining seconds for stability 11
2022-04-02 13:10:31 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-a2cac51a-entity-operator-555968cc87-kn6dw=b0ac7f9c-a5c6-4a27-af0a-2ef72b4303b0} pods not rolling waiting, remaining seconds for stability 10
2022-04-02 13:10:32 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-a2cac51a-entity-operator-555968cc87-kn6dw=b0ac7f9c-a5c6-4a27-af0a-2ef72b4303b0} pods not rolling waiting, remaining seconds for stability 9
2022-04-02 13:10:33 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-a2cac51a-entity-operator-555968cc87-kn6dw=b0ac7f9c-a5c6-4a27-af0a-2ef72b4303b0} pods not rolling waiting, remaining seconds for stability 8
2022-04-02 13:10:34 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-a2cac51a-entity-operator-555968cc87-kn6dw=b0ac7f9c-a5c6-4a27-af0a-2ef72b4303b0} pods not rolling waiting, remaining seconds for stability 7
2022-04-02 13:10:35 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-a2cac51a-entity-operator-555968cc87-kn6dw=b0ac7f9c-a5c6-4a27-af0a-2ef72b4303b0} pods not rolling waiting, remaining seconds for stability 6
2022-04-02 13:10:36 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-a2cac51a-entity-operator-555968cc87-kn6dw=b0ac7f9c-a5c6-4a27-af0a-2ef72b4303b0} pods not rolling waiting, remaining seconds for stability 5
2022-04-02 13:10:37 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-a2cac51a-entity-operator-555968cc87-kn6dw=b0ac7f9c-a5c6-4a27-af0a-2ef72b4303b0} pods not rolling waiting, remaining seconds for stability 4
2022-04-02 13:10:38 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-a2cac51a-entity-operator-555968cc87-kn6dw=b0ac7f9c-a5c6-4a27-af0a-2ef72b4303b0} pods not rolling waiting, remaining seconds for stability 3
2022-04-02 13:10:39 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-a2cac51a-entity-operator-555968cc87-kn6dw=b0ac7f9c-a5c6-4a27-af0a-2ef72b4303b0} pods not rolling waiting, remaining seconds for stability 2
2022-04-02 13:10:40 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-a2cac51a-entity-operator-555968cc87-kn6dw=b0ac7f9c-a5c6-4a27-af0a-2ef72b4303b0} pods not rolling waiting, remaining seconds for stability 1
2022-04-02 13:10:41 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-a2cac51a-entity-operator-555968cc87-kn6dw=b0ac7f9c-a5c6-4a27-af0a-2ef72b4303b0} pods not rolling waiting, remaining seconds for stability 0
2022-04-02 13:10:41 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 13:10:41 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testJvmAndResources
2022-04-02 13:10:41 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-a2cac51a in namespace namespace-48
2022-04-02 13:10:51 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 13:10:51 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testJvmAndResources-FINISHED
2022-04-02 13:10:51 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 13:10:51 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 13:10:51 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testPersistentStorageSize-STARTED
2022-04-02 13:10:51 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 13:10:51 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-49 for test case:testPersistentStorageSize
2022-04-02 13:10:51 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-49
2022-04-02 13:10:51 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-49
2022-04-02 13:10:51 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-49
2022-04-02 13:10:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-0bc80f2a in namespace namespace-49
2022-04-02 13:10:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-49
2022-04-02 13:10:51 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-0bc80f2a will have desired state: Ready
2022-04-02 13:11:58 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-0bc80f2a is in desired state: Ready
2022-04-02 13:11:58 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-759601720-792887857 in namespace namespace-49
2022-04-02 13:11:58 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-49
2022-04-02 13:11:58 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-759601720-792887857 will have desired state: Ready
2022-04-02 13:11:59 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-759601720-792887857 is in desired state: Ready
2022-04-02 13:11:59 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-0bc80f2a-kafka-clients in namespace namespace-49
2022-04-02 13:11:59 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-49
2022-04-02 13:11:59 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-0bc80f2a-kafka-clients will be ready
2022-04-02 13:12:01 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-0bc80f2a-kafka-clients is ready
2022-04-02 13:12:01 [main] [32mINFO [m [KafkaST:1694] Checking volume data-0-my-cluster-0bc80f2a-kafka-0 and size of storage 70Gi
2022-04-02 13:12:01 [main] [32mINFO [m [KafkaST:1694] Checking volume data-0-my-cluster-0bc80f2a-kafka-1 and size of storage 70Gi
2022-04-02 13:12:01 [main] [32mINFO [m [KafkaST:1694] Checking volume data-1-my-cluster-0bc80f2a-kafka-0 and size of storage 20Gi
2022-04-02 13:12:01 [main] [32mINFO [m [KafkaST:1694] Checking volume data-1-my-cluster-0bc80f2a-kafka-1 and size of storage 20Gi
2022-04-02 13:12:01 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-02 13:12:01 [main] [32mINFO [m [KafkaST:983] Checking produced and consumed messages to pod:my-cluster-0bc80f2a-kafka-clients-65d47797fc-lgpww
2022-04-02 13:12:01 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@1d0e9ecb, messages=[], arguments=[--max-messages, 100, --topic, my-topic-759601720-792887857, --bootstrap-server, my-cluster-0bc80f2a-kafka-bootstrap.namespace-49.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-0bc80f2a-kafka-clients-65d47797fc-lgpww', podNamespace='namespace-49', bootstrapServer='my-cluster-0bc80f2a-kafka-bootstrap.namespace-49.svc:9092', topicName='my-topic-759601720-792887857', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@2288512e}
2022-04-02 13:12:01 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-0bc80f2a-kafka-bootstrap.namespace-49.svc:9092:my-topic-759601720-792887857 from pod my-cluster-0bc80f2a-kafka-clients-65d47797fc-lgpww
2022-04-02 13:12:01 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-0bc80f2a-kafka-clients-65d47797fc-lgpww -n namespace-49 -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-759601720-792887857 --bootstrap-server my-cluster-0bc80f2a-kafka-bootstrap.namespace-49.svc:9092
2022-04-02 13:12:03 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-02 13:12:03 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-02 13:12:03 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@55051b9a, messages=[], arguments=[--max-messages, 100, --group-instance-id, instance605896315, --group-id, my-consumer-group-442711365, --topic, my-topic-759601720-792887857, --bootstrap-server, my-cluster-0bc80f2a-kafka-bootstrap.namespace-49.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-0bc80f2a-kafka-clients-65d47797fc-lgpww', podNamespace='namespace-49', bootstrapServer='my-cluster-0bc80f2a-kafka-bootstrap.namespace-49.svc:9092', topicName='my-topic-759601720-792887857', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-442711365', consumerInstanceId='instance605896315', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@35643d39}
2022-04-02 13:12:03 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-0bc80f2a-kafka-bootstrap.namespace-49.svc:9092#my-topic-759601720-792887857 from pod my-cluster-0bc80f2a-kafka-clients-65d47797fc-lgpww
2022-04-02 13:12:03 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-0bc80f2a-kafka-clients-65d47797fc-lgpww -n namespace-49 -- /opt/kafka/consumer.sh --max-messages 100 --group-instance-id instance605896315 --group-id my-consumer-group-442711365 --topic my-topic-759601720-792887857 --bootstrap-server my-cluster-0bc80f2a-kafka-bootstrap.namespace-49.svc:9092
2022-04-02 13:12:09 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-02 13:12:09 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-02 13:12:09 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 13:12:09 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testPersistentStorageSize
2022-04-02 13:12:09 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-759601720-792887857 in namespace namespace-49
2022-04-02 13:12:09 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-0bc80f2a in namespace namespace-49
2022-04-02 13:12:09 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-0bc80f2a-kafka-clients in namespace namespace-49
2022-04-02 13:12:49 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 13:12:49 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testPersistentStorageSize-FINISHED
2022-04-02 13:12:49 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 13:12:49 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 13:12:49 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testForTopicOperator-STARTED
2022-04-02 13:12:49 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 13:12:49 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-50 for test case:testForTopicOperator
2022-04-02 13:12:49 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-50
2022-04-02 13:12:49 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-50
2022-04-02 13:12:49 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-50
2022-04-02 13:12:49 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-0f8cc490 in namespace namespace-50
2022-04-02 13:12:49 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-50
2022-04-02 13:12:49 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-0f8cc490 will have desired state: Ready
2022-04-02 13:14:02 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-0f8cc490 is in desired state: Ready
2022-04-02 13:14:02 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-2094595357-620273265 in namespace namespace-50
2022-04-02 13:14:02 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-50
2022-04-02 13:14:02 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-2094595357-620273265 will have desired state: Ready
2022-04-02 13:14:03 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-2094595357-620273265 is in desired state: Ready
2022-04-02 13:14:03 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-2094595357-620273265 will have desired state: Ready
2022-04-02 13:14:03 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-2094595357-620273265 is in desired state: Ready
2022-04-02 13:14:06 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-50 exec my-cluster-0f8cc490-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-02 13:14:06 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 13:14:09 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-50 exec my-cluster-0f8cc490-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --bootstrap-server localhost:9092 --create  --topic topic-from-cli --replication-factor 1 --partitions 1
2022-04-02 13:14:09 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 13:14:09 [main] [32mINFO [m [KafkaTopicUtils:78] Waiting for KafkaTopic topic-from-cli creation 
2022-04-02 13:14:11 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-50 exec my-cluster-0f8cc490-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-02 13:14:11 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 13:14:14 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-50 exec my-cluster-0f8cc490-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --bootstrap-server localhost:9092 --alter --topic my-topic-2094595357-620273265 --partitions 2
2022-04-02 13:14:14 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 13:14:14 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-0f8cc490 will have desired state: Ready
2022-04-02 13:14:14 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-0f8cc490 is in desired state: Ready
2022-04-02 13:14:17 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-50 exec my-cluster-0f8cc490-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic my-topic-2094595357-620273265
2022-04-02 13:14:17 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 13:14:17 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-0f8cc490 will have desired state: Ready
2022-04-02 13:14:17 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-0f8cc490 is in desired state: Ready
2022-04-02 13:14:20 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-50 exec my-cluster-0f8cc490-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic topic-from-cli
2022-04-02 13:14:20 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 13:14:23 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-50 exec my-cluster-0f8cc490-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --bootstrap-server localhost:9092 --delete --topic my-topic-2094595357-620273265
2022-04-02 13:14:23 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 13:14:23 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic my-topic-2094595357-620273265 deletion
2022-04-02 13:14:23 [main] [33mWARN [m [KafkaTopicUtils:110] KafkaTopic my-topic-2094595357-620273265 is not deleted yet! Triggering force delete by cmd client!
2022-04-02 13:14:37 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-50 exec my-cluster-0f8cc490-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-02 13:14:37 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 13:14:37 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 13:14:37 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testForTopicOperator
2022-04-02 13:14:37 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-2094595357-620273265 in namespace namespace-50
2022-04-02 13:14:37 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-0f8cc490 in namespace namespace-50
2022-04-02 13:14:47 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 13:14:47 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testForTopicOperator-FINISHED
2022-04-02 13:14:47 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 13:14:47 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 13:14:47 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testReadOnlyRootFileSystem-STARTED
2022-04-02 13:14:47 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 13:14:47 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-51 for test case:testReadOnlyRootFileSystem
2022-04-02 13:14:47 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-51
2022-04-02 13:14:47 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-51
2022-04-02 13:14:47 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-51
2022-04-02 13:14:47 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-983709ec in namespace namespace-51
2022-04-02 13:14:47 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-51
2022-04-02 13:14:47 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-983709ec will have desired state: Ready
2022-04-02 13:17:55 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-983709ec is in desired state: Ready
2022-04-02 13:17:55 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-983709ec will have desired state: Ready
2022-04-02 13:17:55 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-983709ec is in desired state: Ready
2022-04-02 13:17:55 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1883121268-1853198657 in namespace namespace-51
2022-04-02 13:17:55 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-51
2022-04-02 13:17:55 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1883121268-1853198657 will have desired state: Ready
2022-04-02 13:17:56 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1883121268-1853198657 is in desired state: Ready
2022-04-02 13:17:56 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-983709ec-kafka-clients in namespace namespace-51
2022-04-02 13:17:56 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-51
2022-04-02 13:17:56 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-983709ec-kafka-clients will be ready
2022-04-02 13:17:57 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-983709ec-kafka-clients is ready
2022-04-02 13:17:57 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-02 13:17:57 [main] [32mINFO [m [KafkaST:1652] Checking produced and consumed messages to pod:my-cluster-983709ec-kafka-clients-7b684c4f55-7fmf5
2022-04-02 13:17:57 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@2dd8d82a, messages=[], arguments=[--max-messages, 100, --topic, my-topic-1883121268-1853198657, --bootstrap-server, my-cluster-983709ec-kafka-bootstrap.namespace-51.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-983709ec-kafka-clients-7b684c4f55-7fmf5', podNamespace='namespace-51', bootstrapServer='my-cluster-983709ec-kafka-bootstrap.namespace-51.svc:9092', topicName='my-topic-1883121268-1853198657', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3d871b40}
2022-04-02 13:17:57 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-983709ec-kafka-bootstrap.namespace-51.svc:9092:my-topic-1883121268-1853198657 from pod my-cluster-983709ec-kafka-clients-7b684c4f55-7fmf5
2022-04-02 13:17:57 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-983709ec-kafka-clients-7b684c4f55-7fmf5 -n namespace-51 -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-1883121268-1853198657 --bootstrap-server my-cluster-983709ec-kafka-bootstrap.namespace-51.svc:9092
2022-04-02 13:18:00 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-02 13:18:00 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-02 13:18:00 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@12841386, messages=[], arguments=[--max-messages, 100, --group-instance-id, instance301294353, --group-id, my-consumer-group-15292187, --topic, my-topic-1883121268-1853198657, --bootstrap-server, my-cluster-983709ec-kafka-bootstrap.namespace-51.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-983709ec-kafka-clients-7b684c4f55-7fmf5', podNamespace='namespace-51', bootstrapServer='my-cluster-983709ec-kafka-bootstrap.namespace-51.svc:9092', topicName='my-topic-1883121268-1853198657', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-15292187', consumerInstanceId='instance301294353', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@17dc5726}
2022-04-02 13:18:00 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-983709ec-kafka-bootstrap.namespace-51.svc:9092#my-topic-1883121268-1853198657 from pod my-cluster-983709ec-kafka-clients-7b684c4f55-7fmf5
2022-04-02 13:18:00 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-983709ec-kafka-clients-7b684c4f55-7fmf5 -n namespace-51 -- /opt/kafka/consumer.sh --max-messages 100 --group-instance-id instance301294353 --group-id my-consumer-group-15292187 --topic my-topic-1883121268-1853198657 --bootstrap-server my-cluster-983709ec-kafka-bootstrap.namespace-51.svc:9092
2022-04-02 13:18:06 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-02 13:18:06 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-02 13:18:06 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 13:18:06 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testReadOnlyRootFileSystem
2022-04-02 13:18:06 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1883121268-1853198657 in namespace namespace-51
2022-04-02 13:18:06 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-983709ec-kafka-clients in namespace namespace-51
2022-04-02 13:18:06 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-983709ec in namespace namespace-51
2022-04-02 13:18:06 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-51, for cruise control Kafka cluster my-cluster-983709ec
2022-04-02 13:18:46 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 13:18:46 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testReadOnlyRootFileSystem-FINISHED
2022-04-02 13:18:46 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 13:18:46 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 13:18:46 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testCustomAndUpdatedValues-STARTED
2022-04-02 13:18:46 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 13:18:46 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-52 for test case:testCustomAndUpdatedValues
2022-04-02 13:18:46 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-52
2022-04-02 13:18:46 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-52
2022-04-02 13:18:46 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-52
2022-04-02 13:18:46 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-44f9bb13 in namespace namespace-52
2022-04-02 13:18:46 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-52
2022-04-02 13:18:46 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-44f9bb13 will have desired state: Ready
2022-04-02 13:21:24 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-44f9bb13 is in desired state: Ready
2022-04-02 13:21:24 [main] [32mINFO [m [KafkaST:290] Verify values before update
2022-04-02 13:21:24 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-44f9bb13-kafka in pod name
2022-04-02 13:21:24 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container kafka
2022-04-02 13:21:24 [main] [32mINFO [m [KafkaST:1661] Checking kafka configuration
2022-04-02 13:21:25 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-52 exec my-cluster-44f9bb13-kafka-0 -- /bin/bash -c cat /tmp/strimzi.properties
2022-04-02 13:21:25 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 13:21:25 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-52 exec my-cluster-44f9bb13-kafka-1 -- /bin/bash -c cat /tmp/strimzi.properties
2022-04-02 13:21:25 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 13:21:25 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-52 exec my-cluster-44f9bb13-kafka-2 -- /bin/bash -c cat /tmp/strimzi.properties
2022-04-02 13:21:25 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 13:21:25 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-44f9bb13-kafka
2022-04-02 13:21:25 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container kafka
2022-04-02 13:21:25 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-52 exec my-cluster-44f9bb13-kafka-0 -- cat /tmp/strimzi.properties
2022-04-02 13:21:25 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 13:21:25 [main] [32mINFO [m [KafkaST:308] Testing Zookeepers
2022-04-02 13:21:25 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-44f9bb13-zookeeper in pod name
2022-04-02 13:21:25 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container zookeeper
2022-04-02 13:21:25 [main] [32mINFO [m [AbstractST:190] Getting pods by prefix in name my-cluster-44f9bb13-zookeeper
2022-04-02 13:21:25 [main] [32mINFO [m [AbstractST:194] Testing configuration for container zookeeper
2022-04-02 13:21:25 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-44f9bb13-zookeeper
2022-04-02 13:21:25 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container zookeeper
2022-04-02 13:21:25 [main] [32mINFO [m [KafkaST:315] Checking configuration of TO and UO
2022-04-02 13:21:25 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-44f9bb13-entity-operator in pod name
2022-04-02 13:21:25 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container topic-operator
2022-04-02 13:21:25 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-44f9bb13-entity-operator
2022-04-02 13:21:25 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container topic-operator
2022-04-02 13:21:25 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-44f9bb13-entity-operator in pod name
2022-04-02 13:21:25 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container user-operator
2022-04-02 13:21:25 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-44f9bb13-entity-operator
2022-04-02 13:21:25 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container user-operator
2022-04-02 13:21:25 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-44f9bb13-entity-operator in pod name
2022-04-02 13:21:25 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container tls-sidecar
2022-04-02 13:21:25 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-44f9bb13-entity-operator
2022-04-02 13:21:25 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container tls-sidecar
2022-04-02 13:21:25 [main] [32mINFO [m [KafkaST:326] Updating configuration of Kafka cluster
2022-04-02 13:21:25 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-44f9bb13-zookeeper rolling update
2022-04-02 13:22:55 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-44f9bb13-zookeeper has been successfully rolled
2022-04-02 13:22:55 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-44f9bb13-zookeeper to be ready
2022-04-02 13:23:32 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-44f9bb13 will have desired state: Ready
2022-04-02 13:23:32 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-44f9bb13 is in desired state: Ready
2022-04-02 13:23:32 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-44f9bb13 is ready
2022-04-02 13:23:33 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-44f9bb13-kafka rolling update
2022-04-02 13:25:03 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-44f9bb13-kafka has been successfully rolled
2022-04-02 13:25:03 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-44f9bb13-kafka to be ready
2022-04-02 13:25:48 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-44f9bb13 will have desired state: Ready
2022-04-02 13:25:48 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-44f9bb13 is in desired state: Ready
2022-04-02 13:25:48 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-44f9bb13 is ready
2022-04-02 13:25:48 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-44f9bb13-entity-operator rolling update
2022-04-02 13:25:48 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-44f9bb13-entity-operator will be ready
2022-04-02 13:29:52 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-44f9bb13-entity-operator is ready
2022-04-02 13:30:02 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-44f9bb13-entity-operator rolling update finished
2022-04-02 13:30:02 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-44f9bb13 will have desired state: Ready
2022-04-02 13:30:02 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-44f9bb13 is in desired state: Ready
2022-04-02 13:30:02 [main] [32mINFO [m [KafkaST:386] Verify values after update
2022-04-02 13:30:02 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-44f9bb13-kafka in pod name
2022-04-02 13:30:02 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container kafka
2022-04-02 13:30:02 [main] [32mINFO [m [KafkaST:1661] Checking kafka configuration
2022-04-02 13:30:02 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-52 exec my-cluster-44f9bb13-kafka-0 -- /bin/bash -c cat /tmp/strimzi.properties
2022-04-02 13:30:02 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 13:30:02 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-52 exec my-cluster-44f9bb13-kafka-1 -- /bin/bash -c cat /tmp/strimzi.properties
2022-04-02 13:30:02 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 13:30:02 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-52 exec my-cluster-44f9bb13-kafka-2 -- /bin/bash -c cat /tmp/strimzi.properties
2022-04-02 13:30:02 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 13:30:02 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-44f9bb13-kafka
2022-04-02 13:30:02 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container kafka
2022-04-02 13:30:03 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-52 exec my-cluster-44f9bb13-kafka-0 -- cat /tmp/strimzi.properties
2022-04-02 13:30:03 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 13:30:03 [main] [32mINFO [m [KafkaST:404] Testing Zookeepers
2022-04-02 13:30:03 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-44f9bb13-zookeeper in pod name
2022-04-02 13:30:03 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container zookeeper
2022-04-02 13:30:03 [main] [32mINFO [m [AbstractST:190] Getting pods by prefix in name my-cluster-44f9bb13-zookeeper
2022-04-02 13:30:03 [main] [32mINFO [m [AbstractST:194] Testing configuration for container zookeeper
2022-04-02 13:30:03 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-44f9bb13-zookeeper
2022-04-02 13:30:03 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container zookeeper
2022-04-02 13:30:03 [main] [32mINFO [m [KafkaST:410] Getting entity operator to check configuration of TO and UO
2022-04-02 13:30:03 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-44f9bb13-entity-operator in pod name
2022-04-02 13:30:03 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container topic-operator
2022-04-02 13:30:03 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-44f9bb13-entity-operator
2022-04-02 13:30:03 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container topic-operator
2022-04-02 13:30:03 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-44f9bb13-entity-operator in pod name
2022-04-02 13:30:03 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container user-operator
2022-04-02 13:30:03 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-44f9bb13-entity-operator
2022-04-02 13:30:03 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container user-operator
2022-04-02 13:30:03 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-44f9bb13-entity-operator in pod name
2022-04-02 13:30:03 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container tls-sidecar
2022-04-02 13:30:03 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-44f9bb13-entity-operator
2022-04-02 13:30:03 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container tls-sidecar
2022-04-02 13:30:03 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 13:30:03 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCustomAndUpdatedValues
2022-04-02 13:30:03 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-44f9bb13 in namespace namespace-52
2022-04-02 13:30:13 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 13:30:13 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testCustomAndUpdatedValues-FINISHED
2022-04-02 13:30:13 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 13:30:13 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 13:30:13 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testKafkaJBODDeleteClaimsTrue-STARTED
2022-04-02 13:30:13 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 13:30:13 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-53 for test case:testKafkaJBODDeleteClaimsTrue
2022-04-02 13:30:13 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-53
2022-04-02 13:30:13 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-53
2022-04-02 13:30:13 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-53
2022-04-02 13:30:13 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-64fe2302 in namespace namespace-53
2022-04-02 13:30:13 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-53
2022-04-02 13:30:13 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-64fe2302 will have desired state: Ready
2022-04-02 13:32:25 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-64fe2302 is in desired state: Ready
2022-04-02 13:32:25 [main] [32mINFO [m [KafkaST:1710] Checking labels for volume:data-0-my-cluster-64fe2302-kafka-0
2022-04-02 13:32:25 [main] [32mINFO [m [KafkaST:1710] Checking labels for volume:data-0-my-cluster-64fe2302-kafka-1
2022-04-02 13:32:25 [main] [32mINFO [m [KafkaST:1710] Checking labels for volume:data-1-my-cluster-64fe2302-kafka-0
2022-04-02 13:32:25 [main] [32mINFO [m [KafkaST:1710] Checking labels for volume:data-1-my-cluster-64fe2302-kafka-1
2022-04-02 13:32:25 [main] [32mINFO [m [KafkaST:1717] Checking PVC names included in JBOD array
2022-04-02 13:32:25 [main] [32mINFO [m [KafkaST:1724] Checking PVC on Kafka pods
2022-04-02 13:32:25 [main] [32mINFO [m [KafkaST:1729] Getting list of mounted data sources and PVCs on Kafka pod 0
2022-04-02 13:32:25 [main] [32mINFO [m [KafkaST:1737] Verifying mounted data sources and PVCs on Kafka pod 0
2022-04-02 13:32:25 [main] [32mINFO [m [KafkaST:1729] Getting list of mounted data sources and PVCs on Kafka pod 1
2022-04-02 13:32:25 [main] [32mINFO [m [KafkaST:1737] Verifying mounted data sources and PVCs on Kafka pod 1
2022-04-02 13:32:25 [main] [32mINFO [m [KafkaST:906] Deleting cluster
2022-04-02 13:32:25 [main] [32mINFO [m [KafkaST:909] Waiting for PVC deletion
2022-04-02 13:33:15 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 13:33:15 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaJBODDeleteClaimsTrue
2022-04-02 13:33:15 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-64fe2302 in namespace namespace-53
2022-04-02 13:33:15 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 13:33:15 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testKafkaJBODDeleteClaimsTrue-FINISHED
2022-04-02 13:33:15 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 13:33:15 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 13:33:15 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testKafkaJBODDeleteClaimsFalse-STARTED
2022-04-02 13:33:15 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 13:33:15 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-54 for test case:testKafkaJBODDeleteClaimsFalse
2022-04-02 13:33:15 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-54
2022-04-02 13:33:16 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-54
2022-04-02 13:33:16 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-54
2022-04-02 13:33:16 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-ea633c5c in namespace namespace-54
2022-04-02 13:33:16 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-54
2022-04-02 13:33:16 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-ea633c5c will have desired state: Ready
2022-04-02 13:34:57 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-ea633c5c is in desired state: Ready
2022-04-02 13:34:57 [main] [32mINFO [m [KafkaST:1710] Checking labels for volume:data-0-my-cluster-ea633c5c-kafka-0
2022-04-02 13:34:57 [main] [32mINFO [m [KafkaST:1710] Checking labels for volume:data-0-my-cluster-ea633c5c-kafka-1
2022-04-02 13:34:57 [main] [32mINFO [m [KafkaST:1710] Checking labels for volume:data-1-my-cluster-ea633c5c-kafka-0
2022-04-02 13:34:57 [main] [32mINFO [m [KafkaST:1710] Checking labels for volume:data-1-my-cluster-ea633c5c-kafka-1
2022-04-02 13:34:57 [main] [32mINFO [m [KafkaST:1717] Checking PVC names included in JBOD array
2022-04-02 13:34:57 [main] [32mINFO [m [KafkaST:1724] Checking PVC on Kafka pods
2022-04-02 13:34:57 [main] [32mINFO [m [KafkaST:1729] Getting list of mounted data sources and PVCs on Kafka pod 0
2022-04-02 13:34:57 [main] [32mINFO [m [KafkaST:1737] Verifying mounted data sources and PVCs on Kafka pod 0
2022-04-02 13:34:57 [main] [32mINFO [m [KafkaST:1729] Getting list of mounted data sources and PVCs on Kafka pod 1
2022-04-02 13:34:57 [main] [32mINFO [m [KafkaST:1737] Verifying mounted data sources and PVCs on Kafka pod 1
2022-04-02 13:34:57 [main] [32mINFO [m [KafkaST:930] Deleting cluster
2022-04-02 13:34:57 [main] [32mINFO [m [KafkaST:933] Waiting for PVC deletion
2022-04-02 13:34:57 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 13:34:57 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaJBODDeleteClaimsFalse
2022-04-02 13:34:57 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-ea633c5c in namespace namespace-54
2022-04-02 13:34:57 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 13:34:57 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testKafkaJBODDeleteClaimsFalse-FINISHED
2022-04-02 13:34:57 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 13:34:57 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 13:34:57 [main] [32mINFO [m [ResourceManager:346] In context KafkaST is everything deleted.
2022-04-02 13:34:57 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;31mERROR[m] Tests run: 23, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 4,387.412 s <<< FAILURE! - in io.strimzi.systemtest.kafka.KafkaST
[[1;31mERROR[m] io.strimzi.systemtest.kafka.KafkaST.testLabelModificationDoesNotBreakCluster(ExtensionContext)  Time elapsed: 434.524 s  <<< ERROR!
io.strimzi.test.WaitException: Timeout after 180000 ms waiting for Service labellabel-name-1 change to null
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.utils.kubeUtils.objects.ServiceUtils.waitForServiceLabelsDeletion(ServiceUtils.java:45)
	at io.strimzi.systemtest.kafka.KafkaST.testLabelModificationDoesNotBreakCluster(KafkaST.java:1156)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)

[[1;34mINFO[m] Running io.strimzi.systemtest.kafka.ConfigProviderST
2022-04-02 13:35:02 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: config-provider-st
2022-04-02 13:35:03 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: config-provider-st
2022-04-02 13:35:03 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: config-provider-st
2022-04-02 13:35:03 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 13:35:03 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.ConfigProviderST.testConnectWithConnectorUsingConfigAndEnvProvider-STARTED
2022-04-02 13:35:03 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 13:35:03 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-55 for test case:testConnectWithConnectorUsingConfigAndEnvProvider
2022-04-02 13:35:03 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-55
2022-04-02 13:35:03 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-55
2022-04-02 13:35:03 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-55
2022-04-02 13:35:03 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-27ea6e01 in namespace namespace-55
2022-04-02 13:35:03 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-55
2022-04-02 13:35:03 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-27ea6e01 will have desired state: Ready
2022-04-02 13:37:11 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-27ea6e01 is in desired state: Ready
2022-04-02 13:37:11 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-27ea6e01 in namespace namespace-55
2022-04-02 13:37:11 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-55
2022-04-02 13:37:11 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-27ea6e01 will have desired state: Ready
2022-04-02 13:38:16 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-27ea6e01 is in desired state: Ready
2022-04-02 13:38:16 [main] [32mINFO [m [ConfigProviderST:100] Creating needed RoleBinding and Role for Kubernetes Config Provider
2022-04-02 13:38:16 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding connector-config-rb in namespace namespace-55
2022-04-02 13:38:16 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-55
2022-04-02 13:38:16 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-27ea6e01 in namespace namespace-55
2022-04-02 13:38:16 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-55
2022-04-02 13:38:16 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-27ea6e01 will have desired state: Ready
2022-04-02 13:38:17 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-27ea6e01 is in desired state: Ready
2022-04-02 13:38:17 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-02 13:38:17 [main] [32mINFO [m [ResourceManager:155] Create/Update Job producer-my-consumer-group-1295222699 in namespace namespace-55
2022-04-02 13:38:17 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-55
2022-04-02 13:38:17 [main] [32mINFO [m [JobUtils:81] Waiting for job: producer-my-consumer-group-1295222699 will be in active state
2022-04-02 13:38:18 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-27ea6e01-connect-7987b6d886-q989r
2022-04-02 13:38:23 [main] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-27ea6e01-connect-7987b6d886-q989r
2022-04-02 13:38:23 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 13:38:23 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testConnectWithConnectorUsingConfigAndEnvProvider
2022-04-02 13:38:23 [main] [32mINFO [m [ResourceManager:241] Delete of RoleBinding connector-config-rb in namespace namespace-55
2022-04-02 13:38:23 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-27ea6e01 in namespace namespace-55
2022-04-02 13:38:23 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-27ea6e01 in namespace namespace-55
2022-04-02 13:38:23 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job producer-my-consumer-group-1295222699 in namespace namespace-55
2022-04-02 13:38:23 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-27ea6e01 in namespace namespace-55
2022-04-02 13:38:33 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 13:38:33 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-55 for test case:testConnectWithConnectorUsingConfigAndEnvProvider
2022-04-02 13:39:16 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.ConfigProviderST.testConnectWithConnectorUsingConfigAndEnvProvider-FINISHED
2022-04-02 13:39:16 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 13:39:16 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 13:39:16 [main] [32mINFO [m [ResourceManager:346] In context ConfigProviderST is everything deleted.
2022-04-02 13:39:16 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 259.386 s - in io.strimzi.systemtest.kafka.ConfigProviderST
[[1;34mINFO[m] Running io.strimzi.systemtest.security.custom.CustomAuthorizerST
2022-04-02 13:39:22 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: custom-authorizer-st
2022-04-02 13:39:22 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: custom-authorizer-st
2022-04-02 13:39:22 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: custom-authorizer-st
2022-04-02 13:39:22 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka custom-authorizer in namespace custom-authorizer-st
2022-04-02 13:39:22 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: custom-authorizer will have desired state: Ready
2022-04-02 13:40:27 [main] [32mINFO [m [ResourceManager:444] Kafka: custom-authorizer is in desired state: Ready
2022-04-02 13:40:27 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 13:40:27 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.custom.CustomAuthorizerST.testAclWithSuperUser-STARTED
2022-04-02 13:40:27 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 13:40:27 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-2030089874-1678544394 in namespace custom-authorizer-st
2022-04-02 13:40:27 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-2030089874-1678544394 will have desired state: Ready
2022-04-02 13:40:28 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-2030089874-1678544394 is in desired state: Ready
2022-04-02 13:40:28 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser sre-admin in namespace custom-authorizer-st
2022-04-02 13:40:28 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: sre-admin will have desired state: Ready
2022-04-02 13:40:29 [main] [32mINFO [m [ResourceManager:444] KafkaUser: sre-admin is in desired state: Ready
2022-04-02 13:40:29 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-b0d8b660-kafka-clients in namespace custom-authorizer-st
2022-04-02 13:40:29 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-b0d8b660-kafka-clients will be ready
2022-04-02 13:40:30 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-b0d8b660-kafka-clients is ready
2022-04-02 13:40:30 [main] [32mINFO [m [CustomAuthorizerST:173] Checking kafka super user:sre-admin that is able to send messages to topic:my-topic-2030089874-1678544394
2022-04-02 13:40:30 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-02 13:40:30 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@3e048dd6, messages=[], arguments=[USER=sre_admin, --max-messages, 100, --topic, my-topic-2030089874-1678544394, --bootstrap-server, custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-b0d8b660-kafka-clients-69bd89b97d-tw2v5', podNamespace='custom-authorizer-st', bootstrapServer='custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093', topicName='my-topic-2030089874-1678544394', maxMessages=100, kafkaUsername='sre-admin', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@2f08fdee}
2022-04-02 13:40:30 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093:my-topic-2030089874-1678544394 from pod my-cluster-b0d8b660-kafka-clients-69bd89b97d-tw2v5
2022-04-02 13:40:30 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b0d8b660-kafka-clients-69bd89b97d-tw2v5 -n custom-authorizer-st -- /opt/kafka/producer.sh USER=sre_admin --max-messages 100 --topic my-topic-2030089874-1678544394 --bootstrap-server custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093
2022-04-02 13:40:34 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-02 13:40:34 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-02 13:40:34 [main] [32mINFO [m [CustomAuthorizerST:187] Checking kafka super user:sre-admin that is able to read messages to topic:my-topic-467311057-683530871 regardless that we configured Acls with only write operation
2022-04-02 13:40:34 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@4559d5ec, messages=[], arguments=[USER=sre_admin, --max-messages, 100, --group-instance-id, instance1713298540, --group-id, my-consumer-group-2038350900, --topic, my-topic-2030089874-1678544394, --bootstrap-server, custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-b0d8b660-kafka-clients-69bd89b97d-tw2v5', podNamespace='custom-authorizer-st', bootstrapServer='custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093', topicName='my-topic-2030089874-1678544394', maxMessages=100, kafkaUsername='sre-admin', consumerGroupName='my-consumer-group-2038350900', consumerInstanceId='instance1713298540', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@2dd6ba35}
2022-04-02 13:40:34 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093:my-topic-2030089874-1678544394 from pod my-cluster-b0d8b660-kafka-clients-69bd89b97d-tw2v5
2022-04-02 13:40:34 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b0d8b660-kafka-clients-69bd89b97d-tw2v5 -n custom-authorizer-st -- /opt/kafka/consumer.sh USER=sre_admin --max-messages 100 --group-instance-id instance1713298540 --group-id my-consumer-group-2038350900 --topic my-topic-2030089874-1678544394 --bootstrap-server custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093
2022-04-02 13:40:41 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-02 13:40:41 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-02 13:40:41 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 13:40:41 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAclWithSuperUser
2022-04-02 13:40:41 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser sre-admin in namespace custom-authorizer-st
2022-04-02 13:40:41 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-2030089874-1678544394 in namespace custom-authorizer-st
2022-04-02 13:40:41 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-b0d8b660-kafka-clients in namespace custom-authorizer-st
2022-04-02 13:41:21 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 13:41:21 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.custom.CustomAuthorizerST.testAclWithSuperUser-FINISHED
2022-04-02 13:41:21 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 13:41:21 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 13:41:21 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.custom.CustomAuthorizerST.testAclRuleReadAndWrite-STARTED
2022-04-02 13:41:21 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 13:41:21 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1947211358-669137559 in namespace custom-authorizer-st
2022-04-02 13:41:21 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1947211358-669137559 will have desired state: Ready
2022-04-02 13:41:22 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1947211358-669137559 is in desired state: Ready
2022-04-02 13:41:22 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser kafka-user-write in namespace custom-authorizer-st
2022-04-02 13:41:22 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: kafka-user-write will have desired state: Ready
2022-04-02 13:41:23 [main] [32mINFO [m [ResourceManager:444] KafkaUser: kafka-user-write is in desired state: Ready
2022-04-02 13:41:23 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser kafka-user-read in namespace custom-authorizer-st
2022-04-02 13:41:23 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: kafka-user-read will have desired state: Ready
2022-04-02 13:41:24 [main] [32mINFO [m [ResourceManager:444] KafkaUser: kafka-user-read is in desired state: Ready
2022-04-02 13:41:24 [main] [32mINFO [m [CustomAuthorizerST:105] Checking KafkaUser kafka-user-write that is able to send messages to topic 'my-topic-1947211358-669137559'
2022-04-02 13:41:24 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-2186bd8d-kafka-clients in namespace custom-authorizer-st
2022-04-02 13:41:24 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-2186bd8d-kafka-clients will be ready
2022-04-02 13:41:25 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-2186bd8d-kafka-clients is ready
2022-04-02 13:41:25 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-02 13:41:25 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@5c229073, messages=[], arguments=[USER=kafka_user_write, --max-messages, 500, --topic, my-topic-1947211358-669137559, --bootstrap-server, custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-2186bd8d-kafka-clients-5dfcc5dc8d-ptvlj', podNamespace='custom-authorizer-st', bootstrapServer='custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093', topicName='my-topic-1947211358-669137559', maxMessages=500, kafkaUsername='kafka-user-write', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1d7bbf4d}
2022-04-02 13:41:25 [main] [32mINFO [m [InternalKafkaClient:124] Producing 500 messages to custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093:my-topic-1947211358-669137559 from pod my-cluster-2186bd8d-kafka-clients-5dfcc5dc8d-ptvlj
2022-04-02 13:41:25 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-2186bd8d-kafka-clients-5dfcc5dc8d-ptvlj -n custom-authorizer-st -- /opt/kafka/producer.sh USER=kafka_user_write --max-messages 500 --topic my-topic-1947211358-669137559 --bootstrap-server custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093
2022-04-02 13:41:28 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-02 13:41:28 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 500 messages
2022-04-02 13:41:28 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@43e00435, messages=[], arguments=[USER=kafka_user_write, --max-messages, 500, --group-instance-id, instance1482131219, --group-id, my-consumer-group-1118268871, --topic, my-topic-1947211358-669137559, --bootstrap-server, custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-2186bd8d-kafka-clients-5dfcc5dc8d-ptvlj', podNamespace='custom-authorizer-st', bootstrapServer='custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093', topicName='my-topic-1947211358-669137559', maxMessages=500, kafkaUsername='kafka-user-write', consumerGroupName='my-consumer-group-1118268871', consumerInstanceId='instance1482131219', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@58ed8b5f}
2022-04-02 13:41:28 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 500 messages from custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093:my-topic-1947211358-669137559 from pod my-cluster-2186bd8d-kafka-clients-5dfcc5dc8d-ptvlj
2022-04-02 13:41:28 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-2186bd8d-kafka-clients-5dfcc5dc8d-ptvlj -n custom-authorizer-st -- /opt/kafka/consumer.sh USER=kafka_user_write --max-messages 500 --group-instance-id instance1482131219 --group-id my-consumer-group-1118268871 --topic my-topic-1947211358-669137559 --bootstrap-server custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093
2022-04-02 13:41:32 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-02 13:41:32 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 0 messages
2022-04-02 13:41:32 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@4bc8f3cc, messages=[], arguments=[USER=kafka_user_read, --max-messages, 500, --group-instance-id, instance1320312681, --group-id, consumer-group-name-1, --topic, my-topic-1947211358-669137559, --bootstrap-server, custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-2186bd8d-kafka-clients-5dfcc5dc8d-ptvlj', podNamespace='custom-authorizer-st', bootstrapServer='custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093', topicName='my-topic-1947211358-669137559', maxMessages=500, kafkaUsername='kafka-user-read', consumerGroupName='consumer-group-name-1', consumerInstanceId='instance1320312681', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3215ad3}
2022-04-02 13:41:32 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 500 messages from custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093:my-topic-1947211358-669137559 from pod my-cluster-2186bd8d-kafka-clients-5dfcc5dc8d-ptvlj
2022-04-02 13:41:32 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-2186bd8d-kafka-clients-5dfcc5dc8d-ptvlj -n custom-authorizer-st -- /opt/kafka/consumer.sh USER=kafka_user_read --max-messages 500 --group-instance-id instance1320312681 --group-id consumer-group-name-1 --topic my-topic-1947211358-669137559 --bootstrap-server custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093
2022-04-02 13:41:39 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-02 13:41:39 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 500 messages
2022-04-02 13:41:39 [main] [32mINFO [m [CustomAuthorizerST:137] Checking KafkaUser kafka-user-read that is not able to send messages to topic 'my-topic-1947211358-669137559'
2022-04-02 13:41:39 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@3c494cf9, messages=[], arguments=[USER=kafka_user_read, --max-messages, 500, --topic, my-topic-1947211358-669137559, --bootstrap-server, custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-2186bd8d-kafka-clients-5dfcc5dc8d-ptvlj', podNamespace='custom-authorizer-st', bootstrapServer='custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093', topicName='my-topic-1947211358-669137559', maxMessages=500, kafkaUsername='kafka-user-read', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7fcb3e99}
2022-04-02 13:41:39 [main] [32mINFO [m [InternalKafkaClient:124] Producing 500 messages to custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093:my-topic-1947211358-669137559 from pod my-cluster-2186bd8d-kafka-clients-5dfcc5dc8d-ptvlj
2022-04-02 13:41:39 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-2186bd8d-kafka-clients-5dfcc5dc8d-ptvlj -n custom-authorizer-st -- /opt/kafka/producer.sh USER=kafka_user_read --max-messages 500 --topic my-topic-1947211358-669137559 --bootstrap-server custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093
2022-04-02 13:41:43 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-02 13:41:43 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced -1 messages
2022-04-02 13:41:43 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 13:41:43 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAclRuleReadAndWrite
2022-04-02 13:41:43 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser kafka-user-read in namespace custom-authorizer-st
2022-04-02 13:41:43 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaUser kafka-user-write in namespace custom-authorizer-st
2022-04-02 13:41:43 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-2186bd8d-kafka-clients in namespace custom-authorizer-st
2022-04-02 13:41:43 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1947211358-669137559 in namespace custom-authorizer-st
2022-04-02 13:42:23 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 13:42:23 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.custom.CustomAuthorizerST.testAclRuleReadAndWrite-FINISHED
2022-04-02 13:42:23 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 13:42:23 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 13:42:23 [main] [32mINFO [m [ResourceManager:348] Delete all resources for CustomAuthorizerST
2022-04-02 13:42:23 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka custom-authorizer in namespace custom-authorizer-st
2022-04-02 13:42:33 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 201.497 s - in io.strimzi.systemtest.security.custom.CustomAuthorizerST
[[1;34mINFO[m] Running io.strimzi.systemtest.security.OpaIntegrationST
2022-04-02 13:42:43 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: opa-integration-st
2022-04-02 13:42:43 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: opa-integration-st
2022-04-02 13:42:43 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: opa-integration-st
2022-04-02 13:42:44 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka opa-cluster in namespace opa-integration-st
2022-04-02 13:42:44 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: opa-cluster will have desired state: Ready
2022-04-02 13:44:04 [main] [32mINFO [m [ResourceManager:444] Kafka: opa-cluster is in desired state: Ready
2022-04-02 13:44:04 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 13:44:04 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.OpaIntegrationST.testOpaAuthorizationSuperUser-STARTED
2022-04-02 13:44:04 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 13:44:04 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-580091523-1319075036 in namespace opa-integration-st
2022-04-02 13:44:04 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-580091523-1319075036 will have desired state: Ready
2022-04-02 13:44:05 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-580091523-1319075036 is in desired state: Ready
2022-04-02 13:44:05 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser arnost in namespace opa-integration-st
2022-04-02 13:44:05 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: arnost will have desired state: Ready
2022-04-02 13:44:06 [main] [32mINFO [m [ResourceManager:444] KafkaUser: arnost is in desired state: Ready
2022-04-02 13:44:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-9a770582-kafka-clients in namespace opa-integration-st
2022-04-02 13:44:06 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-9a770582-kafka-clients will be ready
2022-04-02 13:44:07 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-9a770582-kafka-clients is ready
2022-04-02 13:44:07 [main] [32mINFO [m [OpaIntegrationST:120] Checking KafkaUser good-user that is able to send and receive messages to/from topic 'my-topic-580091523-1319075036'
2022-04-02 13:44:07 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@34b88d6d, messages=[], arguments=[USER=arnost, --max-messages, 100, --topic, my-topic-580091523-1319075036, --bootstrap-server, opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-9a770582-kafka-clients-bf44c9d74-h4wcj', podNamespace='opa-integration-st', bootstrapServer='opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093', topicName='my-topic-580091523-1319075036', maxMessages=100, kafkaUsername='arnost', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7ae0c977}
2022-04-02 13:44:07 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093:my-topic-580091523-1319075036 from pod my-cluster-9a770582-kafka-clients-bf44c9d74-h4wcj
2022-04-02 13:44:07 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-9a770582-kafka-clients-bf44c9d74-h4wcj -n opa-integration-st -- /opt/kafka/producer.sh USER=arnost --max-messages 100 --topic my-topic-580091523-1319075036 --bootstrap-server opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093
2022-04-02 13:44:11 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-02 13:44:11 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-02 13:44:11 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@2a0841e6, messages=[], arguments=[USER=arnost, --max-messages, 100, --group-instance-id, instance1275826329, --group-id, consumer-group-name-2, --topic, my-topic-580091523-1319075036, --bootstrap-server, opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-9a770582-kafka-clients-bf44c9d74-h4wcj', podNamespace='opa-integration-st', bootstrapServer='opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093', topicName='my-topic-580091523-1319075036', maxMessages=100, kafkaUsername='arnost', consumerGroupName='consumer-group-name-2', consumerInstanceId='instance1275826329', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@565f912b}
2022-04-02 13:44:11 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093:my-topic-580091523-1319075036 from pod my-cluster-9a770582-kafka-clients-bf44c9d74-h4wcj
2022-04-02 13:44:11 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-9a770582-kafka-clients-bf44c9d74-h4wcj -n opa-integration-st -- /opt/kafka/consumer.sh USER=arnost --max-messages 100 --group-instance-id instance1275826329 --group-id consumer-group-name-2 --topic my-topic-580091523-1319075036 --bootstrap-server opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093
2022-04-02 13:44:17 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-02 13:44:17 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-02 13:44:17 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 13:44:17 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testOpaAuthorizationSuperUser
2022-04-02 13:44:17 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser arnost in namespace opa-integration-st
2022-04-02 13:44:17 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-9a770582-kafka-clients in namespace opa-integration-st
2022-04-02 13:44:17 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-580091523-1319075036 in namespace opa-integration-st
2022-04-02 13:45:08 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 13:45:08 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.OpaIntegrationST.testOpaAuthorizationSuperUser-FINISHED
2022-04-02 13:45:08 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 13:45:08 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 13:45:08 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.OpaIntegrationST.testOpaAuthorization-STARTED
2022-04-02 13:45:08 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 13:45:08 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser good-user in namespace opa-integration-st
2022-04-02 13:45:08 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: good-user will have desired state: Ready
2022-04-02 13:45:09 [main] [32mINFO [m [ResourceManager:444] KafkaUser: good-user is in desired state: Ready
2022-04-02 13:45:09 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser bad-user in namespace opa-integration-st
2022-04-02 13:45:09 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: bad-user will have desired state: Ready
2022-04-02 13:45:10 [main] [32mINFO [m [ResourceManager:444] KafkaUser: bad-user is in desired state: Ready
2022-04-02 13:45:10 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-212d1439-kafka-clients in namespace opa-integration-st
2022-04-02 13:45:10 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-212d1439-kafka-clients will be ready
2022-04-02 13:45:12 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-212d1439-kafka-clients is ready
2022-04-02 13:45:12 [main] [32mINFO [m [OpaIntegrationST:72] Checking KafkaUser good-user that is able to send and receive messages to/from topic 'my-topic-400131390-185527747'
2022-04-02 13:45:12 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@468b5a48, messages=[], arguments=[USER=good_user, --max-messages, 100, --topic, my-topic-400131390-185527747, --bootstrap-server, opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-212d1439-kafka-clients-7447d9749b-tbtrw', podNamespace='opa-integration-st', bootstrapServer='opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093', topicName='my-topic-400131390-185527747', maxMessages=100, kafkaUsername='good-user', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@68c6b319}
2022-04-02 13:45:12 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093:my-topic-400131390-185527747 from pod my-cluster-212d1439-kafka-clients-7447d9749b-tbtrw
2022-04-02 13:45:12 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-212d1439-kafka-clients-7447d9749b-tbtrw -n opa-integration-st -- /opt/kafka/producer.sh USER=good_user --max-messages 100 --topic my-topic-400131390-185527747 --bootstrap-server opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093
2022-04-02 13:45:16 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-02 13:45:16 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-02 13:45:16 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@1ee4c35e, messages=[], arguments=[USER=good_user, --max-messages, 100, --group-instance-id, instance73692953, --group-id, my-consumer-group-626374687, --topic, my-topic-400131390-185527747, --bootstrap-server, opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-212d1439-kafka-clients-7447d9749b-tbtrw', podNamespace='opa-integration-st', bootstrapServer='opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093', topicName='my-topic-400131390-185527747', maxMessages=100, kafkaUsername='good-user', consumerGroupName='my-consumer-group-626374687', consumerInstanceId='instance73692953', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7b6b0276}
2022-04-02 13:45:16 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093:my-topic-400131390-185527747 from pod my-cluster-212d1439-kafka-clients-7447d9749b-tbtrw
2022-04-02 13:45:16 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-212d1439-kafka-clients-7447d9749b-tbtrw -n opa-integration-st -- /opt/kafka/consumer.sh USER=good_user --max-messages 100 --group-instance-id instance73692953 --group-id my-consumer-group-626374687 --topic my-topic-400131390-185527747 --bootstrap-server opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093
2022-04-02 13:45:23 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-02 13:45:23 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-02 13:45:23 [main] [32mINFO [m [OpaIntegrationST:89] Checking KafkaUser bad-user that is not able to send or receive messages to/from topic 'my-topic-400131390-185527747'
2022-04-02 13:45:23 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@5f22aece, messages=[], arguments=[USER=bad_user, --max-messages, 100, --topic, my-topic-400131390-185527747, --bootstrap-server, opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-212d1439-kafka-clients-7447d9749b-tbtrw', podNamespace='opa-integration-st', bootstrapServer='opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093', topicName='my-topic-400131390-185527747', maxMessages=100, kafkaUsername='bad-user', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@43e7e5e0}
2022-04-02 13:45:23 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093:my-topic-400131390-185527747 from pod my-cluster-212d1439-kafka-clients-7447d9749b-tbtrw
2022-04-02 13:45:23 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-212d1439-kafka-clients-7447d9749b-tbtrw -n opa-integration-st -- /opt/kafka/producer.sh USER=bad_user --max-messages 100 --topic my-topic-400131390-185527747 --bootstrap-server opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093
2022-04-02 13:45:27 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-02 13:45:27 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced -1 messages
2022-04-02 13:45:27 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@443fbd1c, messages=[], arguments=[USER=bad_user, --max-messages, 100, --group-instance-id, instance835511648, --group-id, my-consumer-group-626374687, --topic, my-topic-400131390-185527747, --bootstrap-server, opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-212d1439-kafka-clients-7447d9749b-tbtrw', podNamespace='opa-integration-st', bootstrapServer='opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093', topicName='my-topic-400131390-185527747', maxMessages=100, kafkaUsername='bad-user', consumerGroupName='my-consumer-group-626374687', consumerInstanceId='instance835511648', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7cf97fee}
2022-04-02 13:45:27 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093:my-topic-400131390-185527747 from pod my-cluster-212d1439-kafka-clients-7447d9749b-tbtrw
2022-04-02 13:45:27 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-212d1439-kafka-clients-7447d9749b-tbtrw -n opa-integration-st -- /opt/kafka/consumer.sh USER=bad_user --max-messages 100 --group-instance-id instance835511648 --group-id my-consumer-group-626374687 --topic my-topic-400131390-185527747 --bootstrap-server opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093
2022-04-02 13:45:54 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-02 13:45:54 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 0 messages
2022-04-02 13:45:54 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 13:45:54 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testOpaAuthorization
2022-04-02 13:45:54 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser bad-user in namespace opa-integration-st
2022-04-02 13:45:54 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-212d1439-kafka-clients in namespace opa-integration-st
2022-04-02 13:45:54 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaUser good-user in namespace opa-integration-st
2022-04-02 13:46:34 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 13:46:34 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.OpaIntegrationST.testOpaAuthorization-FINISHED
2022-04-02 13:46:34 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 13:46:34 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 13:46:34 [main] [32mINFO [m [ResourceManager:348] Delete all resources for OpaIntegrationST
2022-04-02 13:46:34 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka opa-cluster in namespace opa-integration-st
2022-04-02 13:46:44 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 283.433 s - in io.strimzi.systemtest.security.OpaIntegrationST
[[1;34mINFO[m] Running io.strimzi.systemtest.security.SecurityST
2022-04-02 13:47:27 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: security-st
2022-04-02 13:47:27 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: security-st
2022-04-02 13:47:27 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: security-st
2022-04-02 13:47:27 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 13:47:27 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAutoRenewCaCertsTriggerByExpiredCertificate-STARTED
2022-04-02 13:47:27 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 13:47:27 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-56 for test case:testAutoRenewCaCertsTriggerByExpiredCertificate
2022-04-02 13:47:27 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-56
2022-04-02 13:47:27 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-56
2022-04-02 13:47:27 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-56
2022-04-02 13:47:27 [main] [32mINFO [m [SecretUtils:70] Creating secret my-cluster-e5bf62c7-cluster-ca-cert
2022-04-02 13:47:27 [main] [32mINFO [m [SecurityST:587] Creating a cluster
2022-04-02 13:47:27 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-e5bf62c7 in namespace namespace-56
2022-04-02 13:47:27 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-56
2022-04-02 13:47:27 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-e5bf62c7 will have desired state: Ready
2022-04-02 13:50:18 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-e5bf62c7 is in desired state: Ready
2022-04-02 13:50:18 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1311502732-1962203924 in namespace namespace-56
2022-04-02 13:50:18 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-56
2022-04-02 13:50:18 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1311502732-1962203924 will have desired state: Ready
2022-04-02 13:50:19 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1311502732-1962203924 is in desired state: Ready
2022-04-02 13:50:19 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1844325024-1947796491 in namespace namespace-56
2022-04-02 13:50:19 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-56
2022-04-02 13:50:19 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1844325024-1947796491 will have desired state: Ready
2022-04-02 13:50:20 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1844325024-1947796491 is in desired state: Ready
2022-04-02 13:50:20 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-e5bf62c7-kafka-clients in namespace namespace-56
2022-04-02 13:50:20 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-56
2022-04-02 13:50:20 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-e5bf62c7-kafka-clients will be ready
2022-04-02 13:50:22 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-e5bf62c7-kafka-clients is ready
2022-04-02 13:50:22 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-02 13:50:22 [main] [32mINFO [m [SecurityST:660] Checking produced and consumed messages to pod:my-cluster-e5bf62c7-kafka-clients-77b4bf9788-9vsm5
2022-04-02 13:50:22 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@4504c8c8, messages=[], arguments=[--max-messages, 100, --topic, my-topic-1844325024-1947796491, --bootstrap-server, my-cluster-e5bf62c7-kafka-bootstrap.namespace-56.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-e5bf62c7-kafka-clients-77b4bf9788-9vsm5', podNamespace='namespace-56', bootstrapServer='my-cluster-e5bf62c7-kafka-bootstrap.namespace-56.svc:9092', topicName='my-topic-1844325024-1947796491', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@587224bb}
2022-04-02 13:50:22 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-e5bf62c7-kafka-bootstrap.namespace-56.svc:9092:my-topic-1844325024-1947796491 from pod my-cluster-e5bf62c7-kafka-clients-77b4bf9788-9vsm5
2022-04-02 13:50:22 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-e5bf62c7-kafka-clients-77b4bf9788-9vsm5 -n namespace-56 -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-1844325024-1947796491 --bootstrap-server my-cluster-e5bf62c7-kafka-bootstrap.namespace-56.svc:9092
2022-04-02 13:50:24 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-02 13:50:24 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-02 13:50:24 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@58093a11, messages=[], arguments=[--max-messages, 100, --group-instance-id, instance741789925, --group-id, my-consumer-group-705527396, --topic, my-topic-1844325024-1947796491, --bootstrap-server, my-cluster-e5bf62c7-kafka-bootstrap.namespace-56.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-e5bf62c7-kafka-clients-77b4bf9788-9vsm5', podNamespace='namespace-56', bootstrapServer='my-cluster-e5bf62c7-kafka-bootstrap.namespace-56.svc:9092', topicName='my-topic-1844325024-1947796491', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-705527396', consumerInstanceId='instance741789925', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@11978364}
2022-04-02 13:50:24 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-e5bf62c7-kafka-bootstrap.namespace-56.svc:9092#my-topic-1844325024-1947796491 from pod my-cluster-e5bf62c7-kafka-clients-77b4bf9788-9vsm5
2022-04-02 13:50:24 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-e5bf62c7-kafka-clients-77b4bf9788-9vsm5 -n namespace-56 -- /opt/kafka/consumer.sh --max-messages 100 --group-instance-id instance741789925 --group-id my-consumer-group-705527396 --topic my-topic-1844325024-1947796491 --bootstrap-server my-cluster-e5bf62c7-kafka-bootstrap.namespace-56.svc:9092
2022-04-02 13:50:30 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-02 13:50:30 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-02 13:50:30 [main] [32mINFO [m [SecretUtils:131] Waiting for Secret my-cluster-e5bf62c7-cluster-ca-cert certificate change
2022-04-02 13:50:30 [main] [32mINFO [m [SecretUtils:138] Certificate in Secret my-cluster-e5bf62c7-cluster-ca-cert has changed, was -----BEGIN CERTIFICATE-----
MIIDKjCCAhKgAwIBAgIJAJBt0u1FFTG+MA0GCSqGSIb3DQEBCwUAMCoxEzARBgNV
BAoMCnN0cmltemkuaW8xEzARBgNVBAMMCmNsdXN0ZXItY2EwHhcNMTgxMDIzMTAw
MTExWhcNMTgxMDI0MTAwMTExWjAqMRMwEQYDVQQKDApzdHJpbXppLmlvMRMwEQYD
VQQDDApjbHVzdGVyLWNhMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA
xpuYrNXYHqw3ajwd12aAeuTlAX4rVwVdPuIex6A4NL8J3d2DV+ngXgNTH//RhiF5
If5KRWSsLei5BUIrwuQutOUNCQwyACmri9+yrx6+tevligiokAUwhHxcDHZpwC3T
+2dzk/BkI++vbSuvjFmBKGQi9gfyoTnStTEQ85KVJUS170hzwDjzaEiJsKpOPx/G
+KTdkAopLucoxr4sxhYeO4mQ2PkT0QL+R8Ohs6LD6v/bqalFP+rS8vibolfxjMNm
lXQCOd8UfXy8OEOaNoNCvhnn/cT/hbEG/ARbV3hHmUh9COV+TSV5dhsbmS5h4MKw
LzP449nGQBmLSkZMu984DQIDAQABo1MwUTAdBgNVHQ4EFgQUOXubcHBZJ7vSzjpi
pfXdFSP3dsEwHwYDVR0jBBgwFoAUOXubcHBZJ7vSzjpipfXdFSP3dsEwDwYDVR0T
AQH/BAUwAwEB/zANBgkqhkiG9w0BAQsFAAOCAQEAFFPGykbzUREDMzh+33i3a8TF
UTQnPMN/SuVbpLfQdpkpLO+aVWjVvJP6qMrI7jRO5zhj4MecAf7YKpe+dyRTTz9B
Dy9BZcujHYjCKdcKBnBFQ7B1xQm9tL1bw+a3ABzSTlhLiBcCxhJEawlWy1Gh18ab
3x/Kqnz0mk/jt5+n9HwlKHuBQVIxRCsfHWwq+WvIfoxM+N//akV8/29hLUf5TlYH
F5CX4G2pA5sSdaDHQ4ekQWuqM6tfvsGLl2KOmEFEgVR4GfaWI4BsUCzlpBNcCGWv
V7klZvBxQPG7MVy0cB8yzTDtUpR0jUFUkZOSp5Pr3yWcwPWEgWkaXYfO+FWETA==
-----END CERTIFICATE-----
, is now -----BEGIN CERTIFICATE-----
MIIFLTCCAxWgAwIBAgIUZ32Cr6gOqewbcEnvSeUtp4I4LTYwDQYJKoZIhvcNAQEN
BQAwLTETMBEGA1UECgwKaW8uc3RyaW16aTEWMBQGA1UEAwwNY2x1c3Rlci1jYSB2
MDAeFw0yMjA0MDIxMzQ3MjdaFw0yMzA0MDIxMzQ3MjdaMC0xEzARBgNVBAoMCmlv
LnN0cmltemkxFjAUBgNVBAMMDWNsdXN0ZXItY2EgdjAwggIiMA0GCSqGSIb3DQEB
AQUAA4ICDwAwggIKAoICAQC6sOLv7uuOoLYWUWZmrhr9aVHG2A2F4fMpEWwVX+Go
a97+0rNcU+m/EreKdZkJe6GxT5DrI0ZAwE/tkLPKHUApfjCmEMuvbjmzr+IUp3wR
boj/Hw7I18cwdG0qwQs062yDYQUMZ6teYQdn53brCgEQugq0C9BEUhtqoXoKhGIP
aWW4nmhwfwkMZAtHYs+8USApDXnqlkqvhNpmRcEwRUCzw+eTyaabNOJG6UNTrbrD
ciDwlqhBel8LyXiafe91flYsGeQIE6VC4ic1XulSjkME12sDQrLgtxs4jjfxUmKM
0mY7eCVd91RFW6r3AOtLVrxTyFlenuCpFyNYsYANHtTj4OaTqYiKL5G0tLq8YLwk
egkwIFqQpR4jipn0X8sOAjqIqHxv2qSrtbnpQnGwgt2R9WwOvbmFKFMZcG2liIp/
FNRJXTZmAZKh0SugNCKT8eOoTov51Tlw6c64/yBIcx3msURphbGitIqwIaM2mw1E
lgQvo1WKvpNr6dg0wvDLXMCNBT/8xxbmf48jUUUJWT0FeeRmQKDa/dzIegUCHSZB
b1bcVC4A4A8h0rIw30d1BMYRBc3cvtW+GHN5A2mDOOhbhjGomFPQE7mXq8PSyGjY
FjPiGLR7sn2+9pT1LK99QkBDPIZ6v1wIlIfxPcRQ+fg6FreRX1c+F4RpGBUC1Q8i
mwIDAQABo0UwQzAdBgNVHQ4EFgQUSUal1ZjAS3oKk7kB9op+txsKiK0wEgYDVR0T
AQH/BAgwBgEB/wIBADAOBgNVHQ8BAf8EBAMCAQYwDQYJKoZIhvcNAQENBQADggIB
ALZmbpJktGWPTpcffu/wjivQwi5Zgn/6hVISxd3OJE5erFBQW7nbVYreEbyvxU0h
YJTZPktWoVlh5YVC7O/YjgzaQR3VwFP+jslyFFfa1madgdGQPOBTVQcczbzcQFKW
483LdjxQvkNJ3HYh1leJzj3zZJYdrD2+cGLorARmAFY3niANtwg4NoGEK4PL5kWb
FRoHfsMfjtZ2i0/JBOQt5ePF5FMiMx7Q25dMuc7kvDy/aIZoUKboh+LI8vJagyrJ
s8pX8gxU5aeY/1hbJT7uwfB9vBZBzjckjIpIPNlE6s7LKAzzYSSTcNijKsfTH3He
r36RogouumD7nJ2zV7xkMDUsjybhpej2cXhhjLpvOjPkUf/CoeambDc0WGm3Jro7
FXHkqkjAdRsnZ9fl5LBRoAy17BZ4sWEtB9oQthgCrzdbHGyRHJG59XOw+Q1w6laG
yDylFRo9k+5lxn5ki29JHkAiKAk1El3/HrhB47AWHnhJbaRS0dpvEkl4CnCLIRnr
2ISoM0murJZ+4lQCrydlKFVF/bUVosRBT5dQFIsgeeual0DO9RgBw4U668mlDTpz
mhokeSHQfUaviWTqMdNeoaUyhxSE1eOmRAY5et3+FlaKkKtHDMCs5XM/tQMqbyOH
/6PvVsy9RdQ9AUPD58SnZX2Fh+PPxhDwf6+F32BfItVC
-----END CERTIFICATE-----

2022-04-02 13:50:30 [main] [32mINFO [m [KafkaUtils:180] Waiting for cluster stability
2022-04-02 13:51:32 [main] [32mINFO [m [KafkaUtils:208] Kafka cluster is stable after 61 polls.
2022-04-02 13:51:32 [main] [32mINFO [m [SecurityST:672] Checking produced and consumed messages to pod:my-cluster-e5bf62c7-kafka-clients-77b4bf9788-9vsm5
2022-04-02 13:51:32 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@6c63236d, messages=[], arguments=[--max-messages, 100, --topic, my-topic-1844325024-1947796491, --bootstrap-server, my-cluster-e5bf62c7-kafka-bootstrap.namespace-56.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-e5bf62c7-kafka-clients-77b4bf9788-9vsm5', podNamespace='namespace-56', bootstrapServer='my-cluster-e5bf62c7-kafka-bootstrap.namespace-56.svc:9092', topicName='my-topic-1844325024-1947796491', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@12c50a8a}
2022-04-02 13:51:32 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-e5bf62c7-kafka-bootstrap.namespace-56.svc:9092:my-topic-1844325024-1947796491 from pod my-cluster-e5bf62c7-kafka-clients-77b4bf9788-9vsm5
2022-04-02 13:51:32 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-e5bf62c7-kafka-clients-77b4bf9788-9vsm5 -n namespace-56 -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-1844325024-1947796491 --bootstrap-server my-cluster-e5bf62c7-kafka-bootstrap.namespace-56.svc:9092
2022-04-02 13:51:34 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-02 13:51:34 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-02 13:51:34 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@6290223a, messages=[], arguments=[--max-messages, 100, --group-instance-id, instance371777264, --group-id, my-consumer-group-705527396, --topic, my-topic-1844325024-1947796491, --bootstrap-server, my-cluster-e5bf62c7-kafka-bootstrap.namespace-56.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-e5bf62c7-kafka-clients-77b4bf9788-9vsm5', podNamespace='namespace-56', bootstrapServer='my-cluster-e5bf62c7-kafka-bootstrap.namespace-56.svc:9092', topicName='my-topic-1844325024-1947796491', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-705527396', consumerInstanceId='instance371777264', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@58bbe2fd}
2022-04-02 13:51:34 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-e5bf62c7-kafka-bootstrap.namespace-56.svc:9092#my-topic-1844325024-1947796491 from pod my-cluster-e5bf62c7-kafka-clients-77b4bf9788-9vsm5
2022-04-02 13:51:34 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-e5bf62c7-kafka-clients-77b4bf9788-9vsm5 -n namespace-56 -- /opt/kafka/consumer.sh --max-messages 100 --group-instance-id instance371777264 --group-id my-consumer-group-705527396 --topic my-topic-1844325024-1947796491 --bootstrap-server my-cluster-e5bf62c7-kafka-bootstrap.namespace-56.svc:9092
2022-04-02 13:51:40 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-02 13:51:40 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-02 13:51:40 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 13:51:40 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAutoRenewCaCertsTriggerByExpiredCertificate
2022-04-02 13:51:40 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1844325024-1947796491 in namespace namespace-56
2022-04-02 13:51:40 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-e5bf62c7-kafka-clients in namespace namespace-56
2022-04-02 13:51:40 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1311502732-1962203924 in namespace namespace-56
2022-04-02 13:51:40 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-e5bf62c7 in namespace namespace-56
2022-04-02 13:51:40 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-56, for cruise control Kafka cluster my-cluster-e5bf62c7
2022-04-02 13:52:40 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 13:52:40 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-56 for test case:testAutoRenewCaCertsTriggerByExpiredCertificate
2022-04-02 13:52:45 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testAutoRenewCaCertsTriggerByExpiredCertificate-FINISHED
2022-04-02 13:52:45 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 13:52:45 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 13:52:45 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAutoReplaceClientsCaKeysTriggeredByAnno-STARTED
2022-04-02 13:52:45 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 13:52:45 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-57 for test case:testAutoReplaceClientsCaKeysTriggeredByAnno
2022-04-02 13:52:45 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-57
2022-04-02 13:52:45 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-57
2022-04-02 13:52:45 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-57
2022-04-02 13:52:45 [main] [32mINFO [m [SecurityST:587] Creating a cluster
2022-04-02 13:52:45 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-4240b926 in namespace namespace-57
2022-04-02 13:52:45 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-57
2022-04-02 13:52:45 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-4240b926 will have desired state: Ready
2022-04-02 13:55:21 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-4240b926 is in desired state: Ready
2022-04-02 13:55:21 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1079040476-1612635516 in namespace namespace-57
2022-04-02 13:55:21 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-57
2022-04-02 13:55:21 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1079040476-1612635516 will have desired state: Ready
2022-04-02 13:55:22 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1079040476-1612635516 is in desired state: Ready
2022-04-02 13:55:22 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-236389318-114662154 in namespace namespace-57
2022-04-02 13:55:22 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-57
2022-04-02 13:55:22 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-236389318-114662154 will have desired state: Ready
2022-04-02 13:55:23 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-236389318-114662154 is in desired state: Ready
2022-04-02 13:55:23 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-4240b926-kafka-clients in namespace namespace-57
2022-04-02 13:55:23 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-57
2022-04-02 13:55:23 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-4240b926-kafka-clients will be ready
2022-04-02 13:55:25 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-4240b926-kafka-clients is ready
2022-04-02 13:55:25 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-02 13:55:25 [main] [32mINFO [m [SecurityST:453] Checking produced and consumed messages to pod:my-cluster-4240b926-kafka-clients-6fdd7c6697-74t8f
2022-04-02 13:55:25 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@281d9235, messages=[], arguments=[--max-messages, 100, --topic, my-topic-236389318-114662154, --bootstrap-server, my-cluster-4240b926-kafka-bootstrap.namespace-57.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-4240b926-kafka-clients-6fdd7c6697-74t8f', podNamespace='namespace-57', bootstrapServer='my-cluster-4240b926-kafka-bootstrap.namespace-57.svc:9092', topicName='my-topic-236389318-114662154', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@2d530db2}
2022-04-02 13:55:25 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-4240b926-kafka-bootstrap.namespace-57.svc:9092:my-topic-236389318-114662154 from pod my-cluster-4240b926-kafka-clients-6fdd7c6697-74t8f
2022-04-02 13:55:25 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-4240b926-kafka-clients-6fdd7c6697-74t8f -n namespace-57 -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-236389318-114662154 --bootstrap-server my-cluster-4240b926-kafka-bootstrap.namespace-57.svc:9092
2022-04-02 13:55:27 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-02 13:55:27 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-02 13:55:27 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@2ea58872, messages=[], arguments=[--max-messages, 100, --group-instance-id, instance1676836514, --group-id, my-consumer-group-613540277, --topic, my-topic-236389318-114662154, --bootstrap-server, my-cluster-4240b926-kafka-bootstrap.namespace-57.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-4240b926-kafka-clients-6fdd7c6697-74t8f', podNamespace='namespace-57', bootstrapServer='my-cluster-4240b926-kafka-bootstrap.namespace-57.svc:9092', topicName='my-topic-236389318-114662154', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-613540277', consumerInstanceId='instance1676836514', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1bae2828}
2022-04-02 13:55:27 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-4240b926-kafka-bootstrap.namespace-57.svc:9092#my-topic-236389318-114662154 from pod my-cluster-4240b926-kafka-clients-6fdd7c6697-74t8f
2022-04-02 13:55:27 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-4240b926-kafka-clients-6fdd7c6697-74t8f -n namespace-57 -- /opt/kafka/consumer.sh --max-messages 100 --group-instance-id instance1676836514 --group-id my-consumer-group-613540277 --topic my-topic-236389318-114662154 --bootstrap-server my-cluster-4240b926-kafka-bootstrap.namespace-57.svc:9092
2022-04-02 13:55:33 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-02 13:55:33 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-02 13:55:33 [main] [32mINFO [m [SecurityST:467] Triggering CA cert renewal by adding the annotation
2022-04-02 13:55:33 [main] [32mINFO [m [SecurityST:479] Patching secret my-cluster-4240b926-clients-ca with strimzi.io/force-replace
2022-04-02 13:55:33 [main] [32mINFO [m [SecurityST:489] Wait for kafka to rolling restart (1)...
2022-04-02 13:55:33 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-4240b926-kafka rolling update
2022-04-02 13:57:13 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-4240b926-kafka has been successfully rolled
2022-04-02 13:57:13 [main] [32mINFO [m [SecurityST:510] Wait for kafka to rolling restart (2)...
2022-04-02 13:57:13 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-4240b926-kafka rolling update
2022-04-02 13:58:53 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-4240b926-kafka has been successfully rolled
2022-04-02 13:58:53 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-4240b926-kafka to be ready
2022-04-02 13:59:24 [main] [32mINFO [m [SecurityST:525] Checking the certificates have been replaced
2022-04-02 13:59:24 [main] [32mINFO [m [SecurityST:536] Checking consumed messages to pod:my-cluster-4240b926-kafka-clients-6fdd7c6697-74t8f
2022-04-02 13:59:24 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@14323885, messages=[], arguments=[--max-messages, 100, --group-instance-id, instance1223589531, --group-id, my-consumer-group-1346936571, --topic, my-topic-236389318-114662154, --bootstrap-server, my-cluster-4240b926-kafka-bootstrap.namespace-57.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-4240b926-kafka-clients-6fdd7c6697-74t8f', podNamespace='namespace-57', bootstrapServer='my-cluster-4240b926-kafka-bootstrap.namespace-57.svc:9092', topicName='my-topic-236389318-114662154', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1346936571', consumerInstanceId='instance1223589531', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1ea9ce73}
2022-04-02 13:59:24 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-4240b926-kafka-bootstrap.namespace-57.svc:9092#my-topic-236389318-114662154 from pod my-cluster-4240b926-kafka-clients-6fdd7c6697-74t8f
2022-04-02 13:59:24 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-4240b926-kafka-clients-6fdd7c6697-74t8f -n namespace-57 -- /opt/kafka/consumer.sh --max-messages 100 --group-instance-id instance1223589531 --group-id my-consumer-group-1346936571 --topic my-topic-236389318-114662154 --bootstrap-server my-cluster-4240b926-kafka-bootstrap.namespace-57.svc:9092
2022-04-02 13:59:29 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-02 13:59:29 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-02 13:59:29 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1365319292-237858249 in namespace namespace-57
2022-04-02 13:59:29 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-57
2022-04-02 13:59:29 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1365319292-237858249 will have desired state: Ready
2022-04-02 13:59:30 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1365319292-237858249 is in desired state: Ready
2022-04-02 13:59:30 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-4240b926-kafka-clients-tls in namespace namespace-57
2022-04-02 13:59:30 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-57
2022-04-02 13:59:30 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-4240b926-kafka-clients-tls will be ready
2022-04-02 13:59:32 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-4240b926-kafka-clients-tls is ready
2022-04-02 13:59:32 [main] [32mINFO [m [SecurityST:561] Checking consumed messages to pod:my-cluster-4240b926-kafka-clients-tls-768fd464d4-m9t6v
2022-04-02 13:59:32 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@7cd205a7, messages=[], arguments=[--max-messages, 100, --group-instance-id, instance321698854, --group-id, my-consumer-group-1714732133, --topic, my-topic-236389318-114662154, --bootstrap-server, my-cluster-4240b926-kafka-bootstrap.namespace-57.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-4240b926-kafka-clients-tls-768fd464d4-m9t6v', podNamespace='namespace-57', bootstrapServer='my-cluster-4240b926-kafka-bootstrap.namespace-57.svc:9092', topicName='my-topic-236389318-114662154', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1714732133', consumerInstanceId='instance321698854', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@2c589c09}
2022-04-02 13:59:32 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-4240b926-kafka-bootstrap.namespace-57.svc:9092#my-topic-236389318-114662154 from pod my-cluster-4240b926-kafka-clients-tls-768fd464d4-m9t6v
2022-04-02 13:59:32 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-4240b926-kafka-clients-tls-768fd464d4-m9t6v -n namespace-57 -- /opt/kafka/consumer.sh --max-messages 100 --group-instance-id instance321698854 --group-id my-consumer-group-1714732133 --topic my-topic-236389318-114662154 --bootstrap-server my-cluster-4240b926-kafka-bootstrap.namespace-57.svc:9092
2022-04-02 13:59:38 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-02 13:59:38 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-02 13:59:38 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 13:59:38 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAutoReplaceClientsCaKeysTriggeredByAnno
2022-04-02 13:59:38 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-4240b926-kafka-clients in namespace namespace-57
2022-04-02 13:59:38 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-4240b926 in namespace namespace-57
2022-04-02 13:59:38 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-57, for cruise control Kafka cluster my-cluster-4240b926
2022-04-02 13:59:38 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-236389318-114662154 in namespace namespace-57
2022-04-02 13:59:38 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1365319292-237858249 in namespace namespace-57
2022-04-02 13:59:38 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1079040476-1612635516 in namespace namespace-57
2022-04-02 13:59:38 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-4240b926-kafka-clients-tls in namespace namespace-57
2022-04-02 14:00:38 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 14:00:38 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-57 for test case:testAutoReplaceClientsCaKeysTriggeredByAnno
2022-04-02 14:00:45 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testAutoReplaceClientsCaKeysTriggeredByAnno-FINISHED
2022-04-02 14:00:45 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 14:00:45 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 14:00:45 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testTlsHostnameVerificationWithMirrorMaker-STARTED
2022-04-02 14:00:45 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 14:00:45 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-58 for test case:testTlsHostnameVerificationWithMirrorMaker
2022-04-02 14:00:45 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-58
2022-04-02 14:00:45 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-58
2022-04-02 14:00:45 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-58
2022-04-02 14:00:45 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-3b76636a-source in namespace namespace-58
2022-04-02 14:00:45 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-58
2022-04-02 14:00:45 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-3b76636a-source will have desired state: Ready
2022-04-02 14:01:53 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-3b76636a-source is in desired state: Ready
2022-04-02 14:01:53 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-3b76636a-target in namespace namespace-58
2022-04-02 14:01:53 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-58
2022-04-02 14:01:53 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-3b76636a-target will have desired state: Ready
2022-04-02 14:03:02 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-3b76636a-target is in desired state: Ready
2022-04-02 14:03:02 [main] [32mINFO [m [SecurityST:888] Getting IP of the source bootstrap service for consumer
2022-04-02 14:03:02 [main] [32mINFO [m [SecurityST:891] Getting IP of the target bootstrap service for producer
2022-04-02 14:03:02 [main] [32mINFO [m [SecurityST:894] KafkaMirrorMaker without config ssl.endpoint.identification.algorithm will not connect to consumer with address 10.104.156.236:9093
2022-04-02 14:03:02 [main] [32mINFO [m [SecurityST:895] KafkaMirrorMaker without config ssl.endpoint.identification.algorithm will not connect to producer with address 10.107.49.159:9093
2022-04-02 14:03:02 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-3b76636a in namespace namespace-58
2022-04-02 14:03:02 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-58
2022-04-02 14:03:02 [main] [32mINFO [m [PodUtils:245] Wait until Pod my-cluster-3b76636a-mirror-maker is present
2022-04-02 14:03:03 [main] [32mINFO [m [PodUtils:249] Pod my-cluster-3b76636a-mirror-maker is present
2022-04-02 14:03:03 [main] [32mINFO [m [PodUtils:236] Wait until Pod my-cluster-3b76636a-mirror-maker-8545db5cd7-dtdrt is in CrashLoopBackOff state
2022-04-02 14:03:14 [main] [32mINFO [m [PodUtils:241] Pod my-cluster-3b76636a-mirror-maker-8545db5cd7-dtdrt is in CrashLoopBackOff state
2022-04-02 14:03:14 [main] [32mINFO [m [SecurityST:930] KafkaMirrorMaker with config ssl.endpoint.identification.algorithm will connect to consumer with address 10.104.156.236:9093
2022-04-02 14:03:14 [main] [32mINFO [m [SecurityST:931] KafkaMirrorMaker with config ssl.endpoint.identification.algorithm will connect to producer with address 10.107.49.159:9093
2022-04-02 14:03:14 [main] [32mINFO [m [SecurityST:933] Adding configuration ssl.endpoint.identification.algorithm to the mirror maker...
2022-04-02 14:03:14 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-3b76636a will have desired state: Ready
2022-04-02 14:09:14 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-3b76636a is in desired state: Ready
2022-04-02 14:09:14 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 14:09:14 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTlsHostnameVerificationWithMirrorMaker
2022-04-02 14:09:14 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-3b76636a-target in namespace namespace-58
2022-04-02 14:09:14 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-3b76636a-source in namespace namespace-58
2022-04-02 14:09:14 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-3b76636a in namespace namespace-58
2022-04-02 14:09:34 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 14:09:34 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-58 for test case:testTlsHostnameVerificationWithMirrorMaker
2022-04-02 14:09:45 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testTlsHostnameVerificationWithMirrorMaker-FINISHED
2022-04-02 14:09:45 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 14:09:45 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 14:09:45 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAutoRenewClusterCaCertsTriggeredByAnno-STARTED
2022-04-02 14:09:45 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 14:09:45 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-59 for test case:testAutoRenewClusterCaCertsTriggeredByAnno
2022-04-02 14:09:45 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-59
2022-04-02 14:09:45 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-59
2022-04-02 14:09:45 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-59
2022-04-02 14:09:45 [main] [32mINFO [m [SecurityST:587] Creating a cluster
2022-04-02 14:09:45 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-c497a7fc in namespace namespace-59
2022-04-02 14:09:45 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-59
2022-04-02 14:09:45 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-c497a7fc will have desired state: Ready
2022-04-02 14:12:36 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-c497a7fc is in desired state: Ready
2022-04-02 14:12:36 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1543496401-1212139522 in namespace namespace-59
2022-04-02 14:12:36 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-59
2022-04-02 14:12:36 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1543496401-1212139522 will have desired state: Ready
2022-04-02 14:12:37 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1543496401-1212139522 is in desired state: Ready
2022-04-02 14:12:37 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-835002850-936606112 in namespace namespace-59
2022-04-02 14:12:37 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-59
2022-04-02 14:12:37 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-835002850-936606112 will have desired state: Ready
2022-04-02 14:12:38 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-835002850-936606112 is in desired state: Ready
2022-04-02 14:12:38 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-c497a7fc-kafka-clients in namespace namespace-59
2022-04-02 14:12:38 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-59
2022-04-02 14:12:38 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-c497a7fc-kafka-clients will be ready
2022-04-02 14:12:40 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-c497a7fc-kafka-clients is ready
2022-04-02 14:12:40 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-02 14:12:40 [main] [32mINFO [m [SecurityST:260] Checking produced and consumed messages to pod:my-cluster-c497a7fc-kafka-clients-7c8f59bd57-lwt57
2022-04-02 14:12:40 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@75001ad9, messages=[], arguments=[--max-messages, 100, --topic, my-topic-835002850-936606112, --bootstrap-server, my-cluster-c497a7fc-kafka-bootstrap.namespace-59.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-c497a7fc-kafka-clients-7c8f59bd57-lwt57', podNamespace='namespace-59', bootstrapServer='my-cluster-c497a7fc-kafka-bootstrap.namespace-59.svc:9092', topicName='my-topic-835002850-936606112', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@8eeea80}
2022-04-02 14:12:40 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-c497a7fc-kafka-bootstrap.namespace-59.svc:9092:my-topic-835002850-936606112 from pod my-cluster-c497a7fc-kafka-clients-7c8f59bd57-lwt57
2022-04-02 14:12:40 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-c497a7fc-kafka-clients-7c8f59bd57-lwt57 -n namespace-59 -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-835002850-936606112 --bootstrap-server my-cluster-c497a7fc-kafka-bootstrap.namespace-59.svc:9092
2022-04-02 14:12:43 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-02 14:12:43 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-02 14:12:43 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@3ed1a895, messages=[], arguments=[--max-messages, 100, --group-instance-id, instance1594178133, --group-id, my-consumer-group-152686104, --topic, my-topic-835002850-936606112, --bootstrap-server, my-cluster-c497a7fc-kafka-bootstrap.namespace-59.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-c497a7fc-kafka-clients-7c8f59bd57-lwt57', podNamespace='namespace-59', bootstrapServer='my-cluster-c497a7fc-kafka-bootstrap.namespace-59.svc:9092', topicName='my-topic-835002850-936606112', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-152686104', consumerInstanceId='instance1594178133', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@4194e0cd}
2022-04-02 14:12:43 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-c497a7fc-kafka-bootstrap.namespace-59.svc:9092#my-topic-835002850-936606112 from pod my-cluster-c497a7fc-kafka-clients-7c8f59bd57-lwt57
2022-04-02 14:12:43 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-c497a7fc-kafka-clients-7c8f59bd57-lwt57 -n namespace-59 -- /opt/kafka/consumer.sh --max-messages 100 --group-instance-id instance1594178133 --group-id my-consumer-group-152686104 --topic my-topic-835002850-936606112 --bootstrap-server my-cluster-c497a7fc-kafka-bootstrap.namespace-59.svc:9092
2022-04-02 14:12:48 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-02 14:12:48 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-02 14:12:49 [main] [32mINFO [m [SecurityST:274] Triggering CA cert renewal by adding the annotation
2022-04-02 14:12:49 [main] [32mINFO [m [SecurityST:286] Patching secret my-cluster-c497a7fc-cluster-ca-cert with strimzi.io/force-renew
2022-04-02 14:12:49 [main] [32mINFO [m [SecurityST:291] Wait for zk to rolling restart ...
2022-04-02 14:12:49 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-c497a7fc-zookeeper rolling update
2022-04-02 14:13:54 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-c497a7fc-zookeeper has been successfully rolled
2022-04-02 14:13:54 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-c497a7fc-zookeeper to be ready
2022-04-02 14:14:23 [main] [32mINFO [m [SecurityST:295] Wait for kafka to rolling restart ...
2022-04-02 14:14:23 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-c497a7fc-kafka rolling update
2022-04-02 14:15:18 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-c497a7fc-kafka has been successfully rolled
2022-04-02 14:15:18 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-c497a7fc-kafka to be ready
2022-04-02 14:15:44 [main] [32mINFO [m [SecurityST:299] Wait for EO to rolling restart ...
2022-04-02 14:15:44 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-c497a7fc-entity-operator rolling update
2022-04-02 14:15:44 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-c497a7fc-entity-operator will be ready
2022-04-02 14:16:26 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-c497a7fc-entity-operator is ready
2022-04-02 14:16:36 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-c497a7fc-entity-operator rolling update finished
2022-04-02 14:16:36 [main] [32mINFO [m [SecurityST:303] Wait for CC and KE to rolling restart ...
2022-04-02 14:16:36 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-c497a7fc-kafka-exporter rolling update
2022-04-02 14:17:31 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-c497a7fc-kafka-exporter will be ready
2022-04-02 14:17:31 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-c497a7fc-kafka-exporter is ready
2022-04-02 14:17:41 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-c497a7fc-kafka-exporter rolling update finished
2022-04-02 14:17:41 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-c497a7fc-cruise-control rolling update
2022-04-02 14:17:41 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-c497a7fc-cruise-control will be ready
2022-04-02 14:17:41 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-c497a7fc-cruise-control is ready
2022-04-02 14:17:51 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-c497a7fc-cruise-control rolling update finished
2022-04-02 14:17:51 [main] [32mINFO [m [SecurityST:308] Checking the certificates have been replaced
2022-04-02 14:17:51 [main] [32mINFO [m [SecurityST:322] Checking consumed messages to pod:my-cluster-c497a7fc-kafka-clients-7c8f59bd57-lwt57
2022-04-02 14:17:51 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@31da15f3, messages=[], arguments=[--max-messages, 100, --group-instance-id, instance1025100813, --group-id, my-consumer-group-1139287901, --topic, my-topic-835002850-936606112, --bootstrap-server, my-cluster-c497a7fc-kafka-bootstrap.namespace-59.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-c497a7fc-kafka-clients-7c8f59bd57-lwt57', podNamespace='namespace-59', bootstrapServer='my-cluster-c497a7fc-kafka-bootstrap.namespace-59.svc:9092', topicName='my-topic-835002850-936606112', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1139287901', consumerInstanceId='instance1025100813', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@74275d56}
2022-04-02 14:17:51 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-c497a7fc-kafka-bootstrap.namespace-59.svc:9092#my-topic-835002850-936606112 from pod my-cluster-c497a7fc-kafka-clients-7c8f59bd57-lwt57
2022-04-02 14:17:51 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-c497a7fc-kafka-clients-7c8f59bd57-lwt57 -n namespace-59 -- /opt/kafka/consumer.sh --max-messages 100 --group-instance-id instance1025100813 --group-id my-consumer-group-1139287901 --topic my-topic-835002850-936606112 --bootstrap-server my-cluster-c497a7fc-kafka-bootstrap.namespace-59.svc:9092
2022-04-02 14:17:57 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-02 14:17:57 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-02 14:17:57 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser bob-my-cluster-c497a7fc in namespace namespace-59
2022-04-02 14:17:57 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-59
2022-04-02 14:17:57 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: bob-my-cluster-c497a7fc will have desired state: Ready
2022-04-02 14:17:58 [main] [32mINFO [m [ResourceManager:444] KafkaUser: bob-my-cluster-c497a7fc is in desired state: Ready
2022-04-02 14:17:58 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-c497a7fc-kafka-clients-tls in namespace namespace-59
2022-04-02 14:17:58 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-59
2022-04-02 14:17:58 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-c497a7fc-kafka-clients-tls will be ready
2022-04-02 14:18:00 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-c497a7fc-kafka-clients-tls is ready
2022-04-02 14:18:00 [main] [32mINFO [m [SecurityST:346] Checking consumed messages to pod:my-cluster-c497a7fc-kafka-clients-tls-79f6cc9f96-z4cbk
2022-04-02 14:18:00 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@5ccd7dc7, messages=[], arguments=[USER=bob_my_cluster_c497a7fc, --max-messages, 100, --group-instance-id, instance1723166552, --group-id, my-consumer-group-90801804, --topic, my-topic-835002850-936606112, --bootstrap-server, my-cluster-c497a7fc-kafka-bootstrap.namespace-59.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-c497a7fc-kafka-clients-tls-79f6cc9f96-z4cbk', podNamespace='namespace-59', bootstrapServer='my-cluster-c497a7fc-kafka-bootstrap.namespace-59.svc:9093', topicName='my-topic-835002850-936606112', maxMessages=100, kafkaUsername='bob-my-cluster-c497a7fc', consumerGroupName='my-consumer-group-90801804', consumerInstanceId='instance1723166552', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@12ce4f25}
2022-04-02 14:18:00 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-c497a7fc-kafka-bootstrap.namespace-59.svc:9093#my-topic-835002850-936606112 from pod my-cluster-c497a7fc-kafka-clients-tls-79f6cc9f96-z4cbk
2022-04-02 14:18:00 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-c497a7fc-kafka-clients-tls-79f6cc9f96-z4cbk -n namespace-59 -- /opt/kafka/consumer.sh USER=bob_my_cluster_c497a7fc --max-messages 100 --group-instance-id instance1723166552 --group-id my-consumer-group-90801804 --topic my-topic-835002850-936606112 --bootstrap-server my-cluster-c497a7fc-kafka-bootstrap.namespace-59.svc:9093
2022-04-02 14:18:07 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-02 14:18:07 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-02 14:18:07 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 14:18:07 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAutoRenewClusterCaCertsTriggeredByAnno
2022-04-02 14:18:07 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-c497a7fc-kafka-clients in namespace namespace-59
2022-04-02 14:18:07 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-c497a7fc in namespace namespace-59
2022-04-02 14:18:07 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-c497a7fc-kafka-clients-tls in namespace namespace-59
2022-04-02 14:18:07 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-59, for cruise control Kafka cluster my-cluster-c497a7fc
2022-04-02 14:18:07 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaUser bob-my-cluster-c497a7fc in namespace namespace-59
2022-04-02 14:18:07 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-835002850-936606112 in namespace namespace-59
2022-04-02 14:18:07 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1543496401-1212139522 in namespace namespace-59
2022-04-02 14:18:57 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 14:18:57 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-59 for test case:testAutoRenewClusterCaCertsTriggeredByAnno
2022-04-02 14:19:04 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testAutoRenewClusterCaCertsTriggeredByAnno-FINISHED
2022-04-02 14:19:04 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 14:19:04 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 14:19:04 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testCaRenewalBreakInMiddle-STARTED
2022-04-02 14:19:04 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 14:19:04 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-60 for test case:testCaRenewalBreakInMiddle
2022-04-02 14:19:04 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-60
2022-04-02 14:19:04 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-60
2022-04-02 14:19:04 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-60
2022-04-02 14:19:04 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-df8669b2 in namespace namespace-60
2022-04-02 14:19:04 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-60
2022-04-02 14:19:04 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-df8669b2 will have desired state: Ready
2022-04-02 14:21:22 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-df8669b2 is in desired state: Ready
2022-04-02 14:21:22 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1300278664-2017987745 in namespace namespace-60
2022-04-02 14:21:22 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-60
2022-04-02 14:21:22 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1300278664-2017987745 will have desired state: Ready
2022-04-02 14:21:23 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1300278664-2017987745 is in desired state: Ready
2022-04-02 14:21:23 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1165857587-2094101896 in namespace namespace-60
2022-04-02 14:21:23 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-60
2022-04-02 14:21:23 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1165857587-2094101896 will have desired state: Ready
2022-04-02 14:21:24 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1165857587-2094101896 is in desired state: Ready
2022-04-02 14:21:24 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-df8669b2-kafka-clients in namespace namespace-60
2022-04-02 14:21:24 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-60
2022-04-02 14:21:24 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-df8669b2-kafka-clients will be ready
2022-04-02 14:21:25 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-df8669b2-kafka-clients is ready
2022-04-02 14:21:25 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-02 14:21:25 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@41ed488f, messages=[], arguments=[USER=my_user_1300278664_2017987745, --max-messages, 100, --topic, my-topic-1165857587-2094101896, --bootstrap-server, my-cluster-df8669b2-kafka-bootstrap.namespace-60.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-df8669b2-kafka-clients-569fcb7954-xmmdc', podNamespace='namespace-60', bootstrapServer='my-cluster-df8669b2-kafka-bootstrap.namespace-60.svc:9093', topicName='my-topic-1165857587-2094101896', maxMessages=100, kafkaUsername='my-user-1300278664-2017987745', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3f097aa9}
2022-04-02 14:21:25 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-df8669b2-kafka-bootstrap.namespace-60.svc:9093:my-topic-1165857587-2094101896 from pod my-cluster-df8669b2-kafka-clients-569fcb7954-xmmdc
2022-04-02 14:21:25 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-df8669b2-kafka-clients-569fcb7954-xmmdc -n namespace-60 -- /opt/kafka/producer.sh USER=my_user_1300278664_2017987745 --max-messages 100 --topic my-topic-1165857587-2094101896 --bootstrap-server my-cluster-df8669b2-kafka-bootstrap.namespace-60.svc:9093
2022-04-02 14:21:29 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-02 14:21:29 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-02 14:21:29 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@52068ab3, messages=[], arguments=[USER=my_user_1300278664_2017987745, --max-messages, 100, --group-instance-id, instance390014861, --group-id, my-consumer-group-813120799, --topic, my-topic-1165857587-2094101896, --bootstrap-server, my-cluster-df8669b2-kafka-bootstrap.namespace-60.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-df8669b2-kafka-clients-569fcb7954-xmmdc', podNamespace='namespace-60', bootstrapServer='my-cluster-df8669b2-kafka-bootstrap.namespace-60.svc:9093', topicName='my-topic-1165857587-2094101896', maxMessages=100, kafkaUsername='my-user-1300278664-2017987745', consumerGroupName='my-consumer-group-813120799', consumerInstanceId='instance390014861', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@26ae60fd}
2022-04-02 14:21:29 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-df8669b2-kafka-bootstrap.namespace-60.svc:9093:my-topic-1165857587-2094101896 from pod my-cluster-df8669b2-kafka-clients-569fcb7954-xmmdc
2022-04-02 14:21:29 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-df8669b2-kafka-clients-569fcb7954-xmmdc -n namespace-60 -- /opt/kafka/consumer.sh USER=my_user_1300278664_2017987745 --max-messages 100 --group-instance-id instance390014861 --group-id my-consumer-group-813120799 --topic my-topic-1165857587-2094101896 --bootstrap-server my-cluster-df8669b2-kafka-bootstrap.namespace-60.svc:9093
2022-04-02 14:21:36 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-02 14:21:36 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-02 14:21:36 [main] [32mINFO [m [SecretUtils:70] Creating secret my-cluster-df8669b2-cluster-ca-cert
2022-04-02 14:21:36 [main] [32mINFO [m [SecurityST:1218] No pods of my-cluster-df8669b2-zookeeper are in desired state
2022-04-02 14:21:37 [main] [32mINFO [m [SecurityST:1218] No pods of my-cluster-df8669b2-zookeeper are in desired state
2022-04-02 14:21:38 [main] [32mINFO [m [SecurityST:1218] No pods of my-cluster-df8669b2-zookeeper are in desired state
2022-04-02 14:21:39 [main] [32mINFO [m [SecurityST:1218] No pods of my-cluster-df8669b2-zookeeper are in desired state
2022-04-02 14:21:40 [main] [32mINFO [m [SecurityST:1218] No pods of my-cluster-df8669b2-zookeeper are in desired state
2022-04-02 14:21:41 [main] [32mINFO [m [SecurityST:1218] No pods of my-cluster-df8669b2-zookeeper are in desired state
2022-04-02 14:21:42 [main] [32mINFO [m [SecurityST:1218] No pods of my-cluster-df8669b2-zookeeper are in desired state
2022-04-02 14:21:43 [main] [32mINFO [m [SecurityST:1218] No pods of my-cluster-df8669b2-zookeeper are in desired state
2022-04-02 14:21:44 [main] [32mINFO [m [SecurityST:1218] No pods of my-cluster-df8669b2-zookeeper are in desired state
2022-04-02 14:21:45 [main] [32mINFO [m [SecurityST:1218] No pods of my-cluster-df8669b2-zookeeper are in desired state
2022-04-02 14:21:46 [main] [32mINFO [m [SecurityST:1218] No pods of my-cluster-df8669b2-zookeeper are in desired state
2022-04-02 14:21:47 [main] [32mINFO [m [SecurityST:1218] No pods of my-cluster-df8669b2-zookeeper are in desired state
2022-04-02 14:21:48 [main] [32mINFO [m [SecurityST:1218] No pods of my-cluster-df8669b2-zookeeper are in desired state
2022-04-02 14:21:49 [main] [32mINFO [m [SecurityST:1218] No pods of my-cluster-df8669b2-zookeeper are in desired state
2022-04-02 14:21:50 [main] [32mINFO [m [SecurityST:1218] No pods of my-cluster-df8669b2-zookeeper are in desired state
2022-04-02 14:21:51 [main] [32mINFO [m [SecurityST:1221] Pod in 'Pending' state: my-cluster-df8669b2-zookeeper-2
2022-04-02 14:21:51 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@3d9cc59b, messages=[], arguments=[USER=my_user_1300278664_2017987745, --max-messages, 100, --group-instance-id, instance867685031, --group-id, my-consumer-group-314978568, --topic, my-topic-1165857587-2094101896, --bootstrap-server, my-cluster-df8669b2-kafka-bootstrap.namespace-60.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-df8669b2-kafka-clients-569fcb7954-xmmdc', podNamespace='namespace-60', bootstrapServer='my-cluster-df8669b2-kafka-bootstrap.namespace-60.svc:9093', topicName='my-topic-1165857587-2094101896', maxMessages=100, kafkaUsername='my-user-1300278664-2017987745', consumerGroupName='my-consumer-group-314978568', consumerInstanceId='instance867685031', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@15f53bff}
2022-04-02 14:21:51 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-df8669b2-kafka-bootstrap.namespace-60.svc:9093:my-topic-1165857587-2094101896 from pod my-cluster-df8669b2-kafka-clients-569fcb7954-xmmdc
2022-04-02 14:21:51 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-df8669b2-kafka-clients-569fcb7954-xmmdc -n namespace-60 -- /opt/kafka/consumer.sh USER=my_user_1300278664_2017987745 --max-messages 100 --group-instance-id instance867685031 --group-id my-consumer-group-314978568 --topic my-topic-1165857587-2094101896 --bootstrap-server my-cluster-df8669b2-kafka-bootstrap.namespace-60.svc:9093
2022-04-02 14:21:58 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-02 14:21:58 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-02 14:21:58 [main] [32mINFO [m [SecretUtils:131] Waiting for Secret my-cluster-df8669b2-cluster-ca-cert certificate change
2022-04-02 14:21:58 [main] [32mINFO [m [SecretUtils:138] Certificate in Secret my-cluster-df8669b2-cluster-ca-cert has changed, was -----BEGIN CERTIFICATE-----
MIIDKjCCAhKgAwIBAgIJAJBt0u1FFTG+MA0GCSqGSIb3DQEBCwUAMCoxEzARBgNV
BAoMCnN0cmltemkuaW8xEzARBgNVBAMMCmNsdXN0ZXItY2EwHhcNMTgxMDIzMTAw
MTExWhcNMTgxMDI0MTAwMTExWjAqMRMwEQYDVQQKDApzdHJpbXppLmlvMRMwEQYD
VQQDDApjbHVzdGVyLWNhMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA
xpuYrNXYHqw3ajwd12aAeuTlAX4rVwVdPuIex6A4NL8J3d2DV+ngXgNTH//RhiF5
If5KRWSsLei5BUIrwuQutOUNCQwyACmri9+yrx6+tevligiokAUwhHxcDHZpwC3T
+2dzk/BkI++vbSuvjFmBKGQi9gfyoTnStTEQ85KVJUS170hzwDjzaEiJsKpOPx/G
+KTdkAopLucoxr4sxhYeO4mQ2PkT0QL+R8Ohs6LD6v/bqalFP+rS8vibolfxjMNm
lXQCOd8UfXy8OEOaNoNCvhnn/cT/hbEG/ARbV3hHmUh9COV+TSV5dhsbmS5h4MKw
LzP449nGQBmLSkZMu984DQIDAQABo1MwUTAdBgNVHQ4EFgQUOXubcHBZJ7vSzjpi
pfXdFSP3dsEwHwYDVR0jBBgwFoAUOXubcHBZJ7vSzjpipfXdFSP3dsEwDwYDVR0T
AQH/BAUwAwEB/zANBgkqhkiG9w0BAQsFAAOCAQEAFFPGykbzUREDMzh+33i3a8TF
UTQnPMN/SuVbpLfQdpkpLO+aVWjVvJP6qMrI7jRO5zhj4MecAf7YKpe+dyRTTz9B
Dy9BZcujHYjCKdcKBnBFQ7B1xQm9tL1bw+a3ABzSTlhLiBcCxhJEawlWy1Gh18ab
3x/Kqnz0mk/jt5+n9HwlKHuBQVIxRCsfHWwq+WvIfoxM+N//akV8/29hLUf5TlYH
F5CX4G2pA5sSdaDHQ4ekQWuqM6tfvsGLl2KOmEFEgVR4GfaWI4BsUCzlpBNcCGWv
V7klZvBxQPG7MVy0cB8yzTDtUpR0jUFUkZOSp5Pr3yWcwPWEgWkaXYfO+FWETA==
-----END CERTIFICATE-----
, is now -----BEGIN CERTIFICATE-----
MIIFLTCCAxWgAwIBAgIUKuKoGGXAc9JBbPe/AWPyzCw7aokwDQYJKoZIhvcNAQEN
BQAwLTETMBEGA1UECgwKaW8uc3RyaW16aTEWMBQGA1UEAwwNY2x1c3Rlci1jYSB2
MDAeFw0yMjA0MDIxNDIxMzZaFw0yMjA0MDkxNDIxMzZaMC0xEzARBgNVBAoMCmlv
LnN0cmltemkxFjAUBgNVBAMMDWNsdXN0ZXItY2EgdjAwggIiMA0GCSqGSIb3DQEB
AQUAA4ICDwAwggIKAoICAQCthQmGUP//apVVD5lPYXJrd1YSJ0AYv0cVXnjeoatx
Ha5RHV2lerpmHwCbml2pFufrjgazRJo9hWyTa8sB3vtOjje8gxPUDXhkMG7m334F
//ckWR8w/aLf7Jay+BL4O54KAUWUGqSnxz2/gtYB7qOp2bjPS7Fi/CZjGtYYkgD1
ZVbhhRKksVdMa5HaXSaMlSGb+2hSHO/HI8wnPS/20j9OQnE2aokyRcTNuVG6JKdq
Um9z1EuGk9QysrilDKkugI3b2vXvQYTapd+MdNgmk4S5T/ibpeHdCDLW/Wozpnwd
7D6vy+mGuvLj/Df673+s8RBOQhfQACyiVm/t9yfZTpWmaaBEc8iXeNWrbvtpmfc9
qA08zu6FrjXSf1+RoOrovzXOpWJMZt/PCOpq5eh6ioR7Bu9PZs+7Ob7R7SPtvwJT
rXWjTKbQ7weLWH11DfSIuU3705FrcWWABl+c6OIl6DYA7mxBvkyiPYjXszJzPRmz
E4MY0VSmrgWZOki+n49dIX1daY9Zo95HF2K/murP8ZrYpjI9P8HqqUEHfuO+trKs
X9cTe/7o+zbFv+VNgUYDexfD3gz7ALltSjZjAaff1wIq4HxCzbn8rvdrORAK7JK0
O7f9MEURO1hKw4AyNiQKYRjIOy26ZkSWfFJqo5Y6A5yYU800H3moBzraIRZ/9yR8
5wIDAQABo0UwQzAdBgNVHQ4EFgQUYbupwOncHyvJoM9zsakggWX1RxUwEgYDVR0T
AQH/BAgwBgEB/wIBADAOBgNVHQ8BAf8EBAMCAQYwDQYJKoZIhvcNAQENBQADggIB
AF31FZ1reG+karBtGEzP5z/w/HvfdRWpW8iWZQX3tfqQ6FLysB7lKlG2xRgpA1mn
V9sd2iSa6yVRVf5eiKSr3Gj9fNeF5sMKs0rAT1dQew75RCE9mRevNJwtaUNgEVkt
m3DF2d9exWbRv3HHWylWqtIfLFQ9Ui5jZaKTq80qOv40BsFE00tq3IfeheBkgmyU
1/3uE/a+tyrOYdckkshNA/uYrZztdfGt/aTLixmRMYda3M+2w1SL3Fj2Tk97Gow0
yB2KW9Er1t3oeMdkHqZNOsvWQ50kxAU7j1YvutTDOkkNi8T1Exi/YqdvT/YMWqg0
nCTXXYbZfgk7C+LNgwvJeh2X1zj6V7k8lVZ0JYvi0wF8DJS5eEVKywMdha2doqsh
F3H+TaMCkPyND8m47azHXOzYwAQ5HwvX68uAlEeHpsRGbMwOCkLXOrglOF1uECMm
O+fk1bOYv1zwCKxnw6s1vzTpNLB+18p+TYmj8yBR3msPINFhiAYV+bfw2B8uGV4a
aWQtCfEABxl4/J9qt7m/4inqVDFTj15lHcdnKGOXEgddA5gWudiWsrJ7sI+rjJKs
ERPFDG31se2YAAVMj74qO18MsvORZaZgoWWNtmvsUKJ9R8V5JoeS84ycvW/mdsBI
vWnStWktc+3yO86OON05AFGfqrDZ7TxYe79XA1jKrl3K
-----END CERTIFICATE-----

2022-04-02 14:21:58 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-df8669b2-zookeeper rolling update
2022-04-02 14:28:03 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-df8669b2-zookeeper has been successfully rolled
2022-04-02 14:28:03 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-df8669b2-zookeeper to be ready
2022-04-02 14:28:36 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-df8669b2-kafka rolling update
2022-04-02 14:29:41 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-df8669b2-kafka has been successfully rolled
2022-04-02 14:29:41 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-df8669b2-kafka to be ready
2022-04-02 14:30:13 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-df8669b2-entity-operator rolling update
2022-04-02 14:30:13 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-df8669b2-entity-operator will be ready
2022-04-02 14:31:01 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-df8669b2-entity-operator is ready
2022-04-02 14:31:11 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-df8669b2-entity-operator rolling update finished
2022-04-02 14:31:11 [main] [32mINFO [m [SecurityST:1252] Checking produced and consumed messages to pod:my-cluster-df8669b2-kafka-clients-569fcb7954-xmmdc
2022-04-02 14:31:11 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@4dd3cdf9, messages=[], arguments=[USER=my_user_1300278664_2017987745, --max-messages, 100, --group-instance-id, instance1106082275, --group-id, my-consumer-group-6192981, --topic, my-topic-1165857587-2094101896, --bootstrap-server, my-cluster-df8669b2-kafka-bootstrap.namespace-60.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-df8669b2-kafka-clients-569fcb7954-xmmdc', podNamespace='namespace-60', bootstrapServer='my-cluster-df8669b2-kafka-bootstrap.namespace-60.svc:9093', topicName='my-topic-1165857587-2094101896', maxMessages=100, kafkaUsername='my-user-1300278664-2017987745', consumerGroupName='my-consumer-group-6192981', consumerInstanceId='instance1106082275', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@4ffc3a73}
2022-04-02 14:31:11 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-df8669b2-kafka-bootstrap.namespace-60.svc:9093:my-topic-1165857587-2094101896 from pod my-cluster-df8669b2-kafka-clients-569fcb7954-xmmdc
2022-04-02 14:31:11 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-df8669b2-kafka-clients-569fcb7954-xmmdc -n namespace-60 -- /opt/kafka/consumer.sh USER=my_user_1300278664_2017987745 --max-messages 100 --group-instance-id instance1106082275 --group-id my-consumer-group-6192981 --topic my-topic-1165857587-2094101896 --bootstrap-server my-cluster-df8669b2-kafka-bootstrap.namespace-60.svc:9093
2022-04-02 14:31:18 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-02 14:31:18 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-02 14:31:18 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-765154588-110389087 in namespace namespace-60
2022-04-02 14:31:18 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-60
2022-04-02 14:31:18 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-765154588-110389087 will have desired state: Ready
2022-04-02 14:31:19 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-765154588-110389087 is in desired state: Ready
2022-04-02 14:31:19 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@4f23de33, messages=[], arguments=[USER=my_user_1300278664_2017987745, --max-messages, 100, --topic, my-topic-765154588-110389087, --bootstrap-server, my-cluster-df8669b2-kafka-bootstrap.namespace-60.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-df8669b2-kafka-clients-569fcb7954-xmmdc', podNamespace='namespace-60', bootstrapServer='my-cluster-df8669b2-kafka-bootstrap.namespace-60.svc:9093', topicName='my-topic-765154588-110389087', maxMessages=100, kafkaUsername='my-user-1300278664-2017987745', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@61a24fd6}
2022-04-02 14:31:19 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-df8669b2-kafka-bootstrap.namespace-60.svc:9093:my-topic-765154588-110389087 from pod my-cluster-df8669b2-kafka-clients-569fcb7954-xmmdc
2022-04-02 14:31:19 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-df8669b2-kafka-clients-569fcb7954-xmmdc -n namespace-60 -- /opt/kafka/producer.sh USER=my_user_1300278664_2017987745 --max-messages 100 --topic my-topic-765154588-110389087 --bootstrap-server my-cluster-df8669b2-kafka-bootstrap.namespace-60.svc:9093
2022-04-02 14:31:22 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-02 14:31:22 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-02 14:31:22 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@6c916acd, messages=[], arguments=[USER=my_user_1300278664_2017987745, --max-messages, 100, --group-instance-id, instance1073596332, --group-id, my-consumer-group-1651657082, --topic, my-topic-765154588-110389087, --bootstrap-server, my-cluster-df8669b2-kafka-bootstrap.namespace-60.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-df8669b2-kafka-clients-569fcb7954-xmmdc', podNamespace='namespace-60', bootstrapServer='my-cluster-df8669b2-kafka-bootstrap.namespace-60.svc:9093', topicName='my-topic-765154588-110389087', maxMessages=100, kafkaUsername='my-user-1300278664-2017987745', consumerGroupName='my-consumer-group-1651657082', consumerInstanceId='instance1073596332', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1c4c6e2b}
2022-04-02 14:31:22 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-df8669b2-kafka-bootstrap.namespace-60.svc:9093:my-topic-765154588-110389087 from pod my-cluster-df8669b2-kafka-clients-569fcb7954-xmmdc
2022-04-02 14:31:22 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-df8669b2-kafka-clients-569fcb7954-xmmdc -n namespace-60 -- /opt/kafka/consumer.sh USER=my_user_1300278664_2017987745 --max-messages 100 --group-instance-id instance1073596332 --group-id my-consumer-group-1651657082 --topic my-topic-765154588-110389087 --bootstrap-server my-cluster-df8669b2-kafka-bootstrap.namespace-60.svc:9093
2022-04-02 14:31:29 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-02 14:31:29 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-02 14:31:29 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 14:31:29 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCaRenewalBreakInMiddle
2022-04-02 14:31:29 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1165857587-2094101896 in namespace namespace-60
2022-04-02 14:31:29 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-df8669b2 in namespace namespace-60
2022-04-02 14:31:29 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1300278664-2017987745 in namespace namespace-60
2022-04-02 14:31:29 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-765154588-110389087 in namespace namespace-60
2022-04-02 14:31:29 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-df8669b2-kafka-clients in namespace namespace-60
2022-04-02 14:32:19 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 14:32:19 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-60 for test case:testCaRenewalBreakInMiddle
2022-04-02 14:32:25 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testCaRenewalBreakInMiddle-FINISHED
2022-04-02 14:32:25 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 14:32:25 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 14:32:25 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAutoRenewAllCaCertsTriggeredByAnno-STARTED
2022-04-02 14:32:25 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 14:32:25 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-61 for test case:testAutoRenewAllCaCertsTriggeredByAnno
2022-04-02 14:32:25 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-61
2022-04-02 14:32:25 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-61
2022-04-02 14:32:25 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-61
2022-04-02 14:32:25 [main] [32mINFO [m [SecurityST:587] Creating a cluster
2022-04-02 14:32:25 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-b5780bc4 in namespace namespace-61
2022-04-02 14:32:25 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-61
2022-04-02 14:32:25 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-b5780bc4 will have desired state: Ready
2022-04-02 14:35:04 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-b5780bc4 is in desired state: Ready
2022-04-02 14:35:04 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-300417859-1004929249 in namespace namespace-61
2022-04-02 14:35:04 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-61
2022-04-02 14:35:04 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-300417859-1004929249 will have desired state: Ready
2022-04-02 14:35:05 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-300417859-1004929249 is in desired state: Ready
2022-04-02 14:35:05 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-766085535-1811801127 in namespace namespace-61
2022-04-02 14:35:05 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-61
2022-04-02 14:35:05 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-766085535-1811801127 will have desired state: Ready
2022-04-02 14:35:06 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-766085535-1811801127 is in desired state: Ready
2022-04-02 14:35:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-b5780bc4-kafka-clients in namespace namespace-61
2022-04-02 14:35:06 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-61
2022-04-02 14:35:06 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-b5780bc4-kafka-clients will be ready
2022-04-02 14:35:08 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-b5780bc4-kafka-clients is ready
2022-04-02 14:35:08 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-02 14:35:08 [main] [32mINFO [m [SecurityST:260] Checking produced and consumed messages to pod:my-cluster-b5780bc4-kafka-clients-645f744888-cg8ms
2022-04-02 14:35:08 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@4e3dc3f4, messages=[], arguments=[--max-messages, 100, --topic, my-topic-766085535-1811801127, --bootstrap-server, my-cluster-b5780bc4-kafka-bootstrap.namespace-61.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-b5780bc4-kafka-clients-645f744888-cg8ms', podNamespace='namespace-61', bootstrapServer='my-cluster-b5780bc4-kafka-bootstrap.namespace-61.svc:9092', topicName='my-topic-766085535-1811801127', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1fbe4476}
2022-04-02 14:35:08 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-b5780bc4-kafka-bootstrap.namespace-61.svc:9092:my-topic-766085535-1811801127 from pod my-cluster-b5780bc4-kafka-clients-645f744888-cg8ms
2022-04-02 14:35:08 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b5780bc4-kafka-clients-645f744888-cg8ms -n namespace-61 -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-766085535-1811801127 --bootstrap-server my-cluster-b5780bc4-kafka-bootstrap.namespace-61.svc:9092
2022-04-02 14:35:11 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-02 14:35:11 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-02 14:35:11 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@3b2f6187, messages=[], arguments=[--max-messages, 100, --group-instance-id, instance1410399610, --group-id, my-consumer-group-353665126, --topic, my-topic-766085535-1811801127, --bootstrap-server, my-cluster-b5780bc4-kafka-bootstrap.namespace-61.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-b5780bc4-kafka-clients-645f744888-cg8ms', podNamespace='namespace-61', bootstrapServer='my-cluster-b5780bc4-kafka-bootstrap.namespace-61.svc:9092', topicName='my-topic-766085535-1811801127', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-353665126', consumerInstanceId='instance1410399610', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@56df12de}
2022-04-02 14:35:11 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-b5780bc4-kafka-bootstrap.namespace-61.svc:9092#my-topic-766085535-1811801127 from pod my-cluster-b5780bc4-kafka-clients-645f744888-cg8ms
2022-04-02 14:35:11 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b5780bc4-kafka-clients-645f744888-cg8ms -n namespace-61 -- /opt/kafka/consumer.sh --max-messages 100 --group-instance-id instance1410399610 --group-id my-consumer-group-353665126 --topic my-topic-766085535-1811801127 --bootstrap-server my-cluster-b5780bc4-kafka-bootstrap.namespace-61.svc:9092
2022-04-02 14:35:17 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-02 14:35:17 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-02 14:35:17 [main] [32mINFO [m [SecurityST:274] Triggering CA cert renewal by adding the annotation
2022-04-02 14:35:17 [main] [32mINFO [m [SecurityST:286] Patching secret my-cluster-b5780bc4-cluster-ca-cert with strimzi.io/force-renew
2022-04-02 14:35:17 [main] [32mINFO [m [SecurityST:286] Patching secret my-cluster-b5780bc4-clients-ca-cert with strimzi.io/force-renew
2022-04-02 14:35:17 [main] [32mINFO [m [SecurityST:291] Wait for zk to rolling restart ...
2022-04-02 14:35:17 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-b5780bc4-zookeeper rolling update
2022-04-02 14:36:27 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-b5780bc4-zookeeper has been successfully rolled
2022-04-02 14:36:27 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-b5780bc4-zookeeper to be ready
2022-04-02 14:36:57 [main] [32mINFO [m [SecurityST:295] Wait for kafka to rolling restart ...
2022-04-02 14:36:57 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-b5780bc4-kafka rolling update
2022-04-02 14:37:52 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-b5780bc4-kafka has been successfully rolled
2022-04-02 14:37:52 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-b5780bc4-kafka to be ready
2022-04-02 14:38:23 [main] [32mINFO [m [SecurityST:299] Wait for EO to rolling restart ...
2022-04-02 14:38:23 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-b5780bc4-entity-operator rolling update
2022-04-02 14:38:23 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-b5780bc4-entity-operator will be ready
2022-04-02 14:39:50 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-b5780bc4-entity-operator is ready
2022-04-02 14:40:00 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-b5780bc4-entity-operator rolling update finished
2022-04-02 14:40:00 [main] [32mINFO [m [SecurityST:303] Wait for CC and KE to rolling restart ...
2022-04-02 14:40:00 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-b5780bc4-kafka-exporter rolling update
2022-04-02 14:40:56 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-b5780bc4-kafka-exporter will be ready
2022-04-02 14:40:56 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-b5780bc4-kafka-exporter is ready
2022-04-02 14:41:06 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-b5780bc4-kafka-exporter rolling update finished
2022-04-02 14:41:06 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-b5780bc4-cruise-control rolling update
2022-04-02 14:41:06 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-b5780bc4-cruise-control will be ready
2022-04-02 14:41:06 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-b5780bc4-cruise-control is ready
2022-04-02 14:41:16 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-b5780bc4-cruise-control rolling update finished
2022-04-02 14:41:16 [main] [32mINFO [m [SecurityST:308] Checking the certificates have been replaced
2022-04-02 14:41:16 [main] [32mINFO [m [SecurityST:322] Checking consumed messages to pod:my-cluster-b5780bc4-kafka-clients-645f744888-cg8ms
2022-04-02 14:41:16 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@5317ea43, messages=[], arguments=[--max-messages, 100, --group-instance-id, instance1996284469, --group-id, my-consumer-group-1628608420, --topic, my-topic-766085535-1811801127, --bootstrap-server, my-cluster-b5780bc4-kafka-bootstrap.namespace-61.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-b5780bc4-kafka-clients-645f744888-cg8ms', podNamespace='namespace-61', bootstrapServer='my-cluster-b5780bc4-kafka-bootstrap.namespace-61.svc:9092', topicName='my-topic-766085535-1811801127', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1628608420', consumerInstanceId='instance1996284469', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@f47a2d3}
2022-04-02 14:41:16 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-b5780bc4-kafka-bootstrap.namespace-61.svc:9092#my-topic-766085535-1811801127 from pod my-cluster-b5780bc4-kafka-clients-645f744888-cg8ms
2022-04-02 14:41:16 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b5780bc4-kafka-clients-645f744888-cg8ms -n namespace-61 -- /opt/kafka/consumer.sh --max-messages 100 --group-instance-id instance1996284469 --group-id my-consumer-group-1628608420 --topic my-topic-766085535-1811801127 --bootstrap-server my-cluster-b5780bc4-kafka-bootstrap.namespace-61.svc:9092
2022-04-02 14:41:22 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-02 14:41:22 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-02 14:41:22 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser bob-my-cluster-b5780bc4 in namespace namespace-61
2022-04-02 14:41:22 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-61
2022-04-02 14:41:22 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: bob-my-cluster-b5780bc4 will have desired state: Ready
2022-04-02 14:41:23 [main] [32mINFO [m [ResourceManager:444] KafkaUser: bob-my-cluster-b5780bc4 is in desired state: Ready
2022-04-02 14:41:23 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-b5780bc4-kafka-clients-tls in namespace namespace-61
2022-04-02 14:41:23 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-61
2022-04-02 14:41:23 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-b5780bc4-kafka-clients-tls will be ready
2022-04-02 14:41:25 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-b5780bc4-kafka-clients-tls is ready
2022-04-02 14:41:25 [main] [32mINFO [m [SecurityST:346] Checking consumed messages to pod:my-cluster-b5780bc4-kafka-clients-tls-5bc8d9dd69-6t5k6
2022-04-02 14:41:25 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@561162a, messages=[], arguments=[USER=bob_my_cluster_b5780bc4, --max-messages, 100, --group-instance-id, instance1026635668, --group-id, my-consumer-group-1336672288, --topic, my-topic-766085535-1811801127, --bootstrap-server, my-cluster-b5780bc4-kafka-bootstrap.namespace-61.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-b5780bc4-kafka-clients-tls-5bc8d9dd69-6t5k6', podNamespace='namespace-61', bootstrapServer='my-cluster-b5780bc4-kafka-bootstrap.namespace-61.svc:9093', topicName='my-topic-766085535-1811801127', maxMessages=100, kafkaUsername='bob-my-cluster-b5780bc4', consumerGroupName='my-consumer-group-1336672288', consumerInstanceId='instance1026635668', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@37826b33}
2022-04-02 14:41:25 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-b5780bc4-kafka-bootstrap.namespace-61.svc:9093#my-topic-766085535-1811801127 from pod my-cluster-b5780bc4-kafka-clients-tls-5bc8d9dd69-6t5k6
2022-04-02 14:41:25 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b5780bc4-kafka-clients-tls-5bc8d9dd69-6t5k6 -n namespace-61 -- /opt/kafka/consumer.sh USER=bob_my_cluster_b5780bc4 --max-messages 100 --group-instance-id instance1026635668 --group-id my-consumer-group-1336672288 --topic my-topic-766085535-1811801127 --bootstrap-server my-cluster-b5780bc4-kafka-bootstrap.namespace-61.svc:9093
2022-04-02 14:41:31 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-02 14:41:31 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-02 14:41:31 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 14:41:31 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAutoRenewAllCaCertsTriggeredByAnno
2022-04-02 14:41:31 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-b5780bc4-kafka-clients in namespace namespace-61
2022-04-02 14:41:31 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-b5780bc4-kafka-clients-tls in namespace namespace-61
2022-04-02 14:41:31 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaUser bob-my-cluster-b5780bc4 in namespace namespace-61
2022-04-02 14:41:31 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-b5780bc4 in namespace namespace-61
2022-04-02 14:41:31 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-61, for cruise control Kafka cluster my-cluster-b5780bc4
2022-04-02 14:41:31 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-766085535-1811801127 in namespace namespace-61
2022-04-02 14:41:31 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-300417859-1004929249 in namespace namespace-61
2022-04-02 14:42:22 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 14:42:22 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-61 for test case:testAutoRenewAllCaCertsTriggeredByAnno
2022-04-02 14:42:28 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testAutoRenewAllCaCertsTriggeredByAnno-FINISHED
2022-04-02 14:42:28 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 14:42:28 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 14:42:28 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testCertRegeneratedAfterInternalCAisDeleted-STARTED
2022-04-02 14:42:28 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 14:42:28 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-62 for test case:testCertRegeneratedAfterInternalCAisDeleted
2022-04-02 14:42:28 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-62
2022-04-02 14:42:28 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-62
2022-04-02 14:42:28 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-62
2022-04-02 14:42:28 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-3793c09f in namespace namespace-62
2022-04-02 14:42:28 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-62
2022-04-02 14:42:28 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-3793c09f will have desired state: Ready
2022-04-02 14:43:34 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-3793c09f is in desired state: Ready
2022-04-02 14:43:34 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1531342345-964936225 in namespace namespace-62
2022-04-02 14:43:34 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-62
2022-04-02 14:43:34 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1531342345-964936225 will have desired state: Ready
2022-04-02 14:43:35 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1531342345-964936225 is in desired state: Ready
2022-04-02 14:43:35 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-107822864-974309566 in namespace namespace-62
2022-04-02 14:43:35 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-62
2022-04-02 14:43:35 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-107822864-974309566 will have desired state: Ready
2022-04-02 14:43:36 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-107822864-974309566 is in desired state: Ready
2022-04-02 14:43:36 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-3793c09f-kafka-clients in namespace namespace-62
2022-04-02 14:43:36 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-62
2022-04-02 14:43:36 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-3793c09f-kafka-clients will be ready
2022-04-02 14:43:38 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-3793c09f-kafka-clients is ready
2022-04-02 14:43:38 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-02 14:43:38 [main] [32mINFO [m [SecurityST:797] Verifying that secret Secret(apiVersion=v1, data={ca.crt=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, ca.p12=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, ca.password=eGNIVElJSG5uZ3JU}, immutable=null, kind=Secret, metadata=ObjectMeta(annotations={strimzi.io/ca-cert-generation=0}, clusterName=null, creationTimestamp=2022-04-02T14:42:30Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[], generateName=null, generation=null, labels={app.kubernetes.io/instance=my-cluster-3793c09f, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=strimzi, app.kubernetes.io/part-of=strimzi-my-cluster-3793c09f, strimzi.io/cluster=my-cluster-3793c09f, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testCertRegeneratedAfterInternalCAisDeleted}, managedFields=[], name=my-cluster-3793c09f-clients-ca-cert, namespace=namespace-62, ownerReferences=[OwnerReference(apiVersion=kafka.strimzi.io/v1beta2, blockOwnerDeletion=false, controller=false, kind=Kafka, name=my-cluster-3793c09f, uid=6419c24f-483e-4549-bbad-8254d46341b8, additionalProperties={})], resourceVersion=372660, selfLink=/api/v1/namespaces/namespace-62/secrets/my-cluster-3793c09f-clients-ca-cert, uid=6296d75b-e0b0-4a09-b13d-837960fb602c, additionalProperties={}), stringData=null, type=Opaque, additionalProperties={}) with name my-cluster-3793c09f-clients-ca-cert is present
2022-04-02 14:43:38 [main] [32mINFO [m [SecurityST:797] Verifying that secret Secret(apiVersion=v1, data={ca.crt=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, ca.p12=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, ca.password=RG5hSjdXTWYzRzNs}, immutable=null, kind=Secret, metadata=ObjectMeta(annotations={strimzi.io/ca-cert-generation=0}, clusterName=null, creationTimestamp=2022-04-02T14:42:30Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[], generateName=null, generation=null, labels={app.kubernetes.io/instance=my-cluster-3793c09f, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=strimzi, app.kubernetes.io/part-of=strimzi-my-cluster-3793c09f, strimzi.io/cluster=my-cluster-3793c09f, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testCertRegeneratedAfterInternalCAisDeleted}, managedFields=[], name=my-cluster-3793c09f-cluster-ca-cert, namespace=namespace-62, ownerReferences=[OwnerReference(apiVersion=kafka.strimzi.io/v1beta2, blockOwnerDeletion=false, controller=false, kind=Kafka, name=my-cluster-3793c09f, uid=6419c24f-483e-4549-bbad-8254d46341b8, additionalProperties={})], resourceVersion=372659, selfLink=/api/v1/namespaces/namespace-62/secrets/my-cluster-3793c09f-cluster-ca-cert, uid=553f42aa-57c4-4b5f-bbd2-7112f9a425ba, additionalProperties={}), stringData=null, type=Opaque, additionalProperties={}) with name my-cluster-3793c09f-cluster-ca-cert is present
2022-04-02 14:43:38 [main] [32mINFO [m [SecurityST:802] Deleting secret my-cluster-3793c09f-clients-ca-cert
2022-04-02 14:43:38 [main] [32mINFO [m [SecurityST:802] Deleting secret my-cluster-3793c09f-cluster-ca-cert
2022-04-02 14:43:38 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-3793c09f-kafka are stable
2022-04-02 14:43:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-02 14:43:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-02 14:43:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-02 14:43:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-clients-5875cc79bd-4z2qp is in the Running state. Remaining seconds pod to be stable 50
2022-04-02 14:43:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-02 14:43:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-02 14:43:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-02 14:43:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-clients-5875cc79bd-4z2qp is in the Running state. Remaining seconds pod to be stable 49
2022-04-02 14:43:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-02 14:43:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-02 14:43:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-02 14:43:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-clients-5875cc79bd-4z2qp is in the Running state. Remaining seconds pod to be stable 48
2022-04-02 14:43:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-02 14:43:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-02 14:43:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-02 14:43:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-clients-5875cc79bd-4z2qp is in the Running state. Remaining seconds pod to be stable 47
2022-04-02 14:43:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-02 14:43:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-02 14:43:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-02 14:43:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-clients-5875cc79bd-4z2qp is in the Running state. Remaining seconds pod to be stable 46
2022-04-02 14:43:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-02 14:43:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-02 14:43:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-02 14:43:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-clients-5875cc79bd-4z2qp is in the Running state. Remaining seconds pod to be stable 45
2022-04-02 14:43:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-02 14:43:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-02 14:43:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-02 14:43:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-clients-5875cc79bd-4z2qp is in the Running state. Remaining seconds pod to be stable 44
2022-04-02 14:43:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-02 14:43:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-02 14:43:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-02 14:43:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-clients-5875cc79bd-4z2qp is in the Running state. Remaining seconds pod to be stable 43
2022-04-02 14:43:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-02 14:43:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-02 14:43:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-02 14:43:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-clients-5875cc79bd-4z2qp is in the Running state. Remaining seconds pod to be stable 42
2022-04-02 14:43:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-02 14:43:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-02 14:43:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-02 14:43:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-clients-5875cc79bd-4z2qp is in the Running state. Remaining seconds pod to be stable 41
2022-04-02 14:43:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-02 14:43:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-02 14:43:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-02 14:43:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-clients-5875cc79bd-4z2qp is in the Running state. Remaining seconds pod to be stable 40
2022-04-02 14:43:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-02 14:43:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-02 14:43:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-02 14:43:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-clients-5875cc79bd-4z2qp is in the Running state. Remaining seconds pod to be stable 39
2022-04-02 14:43:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-02 14:43:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-02 14:43:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-02 14:43:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-clients-5875cc79bd-4z2qp is in the Running state. Remaining seconds pod to be stable 38
2022-04-02 14:43:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-02 14:43:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-02 14:43:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-02 14:43:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-clients-5875cc79bd-4z2qp is in the Running state. Remaining seconds pod to be stable 37
2022-04-02 14:43:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-02 14:43:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-02 14:43:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-02 14:43:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-clients-5875cc79bd-4z2qp is in the Running state. Remaining seconds pod to be stable 36
2022-04-02 14:43:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-02 14:43:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-02 14:43:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-02 14:43:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-clients-5875cc79bd-4z2qp is in the Running state. Remaining seconds pod to be stable 35
2022-04-02 14:43:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-02 14:43:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-02 14:43:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-02 14:43:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-clients-5875cc79bd-4z2qp is in the Running state. Remaining seconds pod to be stable 34
2022-04-02 14:43:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-02 14:43:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-02 14:43:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-02 14:43:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-clients-5875cc79bd-4z2qp is in the Running state. Remaining seconds pod to be stable 33
2022-04-02 14:43:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-02 14:43:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-02 14:43:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-02 14:43:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-clients-5875cc79bd-4z2qp is in the Running state. Remaining seconds pod to be stable 32
2022-04-02 14:43:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-02 14:43:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-02 14:43:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-02 14:43:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-clients-5875cc79bd-4z2qp is in the Running state. Remaining seconds pod to be stable 31
2022-04-02 14:43:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-02 14:43:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-02 14:43:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-02 14:43:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-clients-5875cc79bd-4z2qp is in the Running state. Remaining seconds pod to be stable 30
2022-04-02 14:43:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-02 14:43:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-02 14:43:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-02 14:43:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-clients-5875cc79bd-4z2qp is in the Running state. Remaining seconds pod to be stable 29
2022-04-02 14:44:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-02 14:44:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-02 14:44:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-02 14:44:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-clients-5875cc79bd-4z2qp is in the Running state. Remaining seconds pod to be stable 28
2022-04-02 14:44:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-02 14:44:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-02 14:44:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-02 14:44:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-clients-5875cc79bd-4z2qp is in the Running state. Remaining seconds pod to be stable 27
2022-04-02 14:44:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-02 14:44:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-02 14:44:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-02 14:44:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-clients-5875cc79bd-4z2qp is in the Running state. Remaining seconds pod to be stable 26
2022-04-02 14:44:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-02 14:44:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-02 14:44:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-02 14:44:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-clients-5875cc79bd-4z2qp is in the Running state. Remaining seconds pod to be stable 25
2022-04-02 14:44:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-02 14:44:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-02 14:44:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-02 14:44:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-clients-5875cc79bd-4z2qp is in the Running state. Remaining seconds pod to be stable 24
2022-04-02 14:44:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-02 14:44:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-02 14:44:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-02 14:44:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-clients-5875cc79bd-4z2qp is in the Running state. Remaining seconds pod to be stable 23
2022-04-02 14:44:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-02 14:44:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-02 14:44:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-02 14:44:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-clients-5875cc79bd-4z2qp is in the Running state. Remaining seconds pod to be stable 22
2022-04-02 14:44:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-02 14:44:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-02 14:44:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-02 14:44:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-clients-5875cc79bd-4z2qp is in the Running state. Remaining seconds pod to be stable 21
2022-04-02 14:44:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-02 14:44:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-02 14:44:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-02 14:44:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-clients-5875cc79bd-4z2qp is in the Running state. Remaining seconds pod to be stable 20
2022-04-02 14:44:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-02 14:44:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-02 14:44:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-02 14:44:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-clients-5875cc79bd-4z2qp is in the Running state. Remaining seconds pod to be stable 19
2022-04-02 14:44:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-02 14:44:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-02 14:44:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-02 14:44:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-clients-5875cc79bd-4z2qp is in the Running state. Remaining seconds pod to be stable 18
2022-04-02 14:44:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-02 14:44:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-02 14:44:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-02 14:44:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-clients-5875cc79bd-4z2qp is in the Running state. Remaining seconds pod to be stable 17
2022-04-02 14:44:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-02 14:44:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-02 14:44:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-02 14:44:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-clients-5875cc79bd-4z2qp is in the Running state. Remaining seconds pod to be stable 16
2022-04-02 14:44:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-02 14:44:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-02 14:44:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-02 14:44:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-clients-5875cc79bd-4z2qp is in the Running state. Remaining seconds pod to be stable 15
2022-04-02 14:44:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-02 14:44:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-02 14:44:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-02 14:44:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-clients-5875cc79bd-4z2qp is in the Running state. Remaining seconds pod to be stable 14
2022-04-02 14:44:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-02 14:44:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-02 14:44:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-02 14:44:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-clients-5875cc79bd-4z2qp is in the Running state. Remaining seconds pod to be stable 13
2022-04-02 14:44:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-02 14:44:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-02 14:44:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-02 14:44:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-clients-5875cc79bd-4z2qp is in the Running state. Remaining seconds pod to be stable 12
2022-04-02 14:44:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-02 14:44:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-02 14:44:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-02 14:44:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-clients-5875cc79bd-4z2qp is in the Running state. Remaining seconds pod to be stable 11
2022-04-02 14:44:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-02 14:44:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-02 14:44:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-02 14:44:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-clients-5875cc79bd-4z2qp is in the Running state. Remaining seconds pod to be stable 10
2022-04-02 14:44:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-02 14:44:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-02 14:44:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-02 14:44:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-clients-5875cc79bd-4z2qp is in the Running state. Remaining seconds pod to be stable 9
2022-04-02 14:44:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-02 14:44:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-02 14:44:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-02 14:44:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-clients-5875cc79bd-4z2qp is in the Running state. Remaining seconds pod to be stable 8
2022-04-02 14:44:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-02 14:44:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-02 14:44:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-02 14:44:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-clients-5875cc79bd-4z2qp is in the Running state. Remaining seconds pod to be stable 7
2022-04-02 14:44:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-02 14:44:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-02 14:44:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-02 14:44:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-clients-5875cc79bd-4z2qp is in the Running state. Remaining seconds pod to be stable 6
2022-04-02 14:44:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-02 14:44:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-02 14:44:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-02 14:44:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-clients-5875cc79bd-4z2qp is in the Running state. Remaining seconds pod to be stable 5
2022-04-02 14:44:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-02 14:44:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-02 14:44:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-02 14:44:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-clients-5875cc79bd-4z2qp is in the Running state. Remaining seconds pod to be stable 4
2022-04-02 14:44:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-02 14:44:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-02 14:44:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-02 14:44:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-clients-5875cc79bd-4z2qp is in the Running state. Remaining seconds pod to be stable 3
2022-04-02 14:44:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-02 14:44:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-02 14:44:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-02 14:44:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-clients-5875cc79bd-4z2qp is in the Running state. Remaining seconds pod to be stable 2
2022-04-02 14:44:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-02 14:44:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-02 14:44:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-02 14:44:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3793c09f-kafka-clients-5875cc79bd-4z2qp is in the Running state. Remaining seconds pod to be stable 1
2022-04-02 14:44:27 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-3793c09f-kafka-0 ,my-cluster-3793c09f-kafka-1 ,my-cluster-3793c09f-kafka-2 ,my-cluster-3793c09f-kafka-clients-5875cc79bd-4z2qp
2022-04-02 14:44:27 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-3793c09f-kafka rolling update
2022-04-02 14:45:22 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-3793c09f-kafka has been successfully rolled
2022-04-02 14:45:22 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-3793c09f-kafka to be ready
2022-04-02 14:45:51 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-3793c09f will have desired state: Ready
2022-04-02 14:45:51 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-3793c09f is in desired state: Ready
2022-04-02 14:45:51 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-3793c09f is ready
2022-04-02 14:45:51 [main] [32mINFO [m [SecretUtils:46] Waiting for Secret my-cluster-3793c09f-clients-ca-cert
2022-04-02 14:45:51 [main] [32mINFO [m [SecretUtils:50] Secret my-cluster-3793c09f-clients-ca-cert created
2022-04-02 14:45:51 [main] [32mINFO [m [SecretUtils:46] Waiting for Secret my-cluster-3793c09f-cluster-ca-cert
2022-04-02 14:45:51 [main] [32mINFO [m [SecretUtils:50] Secret my-cluster-3793c09f-cluster-ca-cert created
2022-04-02 14:45:51 [main] [32mINFO [m [SecurityST:821] Checking consumed messages to pod:my-cluster-3793c09f-kafka-clients-5875cc79bd-4z2qp
2022-04-02 14:45:51 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@1dc09433, messages=[], arguments=[USER=my_user_1531342345_964936225, --max-messages, 100, --topic, my-topic-107822864-974309566, --bootstrap-server, my-cluster-3793c09f-kafka-bootstrap.namespace-62.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-3793c09f-kafka-clients-5875cc79bd-4z2qp', podNamespace='namespace-62', bootstrapServer='my-cluster-3793c09f-kafka-bootstrap.namespace-62.svc:9093', topicName='my-topic-107822864-974309566', maxMessages=100, kafkaUsername='my-user-1531342345-964936225', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3c74850f}
2022-04-02 14:45:51 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-3793c09f-kafka-bootstrap.namespace-62.svc:9093:my-topic-107822864-974309566 from pod my-cluster-3793c09f-kafka-clients-5875cc79bd-4z2qp
2022-04-02 14:45:51 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-3793c09f-kafka-clients-5875cc79bd-4z2qp -n namespace-62 -- /opt/kafka/producer.sh USER=my_user_1531342345_964936225 --max-messages 100 --topic my-topic-107822864-974309566 --bootstrap-server my-cluster-3793c09f-kafka-bootstrap.namespace-62.svc:9093
2022-04-02 14:45:55 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-02 14:45:55 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-02 14:45:55 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@189a2d68, messages=[], arguments=[USER=my_user_1531342345_964936225, --max-messages, 100, --group-instance-id, instance296307541, --group-id, my-consumer-group-1392569745, --topic, my-topic-107822864-974309566, --bootstrap-server, my-cluster-3793c09f-kafka-bootstrap.namespace-62.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-3793c09f-kafka-clients-5875cc79bd-4z2qp', podNamespace='namespace-62', bootstrapServer='my-cluster-3793c09f-kafka-bootstrap.namespace-62.svc:9093', topicName='my-topic-107822864-974309566', maxMessages=100, kafkaUsername='my-user-1531342345-964936225', consumerGroupName='my-consumer-group-1392569745', consumerInstanceId='instance296307541', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@de8c81}
2022-04-02 14:45:55 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-3793c09f-kafka-bootstrap.namespace-62.svc:9093:my-topic-107822864-974309566 from pod my-cluster-3793c09f-kafka-clients-5875cc79bd-4z2qp
2022-04-02 14:45:55 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-3793c09f-kafka-clients-5875cc79bd-4z2qp -n namespace-62 -- /opt/kafka/consumer.sh USER=my_user_1531342345_964936225 --max-messages 100 --group-instance-id instance296307541 --group-id my-consumer-group-1392569745 --topic my-topic-107822864-974309566 --bootstrap-server my-cluster-3793c09f-kafka-bootstrap.namespace-62.svc:9093
2022-04-02 14:46:02 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-02 14:46:02 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-02 14:46:02 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 14:46:02 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCertRegeneratedAfterInternalCAisDeleted
2022-04-02 14:46:02 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-107822864-974309566 in namespace namespace-62
2022-04-02 14:46:02 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1531342345-964936225 in namespace namespace-62
2022-04-02 14:46:02 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-3793c09f-kafka-clients in namespace namespace-62
2022-04-02 14:46:02 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-3793c09f in namespace namespace-62
2022-04-02 14:46:52 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 14:46:52 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-62 for test case:testCertRegeneratedAfterInternalCAisDeleted
2022-04-02 14:46:58 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testCertRegeneratedAfterInternalCAisDeleted-FINISHED
2022-04-02 14:46:58 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 14:46:58 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 14:46:58 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testKafkaAndKafkaConnectCipherSuites-STARTED
2022-04-02 14:46:58 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 14:46:58 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-63 for test case:testKafkaAndKafkaConnectCipherSuites
2022-04-02 14:46:58 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-63
2022-04-02 14:46:58 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-63
2022-04-02 14:46:58 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-63
2022-04-02 14:46:58 [main] [32mINFO [m [SecurityST:1362] Deploying Kafka cluster with the support TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 cipher algorithms
2022-04-02 14:46:58 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-1d1add32 in namespace namespace-63
2022-04-02 14:46:58 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-63
2022-04-02 14:46:58 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-1d1add32 will have desired state: Ready
2022-04-02 14:48:23 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-1d1add32 is in desired state: Ready
2022-04-02 14:48:23 [main] [32mINFO [m [SecurityST:1374] Verifying that Kafka Connect has the accepted configuration:
 ssl.cipher.suites -> TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384
2022-04-02 14:48:23 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-1d1add32-kafka-clients in namespace namespace-63
2022-04-02 14:48:23 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-63
2022-04-02 14:48:23 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-1d1add32-kafka-clients will be ready
2022-04-02 14:48:25 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-1d1add32-kafka-clients is ready
2022-04-02 14:48:25 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-1d1add32-scraper in namespace namespace-63
2022-04-02 14:48:25 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-63
2022-04-02 14:48:25 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-1d1add32-scraper will be ready
2022-04-02 14:48:27 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-1d1add32-scraper is ready
2022-04-02 14:48:27 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-1d1add32-scraper to be ready
2022-04-02 14:48:37 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-1d1add32-scraper is ready
2022-04-02 14:48:37 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-1d1add32-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-02 14:48:37 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-1d1add32-allow in namespace namespace-63
2022-04-02 14:48:37 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-63
2022-04-02 14:48:37 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-02 14:48:37 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-1d1add32 in namespace namespace-63
2022-04-02 14:48:37 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-63
2022-04-02 14:48:37 [main] [32mINFO [m [SecurityST:1391] Verifying that Kafka Connect status is NotReady because of different cipher suites complexity of algorithm
2022-04-02 14:48:37 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-1d1add32 will have desired state: NotReady
2022-04-02 14:53:39 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-1d1add32 is in desired state: NotReady
2022-04-02 14:53:39 [main] [32mINFO [m [SecurityST:1395] Replacing Kafka Connect config to the cipher suites same as the Kafka broker has.
2022-04-02 14:53:39 [main] [32mINFO [m [SecurityST:1399] Verifying that Kafka Connect has the accepted configuration:
 ssl.cipher.suites -> TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384
2022-04-02 14:53:39 [main] [32mINFO [m [KafkaConnectUtils:101] Waiting for Kafka Connect property ssl.cipher.suites -> TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 change
2022-04-02 14:53:39 [main] [32mINFO [m [KafkaConnectUtils:109] Kafka Connect property ssl.cipher.suites -> TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 change
2022-04-02 14:53:39 [main] [32mINFO [m [SecurityST:1404] Verifying that Kafka Connect is stable
2022-04-02 14:53:39 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-1d1add32-connect are stable
2022-04-02 14:53:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1d1add32-connect-85f5f69db-8x4fm is in the Running state. Remaining seconds pod to be stable 50
2022-04-02 14:53:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1d1add32-connect-85f5f69db-8x4fm is in the Running state. Remaining seconds pod to be stable 49
2022-04-02 14:53:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1d1add32-connect-85f5f69db-8x4fm is in the Running state. Remaining seconds pod to be stable 48
2022-04-02 14:53:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1d1add32-connect-85f5f69db-8x4fm is in the Running state. Remaining seconds pod to be stable 47
2022-04-02 14:53:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1d1add32-connect-85f5f69db-8x4fm is in the Running state. Remaining seconds pod to be stable 46
2022-04-02 14:53:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1d1add32-connect-85f5f69db-8x4fm is in the Running state. Remaining seconds pod to be stable 45
2022-04-02 14:53:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1d1add32-connect-85f5f69db-8x4fm is in the Running state. Remaining seconds pod to be stable 44
2022-04-02 14:53:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1d1add32-connect-85f5f69db-8x4fm is in the Running state. Remaining seconds pod to be stable 43
2022-04-02 14:53:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1d1add32-connect-85f5f69db-8x4fm is in the Running state. Remaining seconds pod to be stable 42
2022-04-02 14:53:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1d1add32-connect-85f5f69db-8x4fm is in the Running state. Remaining seconds pod to be stable 41
2022-04-02 14:53:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1d1add32-connect-85f5f69db-8x4fm is in the Running state. Remaining seconds pod to be stable 40
2022-04-02 14:53:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1d1add32-connect-85f5f69db-8x4fm is in the Running state. Remaining seconds pod to be stable 39
2022-04-02 14:53:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1d1add32-connect-85f5f69db-8x4fm is in the Running state. Remaining seconds pod to be stable 38
2022-04-02 14:53:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1d1add32-connect-85f5f69db-8x4fm is in the Running state. Remaining seconds pod to be stable 37
2022-04-02 14:53:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1d1add32-connect-85f5f69db-8x4fm is in the Running state. Remaining seconds pod to be stable 36
2022-04-02 14:53:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1d1add32-connect-85f5f69db-8x4fm is in the Running state. Remaining seconds pod to be stable 35
2022-04-02 14:53:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1d1add32-connect-85f5f69db-8x4fm is in the Running state. Remaining seconds pod to be stable 34
2022-04-02 14:53:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1d1add32-connect-85f5f69db-8x4fm is in the Running state. Remaining seconds pod to be stable 33
2022-04-02 14:53:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1d1add32-connect-85f5f69db-8x4fm is in the Running state. Remaining seconds pod to be stable 32
2022-04-02 14:53:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1d1add32-connect-85f5f69db-8x4fm is in the Running state. Remaining seconds pod to be stable 31
2022-04-02 14:53:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1d1add32-connect-85f5f69db-8x4fm is in the Running state. Remaining seconds pod to be stable 30
2022-04-02 14:54:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1d1add32-connect-85f5f69db-8x4fm is in the Running state. Remaining seconds pod to be stable 29
2022-04-02 14:54:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1d1add32-connect-85f5f69db-8x4fm is in the Running state. Remaining seconds pod to be stable 28
2022-04-02 14:54:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1d1add32-connect-85f5f69db-8x4fm is in the Running state. Remaining seconds pod to be stable 27
2022-04-02 14:54:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1d1add32-connect-85f5f69db-8x4fm is in the Running state. Remaining seconds pod to be stable 26
2022-04-02 14:54:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1d1add32-connect-85f5f69db-8x4fm is in the Running state. Remaining seconds pod to be stable 25
2022-04-02 14:54:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1d1add32-connect-85f5f69db-8x4fm is in the Running state. Remaining seconds pod to be stable 24
2022-04-02 14:54:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1d1add32-connect-85f5f69db-8x4fm is in the Running state. Remaining seconds pod to be stable 23
2022-04-02 14:54:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1d1add32-connect-85f5f69db-8x4fm is in the Running state. Remaining seconds pod to be stable 22
2022-04-02 14:54:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1d1add32-connect-85f5f69db-8x4fm is in the Running state. Remaining seconds pod to be stable 21
2022-04-02 14:54:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1d1add32-connect-85f5f69db-8x4fm is in the Running state. Remaining seconds pod to be stable 20
2022-04-02 14:54:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1d1add32-connect-85f5f69db-8x4fm is in the Running state. Remaining seconds pod to be stable 19
2022-04-02 14:54:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1d1add32-connect-85f5f69db-8x4fm is in the Running state. Remaining seconds pod to be stable 18
2022-04-02 14:54:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1d1add32-connect-85f5f69db-8x4fm is in the Running state. Remaining seconds pod to be stable 17
2022-04-02 14:54:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1d1add32-connect-85f5f69db-8x4fm is in the Running state. Remaining seconds pod to be stable 16
2022-04-02 14:54:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1d1add32-connect-85f5f69db-8x4fm is in the Running state. Remaining seconds pod to be stable 15
2022-04-02 14:54:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1d1add32-connect-85f5f69db-8x4fm is in the Running state. Remaining seconds pod to be stable 14
2022-04-02 14:54:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1d1add32-connect-85f5f69db-8x4fm is in the Running state. Remaining seconds pod to be stable 13
2022-04-02 14:54:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1d1add32-connect-85f5f69db-8x4fm is in the Running state. Remaining seconds pod to be stable 12
2022-04-02 14:54:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1d1add32-connect-85f5f69db-8x4fm is in the Running state. Remaining seconds pod to be stable 11
2022-04-02 14:54:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1d1add32-connect-85f5f69db-8x4fm is in the Running state. Remaining seconds pod to be stable 10
2022-04-02 14:54:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1d1add32-connect-85f5f69db-8x4fm is in the Running state. Remaining seconds pod to be stable 9
2022-04-02 14:54:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1d1add32-connect-85f5f69db-8x4fm is in the Running state. Remaining seconds pod to be stable 8
2022-04-02 14:54:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1d1add32-connect-85f5f69db-8x4fm is in the Running state. Remaining seconds pod to be stable 7
2022-04-02 14:54:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1d1add32-connect-85f5f69db-8x4fm is in the Running state. Remaining seconds pod to be stable 6
2022-04-02 14:54:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1d1add32-connect-85f5f69db-8x4fm is in the Running state. Remaining seconds pod to be stable 5
2022-04-02 14:54:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1d1add32-connect-85f5f69db-8x4fm is in the Running state. Remaining seconds pod to be stable 4
2022-04-02 14:54:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1d1add32-connect-85f5f69db-8x4fm is in the Running state. Remaining seconds pod to be stable 3
2022-04-02 14:54:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1d1add32-connect-85f5f69db-8x4fm is in the Running state. Remaining seconds pod to be stable 2
2022-04-02 14:54:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1d1add32-connect-85f5f69db-8x4fm is in the Running state. Remaining seconds pod to be stable 1
2022-04-02 14:54:28 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-1d1add32-connect-85f5f69db-8x4fm
2022-04-02 14:54:28 [main] [32mINFO [m [SecurityST:1408] Verifying that Kafka Connect status is Ready because of the same cipher suites complexity of algorithm
2022-04-02 14:54:28 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-1d1add32 will have desired state: Ready
2022-04-02 14:59:58 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-1d1add32 is in desired state: Ready
2022-04-02 14:59:58 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 14:59:58 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaAndKafkaConnectCipherSuites
2022-04-02 14:59:58 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-1d1add32-scraper in namespace namespace-63
2022-04-02 14:59:58 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-1d1add32-kafka-clients in namespace namespace-63
2022-04-02 14:59:58 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-1d1add32 in namespace namespace-63
2022-04-02 14:59:58 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-1d1add32-allow in namespace namespace-63
2022-04-02 14:59:58 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-1d1add32 in namespace namespace-63
2022-04-02 15:00:48 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 15:00:48 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-63 for test case:testKafkaAndKafkaConnectCipherSuites
2022-04-02 15:00:54 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testKafkaAndKafkaConnectCipherSuites-FINISHED
2022-04-02 15:00:54 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 15:00:54 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 15:00:54 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testCertRenewalInMaintenanceWindow-STARTED
2022-04-02 15:00:54 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 15:00:54 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-64 for test case:testCertRenewalInMaintenanceWindow
2022-04-02 15:00:54 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-64
2022-04-02 15:00:54 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-64
2022-04-02 15:00:54 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-64
2022-04-02 15:00:54 [main] [32mINFO [m [SecurityST:698] Maintenance window is: * 5-19 * * * ? *
2022-04-02 15:00:54 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-c8d3c191 in namespace namespace-64
2022-04-02 15:00:54 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-64
2022-04-02 15:00:54 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-c8d3c191 will have desired state: Ready
2022-04-02 15:02:12 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-c8d3c191 is in desired state: Ready
2022-04-02 15:02:12 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1013248303-1657583745 in namespace namespace-64
2022-04-02 15:02:12 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-64
2022-04-02 15:02:12 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1013248303-1657583745 will have desired state: Ready
2022-04-02 15:02:13 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1013248303-1657583745 is in desired state: Ready
2022-04-02 15:02:13 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1234009655-794567637 in namespace namespace-64
2022-04-02 15:02:13 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-64
2022-04-02 15:02:13 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1234009655-794567637 will have desired state: Ready
2022-04-02 15:02:14 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1234009655-794567637 is in desired state: Ready
2022-04-02 15:02:14 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1234009655-794567637 in namespace namespace-64
2022-04-02 15:02:14 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-64
2022-04-02 15:02:14 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1234009655-794567637 will have desired state: Ready
2022-04-02 15:02:14 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1234009655-794567637 is in desired state: Ready
2022-04-02 15:02:14 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-c8d3c191-kafka-clients in namespace namespace-64
2022-04-02 15:02:14 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-64
2022-04-02 15:02:14 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-c8d3c191-kafka-clients will be ready
2022-04-02 15:02:16 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-c8d3c191-kafka-clients is ready
2022-04-02 15:02:16 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-02 15:02:16 [main] [32mINFO [m [SecurityST:728] Annotate secret my-cluster-c8d3c191-cluster-ca-cert with secret force-renew annotation
2022-04-02 15:02:16 [main] [32mINFO [m [SecurityST:735] Wait until maintenance windows starts
2022-04-02 15:05:00 [main] [32mINFO [m [SecurityST:741] Maintenance window starts
2022-04-02 15:05:00 [main] [32mINFO [m [SecurityST:745] Wait until rolling update is triggered during maintenance window
2022-04-02 15:05:00 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-c8d3c191-kafka rolling update
2022-04-02 15:07:15 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-c8d3c191-kafka has been successfully rolled
2022-04-02 15:07:15 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-c8d3c191-kafka to be ready
2022-04-02 15:07:47 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-c8d3c191 will have desired state: Ready
2022-04-02 15:07:47 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-c8d3c191 is in desired state: Ready
2022-04-02 15:07:47 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-c8d3c191 is ready
2022-04-02 15:07:47 [main] [32mINFO [m [SecurityST:750] Checking consumed messages to pod:my-cluster-c8d3c191-kafka-clients-849775cd79-xlkpx
2022-04-02 15:07:47 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@321506f3, messages=[], arguments=[USER=my_user_1013248303_1657583745, --max-messages, 100, --topic, my-topic-1234009655-794567637, --bootstrap-server, my-cluster-c8d3c191-kafka-bootstrap.namespace-64.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-c8d3c191-kafka-clients-849775cd79-xlkpx', podNamespace='namespace-64', bootstrapServer='my-cluster-c8d3c191-kafka-bootstrap.namespace-64.svc:9093', topicName='my-topic-1234009655-794567637', maxMessages=100, kafkaUsername='my-user-1013248303-1657583745', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1b8b568e}
2022-04-02 15:07:47 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-c8d3c191-kafka-bootstrap.namespace-64.svc:9093:my-topic-1234009655-794567637 from pod my-cluster-c8d3c191-kafka-clients-849775cd79-xlkpx
2022-04-02 15:07:47 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-c8d3c191-kafka-clients-849775cd79-xlkpx -n namespace-64 -- /opt/kafka/producer.sh USER=my_user_1013248303_1657583745 --max-messages 100 --topic my-topic-1234009655-794567637 --bootstrap-server my-cluster-c8d3c191-kafka-bootstrap.namespace-64.svc:9093
2022-04-02 15:07:51 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-02 15:07:51 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-02 15:07:51 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@cce8438, messages=[], arguments=[USER=my_user_1013248303_1657583745, --max-messages, 100, --group-instance-id, instance1006593739, --group-id, my-consumer-group-205991937, --topic, my-topic-1234009655-794567637, --bootstrap-server, my-cluster-c8d3c191-kafka-bootstrap.namespace-64.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-c8d3c191-kafka-clients-849775cd79-xlkpx', podNamespace='namespace-64', bootstrapServer='my-cluster-c8d3c191-kafka-bootstrap.namespace-64.svc:9093', topicName='my-topic-1234009655-794567637', maxMessages=100, kafkaUsername='my-user-1013248303-1657583745', consumerGroupName='my-consumer-group-205991937', consumerInstanceId='instance1006593739', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@4db08426}
2022-04-02 15:07:51 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-c8d3c191-kafka-bootstrap.namespace-64.svc:9093:my-topic-1234009655-794567637 from pod my-cluster-c8d3c191-kafka-clients-849775cd79-xlkpx
2022-04-02 15:07:51 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-c8d3c191-kafka-clients-849775cd79-xlkpx -n namespace-64 -- /opt/kafka/consumer.sh USER=my_user_1013248303_1657583745 --max-messages 100 --group-instance-id instance1006593739 --group-id my-consumer-group-205991937 --topic my-topic-1234009655-794567637 --bootstrap-server my-cluster-c8d3c191-kafka-bootstrap.namespace-64.svc:9093
2022-04-02 15:07:58 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-02 15:07:59 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-02 15:07:59 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 15:07:59 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCertRenewalInMaintenanceWindow
2022-04-02 15:07:59 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1234009655-794567637 in namespace namespace-64
2022-04-02 15:07:59 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-c8d3c191 in namespace namespace-64
2022-04-02 15:07:59 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1013248303-1657583745 in namespace namespace-64
2022-04-02 15:07:59 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1234009655-794567637 in namespace namespace-64
2022-04-02 15:07:59 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-c8d3c191-kafka-clients in namespace namespace-64
2022-04-02 15:08:49 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 15:08:49 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-64 for test case:testCertRenewalInMaintenanceWindow
2022-04-02 15:08:54 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testCertRenewalInMaintenanceWindow-FINISHED
2022-04-02 15:08:54 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 15:08:54 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 15:08:54 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testOwnerReferenceOfCASecrets-STARTED
2022-04-02 15:08:54 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 15:08:54 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-65 for test case:testOwnerReferenceOfCASecrets
2022-04-02 15:08:54 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-65
2022-04-02 15:08:54 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-65
2022-04-02 15:08:54 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-65
2022-04-02 15:08:54 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-6cd2a587 in namespace namespace-65
2022-04-02 15:08:54 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-65
2022-04-02 15:08:54 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-6cd2a587 will have desired state: Ready
2022-04-02 15:10:04 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-6cd2a587 is in desired state: Ready
2022-04-02 15:10:04 [main] [32mINFO [m [SecurityST:1432] Listing all cluster CAs for my-cluster-6cd2a587
2022-04-02 15:10:04 [main] [32mINFO [m [SecurityST:1436] Deleting Kafka:my-cluster-6cd2a587
2022-04-02 15:10:04 [main] [32mINFO [m [KafkaUtils:399] Waiting for deletion of Kafka:my-cluster-6cd2a587
2022-04-02 15:10:05 [main] [32mINFO [m [SecurityST:1440] Checking actual secrets after Kafka deletion
2022-04-02 15:10:05 [main] [32mINFO [m [SecurityST:1443] Checking that my-cluster-6cd2a587-clients-ca secret is still present
2022-04-02 15:10:05 [main] [32mINFO [m [SecurityST:1446] Deleting secret: my-cluster-6cd2a587-clients-ca
2022-04-02 15:10:05 [main] [32mINFO [m [SecurityST:1443] Checking that my-cluster-6cd2a587-clients-ca-cert secret is still present
2022-04-02 15:10:06 [main] [32mINFO [m [SecurityST:1446] Deleting secret: my-cluster-6cd2a587-clients-ca-cert
2022-04-02 15:10:06 [main] [32mINFO [m [SecurityST:1443] Checking that my-cluster-6cd2a587-cluster-ca secret is still present
2022-04-02 15:10:06 [main] [32mINFO [m [SecurityST:1446] Deleting secret: my-cluster-6cd2a587-cluster-ca
2022-04-02 15:10:06 [main] [32mINFO [m [SecurityST:1443] Checking that my-cluster-6cd2a587-cluster-ca-cert secret is still present
2022-04-02 15:10:06 [main] [32mINFO [m [SecurityST:1446] Deleting secret: my-cluster-6cd2a587-cluster-ca-cert
2022-04-02 15:10:06 [main] [32mINFO [m [SecurityST:1450] Deploying Kafka with generateSecretOwnerReference set to true
2022-04-02 15:10:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-second-cluster-my-cluster-6cd2a587 in namespace namespace-65
2022-04-02 15:10:06 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-65
2022-04-02 15:10:06 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-second-cluster-my-cluster-6cd2a587 will have desired state: Ready
2022-04-02 15:12:22 [main] [32mINFO [m [ResourceManager:444] Kafka: my-second-cluster-my-cluster-6cd2a587 is in desired state: Ready
2022-04-02 15:12:22 [main] [32mINFO [m [SecurityST:1465] Deleting Kafka:my-second-cluster-my-cluster-6cd2a587
2022-04-02 15:12:22 [main] [32mINFO [m [KafkaUtils:399] Waiting for deletion of Kafka:my-second-cluster-my-cluster-6cd2a587
2022-04-02 15:12:24 [main] [32mINFO [m [SecurityST:1469] Checking actual secrets after Kafka deletion
2022-04-02 15:12:24 [main] [32mINFO [m [SecurityST:1472] Checking that my-second-cluster-my-cluster-6cd2a587-clients-ca secret is deleted
2022-04-02 15:12:24 [main] [32mINFO [m [SecurityST:1472] Checking that my-second-cluster-my-cluster-6cd2a587-clients-ca-cert secret is deleted
2022-04-02 15:12:24 [main] [32mINFO [m [SecurityST:1472] Checking that my-second-cluster-my-cluster-6cd2a587-cluster-ca secret is deleted
2022-04-02 15:12:24 [main] [32mINFO [m [SecurityST:1472] Checking that my-second-cluster-my-cluster-6cd2a587-cluster-ca-cert secret is deleted
2022-04-02 15:12:24 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 15:12:24 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testOwnerReferenceOfCASecrets
2022-04-02 15:12:24 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-second-cluster-my-cluster-6cd2a587 in namespace namespace-65
2022-04-02 15:12:24 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-6cd2a587 in namespace namespace-65
2022-04-02 15:12:24 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 15:12:24 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-65 for test case:testOwnerReferenceOfCASecrets
2022-04-02 15:12:51 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testOwnerReferenceOfCASecrets-FINISHED
2022-04-02 15:12:51 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 15:12:51 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 15:12:51 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAutoRenewClientsCaCertsTriggeredByAnno-STARTED
2022-04-02 15:12:51 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 15:12:51 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-66 for test case:testAutoRenewClientsCaCertsTriggeredByAnno
2022-04-02 15:12:51 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-66
2022-04-02 15:12:51 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-66
2022-04-02 15:12:51 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-66
2022-04-02 15:12:51 [main] [32mINFO [m [SecurityST:587] Creating a cluster
2022-04-02 15:12:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-dc0af0ea in namespace namespace-66
2022-04-02 15:12:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-66
2022-04-02 15:12:51 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-dc0af0ea will have desired state: Ready
2022-04-02 15:15:03 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-dc0af0ea is in desired state: Ready
2022-04-02 15:15:03 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-414526568-708654837 in namespace namespace-66
2022-04-02 15:15:03 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-66
2022-04-02 15:15:03 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-414526568-708654837 will have desired state: Ready
2022-04-02 15:15:04 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-414526568-708654837 is in desired state: Ready
2022-04-02 15:15:04 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1861217636-789378741 in namespace namespace-66
2022-04-02 15:15:04 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-66
2022-04-02 15:15:04 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1861217636-789378741 will have desired state: Ready
2022-04-02 15:15:05 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1861217636-789378741 is in desired state: Ready
2022-04-02 15:15:05 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-dc0af0ea-kafka-clients in namespace namespace-66
2022-04-02 15:15:05 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-66
2022-04-02 15:15:05 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-dc0af0ea-kafka-clients will be ready
2022-04-02 15:15:07 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-dc0af0ea-kafka-clients is ready
2022-04-02 15:15:07 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-02 15:15:07 [main] [32mINFO [m [SecurityST:260] Checking produced and consumed messages to pod:my-cluster-dc0af0ea-kafka-clients-979b47dc-jm2ft
2022-04-02 15:15:07 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@1fdee3c6, messages=[], arguments=[--max-messages, 100, --topic, my-topic-1861217636-789378741, --bootstrap-server, my-cluster-dc0af0ea-kafka-bootstrap.namespace-66.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-dc0af0ea-kafka-clients-979b47dc-jm2ft', podNamespace='namespace-66', bootstrapServer='my-cluster-dc0af0ea-kafka-bootstrap.namespace-66.svc:9092', topicName='my-topic-1861217636-789378741', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@35450f4d}
2022-04-02 15:15:07 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-dc0af0ea-kafka-bootstrap.namespace-66.svc:9092:my-topic-1861217636-789378741 from pod my-cluster-dc0af0ea-kafka-clients-979b47dc-jm2ft
2022-04-02 15:15:07 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-dc0af0ea-kafka-clients-979b47dc-jm2ft -n namespace-66 -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-1861217636-789378741 --bootstrap-server my-cluster-dc0af0ea-kafka-bootstrap.namespace-66.svc:9092
2022-04-02 15:15:09 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-02 15:15:09 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-02 15:15:09 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@39d9661, messages=[], arguments=[--max-messages, 100, --group-instance-id, instance1001902002, --group-id, my-consumer-group-734196286, --topic, my-topic-1861217636-789378741, --bootstrap-server, my-cluster-dc0af0ea-kafka-bootstrap.namespace-66.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-dc0af0ea-kafka-clients-979b47dc-jm2ft', podNamespace='namespace-66', bootstrapServer='my-cluster-dc0af0ea-kafka-bootstrap.namespace-66.svc:9092', topicName='my-topic-1861217636-789378741', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-734196286', consumerInstanceId='instance1001902002', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1e3fdd8c}
2022-04-02 15:15:09 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-dc0af0ea-kafka-bootstrap.namespace-66.svc:9092#my-topic-1861217636-789378741 from pod my-cluster-dc0af0ea-kafka-clients-979b47dc-jm2ft
2022-04-02 15:15:09 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-dc0af0ea-kafka-clients-979b47dc-jm2ft -n namespace-66 -- /opt/kafka/consumer.sh --max-messages 100 --group-instance-id instance1001902002 --group-id my-consumer-group-734196286 --topic my-topic-1861217636-789378741 --bootstrap-server my-cluster-dc0af0ea-kafka-bootstrap.namespace-66.svc:9092
2022-04-02 15:15:15 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-02 15:15:15 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-02 15:15:15 [main] [32mINFO [m [SecurityST:274] Triggering CA cert renewal by adding the annotation
2022-04-02 15:15:15 [main] [32mINFO [m [SecurityST:286] Patching secret my-cluster-dc0af0ea-clients-ca-cert with strimzi.io/force-renew
2022-04-02 15:15:15 [main] [32mINFO [m [SecurityST:295] Wait for kafka to rolling restart ...
2022-04-02 15:15:15 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-dc0af0ea-kafka rolling update
2022-04-02 15:16:45 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-dc0af0ea-kafka has been successfully rolled
2022-04-02 15:16:45 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-dc0af0ea-kafka to be ready
2022-04-02 15:17:09 [main] [32mINFO [m [SecurityST:308] Checking the certificates have been replaced
2022-04-02 15:17:09 [main] [32mINFO [m [SecurityST:322] Checking consumed messages to pod:my-cluster-dc0af0ea-kafka-clients-979b47dc-jm2ft
2022-04-02 15:17:09 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@7e4acb23, messages=[], arguments=[--max-messages, 100, --group-instance-id, instance760818056, --group-id, my-consumer-group-946309123, --topic, my-topic-1861217636-789378741, --bootstrap-server, my-cluster-dc0af0ea-kafka-bootstrap.namespace-66.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-dc0af0ea-kafka-clients-979b47dc-jm2ft', podNamespace='namespace-66', bootstrapServer='my-cluster-dc0af0ea-kafka-bootstrap.namespace-66.svc:9092', topicName='my-topic-1861217636-789378741', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-946309123', consumerInstanceId='instance760818056', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@c6006eb}
2022-04-02 15:17:09 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-dc0af0ea-kafka-bootstrap.namespace-66.svc:9092#my-topic-1861217636-789378741 from pod my-cluster-dc0af0ea-kafka-clients-979b47dc-jm2ft
2022-04-02 15:17:09 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-dc0af0ea-kafka-clients-979b47dc-jm2ft -n namespace-66 -- /opt/kafka/consumer.sh --max-messages 100 --group-instance-id instance760818056 --group-id my-consumer-group-946309123 --topic my-topic-1861217636-789378741 --bootstrap-server my-cluster-dc0af0ea-kafka-bootstrap.namespace-66.svc:9092
2022-04-02 15:17:15 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-02 15:17:15 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-02 15:17:15 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser bob-my-cluster-dc0af0ea in namespace namespace-66
2022-04-02 15:17:15 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-66
2022-04-02 15:17:15 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: bob-my-cluster-dc0af0ea will have desired state: Ready
2022-04-02 15:17:16 [main] [32mINFO [m [ResourceManager:444] KafkaUser: bob-my-cluster-dc0af0ea is in desired state: Ready
2022-04-02 15:17:16 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-dc0af0ea-kafka-clients-tls in namespace namespace-66
2022-04-02 15:17:16 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-66
2022-04-02 15:17:16 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-dc0af0ea-kafka-clients-tls will be ready
2022-04-02 15:17:17 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-dc0af0ea-kafka-clients-tls is ready
2022-04-02 15:17:17 [main] [32mINFO [m [SecurityST:346] Checking consumed messages to pod:my-cluster-dc0af0ea-kafka-clients-tls-86549844b-vd68m
2022-04-02 15:17:17 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@2f318e39, messages=[], arguments=[USER=bob_my_cluster_dc0af0ea, --max-messages, 100, --group-instance-id, instance940757495, --group-id, my-consumer-group-615769597, --topic, my-topic-1861217636-789378741, --bootstrap-server, my-cluster-dc0af0ea-kafka-bootstrap.namespace-66.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-dc0af0ea-kafka-clients-tls-86549844b-vd68m', podNamespace='namespace-66', bootstrapServer='my-cluster-dc0af0ea-kafka-bootstrap.namespace-66.svc:9093', topicName='my-topic-1861217636-789378741', maxMessages=100, kafkaUsername='bob-my-cluster-dc0af0ea', consumerGroupName='my-consumer-group-615769597', consumerInstanceId='instance940757495', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@236a83e1}
2022-04-02 15:17:17 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-dc0af0ea-kafka-bootstrap.namespace-66.svc:9093#my-topic-1861217636-789378741 from pod my-cluster-dc0af0ea-kafka-clients-tls-86549844b-vd68m
2022-04-02 15:17:17 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-dc0af0ea-kafka-clients-tls-86549844b-vd68m -n namespace-66 -- /opt/kafka/consumer.sh USER=bob_my_cluster_dc0af0ea --max-messages 100 --group-instance-id instance940757495 --group-id my-consumer-group-615769597 --topic my-topic-1861217636-789378741 --bootstrap-server my-cluster-dc0af0ea-kafka-bootstrap.namespace-66.svc:9093
2022-04-02 15:17:24 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-02 15:17:24 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-02 15:17:24 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 15:17:24 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAutoRenewClientsCaCertsTriggeredByAnno
2022-04-02 15:17:24 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-dc0af0ea-kafka-clients in namespace namespace-66
2022-04-02 15:17:24 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-dc0af0ea in namespace namespace-66
2022-04-02 15:17:24 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-66, for cruise control Kafka cluster my-cluster-dc0af0ea
2022-04-02 15:17:24 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1861217636-789378741 in namespace namespace-66
2022-04-02 15:17:24 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-dc0af0ea-kafka-clients-tls in namespace namespace-66
2022-04-02 15:17:24 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaUser bob-my-cluster-dc0af0ea in namespace namespace-66
2022-04-02 15:17:24 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-414526568-708654837 in namespace namespace-66
2022-04-02 15:18:14 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 15:18:14 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-66 for test case:testAutoRenewClientsCaCertsTriggeredByAnno
2022-04-02 15:18:25 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testAutoRenewClientsCaCertsTriggeredByAnno-FINISHED
2022-04-02 15:18:25 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 15:18:25 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 15:18:25 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAutoReplaceClusterCaKeysTriggeredByAnno-STARTED
2022-04-02 15:18:25 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 15:18:25 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-67 for test case:testAutoReplaceClusterCaKeysTriggeredByAnno
2022-04-02 15:18:25 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-67
2022-04-02 15:18:25 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-67
2022-04-02 15:18:25 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-67
2022-04-02 15:18:25 [main] [32mINFO [m [SecurityST:587] Creating a cluster
2022-04-02 15:18:25 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-52004785 in namespace namespace-67
2022-04-02 15:18:25 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-67
2022-04-02 15:18:25 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-52004785 will have desired state: Ready
2022-04-02 15:21:00 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-52004785 is in desired state: Ready
2022-04-02 15:21:00 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1230845870-1268280312 in namespace namespace-67
2022-04-02 15:21:00 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-67
2022-04-02 15:21:00 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1230845870-1268280312 will have desired state: Ready
2022-04-02 15:21:01 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1230845870-1268280312 is in desired state: Ready
2022-04-02 15:21:01 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1801001323-1015896418 in namespace namespace-67
2022-04-02 15:21:01 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-67
2022-04-02 15:21:01 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1801001323-1015896418 will have desired state: Ready
2022-04-02 15:21:02 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1801001323-1015896418 is in desired state: Ready
2022-04-02 15:21:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-52004785-kafka-clients in namespace namespace-67
2022-04-02 15:21:02 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-67
2022-04-02 15:21:02 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-52004785-kafka-clients will be ready
2022-04-02 15:21:04 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-52004785-kafka-clients is ready
2022-04-02 15:21:04 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-02 15:21:04 [main] [32mINFO [m [SecurityST:453] Checking produced and consumed messages to pod:my-cluster-52004785-kafka-clients-7b97889fd5-n5xx2
2022-04-02 15:21:04 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@292117c9, messages=[], arguments=[--max-messages, 100, --topic, my-topic-1801001323-1015896418, --bootstrap-server, my-cluster-52004785-kafka-bootstrap.namespace-67.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-52004785-kafka-clients-7b97889fd5-n5xx2', podNamespace='namespace-67', bootstrapServer='my-cluster-52004785-kafka-bootstrap.namespace-67.svc:9092', topicName='my-topic-1801001323-1015896418', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@600d550b}
2022-04-02 15:21:04 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-52004785-kafka-bootstrap.namespace-67.svc:9092:my-topic-1801001323-1015896418 from pod my-cluster-52004785-kafka-clients-7b97889fd5-n5xx2
2022-04-02 15:21:04 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-52004785-kafka-clients-7b97889fd5-n5xx2 -n namespace-67 -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-1801001323-1015896418 --bootstrap-server my-cluster-52004785-kafka-bootstrap.namespace-67.svc:9092
2022-04-02 15:21:06 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-02 15:21:06 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-02 15:21:06 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@24ae19b3, messages=[], arguments=[--max-messages, 100, --group-instance-id, instance898962163, --group-id, my-consumer-group-361358610, --topic, my-topic-1801001323-1015896418, --bootstrap-server, my-cluster-52004785-kafka-bootstrap.namespace-67.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-52004785-kafka-clients-7b97889fd5-n5xx2', podNamespace='namespace-67', bootstrapServer='my-cluster-52004785-kafka-bootstrap.namespace-67.svc:9092', topicName='my-topic-1801001323-1015896418', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-361358610', consumerInstanceId='instance898962163', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@2e01a475}
2022-04-02 15:21:06 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-52004785-kafka-bootstrap.namespace-67.svc:9092#my-topic-1801001323-1015896418 from pod my-cluster-52004785-kafka-clients-7b97889fd5-n5xx2
2022-04-02 15:21:06 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-52004785-kafka-clients-7b97889fd5-n5xx2 -n namespace-67 -- /opt/kafka/consumer.sh --max-messages 100 --group-instance-id instance898962163 --group-id my-consumer-group-361358610 --topic my-topic-1801001323-1015896418 --bootstrap-server my-cluster-52004785-kafka-bootstrap.namespace-67.svc:9092
2022-04-02 15:21:12 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-02 15:21:12 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-02 15:21:12 [main] [32mINFO [m [SecurityST:467] Triggering CA cert renewal by adding the annotation
2022-04-02 15:21:12 [main] [32mINFO [m [SecurityST:479] Patching secret my-cluster-52004785-cluster-ca with strimzi.io/force-replace
2022-04-02 15:21:12 [main] [32mINFO [m [SecurityST:484] Wait for zk to rolling restart (1)...
2022-04-02 15:21:12 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-52004785-zookeeper rolling update
2022-04-02 15:22:37 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-52004785-zookeeper has been successfully rolled
2022-04-02 15:22:37 [main] [32mINFO [m [SecurityST:489] Wait for kafka to rolling restart (1)...
2022-04-02 15:22:37 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-52004785-kafka rolling update
2022-04-02 15:23:57 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-52004785-kafka has been successfully rolled
2022-04-02 15:23:57 [main] [32mINFO [m [SecurityST:494] Wait for EO to rolling restart (1)...
2022-04-02 15:23:57 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-52004785-entity-operator rolling update
2022-04-02 15:24:32 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-52004785-entity-operator will be ready
2022-04-02 15:25:52 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-52004785-entity-operator is ready
2022-04-02 15:26:02 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-52004785-entity-operator rolling update finished
2022-04-02 15:26:02 [main] [32mINFO [m [SecurityST:499] Wait for KafkaExporter and CruiseControl to rolling restart (1)...
2022-04-02 15:26:02 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-52004785-kafka-exporter rolling update
2022-04-02 15:26:02 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-52004785-kafka-exporter will be ready
2022-04-02 15:26:19 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-52004785-kafka-exporter is ready
2022-04-02 15:26:29 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-52004785-kafka-exporter rolling update finished
2022-04-02 15:26:29 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-52004785-cruise-control rolling update
2022-04-02 15:26:34 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-52004785-cruise-control will be ready
2022-04-02 15:26:40 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-52004785-cruise-control is ready
2022-04-02 15:26:50 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-52004785-cruise-control rolling update finished
2022-04-02 15:26:50 [main] [32mINFO [m [SecurityST:505] Wait for zk to rolling restart (2)...
2022-04-02 15:26:50 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-52004785-zookeeper rolling update
2022-04-02 15:27:40 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-52004785-zookeeper has been successfully rolled
2022-04-02 15:27:40 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-52004785-zookeeper to be ready
2022-04-02 15:28:07 [main] [32mINFO [m [SecurityST:510] Wait for kafka to rolling restart (2)...
2022-04-02 15:28:07 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-52004785-kafka rolling update
2022-04-02 15:29:27 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-52004785-kafka has been successfully rolled
2022-04-02 15:29:27 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-52004785-kafka to be ready
2022-04-02 15:29:50 [main] [32mINFO [m [SecurityST:515] Wait for EO to rolling restart (2)...
2022-04-02 15:29:50 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-52004785-entity-operator rolling update
2022-04-02 15:29:55 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-52004785-entity-operator will be ready
2022-04-02 15:31:16 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-52004785-entity-operator is ready
2022-04-02 15:31:27 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-52004785-entity-operator rolling update finished
2022-04-02 15:31:27 [main] [32mINFO [m [SecurityST:520] Wait for KafkaExporter and CruiseControl to rolling restart (2)...
2022-04-02 15:31:27 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-52004785-kafka-exporter rolling update
2022-04-02 15:32:02 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-52004785-kafka-exporter will be ready
2022-04-02 15:32:02 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-52004785-kafka-exporter is ready
2022-04-02 15:32:12 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-52004785-kafka-exporter rolling update finished
2022-04-02 15:32:12 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-52004785-cruise-control rolling update
2022-04-02 15:32:12 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-52004785-cruise-control will be ready
2022-04-02 15:32:12 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-52004785-cruise-control is ready
2022-04-02 15:32:22 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-52004785-cruise-control rolling update finished
2022-04-02 15:32:22 [main] [32mINFO [m [SecurityST:525] Checking the certificates have been replaced
2022-04-02 15:32:22 [main] [32mINFO [m [SecurityST:536] Checking consumed messages to pod:my-cluster-52004785-kafka-clients-7b97889fd5-n5xx2
2022-04-02 15:32:22 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@6a14a290, messages=[], arguments=[--max-messages, 100, --group-instance-id, instance1707621700, --group-id, my-consumer-group-868742063, --topic, my-topic-1801001323-1015896418, --bootstrap-server, my-cluster-52004785-kafka-bootstrap.namespace-67.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-52004785-kafka-clients-7b97889fd5-n5xx2', podNamespace='namespace-67', bootstrapServer='my-cluster-52004785-kafka-bootstrap.namespace-67.svc:9092', topicName='my-topic-1801001323-1015896418', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-868742063', consumerInstanceId='instance1707621700', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@2b1ed73d}
2022-04-02 15:32:22 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-52004785-kafka-bootstrap.namespace-67.svc:9092#my-topic-1801001323-1015896418 from pod my-cluster-52004785-kafka-clients-7b97889fd5-n5xx2
2022-04-02 15:32:22 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-52004785-kafka-clients-7b97889fd5-n5xx2 -n namespace-67 -- /opt/kafka/consumer.sh --max-messages 100 --group-instance-id instance1707621700 --group-id my-consumer-group-868742063 --topic my-topic-1801001323-1015896418 --bootstrap-server my-cluster-52004785-kafka-bootstrap.namespace-67.svc:9092
2022-04-02 15:32:28 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-02 15:32:28 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-02 15:32:28 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1308322844-1046310246 in namespace namespace-67
2022-04-02 15:32:28 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-67
2022-04-02 15:32:28 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1308322844-1046310246 will have desired state: Ready
2022-04-02 15:32:29 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1308322844-1046310246 is in desired state: Ready
2022-04-02 15:32:29 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-52004785-kafka-clients-tls in namespace namespace-67
2022-04-02 15:32:29 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-67
2022-04-02 15:32:29 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-52004785-kafka-clients-tls will be ready
2022-04-02 15:32:31 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-52004785-kafka-clients-tls is ready
2022-04-02 15:32:31 [main] [32mINFO [m [SecurityST:561] Checking consumed messages to pod:my-cluster-52004785-kafka-clients-tls-787f95c995-tskw6
2022-04-02 15:32:31 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@29c4e3fb, messages=[], arguments=[--max-messages, 100, --group-instance-id, instance727941059, --group-id, my-consumer-group-798879644, --topic, my-topic-1801001323-1015896418, --bootstrap-server, my-cluster-52004785-kafka-bootstrap.namespace-67.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-52004785-kafka-clients-tls-787f95c995-tskw6', podNamespace='namespace-67', bootstrapServer='my-cluster-52004785-kafka-bootstrap.namespace-67.svc:9092', topicName='my-topic-1801001323-1015896418', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-798879644', consumerInstanceId='instance727941059', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@743e757e}
2022-04-02 15:32:31 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-52004785-kafka-bootstrap.namespace-67.svc:9092#my-topic-1801001323-1015896418 from pod my-cluster-52004785-kafka-clients-tls-787f95c995-tskw6
2022-04-02 15:32:31 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-52004785-kafka-clients-tls-787f95c995-tskw6 -n namespace-67 -- /opt/kafka/consumer.sh --max-messages 100 --group-instance-id instance727941059 --group-id my-consumer-group-798879644 --topic my-topic-1801001323-1015896418 --bootstrap-server my-cluster-52004785-kafka-bootstrap.namespace-67.svc:9092
2022-04-02 15:32:36 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-02 15:32:36 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-02 15:32:36 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 15:32:36 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAutoReplaceClusterCaKeysTriggeredByAnno
2022-04-02 15:32:36 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-52004785-kafka-clients in namespace namespace-67
2022-04-02 15:32:36 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1308322844-1046310246 in namespace namespace-67
2022-04-02 15:32:36 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-52004785-kafka-clients-tls in namespace namespace-67
2022-04-02 15:32:36 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-52004785 in namespace namespace-67
2022-04-02 15:32:36 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1801001323-1015896418 in namespace namespace-67
2022-04-02 15:32:36 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-67, for cruise control Kafka cluster my-cluster-52004785
2022-04-02 15:32:36 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1230845870-1268280312 in namespace namespace-67
2022-04-02 15:33:26 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 15:33:26 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-67 for test case:testAutoReplaceClusterCaKeysTriggeredByAnno
2022-04-02 15:33:33 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testAutoReplaceClusterCaKeysTriggeredByAnno-FINISHED
2022-04-02 15:33:33 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 15:33:33 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 15:33:33 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAutoReplaceAllCaKeysTriggeredByAnno-STARTED
2022-04-02 15:33:33 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 15:33:33 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-68 for test case:testAutoReplaceAllCaKeysTriggeredByAnno
2022-04-02 15:33:33 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-68
2022-04-02 15:33:33 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-68
2022-04-02 15:33:33 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-68
2022-04-02 15:33:33 [main] [32mINFO [m [SecurityST:587] Creating a cluster
2022-04-02 15:33:33 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-77559f0c in namespace namespace-68
2022-04-02 15:33:33 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-68
2022-04-02 15:33:33 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-77559f0c will have desired state: Ready
2022-04-02 15:35:37 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-77559f0c is in desired state: Ready
2022-04-02 15:35:37 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1428949225-617158137 in namespace namespace-68
2022-04-02 15:35:37 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-68
2022-04-02 15:35:37 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1428949225-617158137 will have desired state: Ready
2022-04-02 15:35:38 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1428949225-617158137 is in desired state: Ready
2022-04-02 15:35:38 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-134491868-1714128239 in namespace namespace-68
2022-04-02 15:35:38 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-68
2022-04-02 15:35:38 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-134491868-1714128239 will have desired state: Ready
2022-04-02 15:35:39 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-134491868-1714128239 is in desired state: Ready
2022-04-02 15:35:39 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-77559f0c-kafka-clients in namespace namespace-68
2022-04-02 15:35:39 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-68
2022-04-02 15:35:39 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-77559f0c-kafka-clients will be ready
2022-04-02 15:35:42 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-77559f0c-kafka-clients is ready
2022-04-02 15:35:42 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-02 15:35:42 [main] [32mINFO [m [SecurityST:453] Checking produced and consumed messages to pod:my-cluster-77559f0c-kafka-clients-5564c4894d-r4nq9
2022-04-02 15:35:42 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@693400a6, messages=[], arguments=[--max-messages, 100, --topic, my-topic-134491868-1714128239, --bootstrap-server, my-cluster-77559f0c-kafka-bootstrap.namespace-68.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-77559f0c-kafka-clients-5564c4894d-r4nq9', podNamespace='namespace-68', bootstrapServer='my-cluster-77559f0c-kafka-bootstrap.namespace-68.svc:9092', topicName='my-topic-134491868-1714128239', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5677e7f5}
2022-04-02 15:35:42 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-77559f0c-kafka-bootstrap.namespace-68.svc:9092:my-topic-134491868-1714128239 from pod my-cluster-77559f0c-kafka-clients-5564c4894d-r4nq9
2022-04-02 15:35:42 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-77559f0c-kafka-clients-5564c4894d-r4nq9 -n namespace-68 -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-134491868-1714128239 --bootstrap-server my-cluster-77559f0c-kafka-bootstrap.namespace-68.svc:9092
2022-04-02 15:35:44 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-02 15:35:44 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-02 15:35:44 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@4d4e4a62, messages=[], arguments=[--max-messages, 100, --group-instance-id, instance1204300161, --group-id, my-consumer-group-1614467229, --topic, my-topic-134491868-1714128239, --bootstrap-server, my-cluster-77559f0c-kafka-bootstrap.namespace-68.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-77559f0c-kafka-clients-5564c4894d-r4nq9', podNamespace='namespace-68', bootstrapServer='my-cluster-77559f0c-kafka-bootstrap.namespace-68.svc:9092', topicName='my-topic-134491868-1714128239', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1614467229', consumerInstanceId='instance1204300161', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@246f5955}
2022-04-02 15:35:44 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-77559f0c-kafka-bootstrap.namespace-68.svc:9092#my-topic-134491868-1714128239 from pod my-cluster-77559f0c-kafka-clients-5564c4894d-r4nq9
2022-04-02 15:35:44 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-77559f0c-kafka-clients-5564c4894d-r4nq9 -n namespace-68 -- /opt/kafka/consumer.sh --max-messages 100 --group-instance-id instance1204300161 --group-id my-consumer-group-1614467229 --topic my-topic-134491868-1714128239 --bootstrap-server my-cluster-77559f0c-kafka-bootstrap.namespace-68.svc:9092
2022-04-02 15:35:50 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-02 15:35:50 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-02 15:35:50 [main] [32mINFO [m [SecurityST:467] Triggering CA cert renewal by adding the annotation
2022-04-02 15:35:50 [main] [32mINFO [m [SecurityST:479] Patching secret my-cluster-77559f0c-cluster-ca with strimzi.io/force-replace
2022-04-02 15:35:50 [main] [32mINFO [m [SecurityST:479] Patching secret my-cluster-77559f0c-clients-ca with strimzi.io/force-replace
2022-04-02 15:35:50 [main] [32mINFO [m [SecurityST:484] Wait for zk to rolling restart (1)...
2022-04-02 15:35:50 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-77559f0c-zookeeper rolling update
2022-04-02 15:37:15 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-77559f0c-zookeeper has been successfully rolled
2022-04-02 15:37:15 [main] [32mINFO [m [SecurityST:489] Wait for kafka to rolling restart (1)...
2022-04-02 15:37:15 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-77559f0c-kafka rolling update
2022-04-02 15:38:40 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-77559f0c-kafka has been successfully rolled
2022-04-02 15:38:40 [main] [32mINFO [m [SecurityST:494] Wait for EO to rolling restart (1)...
2022-04-02 15:38:40 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-77559f0c-entity-operator rolling update
2022-04-02 15:39:15 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-77559f0c-entity-operator will be ready
2022-04-02 15:42:45 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-77559f0c-entity-operator is ready
2022-04-02 15:42:55 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-77559f0c-entity-operator rolling update finished
2022-04-02 15:42:55 [main] [32mINFO [m [SecurityST:499] Wait for KafkaExporter and CruiseControl to rolling restart (1)...
2022-04-02 15:42:55 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-77559f0c-kafka-exporter rolling update
2022-04-02 15:42:55 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-77559f0c-kafka-exporter will be ready
2022-04-02 15:43:19 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-77559f0c-kafka-exporter is ready
2022-04-02 15:43:29 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-77559f0c-kafka-exporter rolling update finished
2022-04-02 15:43:29 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-77559f0c-cruise-control rolling update
2022-04-02 15:43:29 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-77559f0c-cruise-control will be ready
2022-04-02 15:43:41 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-77559f0c-cruise-control is ready
2022-04-02 15:43:51 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-77559f0c-cruise-control rolling update finished
2022-04-02 15:43:51 [main] [32mINFO [m [SecurityST:505] Wait for zk to rolling restart (2)...
2022-04-02 15:43:51 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-77559f0c-zookeeper rolling update
2022-04-02 15:44:36 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-77559f0c-zookeeper has been successfully rolled
2022-04-02 15:44:36 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-77559f0c-zookeeper to be ready
2022-04-02 15:45:07 [main] [32mINFO [m [SecurityST:510] Wait for kafka to rolling restart (2)...
2022-04-02 15:45:07 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-77559f0c-kafka rolling update
2022-04-02 15:46:07 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-77559f0c-kafka has been successfully rolled
2022-04-02 15:46:07 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-77559f0c-kafka to be ready
2022-04-02 15:46:37 [main] [32mINFO [m [SecurityST:515] Wait for EO to rolling restart (2)...
2022-04-02 15:46:37 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-77559f0c-entity-operator rolling update
2022-04-02 15:46:42 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-77559f0c-entity-operator will be ready
2022-04-02 15:47:19 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-77559f0c-entity-operator is ready
2022-04-02 15:47:29 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-77559f0c-entity-operator rolling update finished
2022-04-02 15:47:29 [main] [32mINFO [m [SecurityST:520] Wait for KafkaExporter and CruiseControl to rolling restart (2)...
2022-04-02 15:47:29 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-77559f0c-kafka-exporter rolling update
2022-04-02 15:48:35 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-77559f0c-kafka-exporter will be ready
2022-04-02 15:48:35 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-77559f0c-kafka-exporter is ready
2022-04-02 15:48:45 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-77559f0c-kafka-exporter rolling update finished
2022-04-02 15:48:45 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-77559f0c-cruise-control rolling update
2022-04-02 15:48:45 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-77559f0c-cruise-control will be ready
2022-04-02 15:48:45 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-77559f0c-cruise-control is ready
2022-04-02 15:48:55 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-77559f0c-cruise-control rolling update finished
2022-04-02 15:48:55 [main] [32mINFO [m [SecurityST:525] Checking the certificates have been replaced
2022-04-02 15:48:55 [main] [32mINFO [m [SecurityST:536] Checking consumed messages to pod:my-cluster-77559f0c-kafka-clients-5564c4894d-r4nq9
2022-04-02 15:48:55 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@36b1a992, messages=[], arguments=[--max-messages, 100, --group-instance-id, instance1382786994, --group-id, my-consumer-group-644768392, --topic, my-topic-134491868-1714128239, --bootstrap-server, my-cluster-77559f0c-kafka-bootstrap.namespace-68.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-77559f0c-kafka-clients-5564c4894d-r4nq9', podNamespace='namespace-68', bootstrapServer='my-cluster-77559f0c-kafka-bootstrap.namespace-68.svc:9092', topicName='my-topic-134491868-1714128239', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-644768392', consumerInstanceId='instance1382786994', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@4af751d0}
2022-04-02 15:48:55 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-77559f0c-kafka-bootstrap.namespace-68.svc:9092#my-topic-134491868-1714128239 from pod my-cluster-77559f0c-kafka-clients-5564c4894d-r4nq9
2022-04-02 15:48:55 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-77559f0c-kafka-clients-5564c4894d-r4nq9 -n namespace-68 -- /opt/kafka/consumer.sh --max-messages 100 --group-instance-id instance1382786994 --group-id my-consumer-group-644768392 --topic my-topic-134491868-1714128239 --bootstrap-server my-cluster-77559f0c-kafka-bootstrap.namespace-68.svc:9092
2022-04-02 15:49:01 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-02 15:49:01 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-02 15:49:01 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-824024512-248410908 in namespace namespace-68
2022-04-02 15:49:01 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-68
2022-04-02 15:49:01 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-824024512-248410908 will have desired state: Ready
2022-04-02 15:49:02 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-824024512-248410908 is in desired state: Ready
2022-04-02 15:49:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-77559f0c-kafka-clients-tls in namespace namespace-68
2022-04-02 15:49:02 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-68
2022-04-02 15:49:02 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-77559f0c-kafka-clients-tls will be ready
2022-04-02 15:49:04 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-77559f0c-kafka-clients-tls is ready
2022-04-02 15:49:04 [main] [32mINFO [m [SecurityST:561] Checking consumed messages to pod:my-cluster-77559f0c-kafka-clients-tls-5bf5ffbd99-sgrlj
2022-04-02 15:49:04 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@66c97213, messages=[], arguments=[--max-messages, 100, --group-instance-id, instance1574942395, --group-id, my-consumer-group-994298964, --topic, my-topic-134491868-1714128239, --bootstrap-server, my-cluster-77559f0c-kafka-bootstrap.namespace-68.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-77559f0c-kafka-clients-tls-5bf5ffbd99-sgrlj', podNamespace='namespace-68', bootstrapServer='my-cluster-77559f0c-kafka-bootstrap.namespace-68.svc:9092', topicName='my-topic-134491868-1714128239', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-994298964', consumerInstanceId='instance1574942395', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@16c0c8ca}
2022-04-02 15:49:04 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-77559f0c-kafka-bootstrap.namespace-68.svc:9092#my-topic-134491868-1714128239 from pod my-cluster-77559f0c-kafka-clients-tls-5bf5ffbd99-sgrlj
2022-04-02 15:49:04 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-77559f0c-kafka-clients-tls-5bf5ffbd99-sgrlj -n namespace-68 -- /opt/kafka/consumer.sh --max-messages 100 --group-instance-id instance1574942395 --group-id my-consumer-group-994298964 --topic my-topic-134491868-1714128239 --bootstrap-server my-cluster-77559f0c-kafka-bootstrap.namespace-68.svc:9092
2022-04-02 15:49:09 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-02 15:49:09 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-02 15:49:09 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 15:49:09 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAutoReplaceAllCaKeysTriggeredByAnno
2022-04-02 15:49:09 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-77559f0c-kafka-clients in namespace namespace-68
2022-04-02 15:49:09 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-77559f0c in namespace namespace-68
2022-04-02 15:49:09 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-68, for cruise control Kafka cluster my-cluster-77559f0c
2022-04-02 15:49:09 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-134491868-1714128239 in namespace namespace-68
2022-04-02 15:49:09 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1428949225-617158137 in namespace namespace-68
2022-04-02 15:49:09 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-77559f0c-kafka-clients-tls in namespace namespace-68
2022-04-02 15:49:09 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-824024512-248410908 in namespace namespace-68
2022-04-02 15:50:10 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 15:50:10 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-68 for test case:testAutoReplaceAllCaKeysTriggeredByAnno
2022-04-02 15:50:16 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testAutoReplaceAllCaKeysTriggeredByAnno-FINISHED
2022-04-02 15:50:16 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 15:50:16 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 15:50:16 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testClusterCACertRenew-STARTED
2022-04-02 15:50:16 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 15:50:16 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-69 for test case:testClusterCACertRenew
2022-04-02 15:50:16 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-69
2022-04-02 15:50:16 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-69
2022-04-02 15:50:16 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-69
2022-04-02 15:50:16 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-4385a53f in namespace namespace-69
2022-04-02 15:50:16 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-69
2022-04-02 15:50:16 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-4385a53f will have desired state: Ready
2022-04-02 15:51:35 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-4385a53f is in desired state: Ready
2022-04-02 15:51:35 [main] [32mINFO [m [SecurityST:1512] Change of kafka validity and renewal days - reconciliation should start.
2022-04-02 15:51:35 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-4385a53f-zookeeper rolling update
2022-04-02 15:52:45 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-4385a53f-zookeeper has been successfully rolled
2022-04-02 15:52:45 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-4385a53f-zookeeper to be ready
2022-04-02 15:53:07 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-4385a53f-kafka rolling update
2022-04-02 15:54:12 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-4385a53f-kafka has been successfully rolled
2022-04-02 15:54:12 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-4385a53f-kafka to be ready
2022-04-02 15:54:41 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-4385a53f-entity-operator rolling update
2022-04-02 15:54:41 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-4385a53f-entity-operator will be ready
2022-04-02 15:56:08 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-4385a53f-entity-operator is ready
2022-04-02 15:56:18 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-4385a53f-entity-operator rolling update finished
2022-04-02 15:56:18 [main] [32mINFO [m [SecurityST:1545] Initial ClusterCA cert dates: Sat Apr 02 15:50:16 UTC 2022 --> Fri Apr 22 15:50:16 UTC 2022
2022-04-02 15:56:18 [main] [32mINFO [m [SecurityST:1546] Changed ClusterCA cert dates: Sat Apr 02 15:51:37 UTC 2022 --> Wed Oct 19 15:51:37 UTC 2022
2022-04-02 15:56:18 [main] [32mINFO [m [SecurityST:1547] KafkaBroker cert creation dates: Sat Apr 02 15:50:45 UTC 2022 --> Fri Apr 22 15:50:45 UTC 2022
2022-04-02 15:56:18 [main] [32mINFO [m [SecurityST:1548] KafkaBroker cert changed dates:  Sat Apr 02 15:52:58 UTC 2022 --> Wed Oct 19 15:52:58 UTC 2022
2022-04-02 15:56:18 [main] [32mINFO [m [SecurityST:1549] Zookeeper cert creation dates: Sat Apr 02 15:50:19 UTC 2022 --> Fri Apr 22 15:50:19 UTC 2022
2022-04-02 15:56:18 [main] [32mINFO [m [SecurityST:1550] Zookeeper cert changed dates:  Sat Apr 02 15:51:38 UTC 2022 --> Wed Oct 19 15:51:38 UTC 2022
2022-04-02 15:56:18 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 15:56:18 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testClusterCACertRenew
2022-04-02 15:56:18 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-4385a53f in namespace namespace-69
2022-04-02 15:56:28 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 15:56:28 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-69 for test case:testClusterCACertRenew
2022-04-02 15:57:11 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testClusterCACertRenew-FINISHED
2022-04-02 15:57:11 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 15:57:11 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 15:57:11 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testKafkaAndKafkaConnectTlsVersion-STARTED
2022-04-02 15:57:11 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 15:57:11 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-70 for test case:testKafkaAndKafkaConnectTlsVersion
2022-04-02 15:57:11 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-70
2022-04-02 15:57:11 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-70
2022-04-02 15:57:11 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-70
2022-04-02 15:57:11 [main] [32mINFO [m [SecurityST:1287] Deploying Kafka cluster with the support TLSv1.2 TLS
2022-04-02 15:57:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-266a01d0 in namespace namespace-70
2022-04-02 15:57:11 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-70
2022-04-02 15:57:11 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-266a01d0 will have desired state: Ready
2022-04-02 15:58:24 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-266a01d0 is in desired state: Ready
2022-04-02 15:58:24 [main] [32mINFO [m [SecurityST:1299] Verifying that Kafka cluster has the accepted configuration:
ssl.enabled.protocols -> TLSv1.2
ssl.protocol -> TLSv1.3
2022-04-02 15:58:24 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-266a01d0-kafka-clients in namespace namespace-70
2022-04-02 15:58:24 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-70
2022-04-02 15:58:24 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-266a01d0-kafka-clients will be ready
2022-04-02 15:58:26 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-266a01d0-kafka-clients is ready
2022-04-02 15:58:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-266a01d0-scraper in namespace namespace-70
2022-04-02 15:58:26 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-70
2022-04-02 15:58:26 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-266a01d0-scraper will be ready
2022-04-02 15:58:28 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-266a01d0-scraper is ready
2022-04-02 15:58:28 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-266a01d0-scraper to be ready
2022-04-02 15:58:38 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-266a01d0-scraper is ready
2022-04-02 15:58:38 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-266a01d0-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-02 15:58:38 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-266a01d0-allow in namespace namespace-70
2022-04-02 15:58:38 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-70
2022-04-02 15:58:38 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-02 15:58:38 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-266a01d0 in namespace namespace-70
2022-04-02 15:58:38 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-70
2022-04-02 15:58:38 [main] [32mINFO [m [SecurityST:1322] Verifying that Kafka Connect status is NotReady because of different TLS version
2022-04-02 15:58:38 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-266a01d0 will have desired state: NotReady
2022-04-02 16:03:39 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-266a01d0 is in desired state: NotReady
2022-04-02 16:03:39 [main] [32mINFO [m [SecurityST:1326] Replacing Kafka Connect config to the newest(TLSv1.2) one same as the Kafka broker has.
2022-04-02 16:03:39 [main] [32mINFO [m [SecurityST:1330] Verifying that Kafka Connect has the accepted configuration:
 ssl.enabled.protocols -> TLSv1.2
 ssl.protocol -> TLSv1.3
2022-04-02 16:03:39 [main] [32mINFO [m [KafkaConnectUtils:101] Waiting for Kafka Connect property ssl.enabled.protocols -> TLSv1.2 change
2022-04-02 16:03:39 [main] [32mINFO [m [KafkaConnectUtils:109] Kafka Connect property ssl.enabled.protocols -> TLSv1.2 change
2022-04-02 16:03:39 [main] [32mINFO [m [KafkaConnectUtils:101] Waiting for Kafka Connect property ssl.protocol -> TLSv1.3 change
2022-04-02 16:03:39 [main] [32mINFO [m [KafkaConnectUtils:109] Kafka Connect property ssl.protocol -> TLSv1.3 change
2022-04-02 16:03:39 [main] [32mINFO [m [SecurityST:1339] Verifying that Kafka Connect is stable
2022-04-02 16:03:39 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-266a01d0-connect are stable
2022-04-02 16:03:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-266a01d0-connect-6bfb559d8d-q5xd8 is in the Running state. Remaining seconds pod to be stable 50
2022-04-02 16:03:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-266a01d0-connect-6bfb559d8d-q5xd8 is in the Running state. Remaining seconds pod to be stable 49
2022-04-02 16:03:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-266a01d0-connect-6bfb559d8d-q5xd8 is in the Running state. Remaining seconds pod to be stable 48
2022-04-02 16:03:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-266a01d0-connect-6bfb559d8d-q5xd8 is in the Running state. Remaining seconds pod to be stable 47
2022-04-02 16:03:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-266a01d0-connect-6bfb559d8d-q5xd8 is in the Running state. Remaining seconds pod to be stable 46
2022-04-02 16:03:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-266a01d0-connect-6bfb559d8d-q5xd8 is in the Running state. Remaining seconds pod to be stable 45
2022-04-02 16:03:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-266a01d0-connect-6bfb559d8d-q5xd8 is in the Running state. Remaining seconds pod to be stable 44
2022-04-02 16:03:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-266a01d0-connect-6bfb559d8d-q5xd8 is in the Running state. Remaining seconds pod to be stable 43
2022-04-02 16:03:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-266a01d0-connect-6bfb559d8d-q5xd8 is in the Running state. Remaining seconds pod to be stable 42
2022-04-02 16:03:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-266a01d0-connect-6bfb559d8d-q5xd8 is in the Running state. Remaining seconds pod to be stable 41
2022-04-02 16:03:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-266a01d0-connect-6bfb559d8d-q5xd8 is in the Running state. Remaining seconds pod to be stable 40
2022-04-02 16:03:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-266a01d0-connect-6bfb559d8d-q5xd8 is in the Running state. Remaining seconds pod to be stable 39
2022-04-02 16:03:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-266a01d0-connect-6bfb559d8d-q5xd8 is in the Running state. Remaining seconds pod to be stable 38
2022-04-02 16:03:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-266a01d0-connect-6bfb559d8d-q5xd8 is in the Running state. Remaining seconds pod to be stable 37
2022-04-02 16:03:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-266a01d0-connect-6bfb559d8d-q5xd8 is in the Running state. Remaining seconds pod to be stable 36
2022-04-02 16:03:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-266a01d0-connect-6bfb559d8d-q5xd8 is in the Running state. Remaining seconds pod to be stable 35
2022-04-02 16:03:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-266a01d0-connect-6bfb559d8d-q5xd8 is in the Running state. Remaining seconds pod to be stable 34
2022-04-02 16:03:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-266a01d0-connect-6bfb559d8d-q5xd8 is in the Running state. Remaining seconds pod to be stable 33
2022-04-02 16:03:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-266a01d0-connect-6bfb559d8d-q5xd8 is in the Running state. Remaining seconds pod to be stable 32
2022-04-02 16:03:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-266a01d0-connect-6bfb559d8d-q5xd8 is in the Running state. Remaining seconds pod to be stable 31
2022-04-02 16:04:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-266a01d0-connect-6bfb559d8d-q5xd8 is in the Running state. Remaining seconds pod to be stable 30
2022-04-02 16:04:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-266a01d0-connect-6bfb559d8d-q5xd8 is in the Running state. Remaining seconds pod to be stable 29
2022-04-02 16:04:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-266a01d0-connect-6bfb559d8d-q5xd8 is in the Running state. Remaining seconds pod to be stable 28
2022-04-02 16:04:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-266a01d0-connect-6bfb559d8d-q5xd8 is in the Running state. Remaining seconds pod to be stable 27
2022-04-02 16:04:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-266a01d0-connect-6bfb559d8d-q5xd8 is in the Running state. Remaining seconds pod to be stable 26
2022-04-02 16:04:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-266a01d0-connect-6bfb559d8d-q5xd8 is in the Running state. Remaining seconds pod to be stable 25
2022-04-02 16:04:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-266a01d0-connect-6bfb559d8d-q5xd8 is in the Running state. Remaining seconds pod to be stable 24
2022-04-02 16:04:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-266a01d0-connect-6bfb559d8d-q5xd8 is in the Running state. Remaining seconds pod to be stable 23
2022-04-02 16:04:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-266a01d0-connect-6bfb559d8d-q5xd8 is in the Running state. Remaining seconds pod to be stable 22
2022-04-02 16:04:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-266a01d0-connect-6bfb559d8d-q5xd8 is in the Running state. Remaining seconds pod to be stable 21
2022-04-02 16:04:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-266a01d0-connect-6bfb559d8d-q5xd8 is in the Running state. Remaining seconds pod to be stable 20
2022-04-02 16:04:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-266a01d0-connect-6bfb559d8d-q5xd8 is in the Running state. Remaining seconds pod to be stable 19
2022-04-02 16:04:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-266a01d0-connect-6bfb559d8d-q5xd8 is in the Running state. Remaining seconds pod to be stable 18
2022-04-02 16:04:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-266a01d0-connect-6bfb559d8d-q5xd8 is in the Running state. Remaining seconds pod to be stable 17
2022-04-02 16:04:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-266a01d0-connect-6bfb559d8d-q5xd8 is in the Running state. Remaining seconds pod to be stable 16
2022-04-02 16:04:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-266a01d0-connect-6bfb559d8d-q5xd8 is in the Running state. Remaining seconds pod to be stable 15
2022-04-02 16:04:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-266a01d0-connect-6bfb559d8d-q5xd8 is in the Running state. Remaining seconds pod to be stable 14
2022-04-02 16:04:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-266a01d0-connect-6bfb559d8d-q5xd8 is in the Running state. Remaining seconds pod to be stable 13
2022-04-02 16:04:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-266a01d0-connect-6bfb559d8d-q5xd8 is in the Running state. Remaining seconds pod to be stable 12
2022-04-02 16:04:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-266a01d0-connect-6bfb559d8d-q5xd8 is in the Running state. Remaining seconds pod to be stable 11
2022-04-02 16:04:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-266a01d0-connect-6bfb559d8d-q5xd8 is in the Running state. Remaining seconds pod to be stable 10
2022-04-02 16:04:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-266a01d0-connect-6bfb559d8d-q5xd8 is in the Running state. Remaining seconds pod to be stable 9
2022-04-02 16:04:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-266a01d0-connect-6bfb559d8d-q5xd8 is in the Running state. Remaining seconds pod to be stable 8
2022-04-02 16:04:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-266a01d0-connect-6bfb559d8d-q5xd8 is in the Running state. Remaining seconds pod to be stable 7
2022-04-02 16:04:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-266a01d0-connect-6bfb559d8d-q5xd8 is in the Running state. Remaining seconds pod to be stable 6
2022-04-02 16:04:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-266a01d0-connect-6bfb559d8d-q5xd8 is in the Running state. Remaining seconds pod to be stable 5
2022-04-02 16:04:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-266a01d0-connect-6bfb559d8d-q5xd8 is in the Running state. Remaining seconds pod to be stable 4
2022-04-02 16:04:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-266a01d0-connect-6bfb559d8d-q5xd8 is in the Running state. Remaining seconds pod to be stable 3
2022-04-02 16:04:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-266a01d0-connect-6bfb559d8d-q5xd8 is in the Running state. Remaining seconds pod to be stable 2
2022-04-02 16:04:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-266a01d0-connect-6bfb559d8d-q5xd8 is in the Running state. Remaining seconds pod to be stable 1
2022-04-02 16:04:29 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-266a01d0-connect-6bfb559d8d-q5xd8
2022-04-02 16:04:29 [main] [32mINFO [m [SecurityST:1343] Verifying that Kafka Connect status is Ready because of same TLS version
2022-04-02 16:04:29 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-266a01d0 will have desired state: Ready
2022-04-02 16:10:07 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-266a01d0 is in desired state: Ready
2022-04-02 16:10:07 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 16:10:07 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaAndKafkaConnectTlsVersion
2022-04-02 16:10:07 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-266a01d0-scraper in namespace namespace-70
2022-04-02 16:10:07 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-266a01d0 in namespace namespace-70
2022-04-02 16:10:07 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-266a01d0-kafka-clients in namespace namespace-70
2022-04-02 16:10:07 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-266a01d0-allow in namespace namespace-70
2022-04-02 16:10:07 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-266a01d0 in namespace namespace-70
2022-04-02 16:10:57 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 16:10:57 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-70 for test case:testKafkaAndKafkaConnectTlsVersion
2022-04-02 16:11:02 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testKafkaAndKafkaConnectTlsVersion-FINISHED
2022-04-02 16:11:02 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 16:11:02 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 16:11:02 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testTlsHostnameVerificationWithKafkaConnect-STARTED
2022-04-02 16:11:02 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 16:11:02 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-71 for test case:testTlsHostnameVerificationWithKafkaConnect
2022-04-02 16:11:02 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-71
2022-04-02 16:11:02 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-71
2022-04-02 16:11:02 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-71
2022-04-02 16:11:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-c8fba052 in namespace namespace-71
2022-04-02 16:11:02 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-71
2022-04-02 16:11:02 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-c8fba052 will have desired state: Ready
2022-04-02 16:12:14 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-c8fba052 is in desired state: Ready
2022-04-02 16:12:14 [main] [32mINFO [m [SecurityST:838] Getting IP of the bootstrap service
2022-04-02 16:12:14 [main] [32mINFO [m [SecurityST:842] KafkaConnect without config ssl.endpoint.identification.algorithm will not connect to 10.104.183.93:9093
2022-04-02 16:12:14 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-c8fba052-kafka-clients in namespace namespace-71
2022-04-02 16:12:14 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-71
2022-04-02 16:12:14 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-c8fba052-kafka-clients will be ready
2022-04-02 16:12:16 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-c8fba052-kafka-clients is ready
2022-04-02 16:12:16 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-c8fba052-scraper in namespace namespace-71
2022-04-02 16:12:16 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-71
2022-04-02 16:12:16 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-c8fba052-scraper will be ready
2022-04-02 16:12:18 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-c8fba052-scraper is ready
2022-04-02 16:12:18 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-c8fba052-scraper to be ready
2022-04-02 16:12:28 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-c8fba052-scraper is ready
2022-04-02 16:12:28 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-c8fba052-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-02 16:12:28 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-c8fba052-allow in namespace namespace-71
2022-04-02 16:12:28 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-71
2022-04-02 16:12:28 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-02 16:12:28 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-c8fba052 in namespace namespace-71
2022-04-02 16:12:28 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-71
2022-04-02 16:12:28 [main] [32mINFO [m [PodUtils:245] Wait until Pod my-cluster-c8fba052-connect is present
2022-04-02 16:12:29 [main] [32mINFO [m [PodUtils:249] Pod my-cluster-c8fba052-connect is present
2022-04-02 16:12:29 [main] [32mINFO [m [PodUtils:236] Wait until Pod my-cluster-c8fba052-connect-6bc7cb45b5-htmv6 is in CrashLoopBackOff state
2022-04-02 16:12:52 [main] [32mINFO [m [PodUtils:241] Pod my-cluster-c8fba052-connect-6bc7cb45b5-htmv6 is in CrashLoopBackOff state
2022-04-02 16:12:52 [main] [32mINFO [m [SecurityST:872] KafkaConnect with config ssl.endpoint.identification.algorithm will connect to 10.104.183.93:9093
2022-04-02 16:12:52 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-c8fba052 will have desired state: Ready
2022-04-02 16:18:34 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-c8fba052 is in desired state: Ready
2022-04-02 16:18:34 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 16:18:34 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTlsHostnameVerificationWithKafkaConnect
2022-04-02 16:18:34 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-c8fba052-scraper in namespace namespace-71
2022-04-02 16:18:34 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-c8fba052 in namespace namespace-71
2022-04-02 16:18:34 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-c8fba052 in namespace namespace-71
2022-04-02 16:18:34 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-c8fba052-kafka-clients in namespace namespace-71
2022-04-02 16:18:34 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-c8fba052-allow in namespace namespace-71
2022-04-02 16:19:24 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 16:19:24 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-71 for test case:testTlsHostnameVerificationWithKafkaConnect
2022-04-02 16:19:29 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testTlsHostnameVerificationWithKafkaConnect-FINISHED
2022-04-02 16:19:29 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 16:19:29 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 16:19:29 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testClientsCACertRenew-STARTED
2022-04-02 16:19:29 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 16:19:29 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-72 for test case:testClientsCACertRenew
2022-04-02 16:19:29 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-72
2022-04-02 16:19:29 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-72
2022-04-02 16:19:29 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-72
2022-04-02 16:19:29 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-c832789d in namespace namespace-72
2022-04-02 16:19:29 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-72
2022-04-02 16:19:29 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-c832789d will have desired state: Ready
2022-04-02 16:20:36 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-c832789d is in desired state: Ready
2022-04-02 16:20:36 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser strimzi-tls-user-714163417 in namespace namespace-72
2022-04-02 16:20:36 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-72
2022-04-02 16:20:36 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: strimzi-tls-user-714163417 will have desired state: Ready
2022-04-02 16:20:38 [main] [32mINFO [m [ResourceManager:444] KafkaUser: strimzi-tls-user-714163417 is in desired state: Ready
2022-04-02 16:20:38 [main] [32mINFO [m [SecurityST:1596] Change of kafka validity and renewal days - reconciliation should start.
2022-04-02 16:20:38 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c832789d-zookeeper-2=b5f30ac1-e153-46c0-bd3f-8743ae3d87ca, my-cluster-c832789d-zookeeper-1=43819985-9d49-4f34-b2b9-2b617f14e752, my-cluster-c832789d-zookeeper-0=8c5821bc-2fd3-4b96-aec1-86f001defb7d} pods didn't roll. Remaining seconds for stability: 50
2022-04-02 16:20:39 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c832789d-zookeeper-2=b5f30ac1-e153-46c0-bd3f-8743ae3d87ca, my-cluster-c832789d-zookeeper-1=43819985-9d49-4f34-b2b9-2b617f14e752, my-cluster-c832789d-zookeeper-0=8c5821bc-2fd3-4b96-aec1-86f001defb7d} pods didn't roll. Remaining seconds for stability: 49
2022-04-02 16:20:40 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c832789d-zookeeper-2=b5f30ac1-e153-46c0-bd3f-8743ae3d87ca, my-cluster-c832789d-zookeeper-1=43819985-9d49-4f34-b2b9-2b617f14e752, my-cluster-c832789d-zookeeper-0=8c5821bc-2fd3-4b96-aec1-86f001defb7d} pods didn't roll. Remaining seconds for stability: 48
2022-04-02 16:20:41 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c832789d-zookeeper-2=b5f30ac1-e153-46c0-bd3f-8743ae3d87ca, my-cluster-c832789d-zookeeper-1=43819985-9d49-4f34-b2b9-2b617f14e752, my-cluster-c832789d-zookeeper-0=8c5821bc-2fd3-4b96-aec1-86f001defb7d} pods didn't roll. Remaining seconds for stability: 47
2022-04-02 16:20:42 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c832789d-zookeeper-2=b5f30ac1-e153-46c0-bd3f-8743ae3d87ca, my-cluster-c832789d-zookeeper-1=43819985-9d49-4f34-b2b9-2b617f14e752, my-cluster-c832789d-zookeeper-0=8c5821bc-2fd3-4b96-aec1-86f001defb7d} pods didn't roll. Remaining seconds for stability: 46
2022-04-02 16:20:43 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c832789d-zookeeper-2=b5f30ac1-e153-46c0-bd3f-8743ae3d87ca, my-cluster-c832789d-zookeeper-1=43819985-9d49-4f34-b2b9-2b617f14e752, my-cluster-c832789d-zookeeper-0=8c5821bc-2fd3-4b96-aec1-86f001defb7d} pods didn't roll. Remaining seconds for stability: 45
2022-04-02 16:20:44 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c832789d-zookeeper-2=b5f30ac1-e153-46c0-bd3f-8743ae3d87ca, my-cluster-c832789d-zookeeper-1=43819985-9d49-4f34-b2b9-2b617f14e752, my-cluster-c832789d-zookeeper-0=8c5821bc-2fd3-4b96-aec1-86f001defb7d} pods didn't roll. Remaining seconds for stability: 44
2022-04-02 16:20:45 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c832789d-zookeeper-2=b5f30ac1-e153-46c0-bd3f-8743ae3d87ca, my-cluster-c832789d-zookeeper-1=43819985-9d49-4f34-b2b9-2b617f14e752, my-cluster-c832789d-zookeeper-0=8c5821bc-2fd3-4b96-aec1-86f001defb7d} pods didn't roll. Remaining seconds for stability: 43
2022-04-02 16:20:46 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c832789d-zookeeper-2=b5f30ac1-e153-46c0-bd3f-8743ae3d87ca, my-cluster-c832789d-zookeeper-1=43819985-9d49-4f34-b2b9-2b617f14e752, my-cluster-c832789d-zookeeper-0=8c5821bc-2fd3-4b96-aec1-86f001defb7d} pods didn't roll. Remaining seconds for stability: 42
2022-04-02 16:20:47 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c832789d-zookeeper-2=b5f30ac1-e153-46c0-bd3f-8743ae3d87ca, my-cluster-c832789d-zookeeper-1=43819985-9d49-4f34-b2b9-2b617f14e752, my-cluster-c832789d-zookeeper-0=8c5821bc-2fd3-4b96-aec1-86f001defb7d} pods didn't roll. Remaining seconds for stability: 41
2022-04-02 16:20:48 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c832789d-zookeeper-2=b5f30ac1-e153-46c0-bd3f-8743ae3d87ca, my-cluster-c832789d-zookeeper-1=43819985-9d49-4f34-b2b9-2b617f14e752, my-cluster-c832789d-zookeeper-0=8c5821bc-2fd3-4b96-aec1-86f001defb7d} pods didn't roll. Remaining seconds for stability: 40
2022-04-02 16:20:49 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c832789d-zookeeper-2=b5f30ac1-e153-46c0-bd3f-8743ae3d87ca, my-cluster-c832789d-zookeeper-1=43819985-9d49-4f34-b2b9-2b617f14e752, my-cluster-c832789d-zookeeper-0=8c5821bc-2fd3-4b96-aec1-86f001defb7d} pods didn't roll. Remaining seconds for stability: 39
2022-04-02 16:20:50 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c832789d-zookeeper-2=b5f30ac1-e153-46c0-bd3f-8743ae3d87ca, my-cluster-c832789d-zookeeper-1=43819985-9d49-4f34-b2b9-2b617f14e752, my-cluster-c832789d-zookeeper-0=8c5821bc-2fd3-4b96-aec1-86f001defb7d} pods didn't roll. Remaining seconds for stability: 38
2022-04-02 16:20:51 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c832789d-zookeeper-2=b5f30ac1-e153-46c0-bd3f-8743ae3d87ca, my-cluster-c832789d-zookeeper-1=43819985-9d49-4f34-b2b9-2b617f14e752, my-cluster-c832789d-zookeeper-0=8c5821bc-2fd3-4b96-aec1-86f001defb7d} pods didn't roll. Remaining seconds for stability: 37
2022-04-02 16:20:52 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c832789d-zookeeper-2=b5f30ac1-e153-46c0-bd3f-8743ae3d87ca, my-cluster-c832789d-zookeeper-1=43819985-9d49-4f34-b2b9-2b617f14e752, my-cluster-c832789d-zookeeper-0=8c5821bc-2fd3-4b96-aec1-86f001defb7d} pods didn't roll. Remaining seconds for stability: 36
2022-04-02 16:20:53 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c832789d-zookeeper-2=b5f30ac1-e153-46c0-bd3f-8743ae3d87ca, my-cluster-c832789d-zookeeper-1=43819985-9d49-4f34-b2b9-2b617f14e752, my-cluster-c832789d-zookeeper-0=8c5821bc-2fd3-4b96-aec1-86f001defb7d} pods didn't roll. Remaining seconds for stability: 35
2022-04-02 16:20:54 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c832789d-zookeeper-2=b5f30ac1-e153-46c0-bd3f-8743ae3d87ca, my-cluster-c832789d-zookeeper-1=43819985-9d49-4f34-b2b9-2b617f14e752, my-cluster-c832789d-zookeeper-0=8c5821bc-2fd3-4b96-aec1-86f001defb7d} pods didn't roll. Remaining seconds for stability: 34
2022-04-02 16:20:55 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c832789d-zookeeper-2=b5f30ac1-e153-46c0-bd3f-8743ae3d87ca, my-cluster-c832789d-zookeeper-1=43819985-9d49-4f34-b2b9-2b617f14e752, my-cluster-c832789d-zookeeper-0=8c5821bc-2fd3-4b96-aec1-86f001defb7d} pods didn't roll. Remaining seconds for stability: 33
2022-04-02 16:20:56 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c832789d-zookeeper-2=b5f30ac1-e153-46c0-bd3f-8743ae3d87ca, my-cluster-c832789d-zookeeper-1=43819985-9d49-4f34-b2b9-2b617f14e752, my-cluster-c832789d-zookeeper-0=8c5821bc-2fd3-4b96-aec1-86f001defb7d} pods didn't roll. Remaining seconds for stability: 32
2022-04-02 16:20:57 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c832789d-zookeeper-2=b5f30ac1-e153-46c0-bd3f-8743ae3d87ca, my-cluster-c832789d-zookeeper-1=43819985-9d49-4f34-b2b9-2b617f14e752, my-cluster-c832789d-zookeeper-0=8c5821bc-2fd3-4b96-aec1-86f001defb7d} pods didn't roll. Remaining seconds for stability: 31
2022-04-02 16:20:58 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c832789d-zookeeper-2=b5f30ac1-e153-46c0-bd3f-8743ae3d87ca, my-cluster-c832789d-zookeeper-1=43819985-9d49-4f34-b2b9-2b617f14e752, my-cluster-c832789d-zookeeper-0=8c5821bc-2fd3-4b96-aec1-86f001defb7d} pods didn't roll. Remaining seconds for stability: 30
2022-04-02 16:20:59 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c832789d-zookeeper-2=b5f30ac1-e153-46c0-bd3f-8743ae3d87ca, my-cluster-c832789d-zookeeper-1=43819985-9d49-4f34-b2b9-2b617f14e752, my-cluster-c832789d-zookeeper-0=8c5821bc-2fd3-4b96-aec1-86f001defb7d} pods didn't roll. Remaining seconds for stability: 29
2022-04-02 16:21:00 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c832789d-zookeeper-2=b5f30ac1-e153-46c0-bd3f-8743ae3d87ca, my-cluster-c832789d-zookeeper-1=43819985-9d49-4f34-b2b9-2b617f14e752, my-cluster-c832789d-zookeeper-0=8c5821bc-2fd3-4b96-aec1-86f001defb7d} pods didn't roll. Remaining seconds for stability: 28
2022-04-02 16:21:01 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c832789d-zookeeper-2=b5f30ac1-e153-46c0-bd3f-8743ae3d87ca, my-cluster-c832789d-zookeeper-1=43819985-9d49-4f34-b2b9-2b617f14e752, my-cluster-c832789d-zookeeper-0=8c5821bc-2fd3-4b96-aec1-86f001defb7d} pods didn't roll. Remaining seconds for stability: 27
2022-04-02 16:21:02 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c832789d-zookeeper-2=b5f30ac1-e153-46c0-bd3f-8743ae3d87ca, my-cluster-c832789d-zookeeper-1=43819985-9d49-4f34-b2b9-2b617f14e752, my-cluster-c832789d-zookeeper-0=8c5821bc-2fd3-4b96-aec1-86f001defb7d} pods didn't roll. Remaining seconds for stability: 26
2022-04-02 16:21:03 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c832789d-zookeeper-2=b5f30ac1-e153-46c0-bd3f-8743ae3d87ca, my-cluster-c832789d-zookeeper-1=43819985-9d49-4f34-b2b9-2b617f14e752, my-cluster-c832789d-zookeeper-0=8c5821bc-2fd3-4b96-aec1-86f001defb7d} pods didn't roll. Remaining seconds for stability: 25
2022-04-02 16:21:04 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c832789d-zookeeper-2=b5f30ac1-e153-46c0-bd3f-8743ae3d87ca, my-cluster-c832789d-zookeeper-1=43819985-9d49-4f34-b2b9-2b617f14e752, my-cluster-c832789d-zookeeper-0=8c5821bc-2fd3-4b96-aec1-86f001defb7d} pods didn't roll. Remaining seconds for stability: 24
2022-04-02 16:21:05 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c832789d-zookeeper-2=b5f30ac1-e153-46c0-bd3f-8743ae3d87ca, my-cluster-c832789d-zookeeper-1=43819985-9d49-4f34-b2b9-2b617f14e752, my-cluster-c832789d-zookeeper-0=8c5821bc-2fd3-4b96-aec1-86f001defb7d} pods didn't roll. Remaining seconds for stability: 23
2022-04-02 16:21:06 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c832789d-zookeeper-2=b5f30ac1-e153-46c0-bd3f-8743ae3d87ca, my-cluster-c832789d-zookeeper-1=43819985-9d49-4f34-b2b9-2b617f14e752, my-cluster-c832789d-zookeeper-0=8c5821bc-2fd3-4b96-aec1-86f001defb7d} pods didn't roll. Remaining seconds for stability: 22
2022-04-02 16:21:07 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c832789d-zookeeper-2=b5f30ac1-e153-46c0-bd3f-8743ae3d87ca, my-cluster-c832789d-zookeeper-1=43819985-9d49-4f34-b2b9-2b617f14e752, my-cluster-c832789d-zookeeper-0=8c5821bc-2fd3-4b96-aec1-86f001defb7d} pods didn't roll. Remaining seconds for stability: 21
2022-04-02 16:21:08 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c832789d-zookeeper-2=b5f30ac1-e153-46c0-bd3f-8743ae3d87ca, my-cluster-c832789d-zookeeper-1=43819985-9d49-4f34-b2b9-2b617f14e752, my-cluster-c832789d-zookeeper-0=8c5821bc-2fd3-4b96-aec1-86f001defb7d} pods didn't roll. Remaining seconds for stability: 20
2022-04-02 16:21:09 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c832789d-zookeeper-2=b5f30ac1-e153-46c0-bd3f-8743ae3d87ca, my-cluster-c832789d-zookeeper-1=43819985-9d49-4f34-b2b9-2b617f14e752, my-cluster-c832789d-zookeeper-0=8c5821bc-2fd3-4b96-aec1-86f001defb7d} pods didn't roll. Remaining seconds for stability: 19
2022-04-02 16:21:10 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c832789d-zookeeper-2=b5f30ac1-e153-46c0-bd3f-8743ae3d87ca, my-cluster-c832789d-zookeeper-1=43819985-9d49-4f34-b2b9-2b617f14e752, my-cluster-c832789d-zookeeper-0=8c5821bc-2fd3-4b96-aec1-86f001defb7d} pods didn't roll. Remaining seconds for stability: 18
2022-04-02 16:21:11 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c832789d-zookeeper-2=b5f30ac1-e153-46c0-bd3f-8743ae3d87ca, my-cluster-c832789d-zookeeper-1=43819985-9d49-4f34-b2b9-2b617f14e752, my-cluster-c832789d-zookeeper-0=8c5821bc-2fd3-4b96-aec1-86f001defb7d} pods didn't roll. Remaining seconds for stability: 17
2022-04-02 16:21:12 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c832789d-zookeeper-2=b5f30ac1-e153-46c0-bd3f-8743ae3d87ca, my-cluster-c832789d-zookeeper-1=43819985-9d49-4f34-b2b9-2b617f14e752, my-cluster-c832789d-zookeeper-0=8c5821bc-2fd3-4b96-aec1-86f001defb7d} pods didn't roll. Remaining seconds for stability: 16
2022-04-02 16:21:13 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c832789d-zookeeper-2=b5f30ac1-e153-46c0-bd3f-8743ae3d87ca, my-cluster-c832789d-zookeeper-1=43819985-9d49-4f34-b2b9-2b617f14e752, my-cluster-c832789d-zookeeper-0=8c5821bc-2fd3-4b96-aec1-86f001defb7d} pods didn't roll. Remaining seconds for stability: 15
2022-04-02 16:21:14 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c832789d-zookeeper-2=b5f30ac1-e153-46c0-bd3f-8743ae3d87ca, my-cluster-c832789d-zookeeper-1=43819985-9d49-4f34-b2b9-2b617f14e752, my-cluster-c832789d-zookeeper-0=8c5821bc-2fd3-4b96-aec1-86f001defb7d} pods didn't roll. Remaining seconds for stability: 14
2022-04-02 16:21:15 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c832789d-zookeeper-2=b5f30ac1-e153-46c0-bd3f-8743ae3d87ca, my-cluster-c832789d-zookeeper-1=43819985-9d49-4f34-b2b9-2b617f14e752, my-cluster-c832789d-zookeeper-0=8c5821bc-2fd3-4b96-aec1-86f001defb7d} pods didn't roll. Remaining seconds for stability: 13
2022-04-02 16:21:16 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c832789d-zookeeper-2=b5f30ac1-e153-46c0-bd3f-8743ae3d87ca, my-cluster-c832789d-zookeeper-1=43819985-9d49-4f34-b2b9-2b617f14e752, my-cluster-c832789d-zookeeper-0=8c5821bc-2fd3-4b96-aec1-86f001defb7d} pods didn't roll. Remaining seconds for stability: 12
2022-04-02 16:21:17 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c832789d-zookeeper-2=b5f30ac1-e153-46c0-bd3f-8743ae3d87ca, my-cluster-c832789d-zookeeper-1=43819985-9d49-4f34-b2b9-2b617f14e752, my-cluster-c832789d-zookeeper-0=8c5821bc-2fd3-4b96-aec1-86f001defb7d} pods didn't roll. Remaining seconds for stability: 11
2022-04-02 16:21:18 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c832789d-zookeeper-2=b5f30ac1-e153-46c0-bd3f-8743ae3d87ca, my-cluster-c832789d-zookeeper-1=43819985-9d49-4f34-b2b9-2b617f14e752, my-cluster-c832789d-zookeeper-0=8c5821bc-2fd3-4b96-aec1-86f001defb7d} pods didn't roll. Remaining seconds for stability: 10
2022-04-02 16:21:19 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c832789d-zookeeper-2=b5f30ac1-e153-46c0-bd3f-8743ae3d87ca, my-cluster-c832789d-zookeeper-1=43819985-9d49-4f34-b2b9-2b617f14e752, my-cluster-c832789d-zookeeper-0=8c5821bc-2fd3-4b96-aec1-86f001defb7d} pods didn't roll. Remaining seconds for stability: 9
2022-04-02 16:21:20 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c832789d-zookeeper-2=b5f30ac1-e153-46c0-bd3f-8743ae3d87ca, my-cluster-c832789d-zookeeper-1=43819985-9d49-4f34-b2b9-2b617f14e752, my-cluster-c832789d-zookeeper-0=8c5821bc-2fd3-4b96-aec1-86f001defb7d} pods didn't roll. Remaining seconds for stability: 8
2022-04-02 16:21:21 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c832789d-zookeeper-2=b5f30ac1-e153-46c0-bd3f-8743ae3d87ca, my-cluster-c832789d-zookeeper-1=43819985-9d49-4f34-b2b9-2b617f14e752, my-cluster-c832789d-zookeeper-0=8c5821bc-2fd3-4b96-aec1-86f001defb7d} pods didn't roll. Remaining seconds for stability: 7
2022-04-02 16:21:22 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c832789d-zookeeper-2=b5f30ac1-e153-46c0-bd3f-8743ae3d87ca, my-cluster-c832789d-zookeeper-1=43819985-9d49-4f34-b2b9-2b617f14e752, my-cluster-c832789d-zookeeper-0=8c5821bc-2fd3-4b96-aec1-86f001defb7d} pods didn't roll. Remaining seconds for stability: 6
2022-04-02 16:21:23 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c832789d-zookeeper-2=b5f30ac1-e153-46c0-bd3f-8743ae3d87ca, my-cluster-c832789d-zookeeper-1=43819985-9d49-4f34-b2b9-2b617f14e752, my-cluster-c832789d-zookeeper-0=8c5821bc-2fd3-4b96-aec1-86f001defb7d} pods didn't roll. Remaining seconds for stability: 5
2022-04-02 16:21:24 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c832789d-zookeeper-2=b5f30ac1-e153-46c0-bd3f-8743ae3d87ca, my-cluster-c832789d-zookeeper-1=43819985-9d49-4f34-b2b9-2b617f14e752, my-cluster-c832789d-zookeeper-0=8c5821bc-2fd3-4b96-aec1-86f001defb7d} pods didn't roll. Remaining seconds for stability: 4
2022-04-02 16:21:25 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c832789d-zookeeper-2=b5f30ac1-e153-46c0-bd3f-8743ae3d87ca, my-cluster-c832789d-zookeeper-1=43819985-9d49-4f34-b2b9-2b617f14e752, my-cluster-c832789d-zookeeper-0=8c5821bc-2fd3-4b96-aec1-86f001defb7d} pods didn't roll. Remaining seconds for stability: 3
2022-04-02 16:21:26 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c832789d-zookeeper-2=b5f30ac1-e153-46c0-bd3f-8743ae3d87ca, my-cluster-c832789d-zookeeper-1=43819985-9d49-4f34-b2b9-2b617f14e752, my-cluster-c832789d-zookeeper-0=8c5821bc-2fd3-4b96-aec1-86f001defb7d} pods didn't roll. Remaining seconds for stability: 2
2022-04-02 16:21:27 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c832789d-zookeeper-2=b5f30ac1-e153-46c0-bd3f-8743ae3d87ca, my-cluster-c832789d-zookeeper-1=43819985-9d49-4f34-b2b9-2b617f14e752, my-cluster-c832789d-zookeeper-0=8c5821bc-2fd3-4b96-aec1-86f001defb7d} pods didn't roll. Remaining seconds for stability: 1
2022-04-02 16:21:28 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c832789d-zookeeper-2=b5f30ac1-e153-46c0-bd3f-8743ae3d87ca, my-cluster-c832789d-zookeeper-1=43819985-9d49-4f34-b2b9-2b617f14e752, my-cluster-c832789d-zookeeper-0=8c5821bc-2fd3-4b96-aec1-86f001defb7d} pods didn't roll. Remaining seconds for stability: 0
2022-04-02 16:21:28 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-c832789d-kafka rolling update
2022-04-02 16:21:48 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-c832789d-kafka has been successfully rolled
2022-04-02 16:21:48 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-c832789d-kafka to be ready
2022-04-02 16:22:16 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-c832789d-entity-operator rolling update
2022-04-02 16:22:21 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-c832789d-entity-operator will be ready
2022-04-02 16:22:57 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-c832789d-entity-operator is ready
2022-04-02 16:23:07 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-c832789d-entity-operator rolling update finished
2022-04-02 16:23:07 [main] [32mINFO [m [SecurityST:1624] Initial ClientsCA cert dates: Sat Apr 02 16:19:30 UTC 2022 --> Fri Apr 22 16:19:30 UTC 2022
2022-04-02 16:23:07 [main] [32mINFO [m [SecurityST:1625] Changed ClientsCA cert dates: Sat Apr 02 16:20:38 UTC 2022 --> Wed Oct 19 16:20:38 UTC 2022
2022-04-02 16:23:07 [main] [32mINFO [m [SecurityST:1626] Initial userCert dates: Sat Apr 02 16:20:37 UTC 2022 --> Fri Apr 22 16:20:37 UTC 2022
2022-04-02 16:23:07 [main] [32mINFO [m [SecurityST:1627] Changed userCert dates: Sat Apr 02 16:22:25 UTC 2022 --> Wed Oct 19 16:22:25 UTC 2022
2022-04-02 16:23:07 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 16:23:07 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testClientsCACertRenew
2022-04-02 16:23:07 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser strimzi-tls-user-714163417 in namespace namespace-72
2022-04-02 16:23:07 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-c832789d in namespace namespace-72
2022-04-02 16:23:17 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 16:23:17 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-72 for test case:testClientsCACertRenew
2022-04-02 16:24:00 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testClientsCACertRenew-FINISHED
2022-04-02 16:24:00 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 16:24:00 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 16:24:00 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testCertificates-STARTED
2022-04-02 16:24:00 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 16:24:00 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-73 for test case:testCertificates
2022-04-02 16:24:00 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-73
2022-04-02 16:24:00 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-73
2022-04-02 16:24:00 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-73
2022-04-02 16:24:00 [main] [32mINFO [m [SecurityST:118] Running testCertificates my-cluster-66c2c4ca
2022-04-02 16:24:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-66c2c4ca in namespace namespace-73
2022-04-02 16:24:00 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-73
2022-04-02 16:24:00 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-66c2c4ca will have desired state: Ready
2022-04-02 16:25:21 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-66c2c4ca is in desired state: Ready
2022-04-02 16:25:21 [main] [32mINFO [m [SecurityST:122] Check Kafka bootstrap certificate
2022-04-02 16:25:21 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-66c2c4ca-kafka-0 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-66c2c4ca-kafka-bootstrap:9093 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-66c2c4ca-kafka-bootstrap
2022-04-02 16:25:21 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 16:25:21 [main] [32mINFO [m [SecurityST:125] OPENSSL OUTPUT: 

CONNECTED(00000003)
---
Certificate chain
 0 s:O = io.strimzi, CN = my-cluster-66c2c4ca-kafka
   i:O = io.strimzi, CN = cluster-ca v0
-----BEGIN CERTIFICATE-----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-----END CERTIFICATE-----
 1 s:O = io.strimzi, CN = cluster-ca v0
   i:O = io.strimzi, CN = cluster-ca v0
-----BEGIN CERTIFICATE-----
MIIFLTCCAxWgAwIBAgIUWIc/ebgvTsrvjfdWRcVDtvcIqb4wDQYJKoZIhvcNAQEN
BQAwLTETMBEGA1UECgwKaW8uc3RyaW16aTEWMBQGA1UEAwwNY2x1c3Rlci1jYSB2
MDAeFw0yMjA0MDIxNjI0MDBaFw0yMzA0MDIxNjI0MDBaMC0xEzARBgNVBAoMCmlv
LnN0cmltemkxFjAUBgNVBAMMDWNsdXN0ZXItY2EgdjAwggIiMA0GCSqGSIb3DQEB
AQUAA4ICDwAwggIKAoICAQDAmZojl4EleW2GODvQUlxk7Ffv1DQGeuk7bS+2ja/H
xuG0+7Jax99m1WnYjCzZiOKBXJTp5w+O+q889Z4V9IY87xMR0mbRkNO7+MDI2HB8
sMStPBib1rp8MvH/lwFXu9F+K2jukEssBo+kCu6OJPxR+VKTDxrWZLalL8rNXJnT
JNmfE+hJ90wnKM9MX9AXFlzVgIZIjz7twbFRA9gxb2EWOxnSfSVJ8qW/6sZmWf4c
DRWWhfK4VTwlDjy06jURPw8h4YuHq/flzhi4yRjiLH4ww9GO2UB5J6WzjrCYarMT
hxmlXiPdUQaS74kcLlO0+l+F7eiL6arU2SJgMHNpJ5ZDy7rxUa6jXA94WbjG7zlW
bNcnwxTCCUuXygFNOrjmTOtN1ZxHIO4YkdRLLGWl80griI+OAoEK70lVP50TCOiw
BeR/agHXeuQ44RV9rZSOeeJtFxooG3jSpxJ575WOCISs/RpmF+29D61XbCE0kY7B
2BccG06GfDO0syZ7GxNtp0Lhr3CTuXLLV4upD66IyoChvpx3MgzaQIEBMBToSAil
vPABQHE3Si7br/IkpP3NrIjJ/qhvuGd/DfzABuYWNZLUv7calCUGqoWelZkqkrvv
Fo6DPlY43zqYCa6EaD4t2gOKKCI8d6WWoBlu20YQDXDv7+wD+Qmr3UNQ0Zom2vKs
GwIDAQABo0UwQzAdBgNVHQ4EFgQUQMa7bB08rxBmiiM770xFffsmf9UwEgYDVR0T
AQH/BAgwBgEB/wIBADAOBgNVHQ8BAf8EBAMCAQYwDQYJKoZIhvcNAQENBQADggIB
AAZ96O4P1EYLtdWSYLqZnmuQz3rJgWfXgwX7l6jH9vTqKReBkTACl2IWYV/kDTZz
n/9azuXKpGPtDyrvuFpbJaSyr84/va/k0856aomogkhWm7Cqi+wpFB+73+yKKyE5
0fMisRoJqQJRP2YmHCQxxK7oPRv984BRqeOvX1TPv3NU1Rip41I5aQEq7NkG5e7o
ujQSXvKwDJR/SlHm+KkReMwwO3iaFOvRY3KqO207CujYdbdYoE1ZByHEn5x+/+T/
j1dSYDIxePt/PPYN5ANflIwcFEILtDkWelKpWuqHy0gt0BmrWFAtSsHHchrHOQDF
I08QcidR4k1ErKSsSpQlMyw2TzXpTOQnMtPh2XyJY1AItpMycgKpUkYSedKWAjCx
Zc1RMjFafUwymMOHwIDoejeK3hNGI9aaSSWtGDN964R8QYM0Fias9hKNzFY0dFGR
J+c8bUz97NLYiYLYPWNFjXm3yY3RwKCzMXmwvFt4QpsKRzDFyXBRAweQcp+z0vP0
4Ff5zaLLxIRVdMyJpUiPzHO0zgGHX26gBOsKigf3slAKZpZSSYqjy06TAqBDBi5K
Ucv3MbTAEyBraL5lprAqfqPktv0eyJvinsu6cBT/XxrnXl4P2sOSLJJdVtYeA9aX
Yfo60NwkUOmbO03OVK8yEaGNgYx627/Nx4+Pn5RL459z
-----END CERTIFICATE-----
---
Server certificate
subject=O = io.strimzi, CN = my-cluster-66c2c4ca-kafka

issuer=O = io.strimzi, CN = cluster-ca v0

---
No client certificate CA names sent
Peer signing digest: SHA256
Peer signature type: RSA-PSS
Server Temp Key: X25519, 253 bits
---
SSL handshake has read 3489 bytes and written 369 bytes
Verification: OK
Verified peername: my-cluster-66c2c4ca-kafka-bootstrap
---
New, TLSv1.3, Cipher is TLS_AES_256_GCM_SHA384
Server public key is 2048 bit
Secure Renegotiation IS NOT supported
Compression: NONE
Expansion: NONE
No ALPN negotiated
Early data was not sent
Verify return code: 0 (ok)
---



2022-04-02 16:25:21 [main] [32mINFO [m [SecurityST:128] Check zookeeper client certificate
2022-04-02 16:25:21 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-66c2c4ca-kafka-0 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-66c2c4ca-zookeeper-client:2181 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-66c2c4ca-zookeeper-client -cert /opt/kafka/broker-certs/my-cluster-66c2c4ca-kafka-0.crt -key /opt/kafka/broker-certs/my-cluster-66c2c4ca-kafka-0.key
2022-04-02 16:25:21 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 16:25:21 [main] [32mINFO [m [SecurityST:139] Checking certificates for podId 0
2022-04-02 16:25:21 [main] [32mINFO [m [SecurityST:141] Check kafka certificate for port 9091
2022-04-02 16:25:21 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-66c2c4ca-kafka-0 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-66c2c4ca-kafka-0.my-cluster-66c2c4ca-kafka-brokers:9091 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-66c2c4ca-kafka-0.my-cluster-66c2c4ca-kafka-brokers.namespace-73.svc.cluster.local -cert /opt/kafka/broker-certs/my-cluster-66c2c4ca-kafka-0.crt -key /opt/kafka/broker-certs/my-cluster-66c2c4ca-kafka-0.key
2022-04-02 16:25:21 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 16:25:21 [main] [32mINFO [m [SecurityST:141] Check kafka certificate for port 9093
2022-04-02 16:25:22 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-66c2c4ca-kafka-0 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-66c2c4ca-kafka-0.my-cluster-66c2c4ca-kafka-brokers:9093 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-66c2c4ca-kafka-0.my-cluster-66c2c4ca-kafka-brokers.namespace-73.svc.cluster.local -cert /opt/kafka/broker-certs/my-cluster-66c2c4ca-kafka-0.crt -key /opt/kafka/broker-certs/my-cluster-66c2c4ca-kafka-0.key
2022-04-02 16:25:22 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 16:25:22 [main] [32mINFO [m [SecurityST:148] Check zookeeper certificate for port 2181
2022-04-02 16:25:22 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-66c2c4ca-zookeeper-0 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-66c2c4ca-zookeeper-0.my-cluster-66c2c4ca-zookeeper-nodes:2181 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-66c2c4ca-zookeeper-0.my-cluster-66c2c4ca-zookeeper-nodes.namespace-73.svc.cluster.local -cert /opt/kafka/zookeeper-node-certs/my-cluster-66c2c4ca-zookeeper-0.crt -key /opt/kafka/zookeeper-node-certs/my-cluster-66c2c4ca-zookeeper-0.key
2022-04-02 16:25:22 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 16:25:22 [main] [32mINFO [m [SecurityST:148] Check zookeeper certificate for port 3888
2022-04-02 16:25:22 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-66c2c4ca-zookeeper-0 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-66c2c4ca-zookeeper-0.my-cluster-66c2c4ca-zookeeper-nodes:3888 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-66c2c4ca-zookeeper-0.my-cluster-66c2c4ca-zookeeper-nodes.namespace-73.svc.cluster.local -cert /opt/kafka/zookeeper-node-certs/my-cluster-66c2c4ca-zookeeper-0.crt -key /opt/kafka/zookeeper-node-certs/my-cluster-66c2c4ca-zookeeper-0.key
2022-04-02 16:25:22 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 16:25:22 [main] [32mINFO [m [SecurityST:139] Checking certificates for podId 1
2022-04-02 16:25:22 [main] [32mINFO [m [SecurityST:141] Check kafka certificate for port 9091
2022-04-02 16:25:22 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-66c2c4ca-kafka-1 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-66c2c4ca-kafka-1.my-cluster-66c2c4ca-kafka-brokers:9091 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-66c2c4ca-kafka-1.my-cluster-66c2c4ca-kafka-brokers.namespace-73.svc.cluster.local -cert /opt/kafka/broker-certs/my-cluster-66c2c4ca-kafka-1.crt -key /opt/kafka/broker-certs/my-cluster-66c2c4ca-kafka-1.key
2022-04-02 16:25:22 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 16:25:22 [main] [32mINFO [m [SecurityST:141] Check kafka certificate for port 9093
2022-04-02 16:25:22 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-66c2c4ca-kafka-1 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-66c2c4ca-kafka-1.my-cluster-66c2c4ca-kafka-brokers:9093 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-66c2c4ca-kafka-1.my-cluster-66c2c4ca-kafka-brokers.namespace-73.svc.cluster.local -cert /opt/kafka/broker-certs/my-cluster-66c2c4ca-kafka-1.crt -key /opt/kafka/broker-certs/my-cluster-66c2c4ca-kafka-1.key
2022-04-02 16:25:22 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 16:25:22 [main] [32mINFO [m [SecurityST:148] Check zookeeper certificate for port 2181
2022-04-02 16:25:23 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-66c2c4ca-zookeeper-1 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-66c2c4ca-zookeeper-1.my-cluster-66c2c4ca-zookeeper-nodes:2181 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-66c2c4ca-zookeeper-1.my-cluster-66c2c4ca-zookeeper-nodes.namespace-73.svc.cluster.local -cert /opt/kafka/zookeeper-node-certs/my-cluster-66c2c4ca-zookeeper-1.crt -key /opt/kafka/zookeeper-node-certs/my-cluster-66c2c4ca-zookeeper-1.key
2022-04-02 16:25:23 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 16:25:23 [main] [32mINFO [m [SecurityST:148] Check zookeeper certificate for port 3888
2022-04-02 16:25:23 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-66c2c4ca-zookeeper-1 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-66c2c4ca-zookeeper-1.my-cluster-66c2c4ca-zookeeper-nodes:3888 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-66c2c4ca-zookeeper-1.my-cluster-66c2c4ca-zookeeper-nodes.namespace-73.svc.cluster.local -cert /opt/kafka/zookeeper-node-certs/my-cluster-66c2c4ca-zookeeper-1.crt -key /opt/kafka/zookeeper-node-certs/my-cluster-66c2c4ca-zookeeper-1.key
2022-04-02 16:25:23 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 16:25:23 [main] [32mINFO [m [SecurityST:139] Checking certificates for podId 2
2022-04-02 16:25:23 [main] [32mINFO [m [SecurityST:141] Check kafka certificate for port 9091
2022-04-02 16:25:23 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-66c2c4ca-kafka-2 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-66c2c4ca-kafka-2.my-cluster-66c2c4ca-kafka-brokers:9091 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-66c2c4ca-kafka-2.my-cluster-66c2c4ca-kafka-brokers.namespace-73.svc.cluster.local -cert /opt/kafka/broker-certs/my-cluster-66c2c4ca-kafka-2.crt -key /opt/kafka/broker-certs/my-cluster-66c2c4ca-kafka-2.key
2022-04-02 16:25:23 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 16:25:23 [main] [32mINFO [m [SecurityST:141] Check kafka certificate for port 9093
2022-04-02 16:25:23 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-66c2c4ca-kafka-2 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-66c2c4ca-kafka-2.my-cluster-66c2c4ca-kafka-brokers:9093 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-66c2c4ca-kafka-2.my-cluster-66c2c4ca-kafka-brokers.namespace-73.svc.cluster.local -cert /opt/kafka/broker-certs/my-cluster-66c2c4ca-kafka-2.crt -key /opt/kafka/broker-certs/my-cluster-66c2c4ca-kafka-2.key
2022-04-02 16:25:23 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 16:25:23 [main] [32mINFO [m [SecurityST:148] Check zookeeper certificate for port 2181
2022-04-02 16:25:23 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-66c2c4ca-zookeeper-2 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-66c2c4ca-zookeeper-2.my-cluster-66c2c4ca-zookeeper-nodes:2181 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-66c2c4ca-zookeeper-2.my-cluster-66c2c4ca-zookeeper-nodes.namespace-73.svc.cluster.local -cert /opt/kafka/zookeeper-node-certs/my-cluster-66c2c4ca-zookeeper-2.crt -key /opt/kafka/zookeeper-node-certs/my-cluster-66c2c4ca-zookeeper-2.key
2022-04-02 16:25:23 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 16:25:23 [main] [32mINFO [m [SecurityST:148] Check zookeeper certificate for port 3888
2022-04-02 16:25:24 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-66c2c4ca-zookeeper-2 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-66c2c4ca-zookeeper-2.my-cluster-66c2c4ca-zookeeper-nodes:3888 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-66c2c4ca-zookeeper-2.my-cluster-66c2c4ca-zookeeper-nodes.namespace-73.svc.cluster.local -cert /opt/kafka/zookeeper-node-certs/my-cluster-66c2c4ca-zookeeper-2.crt -key /opt/kafka/zookeeper-node-certs/my-cluster-66c2c4ca-zookeeper-2.key
2022-04-02 16:25:24 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 16:25:24 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 16:25:24 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCertificates
2022-04-02 16:25:24 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-66c2c4ca in namespace namespace-73
2022-04-02 16:25:34 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 16:25:34 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-73 for test case:testCertificates
2022-04-02 16:26:16 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testCertificates-FINISHED
2022-04-02 16:26:16 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 16:26:16 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 16:26:16 [main] [32mINFO [m [ResourceManager:346] In context SecurityST is everything deleted.
2022-04-02 16:26:16 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 18, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9,534.23 s - in io.strimzi.systemtest.security.SecurityST
[[1;34mINFO[m] Running io.strimzi.systemtest.rollingupdate.AlternativeReconcileTriggersST
2022-04-02 16:26:21 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: alternative-reconcile-triggers-st
2022-04-02 16:26:21 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: alternative-reconcile-triggers-st
2022-04-02 16:26:21 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: alternative-reconcile-triggers-st
2022-04-02 16:26:21 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 16:26:21 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.AlternativeReconcileTriggersST.testManualRollingUpdateForSinglePod-STARTED
2022-04-02 16:26:21 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 16:26:21 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-74 for test case:testManualRollingUpdateForSinglePod
2022-04-02 16:26:21 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-74
2022-04-02 16:26:21 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-74
2022-04-02 16:26:21 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-74
2022-04-02 16:26:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-055e2729 in namespace namespace-74
2022-04-02 16:26:21 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-74
2022-04-02 16:26:21 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-055e2729 will have desired state: Ready
2022-04-02 16:27:39 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-055e2729 is in desired state: Ready
2022-04-02 16:27:39 [main] [32mINFO [m [AlternativeReconcileTriggersST:290] Trying to roll just single Kafka and single ZK pod
2022-04-02 16:27:40 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-055e2729-kafka rolling update
2022-04-02 16:27:55 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-055e2729-kafka has been successfully rolled
2022-04-02 16:27:55 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-055e2729-kafka to be ready
2022-04-02 16:28:20 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-055e2729 will have desired state: Ready
2022-04-02 16:28:20 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-055e2729 is in desired state: Ready
2022-04-02 16:28:20 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-055e2729 is ready
2022-04-02 16:28:20 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-055e2729-zookeeper rolling update
2022-04-02 16:28:30 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-055e2729-zookeeper has been successfully rolled
2022-04-02 16:28:30 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-055e2729-zookeeper to be ready
2022-04-02 16:29:05 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-055e2729 will have desired state: Ready
2022-04-02 16:29:05 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-055e2729 is in desired state: Ready
2022-04-02 16:29:05 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-055e2729 is ready
2022-04-02 16:29:05 [main] [32mINFO [m [AlternativeReconcileTriggersST:311] Adding anno to all ZK and Kafka pods
2022-04-02 16:29:05 [main] [32mINFO [m [AlternativeReconcileTriggersST:320] Checking if the rolling update will be successful for Kafka
2022-04-02 16:29:05 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-055e2729-kafka rolling update
2022-04-02 16:30:35 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-055e2729-kafka has been successfully rolled
2022-04-02 16:30:35 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-055e2729-kafka to be ready
2022-04-02 16:30:59 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-055e2729 will have desired state: Ready
2022-04-02 16:30:59 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-055e2729 is in desired state: Ready
2022-04-02 16:30:59 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-055e2729 is ready
2022-04-02 16:30:59 [main] [32mINFO [m [AlternativeReconcileTriggersST:331] Checking if the rolling update will be successful for ZK
2022-04-02 16:30:59 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-055e2729-zookeeper rolling update
2022-04-02 16:32:19 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-055e2729-zookeeper has been successfully rolled
2022-04-02 16:32:19 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-055e2729-zookeeper to be ready
2022-04-02 16:32:46 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-055e2729 will have desired state: Ready
2022-04-02 16:32:46 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-055e2729 is in desired state: Ready
2022-04-02 16:32:46 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-055e2729 is ready
2022-04-02 16:32:46 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 16:32:46 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testManualRollingUpdateForSinglePod
2022-04-02 16:32:46 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-055e2729 in namespace namespace-74
2022-04-02 16:32:56 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 16:32:56 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-74 for test case:testManualRollingUpdateForSinglePod
2022-04-02 16:33:40 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.AlternativeReconcileTriggersST.testManualRollingUpdateForSinglePod-FINISHED
2022-04-02 16:33:40 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 16:33:40 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 16:33:40 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.AlternativeReconcileTriggersST.testManualTriggeringRollingUpdate-STARTED
2022-04-02 16:33:40 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 16:33:40 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-75 for test case:testManualTriggeringRollingUpdate
2022-04-02 16:33:40 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-75
2022-04-02 16:33:40 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-75
2022-04-02 16:33:40 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-75
2022-04-02 16:33:40 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-65f2b263 in namespace namespace-75
2022-04-02 16:33:40 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-75
2022-04-02 16:33:40 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-65f2b263 will have desired state: Ready
2022-04-02 16:34:55 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-65f2b263 is in desired state: Ready
2022-04-02 16:34:55 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-877019258-2124546721 in namespace namespace-75
2022-04-02 16:34:55 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-75
2022-04-02 16:34:55 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-877019258-2124546721 will have desired state: Ready
2022-04-02 16:34:56 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-877019258-2124546721 is in desired state: Ready
2022-04-02 16:34:56 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic continuous-topic in namespace namespace-75
2022-04-02 16:34:56 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-75
2022-04-02 16:34:56 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: continuous-topic will have desired state: Ready
2022-04-02 16:34:57 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: continuous-topic is in desired state: Ready
2022-04-02 16:34:57 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-02 16:34:57 [main] [32mINFO [m [ResourceManager:155] Create/Update Job hello-world-producer in namespace namespace-75
2022-04-02 16:34:57 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-75
2022-04-02 16:34:57 [main] [32mINFO [m [JobUtils:81] Waiting for job: hello-world-producer will be in active state
2022-04-02 16:34:58 [main] [32mINFO [m [ResourceManager:155] Create/Update Job hello-world-consumer in namespace namespace-75
2022-04-02 16:34:58 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-75
2022-04-02 16:34:58 [main] [32mINFO [m [JobUtils:81] Waiting for job: hello-world-consumer will be in active state
2022-04-02 16:34:59 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1569100419-1062005354 in namespace namespace-75
2022-04-02 16:34:59 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-75
2022-04-02 16:34:59 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1569100419-1062005354 will have desired state: Ready
2022-04-02 16:35:00 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1569100419-1062005354 is in desired state: Ready
2022-04-02 16:35:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-65f2b263-kafka-clients in namespace namespace-75
2022-04-02 16:35:00 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-75
2022-04-02 16:35:10 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-02 16:35:10 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@5a62d013, messages=[], arguments=[USER=my_user_1569100419_1062005354, --max-messages, 100, --topic, my-topic-877019258-2124546721, --bootstrap-server, my-cluster-65f2b263-kafka-bootstrap.namespace-75.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-65f2b263-kafka-clients-688fd47dd9-rh5nd', podNamespace='namespace-75', bootstrapServer='my-cluster-65f2b263-kafka-bootstrap.namespace-75.svc:9093', topicName='my-topic-877019258-2124546721', maxMessages=100, kafkaUsername='my-user-1569100419-1062005354', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@c61ac89}
2022-04-02 16:35:10 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-65f2b263-kafka-bootstrap.namespace-75.svc:9093:my-topic-877019258-2124546721 from pod my-cluster-65f2b263-kafka-clients-688fd47dd9-rh5nd
2022-04-02 16:35:10 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-65f2b263-kafka-clients-688fd47dd9-rh5nd -n namespace-75 -- /opt/kafka/producer.sh USER=my_user_1569100419_1062005354 --max-messages 100 --topic my-topic-877019258-2124546721 --bootstrap-server my-cluster-65f2b263-kafka-bootstrap.namespace-75.svc:9093
2022-04-02 16:35:14 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-02 16:35:14 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-02 16:35:14 [main] [32mINFO [m [AlternativeReconcileTriggersST:145] Annotate Kafka StatefulSet my-cluster-65f2b263-kafka with manual rolling update annotation
2022-04-02 16:35:14 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-65f2b263-kafka rolling update
2022-04-02 16:36:44 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-65f2b263-kafka has been successfully rolled
2022-04-02 16:36:44 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-65f2b263-kafka to be ready
2022-04-02 16:37:11 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-65f2b263 will have desired state: Ready
2022-04-02 16:37:11 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-65f2b263 is in desired state: Ready
2022-04-02 16:37:11 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-65f2b263 is ready
2022-04-02 16:37:11 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@6baa2c79, messages=[], arguments=[USER=my_user_1569100419_1062005354, --max-messages, 100, --group-instance-id, instance1768721715, --group-id, my-consumer-group-408218251, --topic, my-topic-877019258-2124546721, --bootstrap-server, my-cluster-65f2b263-kafka-bootstrap.namespace-75.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-65f2b263-kafka-clients-688fd47dd9-rh5nd', podNamespace='namespace-75', bootstrapServer='my-cluster-65f2b263-kafka-bootstrap.namespace-75.svc:9093', topicName='my-topic-877019258-2124546721', maxMessages=100, kafkaUsername='my-user-1569100419-1062005354', consumerGroupName='my-consumer-group-408218251', consumerInstanceId='instance1768721715', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@b35f953}
2022-04-02 16:37:11 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-65f2b263-kafka-bootstrap.namespace-75.svc:9093:my-topic-877019258-2124546721 from pod my-cluster-65f2b263-kafka-clients-688fd47dd9-rh5nd
2022-04-02 16:37:11 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-65f2b263-kafka-clients-688fd47dd9-rh5nd -n namespace-75 -- /opt/kafka/consumer.sh USER=my_user_1569100419_1062005354 --max-messages 100 --group-instance-id instance1768721715 --group-id my-consumer-group-408218251 --topic my-topic-877019258-2124546721 --bootstrap-server my-cluster-65f2b263-kafka-bootstrap.namespace-75.svc:9093
2022-04-02 16:37:18 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-02 16:37:18 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-02 16:37:18 [main] [32mINFO [m [AlternativeReconcileTriggersST:166] Annotate Zookeeper StatefulSet my-cluster-65f2b263-zookeeper with manual rolling update annotation
2022-04-02 16:37:18 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-65f2b263-zookeeper rolling update
2022-04-02 16:38:18 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-65f2b263-zookeeper has been successfully rolled
2022-04-02 16:38:18 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-65f2b263-zookeeper to be ready
2022-04-02 16:38:53 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-65f2b263 will have desired state: Ready
2022-04-02 16:38:53 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-65f2b263 is in desired state: Ready
2022-04-02 16:38:53 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-65f2b263 is ready
2022-04-02 16:38:53 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@2004f524, messages=[], arguments=[USER=my_user_1569100419_1062005354, --max-messages, 100, --group-instance-id, instance599555246, --group-id, my-consumer-group-81866722, --topic, my-topic-877019258-2124546721, --bootstrap-server, my-cluster-65f2b263-kafka-bootstrap.namespace-75.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-65f2b263-kafka-clients-688fd47dd9-rh5nd', podNamespace='namespace-75', bootstrapServer='my-cluster-65f2b263-kafka-bootstrap.namespace-75.svc:9093', topicName='my-topic-877019258-2124546721', maxMessages=100, kafkaUsername='my-user-1569100419-1062005354', consumerGroupName='my-consumer-group-81866722', consumerInstanceId='instance599555246', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@29378251}
2022-04-02 16:38:53 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-65f2b263-kafka-bootstrap.namespace-75.svc:9093:my-topic-877019258-2124546721 from pod my-cluster-65f2b263-kafka-clients-688fd47dd9-rh5nd
2022-04-02 16:38:53 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-65f2b263-kafka-clients-688fd47dd9-rh5nd -n namespace-75 -- /opt/kafka/consumer.sh USER=my_user_1569100419_1062005354 --max-messages 100 --group-instance-id instance599555246 --group-id my-consumer-group-81866722 --topic my-topic-877019258-2124546721 --bootstrap-server my-cluster-65f2b263-kafka-bootstrap.namespace-75.svc:9093
2022-04-02 16:39:00 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-02 16:39:00 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-02 16:39:00 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-285153938-525394058 in namespace namespace-75
2022-04-02 16:39:00 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-75
2022-04-02 16:39:00 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-285153938-525394058 will have desired state: Ready
2022-04-02 16:39:01 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-285153938-525394058 is in desired state: Ready
2022-04-02 16:39:01 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@fc3c0c6, messages=[], arguments=[USER=my_user_1569100419_1062005354, --max-messages, 100, --topic, my-topic-285153938-525394058, --bootstrap-server, my-cluster-65f2b263-kafka-bootstrap.namespace-75.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-65f2b263-kafka-clients-688fd47dd9-rh5nd', podNamespace='namespace-75', bootstrapServer='my-cluster-65f2b263-kafka-bootstrap.namespace-75.svc:9093', topicName='my-topic-285153938-525394058', maxMessages=100, kafkaUsername='my-user-1569100419-1062005354', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1a73ecd3}
2022-04-02 16:39:01 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-65f2b263-kafka-bootstrap.namespace-75.svc:9093:my-topic-285153938-525394058 from pod my-cluster-65f2b263-kafka-clients-688fd47dd9-rh5nd
2022-04-02 16:39:01 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-65f2b263-kafka-clients-688fd47dd9-rh5nd -n namespace-75 -- /opt/kafka/producer.sh USER=my_user_1569100419_1062005354 --max-messages 100 --topic my-topic-285153938-525394058 --bootstrap-server my-cluster-65f2b263-kafka-bootstrap.namespace-75.svc:9093
2022-04-02 16:39:04 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-02 16:39:04 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-02 16:39:04 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@6e426e43, messages=[], arguments=[USER=my_user_1569100419_1062005354, --max-messages, 100, --group-instance-id, instance1183986294, --group-id, my-consumer-group-406149802, --topic, my-topic-285153938-525394058, --bootstrap-server, my-cluster-65f2b263-kafka-bootstrap.namespace-75.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-65f2b263-kafka-clients-688fd47dd9-rh5nd', podNamespace='namespace-75', bootstrapServer='my-cluster-65f2b263-kafka-bootstrap.namespace-75.svc:9093', topicName='my-topic-285153938-525394058', maxMessages=100, kafkaUsername='my-user-1569100419-1062005354', consumerGroupName='my-consumer-group-406149802', consumerInstanceId='instance1183986294', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@8e9a9cf}
2022-04-02 16:39:04 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-65f2b263-kafka-bootstrap.namespace-75.svc:9093:my-topic-285153938-525394058 from pod my-cluster-65f2b263-kafka-clients-688fd47dd9-rh5nd
2022-04-02 16:39:04 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-65f2b263-kafka-clients-688fd47dd9-rh5nd -n namespace-75 -- /opt/kafka/consumer.sh USER=my_user_1569100419_1062005354 --max-messages 100 --group-instance-id instance1183986294 --group-id my-consumer-group-406149802 --topic my-topic-285153938-525394058 --bootstrap-server my-cluster-65f2b263-kafka-bootstrap.namespace-75.svc:9093
2022-04-02 16:39:11 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-02 16:39:11 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-02 16:39:11 [main] [32mINFO [m [ClientUtils:61] Waiting till producer hello-world-producer and consumer hello-world-consumer finish
2022-04-02 16:43:38 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 16:43:38 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testManualTriggeringRollingUpdate
2022-04-02 16:43:38 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1569100419-1062005354 in namespace namespace-75
2022-04-02 16:43:38 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job hello-world-consumer in namespace namespace-75
2022-04-02 16:43:38 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-285153938-525394058 in namespace namespace-75
2022-04-02 16:43:38 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-877019258-2124546721 in namespace namespace-75
2022-04-02 16:43:38 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job hello-world-producer in namespace namespace-75
2022-04-02 16:43:38 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-65f2b263-kafka-clients in namespace namespace-75
2022-04-02 16:43:38 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic continuous-topic in namespace namespace-75
2022-04-02 16:43:38 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-65f2b263 in namespace namespace-75
2022-04-02 16:44:18 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 16:44:18 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-75 for test case:testManualTriggeringRollingUpdate
2022-04-02 16:44:24 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.AlternativeReconcileTriggersST.testManualTriggeringRollingUpdate-FINISHED
2022-04-02 16:44:24 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 16:44:24 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 16:44:24 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.AlternativeReconcileTriggersST.testAddingAndRemovingJbodVolumes-STARTED
2022-04-02 16:44:24 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 16:44:24 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-76 for test case:testAddingAndRemovingJbodVolumes
2022-04-02 16:44:24 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-76
2022-04-02 16:44:24 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-76
2022-04-02 16:44:24 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-76
2022-04-02 16:44:24 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-d94da6bc in namespace namespace-76
2022-04-02 16:44:24 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-76
2022-04-02 16:44:24 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d94da6bc will have desired state: Ready
2022-04-02 16:46:37 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d94da6bc is in desired state: Ready
2022-04-02 16:46:37 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1804403081-1585876608 in namespace namespace-76
2022-04-02 16:46:37 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-76
2022-04-02 16:46:37 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1804403081-1585876608 will have desired state: Ready
2022-04-02 16:46:38 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1804403081-1585876608 is in desired state: Ready
2022-04-02 16:46:38 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic continuous-topic in namespace namespace-76
2022-04-02 16:46:38 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-76
2022-04-02 16:46:38 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: continuous-topic will have desired state: Ready
2022-04-02 16:46:39 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: continuous-topic is in desired state: Ready
2022-04-02 16:46:39 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-02 16:46:39 [main] [32mINFO [m [ResourceManager:155] Create/Update Job hello-world-producer in namespace namespace-76
2022-04-02 16:46:39 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-76
2022-04-02 16:46:39 [main] [32mINFO [m [JobUtils:81] Waiting for job: hello-world-producer will be in active state
2022-04-02 16:46:40 [main] [32mINFO [m [ResourceManager:155] Create/Update Job hello-world-consumer in namespace namespace-76
2022-04-02 16:46:40 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-76
2022-04-02 16:46:40 [main] [32mINFO [m [JobUtils:81] Waiting for job: hello-world-consumer will be in active state
2022-04-02 16:46:41 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1430498020-1804542112 in namespace namespace-76
2022-04-02 16:46:41 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-76
2022-04-02 16:46:41 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1430498020-1804542112 will have desired state: Ready
2022-04-02 16:46:42 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1430498020-1804542112 is in desired state: Ready
2022-04-02 16:46:42 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-d94da6bc-kafka-clients in namespace namespace-76
2022-04-02 16:46:42 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-76
2022-04-02 16:46:42 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-02 16:46:42 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@691cd57a, messages=[], arguments=[USER=my_user_1430498020_1804542112, --max-messages, 100, --topic, my-topic-1804403081-1585876608, --bootstrap-server, my-cluster-d94da6bc-kafka-bootstrap.namespace-76.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-d94da6bc-kafka-clients-68754f9684-4dnhn', podNamespace='namespace-76', bootstrapServer='my-cluster-d94da6bc-kafka-bootstrap.namespace-76.svc:9093', topicName='my-topic-1804403081-1585876608', maxMessages=100, kafkaUsername='my-user-1430498020-1804542112', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@13aac70b}
2022-04-02 16:46:42 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-d94da6bc-kafka-bootstrap.namespace-76.svc:9093:my-topic-1804403081-1585876608 from pod my-cluster-d94da6bc-kafka-clients-68754f9684-4dnhn
2022-04-02 16:46:42 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-d94da6bc-kafka-clients-68754f9684-4dnhn -n namespace-76 -- /opt/kafka/producer.sh USER=my_user_1430498020_1804542112 --max-messages 100 --topic my-topic-1804403081-1585876608 --bootstrap-server my-cluster-d94da6bc-kafka-bootstrap.namespace-76.svc:9093
2022-04-02 16:46:42 [main] [32mINFO [m [VerifiableClient:199] CLI_KAFKA_VERIFIABLE_PRODUCER RETURN code: 1
2022-04-02 16:46:42 [main] [32mINFO [m [VerifiableClient:206] ======STDERR START=======
2022-04-02 16:46:42 [main] [32mINFO [m [VerifiableClient:207] error: unable to upgrade connection: container not found ("my-cluster-d94da6bc-kafka-clients")

2022-04-02 16:46:42 [main] [32mINFO [m [VerifiableClient:208] ======STDERR END======
2022-04-02 16:46:42 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: false
2022-04-02 16:46:42 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced -1 messages
2022-04-02 16:46:57 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@22313bb1, messages=[], arguments=[USER=my_user_1430498020_1804542112, --max-messages, 100, --topic, my-topic-1804403081-1585876608, --bootstrap-server, my-cluster-d94da6bc-kafka-bootstrap.namespace-76.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-d94da6bc-kafka-clients-68754f9684-4dnhn', podNamespace='namespace-76', bootstrapServer='my-cluster-d94da6bc-kafka-bootstrap.namespace-76.svc:9093', topicName='my-topic-1804403081-1585876608', maxMessages=100, kafkaUsername='my-user-1430498020-1804542112', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@67e62ad9}
2022-04-02 16:46:57 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-d94da6bc-kafka-bootstrap.namespace-76.svc:9093:my-topic-1804403081-1585876608 from pod my-cluster-d94da6bc-kafka-clients-68754f9684-4dnhn
2022-04-02 16:46:57 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-d94da6bc-kafka-clients-68754f9684-4dnhn -n namespace-76 -- /opt/kafka/producer.sh USER=my_user_1430498020_1804542112 --max-messages 100 --topic my-topic-1804403081-1585876608 --bootstrap-server my-cluster-d94da6bc-kafka-bootstrap.namespace-76.svc:9093
2022-04-02 16:47:01 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-02 16:47:01 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-02 16:47:01 [main] [32mINFO [m [AlternativeReconcileTriggersST:408] Add JBOD volume to the Kafka cluster my-cluster-d94da6bc-kafka
2022-04-02 16:47:01 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-d94da6bc-kafka rolling update
2022-04-02 16:48:21 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-d94da6bc-kafka has been successfully rolled
2022-04-02 16:48:21 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-d94da6bc-kafka to be ready
2022-04-02 16:48:52 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d94da6bc will have desired state: Ready
2022-04-02 16:48:52 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d94da6bc is in desired state: Ready
2022-04-02 16:48:52 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-d94da6bc is ready
2022-04-02 16:48:52 [main] [32mINFO [m [AlternativeReconcileTriggersST:419] Remove JBOD volume to the Kafka cluster my-cluster-d94da6bc-kafka
2022-04-02 16:48:52 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-d94da6bc-kafka rolling update
2022-04-02 16:50:02 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-d94da6bc-kafka has been successfully rolled
2022-04-02 16:50:02 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-d94da6bc-kafka to be ready
2022-04-02 16:50:35 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d94da6bc will have desired state: Ready
2022-04-02 16:50:35 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d94da6bc is in desired state: Ready
2022-04-02 16:50:35 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-d94da6bc is ready
2022-04-02 16:50:35 [main] [32mINFO [m [ClientUtils:61] Waiting till producer hello-world-producer and consumer hello-world-consumer finish
2022-04-02 16:55:27 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 16:55:27 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAddingAndRemovingJbodVolumes
2022-04-02 16:55:27 [main] [32mINFO [m [ResourceManager:241] Delete of Job hello-world-consumer in namespace namespace-76
2022-04-02 16:55:27 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-d94da6bc in namespace namespace-76
2022-04-02 16:55:27 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Job hello-world-producer in namespace namespace-76
2022-04-02 16:55:27 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic continuous-topic in namespace namespace-76
2022-04-02 16:55:27 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1804403081-1585876608 in namespace namespace-76
2022-04-02 16:55:27 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-d94da6bc-kafka-clients in namespace namespace-76
2022-04-02 16:55:27 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1430498020-1804542112 in namespace namespace-76
2022-04-02 16:56:17 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 16:56:17 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-76 for test case:testAddingAndRemovingJbodVolumes
2022-04-02 16:56:28 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.AlternativeReconcileTriggersST.testAddingAndRemovingJbodVolumes-FINISHED
2022-04-02 16:56:28 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 16:56:28 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 16:56:28 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.AlternativeReconcileTriggersST.testTriggerRollingUpdateAfterOverrideBootstrap-STARTED
2022-04-02 16:56:28 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 16:56:28 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-77 for test case:testTriggerRollingUpdateAfterOverrideBootstrap
2022-04-02 16:56:28 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-77
2022-04-02 16:56:28 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-77
2022-04-02 16:56:28 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-77
2022-04-02 16:56:28 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-f6c6715f in namespace namespace-77
2022-04-02 16:56:28 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-77
2022-04-02 16:56:28 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-f6c6715f will have desired state: Ready
2022-04-02 16:58:18 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-f6c6715f is in desired state: Ready
2022-04-02 16:58:18 [main] [32mINFO [m [AlternativeReconcileTriggersST:228] Adding new bootstrap dns: kafka-test.XXXX.azure.XXXX.net to external listeners
2022-04-02 16:58:18 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-f6c6715f-kafka rolling update
2022-04-02 16:59:33 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-f6c6715f-kafka has been successfully rolled
2022-04-02 16:59:33 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-f6c6715f-kafka to be ready
2022-04-02 16:59:59 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-f6c6715f will have desired state: Ready
2022-04-02 16:59:59 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-f6c6715f is in desired state: Ready
2022-04-02 16:59:59 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-f6c6715f is ready
2022-04-02 16:59:59 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-f6c6715f will have desired state: Ready
2022-04-02 16:59:59 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-f6c6715f is in desired state: Ready
2022-04-02 16:59:59 [main] [32mINFO [m [AlternativeReconcileTriggersST:258] Encoding my-cluster-f6c6715f-kafka-0.crt cert
2022-04-02 16:59:59 [main] [32mINFO [m [AlternativeReconcileTriggersST:263] Verifying that new DNS is in certificate subject alternative names
2022-04-02 16:59:59 [main] [32mINFO [m [AlternativeReconcileTriggersST:258] Encoding my-cluster-f6c6715f-kafka-1.crt cert
2022-04-02 16:59:59 [main] [32mINFO [m [AlternativeReconcileTriggersST:263] Verifying that new DNS is in certificate subject alternative names
2022-04-02 16:59:59 [main] [32mINFO [m [AlternativeReconcileTriggersST:258] Encoding my-cluster-f6c6715f-kafka-2.crt cert
2022-04-02 16:59:59 [main] [32mINFO [m [AlternativeReconcileTriggersST:263] Verifying that new DNS is in certificate subject alternative names
2022-04-02 16:59:59 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 16:59:59 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTriggerRollingUpdateAfterOverrideBootstrap
2022-04-02 16:59:59 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-f6c6715f in namespace namespace-77
2022-04-02 17:00:09 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 17:00:09 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-77 for test case:testTriggerRollingUpdateAfterOverrideBootstrap
2022-04-02 17:00:36 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.AlternativeReconcileTriggersST.testTriggerRollingUpdateAfterOverrideBootstrap-FINISHED
2022-04-02 17:00:36 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 17:00:36 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 17:00:36 [main] [32mINFO [m [ResourceManager:346] In context AlternativeReconcileTriggersST is everything deleted.
2022-04-02 17:00:36 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2,060.426 s - in io.strimzi.systemtest.rollingupdate.AlternativeReconcileTriggersST
[[1;34mINFO[m] Running io.strimzi.systemtest.rollingupdate.RollingUpdateST
2022-04-02 17:00:41 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: rolling-update-st
2022-04-02 17:00:42 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: rolling-update-st
2022-04-02 17:00:42 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: rolling-update-st
2022-04-02 17:00:42 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 17:00:42 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testMetricsChange-STARTED
2022-04-02 17:00:42 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 17:00:42 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-bb18d178 in namespace rolling-update-st
2022-04-02 17:00:42 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-bb18d178 will have desired state: Ready
2022-04-02 17:02:24 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-bb18d178 is in desired state: Ready
2022-04-02 17:02:24 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-bb18d178-kafka-clients in namespace rolling-update-st
2022-04-02 17:02:34 [main] [32mINFO [m [RollingUpdateST:755] Check if metrics are present in pod of Kafka and Zookeeper
2022-04-02 17:02:35 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.10 from Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn finished with return code: 0
2022-04-02 17:02:35 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.12 from Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn finished with return code: 0
2022-04-02 17:02:36 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.11 from Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn finished with return code: 0
2022-04-02 17:02:37 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.7 from Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn finished with return code: 0
2022-04-02 17:02:37 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.9 from Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn finished with return code: 0
2022-04-02 17:02:37 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.8 from Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn finished with return code: 0
2022-04-02 17:02:37 [main] [32mINFO [m [RollingUpdateST:765] Changing metrics to something else
2022-04-02 17:02:37 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-bb18d178-zookeeper are stable
2022-04-02 17:02:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-02 17:02:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-02 17:02:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-02 17:02:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-02 17:02:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-02 17:02:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-02 17:02:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-02 17:02:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-02 17:02:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-02 17:02:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-02 17:02:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-02 17:02:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-02 17:02:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-02 17:02:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-02 17:02:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-02 17:02:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-02 17:02:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-02 17:02:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-02 17:02:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-02 17:02:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-02 17:02:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-02 17:02:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-02 17:02:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-02 17:02:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-02 17:02:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-02 17:02:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-02 17:02:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-02 17:02:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-02 17:02:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-02 17:02:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-02 17:02:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-02 17:02:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-02 17:02:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-02 17:02:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-02 17:02:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-02 17:02:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-02 17:02:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-02 17:02:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-02 17:02:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-02 17:02:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-02 17:02:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-02 17:02:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-02 17:02:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-02 17:02:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-02 17:02:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-02 17:02:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-02 17:02:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-02 17:02:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-02 17:02:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-02 17:02:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-02 17:02:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-02 17:02:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-02 17:02:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-02 17:02:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-02 17:02:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-02 17:02:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-02 17:02:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-02 17:02:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-02 17:02:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-02 17:02:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-02 17:02:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-02 17:02:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-02 17:02:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-02 17:02:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-02 17:02:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-02 17:02:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-02 17:03:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-02 17:03:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-02 17:03:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-02 17:03:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-02 17:03:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-02 17:03:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-02 17:03:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-02 17:03:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-02 17:03:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-02 17:03:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-02 17:03:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-02 17:03:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-02 17:03:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-02 17:03:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-02 17:03:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-02 17:03:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-02 17:03:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-02 17:03:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-02 17:03:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-02 17:03:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-02 17:03:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-02 17:03:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-02 17:03:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-02 17:03:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-02 17:03:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-02 17:03:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-02 17:03:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-02 17:03:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-02 17:03:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-02 17:03:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-02 17:03:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-02 17:03:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-02 17:03:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-02 17:03:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-02 17:03:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-02 17:03:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-02 17:03:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-02 17:03:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-02 17:03:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-02 17:03:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-02 17:03:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-02 17:03:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-02 17:03:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-02 17:03:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-02 17:03:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-02 17:03:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-02 17:03:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-02 17:03:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-02 17:03:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-02 17:03:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-02 17:03:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-02 17:03:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-02 17:03:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-02 17:03:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-02 17:03:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-02 17:03:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-02 17:03:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-02 17:03:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-02 17:03:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-02 17:03:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-02 17:03:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-02 17:03:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-02 17:03:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-02 17:03:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-02 17:03:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-02 17:03:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-02 17:03:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-02 17:03:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-02 17:03:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-02 17:03:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-02 17:03:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-02 17:03:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-02 17:03:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-02 17:03:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-02 17:03:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-02 17:03:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-02 17:03:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-02 17:03:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-02 17:03:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-02 17:03:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-02 17:03:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-02 17:03:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-02 17:03:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-02 17:03:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-02 17:03:27 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-bb18d178-zookeeper-0 ,my-cluster-bb18d178-zookeeper-1 ,my-cluster-bb18d178-zookeeper-2
2022-04-02 17:03:27 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-bb18d178-kafka are stable
2022-04-02 17:03:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-02 17:03:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-02 17:03:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-02 17:03:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn is in the Running state. Remaining seconds pod to be stable 50
2022-04-02 17:03:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-exporter-54bfbb47b-5w6jf is in the Running state. Remaining seconds pod to be stable 50
2022-04-02 17:03:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-02 17:03:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-02 17:03:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-02 17:03:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn is in the Running state. Remaining seconds pod to be stable 49
2022-04-02 17:03:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-exporter-54bfbb47b-5w6jf is in the Running state. Remaining seconds pod to be stable 49
2022-04-02 17:03:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-02 17:03:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-02 17:03:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-02 17:03:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn is in the Running state. Remaining seconds pod to be stable 48
2022-04-02 17:03:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-exporter-54bfbb47b-5w6jf is in the Running state. Remaining seconds pod to be stable 48
2022-04-02 17:03:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-02 17:03:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-02 17:03:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-02 17:03:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn is in the Running state. Remaining seconds pod to be stable 47
2022-04-02 17:03:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-exporter-54bfbb47b-5w6jf is in the Running state. Remaining seconds pod to be stable 47
2022-04-02 17:03:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-02 17:03:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-02 17:03:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-02 17:03:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn is in the Running state. Remaining seconds pod to be stable 46
2022-04-02 17:03:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-exporter-54bfbb47b-5w6jf is in the Running state. Remaining seconds pod to be stable 46
2022-04-02 17:03:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-02 17:03:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-02 17:03:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-02 17:03:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn is in the Running state. Remaining seconds pod to be stable 45
2022-04-02 17:03:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-exporter-54bfbb47b-5w6jf is in the Running state. Remaining seconds pod to be stable 45
2022-04-02 17:03:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-02 17:03:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-02 17:03:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-02 17:03:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn is in the Running state. Remaining seconds pod to be stable 44
2022-04-02 17:03:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-exporter-54bfbb47b-5w6jf is in the Running state. Remaining seconds pod to be stable 44
2022-04-02 17:03:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-02 17:03:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-02 17:03:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-02 17:03:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn is in the Running state. Remaining seconds pod to be stable 43
2022-04-02 17:03:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-exporter-54bfbb47b-5w6jf is in the Running state. Remaining seconds pod to be stable 43
2022-04-02 17:03:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-02 17:03:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-02 17:03:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-02 17:03:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn is in the Running state. Remaining seconds pod to be stable 42
2022-04-02 17:03:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-exporter-54bfbb47b-5w6jf is in the Running state. Remaining seconds pod to be stable 42
2022-04-02 17:03:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-02 17:03:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-02 17:03:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-02 17:03:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn is in the Running state. Remaining seconds pod to be stable 41
2022-04-02 17:03:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-exporter-54bfbb47b-5w6jf is in the Running state. Remaining seconds pod to be stable 41
2022-04-02 17:03:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-02 17:03:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-02 17:03:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-02 17:03:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn is in the Running state. Remaining seconds pod to be stable 40
2022-04-02 17:03:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-exporter-54bfbb47b-5w6jf is in the Running state. Remaining seconds pod to be stable 40
2022-04-02 17:03:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-02 17:03:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-02 17:03:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-02 17:03:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn is in the Running state. Remaining seconds pod to be stable 39
2022-04-02 17:03:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-exporter-54bfbb47b-5w6jf is in the Running state. Remaining seconds pod to be stable 39
2022-04-02 17:03:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-02 17:03:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-02 17:03:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-02 17:03:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn is in the Running state. Remaining seconds pod to be stable 38
2022-04-02 17:03:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-exporter-54bfbb47b-5w6jf is in the Running state. Remaining seconds pod to be stable 38
2022-04-02 17:03:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-02 17:03:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-02 17:03:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-02 17:03:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn is in the Running state. Remaining seconds pod to be stable 37
2022-04-02 17:03:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-exporter-54bfbb47b-5w6jf is in the Running state. Remaining seconds pod to be stable 37
2022-04-02 17:03:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-02 17:03:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-02 17:03:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-02 17:03:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn is in the Running state. Remaining seconds pod to be stable 36
2022-04-02 17:03:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-exporter-54bfbb47b-5w6jf is in the Running state. Remaining seconds pod to be stable 36
2022-04-02 17:03:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-02 17:03:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-02 17:03:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-02 17:03:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn is in the Running state. Remaining seconds pod to be stable 35
2022-04-02 17:03:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-exporter-54bfbb47b-5w6jf is in the Running state. Remaining seconds pod to be stable 35
2022-04-02 17:03:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-02 17:03:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-02 17:03:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-02 17:03:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn is in the Running state. Remaining seconds pod to be stable 34
2022-04-02 17:03:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-exporter-54bfbb47b-5w6jf is in the Running state. Remaining seconds pod to be stable 34
2022-04-02 17:03:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-02 17:03:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-02 17:03:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-02 17:03:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn is in the Running state. Remaining seconds pod to be stable 33
2022-04-02 17:03:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-exporter-54bfbb47b-5w6jf is in the Running state. Remaining seconds pod to be stable 33
2022-04-02 17:03:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-02 17:03:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-02 17:03:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-02 17:03:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn is in the Running state. Remaining seconds pod to be stable 32
2022-04-02 17:03:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-exporter-54bfbb47b-5w6jf is in the Running state. Remaining seconds pod to be stable 32
2022-04-02 17:03:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-02 17:03:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-02 17:03:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-02 17:03:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn is in the Running state. Remaining seconds pod to be stable 31
2022-04-02 17:03:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-exporter-54bfbb47b-5w6jf is in the Running state. Remaining seconds pod to be stable 31
2022-04-02 17:03:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-02 17:03:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-02 17:03:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-02 17:03:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn is in the Running state. Remaining seconds pod to be stable 30
2022-04-02 17:03:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-exporter-54bfbb47b-5w6jf is in the Running state. Remaining seconds pod to be stable 30
2022-04-02 17:03:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-02 17:03:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-02 17:03:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-02 17:03:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn is in the Running state. Remaining seconds pod to be stable 29
2022-04-02 17:03:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-exporter-54bfbb47b-5w6jf is in the Running state. Remaining seconds pod to be stable 29
2022-04-02 17:03:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-02 17:03:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-02 17:03:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-02 17:03:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn is in the Running state. Remaining seconds pod to be stable 28
2022-04-02 17:03:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-exporter-54bfbb47b-5w6jf is in the Running state. Remaining seconds pod to be stable 28
2022-04-02 17:03:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-02 17:03:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-02 17:03:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-02 17:03:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn is in the Running state. Remaining seconds pod to be stable 27
2022-04-02 17:03:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-exporter-54bfbb47b-5w6jf is in the Running state. Remaining seconds pod to be stable 27
2022-04-02 17:03:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-02 17:03:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-02 17:03:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-02 17:03:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn is in the Running state. Remaining seconds pod to be stable 26
2022-04-02 17:03:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-exporter-54bfbb47b-5w6jf is in the Running state. Remaining seconds pod to be stable 26
2022-04-02 17:03:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-02 17:03:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-02 17:03:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-02 17:03:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn is in the Running state. Remaining seconds pod to be stable 25
2022-04-02 17:03:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-exporter-54bfbb47b-5w6jf is in the Running state. Remaining seconds pod to be stable 25
2022-04-02 17:03:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-02 17:03:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-02 17:03:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-02 17:03:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn is in the Running state. Remaining seconds pod to be stable 24
2022-04-02 17:03:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-exporter-54bfbb47b-5w6jf is in the Running state. Remaining seconds pod to be stable 24
2022-04-02 17:03:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-02 17:03:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-02 17:03:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-02 17:03:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn is in the Running state. Remaining seconds pod to be stable 23
2022-04-02 17:03:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-exporter-54bfbb47b-5w6jf is in the Running state. Remaining seconds pod to be stable 23
2022-04-02 17:03:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-02 17:03:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-02 17:03:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-02 17:03:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn is in the Running state. Remaining seconds pod to be stable 22
2022-04-02 17:03:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-exporter-54bfbb47b-5w6jf is in the Running state. Remaining seconds pod to be stable 22
2022-04-02 17:03:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-02 17:03:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-02 17:03:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-02 17:03:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn is in the Running state. Remaining seconds pod to be stable 21
2022-04-02 17:03:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-exporter-54bfbb47b-5w6jf is in the Running state. Remaining seconds pod to be stable 21
2022-04-02 17:03:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-02 17:03:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-02 17:03:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-02 17:03:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn is in the Running state. Remaining seconds pod to be stable 20
2022-04-02 17:03:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-exporter-54bfbb47b-5w6jf is in the Running state. Remaining seconds pod to be stable 20
2022-04-02 17:03:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-02 17:03:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-02 17:03:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-02 17:03:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn is in the Running state. Remaining seconds pod to be stable 19
2022-04-02 17:03:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-exporter-54bfbb47b-5w6jf is in the Running state. Remaining seconds pod to be stable 19
2022-04-02 17:03:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-02 17:03:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-02 17:03:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-02 17:03:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn is in the Running state. Remaining seconds pod to be stable 18
2022-04-02 17:03:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-exporter-54bfbb47b-5w6jf is in the Running state. Remaining seconds pod to be stable 18
2022-04-02 17:04:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-02 17:04:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-02 17:04:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-02 17:04:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn is in the Running state. Remaining seconds pod to be stable 17
2022-04-02 17:04:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-exporter-54bfbb47b-5w6jf is in the Running state. Remaining seconds pod to be stable 17
2022-04-02 17:04:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-02 17:04:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-02 17:04:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-02 17:04:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn is in the Running state. Remaining seconds pod to be stable 16
2022-04-02 17:04:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-exporter-54bfbb47b-5w6jf is in the Running state. Remaining seconds pod to be stable 16
2022-04-02 17:04:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-02 17:04:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-02 17:04:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-02 17:04:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn is in the Running state. Remaining seconds pod to be stable 15
2022-04-02 17:04:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-exporter-54bfbb47b-5w6jf is in the Running state. Remaining seconds pod to be stable 15
2022-04-02 17:04:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-02 17:04:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-02 17:04:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-02 17:04:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn is in the Running state. Remaining seconds pod to be stable 14
2022-04-02 17:04:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-exporter-54bfbb47b-5w6jf is in the Running state. Remaining seconds pod to be stable 14
2022-04-02 17:04:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-02 17:04:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-02 17:04:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-02 17:04:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn is in the Running state. Remaining seconds pod to be stable 13
2022-04-02 17:04:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-exporter-54bfbb47b-5w6jf is in the Running state. Remaining seconds pod to be stable 13
2022-04-02 17:04:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-02 17:04:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-02 17:04:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-02 17:04:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn is in the Running state. Remaining seconds pod to be stable 12
2022-04-02 17:04:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-exporter-54bfbb47b-5w6jf is in the Running state. Remaining seconds pod to be stable 12
2022-04-02 17:04:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-02 17:04:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-02 17:04:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-02 17:04:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn is in the Running state. Remaining seconds pod to be stable 11
2022-04-02 17:04:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-exporter-54bfbb47b-5w6jf is in the Running state. Remaining seconds pod to be stable 11
2022-04-02 17:04:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-02 17:04:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-02 17:04:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-02 17:04:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn is in the Running state. Remaining seconds pod to be stable 10
2022-04-02 17:04:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-exporter-54bfbb47b-5w6jf is in the Running state. Remaining seconds pod to be stable 10
2022-04-02 17:04:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-02 17:04:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-02 17:04:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-02 17:04:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn is in the Running state. Remaining seconds pod to be stable 9
2022-04-02 17:04:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-exporter-54bfbb47b-5w6jf is in the Running state. Remaining seconds pod to be stable 9
2022-04-02 17:04:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-02 17:04:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-02 17:04:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-02 17:04:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn is in the Running state. Remaining seconds pod to be stable 8
2022-04-02 17:04:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-exporter-54bfbb47b-5w6jf is in the Running state. Remaining seconds pod to be stable 8
2022-04-02 17:04:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-02 17:04:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-02 17:04:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-02 17:04:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn is in the Running state. Remaining seconds pod to be stable 7
2022-04-02 17:04:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-exporter-54bfbb47b-5w6jf is in the Running state. Remaining seconds pod to be stable 7
2022-04-02 17:04:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-02 17:04:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-02 17:04:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-02 17:04:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn is in the Running state. Remaining seconds pod to be stable 6
2022-04-02 17:04:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-exporter-54bfbb47b-5w6jf is in the Running state. Remaining seconds pod to be stable 6
2022-04-02 17:04:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-02 17:04:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-02 17:04:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-02 17:04:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn is in the Running state. Remaining seconds pod to be stable 5
2022-04-02 17:04:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-exporter-54bfbb47b-5w6jf is in the Running state. Remaining seconds pod to be stable 5
2022-04-02 17:04:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-02 17:04:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-02 17:04:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-02 17:04:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn is in the Running state. Remaining seconds pod to be stable 4
2022-04-02 17:04:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-exporter-54bfbb47b-5w6jf is in the Running state. Remaining seconds pod to be stable 4
2022-04-02 17:04:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-02 17:04:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-02 17:04:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-02 17:04:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn is in the Running state. Remaining seconds pod to be stable 3
2022-04-02 17:04:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-exporter-54bfbb47b-5w6jf is in the Running state. Remaining seconds pod to be stable 3
2022-04-02 17:04:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-02 17:04:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-02 17:04:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-02 17:04:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn is in the Running state. Remaining seconds pod to be stable 2
2022-04-02 17:04:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-exporter-54bfbb47b-5w6jf is in the Running state. Remaining seconds pod to be stable 2
2022-04-02 17:04:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-02 17:04:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-02 17:04:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-02 17:04:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn is in the Running state. Remaining seconds pod to be stable 1
2022-04-02 17:04:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bb18d178-kafka-exporter-54bfbb47b-5w6jf is in the Running state. Remaining seconds pod to be stable 1
2022-04-02 17:04:16 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-bb18d178-kafka-0 ,my-cluster-bb18d178-kafka-1 ,my-cluster-bb18d178-kafka-2 ,my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn ,my-cluster-bb18d178-kafka-exporter-54bfbb47b-5w6jf
2022-04-02 17:04:16 [main] [32mINFO [m [RollingUpdateST:800] Check if Kafka and Zookeeper pods didn't roll
2022-04-02 17:04:16 [main] [32mINFO [m [RollingUpdateST:804] Check if Kafka and Zookeeper metrics are changed
2022-04-02 17:04:16 [main] [32mINFO [m [RollingUpdateST:818] Check if metrics are present in pod of Kafka and Zookeeper
2022-04-02 17:04:17 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.10 from Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn finished with return code: 0
2022-04-02 17:04:17 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.12 from Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn finished with return code: 0
2022-04-02 17:04:18 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.11 from Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn finished with return code: 0
2022-04-02 17:04:18 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.7 from Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn finished with return code: 0
2022-04-02 17:04:18 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.9 from Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn finished with return code: 0
2022-04-02 17:04:18 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.8 from Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn finished with return code: 0
2022-04-02 17:04:18 [main] [32mINFO [m [RollingUpdateST:829] Removing metrics from Kafka and Zookeeper and setting them to null
2022-04-02 17:04:18 [main] [32mINFO [m [RollingUpdateST:836] Wait if Kafka and Zookeeper pods will roll
2022-04-02 17:04:18 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-bb18d178-zookeeper rolling update
2022-04-02 17:05:18 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-bb18d178-zookeeper has been successfully rolled
2022-04-02 17:05:18 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-bb18d178-zookeeper to be ready
2022-04-02 17:05:50 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-bb18d178-kafka rolling update
2022-04-02 17:06:55 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-bb18d178-kafka has been successfully rolled
2022-04-02 17:06:55 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-bb18d178-kafka to be ready
2022-04-02 17:07:23 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-bb18d178 will have desired state: Ready
2022-04-02 17:07:23 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-bb18d178 is in desired state: Ready
2022-04-02 17:07:23 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-bb18d178 is ready
2022-04-02 17:07:23 [main] [32mINFO [m [RollingUpdateST:840] Check if metrics are not existing in pods
2022-04-02 17:07:23 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.10 from Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn finished with return code: 7
2022-04-02 17:07:23 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.12 from Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn finished with return code: 7
2022-04-02 17:07:23 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.11 from Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn finished with return code: 7
2022-04-02 17:07:24 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.7 from Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn finished with return code: 7
2022-04-02 17:07:24 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.9 from Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn finished with return code: 7
2022-04-02 17:07:24 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.8 from Pod my-cluster-bb18d178-kafka-clients-65f5ddf759-4s8zn finished with return code: 7
2022-04-02 17:07:24 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 17:07:24 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMetricsChange
2022-04-02 17:07:24 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-bb18d178-kafka-clients in namespace rolling-update-st
2022-04-02 17:07:24 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-bb18d178 in namespace rolling-update-st
2022-04-02 17:08:04 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 17:08:04 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testMetricsChange-FINISHED
2022-04-02 17:08:04 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 17:08:04 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 17:08:04 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testExternalLoggingChangeTriggerRollingUpdate-STARTED
2022-04-02 17:08:04 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 17:08:04 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-78 for test case:testExternalLoggingChangeTriggerRollingUpdate
2022-04-02 17:08:04 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-78
2022-04-02 17:08:04 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-78
2022-04-02 17:08:04 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-78
2022-04-02 17:08:04 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-0016d66e in namespace namespace-78
2022-04-02 17:08:04 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-78
2022-04-02 17:08:04 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-0016d66e will have desired state: Ready
2022-04-02 17:09:19 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-0016d66e is in desired state: Ready
2022-04-02 17:09:19 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-0016d66e-zookeeper rolling update
2022-04-02 17:10:15 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-0016d66e-zookeeper has been successfully rolled
2022-04-02 17:10:15 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-0016d66e-zookeeper to be ready
2022-04-02 17:10:45 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-0016d66e-kafka rolling update
2022-04-02 17:11:50 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-0016d66e-kafka has been successfully rolled
2022-04-02 17:11:50 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-0016d66e-kafka to be ready
2022-04-02 17:12:13 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-0016d66e will have desired state: Ready
2022-04-02 17:12:13 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-0016d66e is in desired state: Ready
2022-04-02 17:12:13 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-0016d66e is ready
2022-04-02 17:12:13 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-0016d66e-zookeeper rolling update
2022-04-02 17:13:23 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-0016d66e-zookeeper has been successfully rolled
2022-04-02 17:13:23 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-0016d66e-zookeeper to be ready
2022-04-02 17:13:52 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-0016d66e-kafka rolling update
2022-04-02 17:14:52 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-0016d66e-kafka has been successfully rolled
2022-04-02 17:14:52 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-0016d66e-kafka to be ready
2022-04-02 17:15:18 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-0016d66e will have desired state: Ready
2022-04-02 17:15:18 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-0016d66e is in desired state: Ready
2022-04-02 17:15:18 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-0016d66e is ready
2022-04-02 17:15:18 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 17:15:18 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testExternalLoggingChangeTriggerRollingUpdate
2022-04-02 17:15:18 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-0016d66e in namespace namespace-78
2022-04-02 17:15:28 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 17:15:28 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-78 for test case:testExternalLoggingChangeTriggerRollingUpdate
2022-04-02 17:16:11 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testExternalLoggingChangeTriggerRollingUpdate-FINISHED
2022-04-02 17:16:11 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 17:16:11 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 17:16:11 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testBrokerConfigurationChangeTriggerRollingUpdate-STARTED
2022-04-02 17:16:11 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 17:16:11 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-79 for test case:testBrokerConfigurationChangeTriggerRollingUpdate
2022-04-02 17:16:11 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-79
2022-04-02 17:16:11 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-79
2022-04-02 17:16:11 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-79
2022-04-02 17:16:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-a1db0e0a in namespace namespace-79
2022-04-02 17:16:11 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-79
2022-04-02 17:16:11 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-a1db0e0a will have desired state: Ready
2022-04-02 17:18:01 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-a1db0e0a is in desired state: Ready
2022-04-02 17:18:01 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-a1db0e0a-kafka rolling update
2022-04-02 17:19:16 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-a1db0e0a-kafka has been successfully rolled
2022-04-02 17:19:16 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-a1db0e0a-kafka to be ready
2022-04-02 17:19:49 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-a1db0e0a will have desired state: Ready
2022-04-02 17:19:49 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-a1db0e0a is in desired state: Ready
2022-04-02 17:19:49 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-a1db0e0a is ready
2022-04-02 17:19:49 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 17:19:49 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testBrokerConfigurationChangeTriggerRollingUpdate
2022-04-02 17:19:49 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-a1db0e0a in namespace namespace-79
2022-04-02 17:19:59 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 17:19:59 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-79 for test case:testBrokerConfigurationChangeTriggerRollingUpdate
2022-04-02 17:20:26 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testBrokerConfigurationChangeTriggerRollingUpdate-FINISHED
2022-04-02 17:20:26 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 17:20:26 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 17:20:26 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testManualKafkaConfigMapChangeDontTriggerRollingUpdate-STARTED
2022-04-02 17:20:26 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 17:20:26 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-80 for test case:testManualKafkaConfigMapChangeDontTriggerRollingUpdate
2022-04-02 17:20:26 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-80
2022-04-02 17:20:26 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-80
2022-04-02 17:20:26 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-80
2022-04-02 17:20:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-7d3b6287 in namespace namespace-80
2022-04-02 17:20:26 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-80
2022-04-02 17:20:26 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-7d3b6287 will have desired state: Ready
2022-04-02 17:22:39 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-7d3b6287 is in desired state: Ready
2022-04-02 17:22:39 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-7d3b6287 are stable
2022-04-02 17:22:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-entity-operator-5d67755758-5vvd6 is in the Running state. Remaining seconds pod to be stable 50
2022-04-02 17:22:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-02 17:22:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-02 17:22:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-02 17:22:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-02 17:22:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-02 17:22:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-02 17:22:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-entity-operator-5d67755758-5vvd6 is in the Running state. Remaining seconds pod to be stable 49
2022-04-02 17:22:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-02 17:22:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-02 17:22:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-02 17:22:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-02 17:22:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-02 17:22:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-02 17:22:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-entity-operator-5d67755758-5vvd6 is in the Running state. Remaining seconds pod to be stable 48
2022-04-02 17:22:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-02 17:22:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-02 17:22:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-02 17:22:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-02 17:22:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-02 17:22:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-02 17:22:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-entity-operator-5d67755758-5vvd6 is in the Running state. Remaining seconds pod to be stable 47
2022-04-02 17:22:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-02 17:22:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-02 17:22:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-02 17:22:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-02 17:22:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-02 17:22:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-02 17:22:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-entity-operator-5d67755758-5vvd6 is in the Running state. Remaining seconds pod to be stable 46
2022-04-02 17:22:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-02 17:22:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-02 17:22:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-02 17:22:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-02 17:22:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-02 17:22:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-02 17:22:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-entity-operator-5d67755758-5vvd6 is in the Running state. Remaining seconds pod to be stable 45
2022-04-02 17:22:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-02 17:22:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-02 17:22:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-02 17:22:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-02 17:22:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-02 17:22:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-02 17:22:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-entity-operator-5d67755758-5vvd6 is in the Running state. Remaining seconds pod to be stable 44
2022-04-02 17:22:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-02 17:22:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-02 17:22:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-02 17:22:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-02 17:22:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-02 17:22:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-02 17:22:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-entity-operator-5d67755758-5vvd6 is in the Running state. Remaining seconds pod to be stable 43
2022-04-02 17:22:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-02 17:22:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-02 17:22:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-02 17:22:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-02 17:22:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-02 17:22:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-02 17:22:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-entity-operator-5d67755758-5vvd6 is in the Running state. Remaining seconds pod to be stable 42
2022-04-02 17:22:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-02 17:22:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-02 17:22:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-02 17:22:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-02 17:22:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-02 17:22:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-02 17:22:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-entity-operator-5d67755758-5vvd6 is in the Running state. Remaining seconds pod to be stable 41
2022-04-02 17:22:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-02 17:22:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-02 17:22:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-02 17:22:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-02 17:22:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-02 17:22:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-02 17:22:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-entity-operator-5d67755758-5vvd6 is in the Running state. Remaining seconds pod to be stable 40
2022-04-02 17:22:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-02 17:22:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-02 17:22:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-02 17:22:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-02 17:22:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-02 17:22:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-02 17:22:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-entity-operator-5d67755758-5vvd6 is in the Running state. Remaining seconds pod to be stable 39
2022-04-02 17:22:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-02 17:22:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-02 17:22:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-02 17:22:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-02 17:22:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-02 17:22:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-02 17:22:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-entity-operator-5d67755758-5vvd6 is in the Running state. Remaining seconds pod to be stable 38
2022-04-02 17:22:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-02 17:22:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-02 17:22:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-02 17:22:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-02 17:22:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-02 17:22:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-02 17:22:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-entity-operator-5d67755758-5vvd6 is in the Running state. Remaining seconds pod to be stable 37
2022-04-02 17:22:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-02 17:22:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-02 17:22:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-02 17:22:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-02 17:22:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-02 17:22:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-02 17:22:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-entity-operator-5d67755758-5vvd6 is in the Running state. Remaining seconds pod to be stable 36
2022-04-02 17:22:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-02 17:22:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-02 17:22:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-02 17:22:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-02 17:22:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-02 17:22:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-02 17:22:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-entity-operator-5d67755758-5vvd6 is in the Running state. Remaining seconds pod to be stable 35
2022-04-02 17:22:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-02 17:22:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-02 17:22:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-02 17:22:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-02 17:22:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-02 17:22:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-02 17:22:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-entity-operator-5d67755758-5vvd6 is in the Running state. Remaining seconds pod to be stable 34
2022-04-02 17:22:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-02 17:22:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-02 17:22:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-02 17:22:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-02 17:22:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-02 17:22:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-02 17:22:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-entity-operator-5d67755758-5vvd6 is in the Running state. Remaining seconds pod to be stable 33
2022-04-02 17:22:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-02 17:22:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-02 17:22:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-02 17:22:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-02 17:22:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-02 17:22:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-02 17:22:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-entity-operator-5d67755758-5vvd6 is in the Running state. Remaining seconds pod to be stable 32
2022-04-02 17:22:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-02 17:22:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-02 17:22:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-02 17:22:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-02 17:22:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-02 17:22:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-02 17:22:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-entity-operator-5d67755758-5vvd6 is in the Running state. Remaining seconds pod to be stable 31
2022-04-02 17:22:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-02 17:22:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-02 17:22:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-02 17:22:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-02 17:22:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-02 17:22:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-02 17:22:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-entity-operator-5d67755758-5vvd6 is in the Running state. Remaining seconds pod to be stable 30
2022-04-02 17:22:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-02 17:22:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-02 17:22:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-02 17:22:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-02 17:22:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-02 17:22:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-02 17:23:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-entity-operator-5d67755758-5vvd6 is in the Running state. Remaining seconds pod to be stable 29
2022-04-02 17:23:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-02 17:23:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-02 17:23:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-02 17:23:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-02 17:23:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-02 17:23:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-02 17:23:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-entity-operator-5d67755758-5vvd6 is in the Running state. Remaining seconds pod to be stable 28
2022-04-02 17:23:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-02 17:23:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-02 17:23:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-02 17:23:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-02 17:23:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-02 17:23:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-02 17:23:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-entity-operator-5d67755758-5vvd6 is in the Running state. Remaining seconds pod to be stable 27
2022-04-02 17:23:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-02 17:23:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-02 17:23:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-02 17:23:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-02 17:23:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-02 17:23:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-02 17:23:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-entity-operator-5d67755758-5vvd6 is in the Running state. Remaining seconds pod to be stable 26
2022-04-02 17:23:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-02 17:23:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-02 17:23:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-02 17:23:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-02 17:23:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-02 17:23:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-02 17:23:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-entity-operator-5d67755758-5vvd6 is in the Running state. Remaining seconds pod to be stable 25
2022-04-02 17:23:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-02 17:23:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-02 17:23:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-02 17:23:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-02 17:23:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-02 17:23:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-02 17:23:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-entity-operator-5d67755758-5vvd6 is in the Running state. Remaining seconds pod to be stable 24
2022-04-02 17:23:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-02 17:23:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-02 17:23:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-02 17:23:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-02 17:23:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-02 17:23:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-02 17:23:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-entity-operator-5d67755758-5vvd6 is in the Running state. Remaining seconds pod to be stable 23
2022-04-02 17:23:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-02 17:23:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-02 17:23:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-02 17:23:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-02 17:23:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-02 17:23:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-02 17:23:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-entity-operator-5d67755758-5vvd6 is in the Running state. Remaining seconds pod to be stable 22
2022-04-02 17:23:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-02 17:23:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-02 17:23:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-02 17:23:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-02 17:23:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-02 17:23:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-02 17:23:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-entity-operator-5d67755758-5vvd6 is in the Running state. Remaining seconds pod to be stable 21
2022-04-02 17:23:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-02 17:23:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-02 17:23:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-02 17:23:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-02 17:23:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-02 17:23:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-02 17:23:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-entity-operator-5d67755758-5vvd6 is in the Running state. Remaining seconds pod to be stable 20
2022-04-02 17:23:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-02 17:23:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-02 17:23:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-02 17:23:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-02 17:23:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-02 17:23:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-02 17:23:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-entity-operator-5d67755758-5vvd6 is in the Running state. Remaining seconds pod to be stable 19
2022-04-02 17:23:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-02 17:23:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-02 17:23:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-02 17:23:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-02 17:23:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-02 17:23:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-02 17:23:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-entity-operator-5d67755758-5vvd6 is in the Running state. Remaining seconds pod to be stable 18
2022-04-02 17:23:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-02 17:23:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-02 17:23:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-02 17:23:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-02 17:23:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-02 17:23:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-02 17:23:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-entity-operator-5d67755758-5vvd6 is in the Running state. Remaining seconds pod to be stable 17
2022-04-02 17:23:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-02 17:23:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-02 17:23:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-02 17:23:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-02 17:23:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-02 17:23:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-02 17:23:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-entity-operator-5d67755758-5vvd6 is in the Running state. Remaining seconds pod to be stable 16
2022-04-02 17:23:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-02 17:23:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-02 17:23:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-02 17:23:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-02 17:23:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-02 17:23:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-02 17:23:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-entity-operator-5d67755758-5vvd6 is in the Running state. Remaining seconds pod to be stable 15
2022-04-02 17:23:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-02 17:23:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-02 17:23:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-02 17:23:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-02 17:23:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-02 17:23:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-02 17:23:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-entity-operator-5d67755758-5vvd6 is in the Running state. Remaining seconds pod to be stable 14
2022-04-02 17:23:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-02 17:23:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-02 17:23:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-02 17:23:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-02 17:23:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-02 17:23:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-02 17:23:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-entity-operator-5d67755758-5vvd6 is in the Running state. Remaining seconds pod to be stable 13
2022-04-02 17:23:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-02 17:23:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-02 17:23:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-02 17:23:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-02 17:23:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-02 17:23:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-02 17:23:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-entity-operator-5d67755758-5vvd6 is in the Running state. Remaining seconds pod to be stable 12
2022-04-02 17:23:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-02 17:23:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-02 17:23:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-02 17:23:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-02 17:23:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-02 17:23:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-02 17:23:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-entity-operator-5d67755758-5vvd6 is in the Running state. Remaining seconds pod to be stable 11
2022-04-02 17:23:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-02 17:23:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-02 17:23:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-02 17:23:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-02 17:23:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-02 17:23:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-02 17:23:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-entity-operator-5d67755758-5vvd6 is in the Running state. Remaining seconds pod to be stable 10
2022-04-02 17:23:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-02 17:23:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-02 17:23:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-02 17:23:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-02 17:23:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-02 17:23:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-02 17:23:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-entity-operator-5d67755758-5vvd6 is in the Running state. Remaining seconds pod to be stable 9
2022-04-02 17:23:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-02 17:23:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-02 17:23:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-02 17:23:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-02 17:23:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-02 17:23:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-02 17:23:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-entity-operator-5d67755758-5vvd6 is in the Running state. Remaining seconds pod to be stable 8
2022-04-02 17:23:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-02 17:23:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-02 17:23:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-02 17:23:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-02 17:23:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-02 17:23:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-02 17:23:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-entity-operator-5d67755758-5vvd6 is in the Running state. Remaining seconds pod to be stable 7
2022-04-02 17:23:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-02 17:23:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-02 17:23:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-02 17:23:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-02 17:23:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-02 17:23:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-02 17:23:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-entity-operator-5d67755758-5vvd6 is in the Running state. Remaining seconds pod to be stable 6
2022-04-02 17:23:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-02 17:23:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-02 17:23:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-02 17:23:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-02 17:23:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-02 17:23:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-02 17:23:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-entity-operator-5d67755758-5vvd6 is in the Running state. Remaining seconds pod to be stable 5
2022-04-02 17:23:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-02 17:23:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-02 17:23:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-02 17:23:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-02 17:23:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-02 17:23:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-02 17:23:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-entity-operator-5d67755758-5vvd6 is in the Running state. Remaining seconds pod to be stable 4
2022-04-02 17:23:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-02 17:23:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-02 17:23:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-02 17:23:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-02 17:23:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-02 17:23:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-02 17:23:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-entity-operator-5d67755758-5vvd6 is in the Running state. Remaining seconds pod to be stable 3
2022-04-02 17:23:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-02 17:23:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-02 17:23:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-02 17:23:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-02 17:23:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-02 17:23:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-02 17:23:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-entity-operator-5d67755758-5vvd6 is in the Running state. Remaining seconds pod to be stable 2
2022-04-02 17:23:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-02 17:23:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-02 17:23:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-02 17:23:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-02 17:23:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-02 17:23:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-02 17:23:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-entity-operator-5d67755758-5vvd6 is in the Running state. Remaining seconds pod to be stable 1
2022-04-02 17:23:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-02 17:23:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-02 17:23:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-kafka-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-02 17:23:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-02 17:23:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-02 17:23:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7d3b6287-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-02 17:23:28 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-7d3b6287-entity-operator-5d67755758-5vvd6 ,my-cluster-7d3b6287-kafka-0 ,my-cluster-7d3b6287-kafka-1 ,my-cluster-7d3b6287-kafka-2 ,my-cluster-7d3b6287-zookeeper-0 ,my-cluster-7d3b6287-zookeeper-1 ,my-cluster-7d3b6287-zookeeper-2
2022-04-02 17:23:28 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 17:23:28 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testManualKafkaConfigMapChangeDontTriggerRollingUpdate
2022-04-02 17:23:28 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-7d3b6287 in namespace namespace-80
2022-04-02 17:23:38 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 17:23:38 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-80 for test case:testManualKafkaConfigMapChangeDontTriggerRollingUpdate
2022-04-02 17:24:22 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testManualKafkaConfigMapChangeDontTriggerRollingUpdate-FINISHED
2022-04-02 17:24:22 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 17:24:22 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 17:24:22 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testZookeeperScaleUpScaleDown-STARTED
2022-04-02 17:24:22 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 17:24:22 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-81 for test case:testZookeeperScaleUpScaleDown
2022-04-02 17:24:22 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-81
2022-04-02 17:24:22 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-81
2022-04-02 17:24:22 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-81
2022-04-02 17:24:22 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-d48dd001 in namespace namespace-81
2022-04-02 17:24:22 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-81
2022-04-02 17:24:22 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d48dd001 will have desired state: Ready
2022-04-02 17:25:39 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d48dd001 is in desired state: Ready
2022-04-02 17:25:39 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-511792181-1932192937 in namespace namespace-81
2022-04-02 17:25:39 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-81
2022-04-02 17:25:39 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-511792181-1932192937 will have desired state: Ready
2022-04-02 17:25:40 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-511792181-1932192937 is in desired state: Ready
2022-04-02 17:25:40 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-566765709-191133477 in namespace namespace-81
2022-04-02 17:25:40 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-81
2022-04-02 17:25:40 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-566765709-191133477 will have desired state: Ready
2022-04-02 17:25:41 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-566765709-191133477 is in desired state: Ready
2022-04-02 17:25:41 [main] [32mINFO [m [RollingUpdateST:398] Running zookeeperScaleUpScaleDown with cluster my-cluster-d48dd001
2022-04-02 17:25:41 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-d48dd001-kafka-clients in namespace namespace-81
2022-04-02 17:25:41 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-81
2022-04-02 17:25:51 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-02 17:25:51 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@5173fcc1, messages=[], arguments=[USER=my_user_566765709_191133477, --max-messages, 100, --topic, my-topic-511792181-1932192937, --bootstrap-server, my-cluster-d48dd001-kafka-bootstrap.namespace-81.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-d48dd001-kafka-clients-5c5c755cf8-szxvb', podNamespace='namespace-81', bootstrapServer='my-cluster-d48dd001-kafka-bootstrap.namespace-81.svc:9093', topicName='my-topic-511792181-1932192937', maxMessages=100, kafkaUsername='my-user-566765709-191133477', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@516888c8}
2022-04-02 17:25:51 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-d48dd001-kafka-bootstrap.namespace-81.svc:9093:my-topic-511792181-1932192937 from pod my-cluster-d48dd001-kafka-clients-5c5c755cf8-szxvb
2022-04-02 17:25:51 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-d48dd001-kafka-clients-5c5c755cf8-szxvb -n namespace-81 -- /opt/kafka/producer.sh USER=my_user_566765709_191133477 --max-messages 100 --topic my-topic-511792181-1932192937 --bootstrap-server my-cluster-d48dd001-kafka-bootstrap.namespace-81.svc:9093
2022-04-02 17:25:54 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-02 17:25:54 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-02 17:25:54 [main] [32mINFO [m [RollingUpdateST:426] Scale up Zookeeper to 7
2022-04-02 17:25:54 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@6844ae18, messages=[], arguments=[USER=my_user_566765709_191133477, --max-messages, 100, --group-instance-id, instance2096025823, --group-id, my-consumer-group-594337296, --topic, my-topic-511792181-1932192937, --bootstrap-server, my-cluster-d48dd001-kafka-bootstrap.namespace-81.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-d48dd001-kafka-clients-5c5c755cf8-szxvb', podNamespace='namespace-81', bootstrapServer='my-cluster-d48dd001-kafka-bootstrap.namespace-81.svc:9093', topicName='my-topic-511792181-1932192937', maxMessages=100, kafkaUsername='my-user-566765709-191133477', consumerGroupName='my-consumer-group-594337296', consumerInstanceId='instance2096025823', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5f27511e}
2022-04-02 17:25:54 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-d48dd001-kafka-bootstrap.namespace-81.svc:9093:my-topic-511792181-1932192937 from pod my-cluster-d48dd001-kafka-clients-5c5c755cf8-szxvb
2022-04-02 17:25:54 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-d48dd001-kafka-clients-5c5c755cf8-szxvb -n namespace-81 -- /opt/kafka/consumer.sh USER=my_user_566765709_191133477 --max-messages 100 --group-instance-id instance2096025823 --group-id my-consumer-group-594337296 --topic my-topic-511792181-1932192937 --bootstrap-server my-cluster-d48dd001-kafka-bootstrap.namespace-81.svc:9093
2022-04-02 17:26:01 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-02 17:26:01 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-02 17:26:01 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 7 Pod(s) of my-cluster-d48dd001-zookeeper to be ready
2022-04-02 17:28:18 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d48dd001 will have desired state: Ready
2022-04-02 17:28:18 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d48dd001 is in desired state: Ready
2022-04-02 17:28:18 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-d48dd001 is ready
2022-04-02 17:28:18 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-81 exec my-cluster-d48dd001-zookeeper-0 -- /bin/bash -c echo mntr | nc localhost 12181
2022-04-02 17:28:18 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 17:28:18 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-81 exec my-cluster-d48dd001-zookeeper-1 -- /bin/bash -c echo mntr | nc localhost 12181
2022-04-02 17:28:18 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 17:28:19 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-81 exec my-cluster-d48dd001-zookeeper-2 -- /bin/bash -c echo mntr | nc localhost 12181
2022-04-02 17:28:19 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 17:28:19 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-81 exec my-cluster-d48dd001-zookeeper-3 -- /bin/bash -c echo mntr | nc localhost 12181
2022-04-02 17:28:19 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 17:28:19 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-81 exec my-cluster-d48dd001-zookeeper-4 -- /bin/bash -c echo mntr | nc localhost 12181
2022-04-02 17:28:19 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 17:28:19 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-81 exec my-cluster-d48dd001-zookeeper-5 -- /bin/bash -c echo mntr | nc localhost 12181
2022-04-02 17:28:19 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 17:28:20 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-81 exec my-cluster-d48dd001-zookeeper-6 -- /bin/bash -c echo mntr | nc localhost 12181
2022-04-02 17:28:20 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 17:28:20 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@1d1bbd34, messages=[], arguments=[USER=my_user_566765709_191133477, --max-messages, 100, --group-instance-id, instance1977665945, --group-id, my-consumer-group-1950231879, --topic, my-topic-511792181-1932192937, --bootstrap-server, my-cluster-d48dd001-kafka-bootstrap.namespace-81.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-d48dd001-kafka-clients-5c5c755cf8-szxvb', podNamespace='namespace-81', bootstrapServer='my-cluster-d48dd001-kafka-bootstrap.namespace-81.svc:9093', topicName='my-topic-511792181-1932192937', maxMessages=100, kafkaUsername='my-user-566765709-191133477', consumerGroupName='my-consumer-group-1950231879', consumerInstanceId='instance1977665945', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@37b351c7}
2022-04-02 17:28:20 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-d48dd001-kafka-bootstrap.namespace-81.svc:9093:my-topic-511792181-1932192937 from pod my-cluster-d48dd001-kafka-clients-5c5c755cf8-szxvb
2022-04-02 17:28:20 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-d48dd001-kafka-clients-5c5c755cf8-szxvb -n namespace-81 -- /opt/kafka/consumer.sh USER=my_user_566765709_191133477 --max-messages 100 --group-instance-id instance1977665945 --group-id my-consumer-group-1950231879 --topic my-topic-511792181-1932192937 --bootstrap-server my-cluster-d48dd001-kafka-bootstrap.namespace-81.svc:9093
2022-04-02 17:28:26 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-02 17:28:26 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-02 17:28:26 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1939515222-421338350 in namespace namespace-81
2022-04-02 17:28:26 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-81
2022-04-02 17:28:26 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1939515222-421338350 will have desired state: Ready
2022-04-02 17:28:28 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1939515222-421338350 is in desired state: Ready
2022-04-02 17:28:28 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@1af17961, messages=[], arguments=[USER=my_user_566765709_191133477, --max-messages, 100, --topic, my-topic-1939515222-421338350, --bootstrap-server, my-cluster-d48dd001-kafka-bootstrap.namespace-81.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-d48dd001-kafka-clients-5c5c755cf8-szxvb', podNamespace='namespace-81', bootstrapServer='my-cluster-d48dd001-kafka-bootstrap.namespace-81.svc:9093', topicName='my-topic-1939515222-421338350', maxMessages=100, kafkaUsername='my-user-566765709-191133477', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@21b3b0f}
2022-04-02 17:28:28 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-d48dd001-kafka-bootstrap.namespace-81.svc:9093:my-topic-1939515222-421338350 from pod my-cluster-d48dd001-kafka-clients-5c5c755cf8-szxvb
2022-04-02 17:28:28 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-d48dd001-kafka-clients-5c5c755cf8-szxvb -n namespace-81 -- /opt/kafka/producer.sh USER=my_user_566765709_191133477 --max-messages 100 --topic my-topic-1939515222-421338350 --bootstrap-server my-cluster-d48dd001-kafka-bootstrap.namespace-81.svc:9093
2022-04-02 17:28:32 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-02 17:28:32 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-02 17:28:32 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@7753d754, messages=[], arguments=[USER=my_user_566765709_191133477, --max-messages, 100, --group-instance-id, instance922967976, --group-id, my-consumer-group-488208506, --topic, my-topic-1939515222-421338350, --bootstrap-server, my-cluster-d48dd001-kafka-bootstrap.namespace-81.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-d48dd001-kafka-clients-5c5c755cf8-szxvb', podNamespace='namespace-81', bootstrapServer='my-cluster-d48dd001-kafka-bootstrap.namespace-81.svc:9093', topicName='my-topic-1939515222-421338350', maxMessages=100, kafkaUsername='my-user-566765709-191133477', consumerGroupName='my-consumer-group-488208506', consumerInstanceId='instance922967976', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@37612e91}
2022-04-02 17:28:32 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-d48dd001-kafka-bootstrap.namespace-81.svc:9093:my-topic-1939515222-421338350 from pod my-cluster-d48dd001-kafka-clients-5c5c755cf8-szxvb
2022-04-02 17:28:32 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-d48dd001-kafka-clients-5c5c755cf8-szxvb -n namespace-81 -- /opt/kafka/consumer.sh USER=my_user_566765709_191133477 --max-messages 100 --group-instance-id instance922967976 --group-id my-consumer-group-488208506 --topic my-topic-1939515222-421338350 --bootstrap-server my-cluster-d48dd001-kafka-bootstrap.namespace-81.svc:9093
2022-04-02 17:28:39 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-02 17:28:39 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-02 17:28:39 [main] [32mINFO [m [RollingUpdateST:453] Scale down Zookeeper to 3
2022-04-02 17:28:39 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-d48dd001-zookeeper to be ready
2022-04-02 17:29:21 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d48dd001 will have desired state: Ready
2022-04-02 17:29:21 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d48dd001 is in desired state: Ready
2022-04-02 17:29:21 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-d48dd001 is ready
2022-04-02 17:29:21 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-81 exec my-cluster-d48dd001-zookeeper-0 -- /bin/bash -c echo mntr | nc localhost 12181
2022-04-02 17:29:21 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 17:29:21 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-81 exec my-cluster-d48dd001-zookeeper-1 -- /bin/bash -c echo mntr | nc localhost 12181
2022-04-02 17:29:21 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 17:29:22 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-81 exec my-cluster-d48dd001-zookeeper-2 -- /bin/bash -c echo mntr | nc localhost 12181
2022-04-02 17:29:22 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 17:29:22 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@3cbb3e0, messages=[], arguments=[USER=my_user_566765709_191133477, --max-messages, 100, --group-instance-id, instance736302414, --group-id, my-consumer-group-1638451726, --topic, my-topic-1939515222-421338350, --bootstrap-server, my-cluster-d48dd001-kafka-bootstrap.namespace-81.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-d48dd001-kafka-clients-5c5c755cf8-szxvb', podNamespace='namespace-81', bootstrapServer='my-cluster-d48dd001-kafka-bootstrap.namespace-81.svc:9093', topicName='my-topic-1939515222-421338350', maxMessages=100, kafkaUsername='my-user-566765709-191133477', consumerGroupName='my-consumer-group-1638451726', consumerInstanceId='instance736302414', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3d60177b}
2022-04-02 17:29:22 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-d48dd001-kafka-bootstrap.namespace-81.svc:9093:my-topic-1939515222-421338350 from pod my-cluster-d48dd001-kafka-clients-5c5c755cf8-szxvb
2022-04-02 17:29:22 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-d48dd001-kafka-clients-5c5c755cf8-szxvb -n namespace-81 -- /opt/kafka/consumer.sh USER=my_user_566765709_191133477 --max-messages 100 --group-instance-id instance736302414 --group-id my-consumer-group-1638451726 --topic my-topic-1939515222-421338350 --bootstrap-server my-cluster-d48dd001-kafka-bootstrap.namespace-81.svc:9093
2022-04-02 17:29:28 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-02 17:29:28 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-02 17:29:28 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1222165625-354613493 in namespace namespace-81
2022-04-02 17:29:28 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-81
2022-04-02 17:29:28 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1222165625-354613493 will have desired state: Ready
2022-04-02 17:29:30 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1222165625-354613493 is in desired state: Ready
2022-04-02 17:29:30 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@1cb9fdd8, messages=[], arguments=[USER=my_user_566765709_191133477, --max-messages, 100, --topic, my-topic-1222165625-354613493, --bootstrap-server, my-cluster-d48dd001-kafka-bootstrap.namespace-81.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-d48dd001-kafka-clients-5c5c755cf8-szxvb', podNamespace='namespace-81', bootstrapServer='my-cluster-d48dd001-kafka-bootstrap.namespace-81.svc:9093', topicName='my-topic-1222165625-354613493', maxMessages=100, kafkaUsername='my-user-566765709-191133477', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6acb2dba}
2022-04-02 17:29:30 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-d48dd001-kafka-bootstrap.namespace-81.svc:9093:my-topic-1222165625-354613493 from pod my-cluster-d48dd001-kafka-clients-5c5c755cf8-szxvb
2022-04-02 17:29:30 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-d48dd001-kafka-clients-5c5c755cf8-szxvb -n namespace-81 -- /opt/kafka/producer.sh USER=my_user_566765709_191133477 --max-messages 100 --topic my-topic-1222165625-354613493 --bootstrap-server my-cluster-d48dd001-kafka-bootstrap.namespace-81.svc:9093
2022-04-02 17:29:34 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-02 17:29:34 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-02 17:29:34 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@7fd51993, messages=[], arguments=[USER=my_user_566765709_191133477, --max-messages, 100, --group-instance-id, instance756788194, --group-id, my-consumer-group-881509402, --topic, my-topic-1222165625-354613493, --bootstrap-server, my-cluster-d48dd001-kafka-bootstrap.namespace-81.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-d48dd001-kafka-clients-5c5c755cf8-szxvb', podNamespace='namespace-81', bootstrapServer='my-cluster-d48dd001-kafka-bootstrap.namespace-81.svc:9093', topicName='my-topic-1222165625-354613493', maxMessages=100, kafkaUsername='my-user-566765709-191133477', consumerGroupName='my-consumer-group-881509402', consumerInstanceId='instance756788194', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@21dffafb}
2022-04-02 17:29:34 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-d48dd001-kafka-bootstrap.namespace-81.svc:9093:my-topic-1222165625-354613493 from pod my-cluster-d48dd001-kafka-clients-5c5c755cf8-szxvb
2022-04-02 17:29:34 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-d48dd001-kafka-clients-5c5c755cf8-szxvb -n namespace-81 -- /opt/kafka/consumer.sh USER=my_user_566765709_191133477 --max-messages 100 --group-instance-id instance756788194 --group-id my-consumer-group-881509402 --topic my-topic-1222165625-354613493 --bootstrap-server my-cluster-d48dd001-kafka-bootstrap.namespace-81.svc:9093
2022-04-02 17:29:41 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-02 17:29:41 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-02 17:29:41 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 17:29:41 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testZookeeperScaleUpScaleDown
2022-04-02 17:29:41 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-d48dd001-kafka-clients in namespace namespace-81
2022-04-02 17:29:41 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-d48dd001 in namespace namespace-81
2022-04-02 17:29:41 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1222165625-354613493 in namespace namespace-81
2022-04-02 17:29:41 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1939515222-421338350 in namespace namespace-81
2022-04-02 17:29:41 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-566765709-191133477 in namespace namespace-81
2022-04-02 17:29:41 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-511792181-1932192937 in namespace namespace-81
2022-04-02 17:30:21 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 17:30:21 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-81 for test case:testZookeeperScaleUpScaleDown
2022-04-02 17:30:26 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testZookeeperScaleUpScaleDown-FINISHED
2022-04-02 17:30:26 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 17:30:26 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 17:30:26 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testRecoveryDuringZookeeperRollingUpdate-STARTED
2022-04-02 17:30:26 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 17:30:26 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-82 for test case:testRecoveryDuringZookeeperRollingUpdate
2022-04-02 17:30:26 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-82
2022-04-02 17:30:26 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-82
2022-04-02 17:30:26 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-82
2022-04-02 17:30:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-c976521b in namespace namespace-82
2022-04-02 17:30:26 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-82
2022-04-02 17:30:26 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-630724012-692873471 in namespace namespace-82
2022-04-02 17:30:26 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-82
2022-04-02 17:30:26 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-c976521b will have desired state: Ready
2022-04-02 17:31:48 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-c976521b is in desired state: Ready
2022-04-02 17:31:48 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-630724012-692873471 will have desired state: Ready
2022-04-02 17:31:48 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-630724012-692873471 is in desired state: Ready
2022-04-02 17:31:48 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-841184228-135578693 in namespace namespace-82
2022-04-02 17:31:48 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-82
2022-04-02 17:31:48 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-841184228-135578693 will have desired state: Ready
2022-04-02 17:31:49 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-841184228-135578693 is in desired state: Ready
2022-04-02 17:31:49 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-c976521b-kafka-clients in namespace namespace-82
2022-04-02 17:31:49 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-82
2022-04-02 17:31:59 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-02 17:31:59 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@76a1490f, messages=[], arguments=[USER=my_user_841184228_135578693, --max-messages, 100, --topic, my-topic-630724012-692873471, --bootstrap-server, my-cluster-c976521b-kafka-bootstrap.namespace-82.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-c976521b-kafka-clients-57764b4d5-97qkz', podNamespace='namespace-82', bootstrapServer='my-cluster-c976521b-kafka-bootstrap.namespace-82.svc:9093', topicName='my-topic-630724012-692873471', maxMessages=100, kafkaUsername='my-user-841184228-135578693', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@544aabdd}
2022-04-02 17:31:59 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-c976521b-kafka-bootstrap.namespace-82.svc:9093:my-topic-630724012-692873471 from pod my-cluster-c976521b-kafka-clients-57764b4d5-97qkz
2022-04-02 17:31:59 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-c976521b-kafka-clients-57764b4d5-97qkz -n namespace-82 -- /opt/kafka/producer.sh USER=my_user_841184228_135578693 --max-messages 100 --topic my-topic-630724012-692873471 --bootstrap-server my-cluster-c976521b-kafka-bootstrap.namespace-82.svc:9093
2022-04-02 17:32:02 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-02 17:32:02 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-02 17:32:02 [main] [32mINFO [m [RollingUpdateST:117] Update resources for pods
2022-04-02 17:32:02 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@27579e59, messages=[], arguments=[USER=my_user_841184228_135578693, --max-messages, 100, --group-instance-id, instance1522321426, --group-id, my-consumer-group-1346752118, --topic, my-topic-630724012-692873471, --bootstrap-server, my-cluster-c976521b-kafka-bootstrap.namespace-82.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-c976521b-kafka-clients-57764b4d5-97qkz', podNamespace='namespace-82', bootstrapServer='my-cluster-c976521b-kafka-bootstrap.namespace-82.svc:9093', topicName='my-topic-630724012-692873471', maxMessages=100, kafkaUsername='my-user-841184228-135578693', consumerGroupName='my-consumer-group-1346752118', consumerInstanceId='instance1522321426', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5bc24d1f}
2022-04-02 17:32:02 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-c976521b-kafka-bootstrap.namespace-82.svc:9093:my-topic-630724012-692873471 from pod my-cluster-c976521b-kafka-clients-57764b4d5-97qkz
2022-04-02 17:32:02 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-c976521b-kafka-clients-57764b4d5-97qkz -n namespace-82 -- /opt/kafka/consumer.sh USER=my_user_841184228_135578693 --max-messages 100 --group-instance-id instance1522321426 --group-id my-consumer-group-1346752118 --topic my-topic-630724012-692873471 --bootstrap-server my-cluster-c976521b-kafka-bootstrap.namespace-82.svc:9093
2022-04-02 17:32:09 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-02 17:32:09 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-02 17:32:09 [main] [32mINFO [m [ClientUtils:45] Consumer successfully consumed 100 messages for the 1 time
2022-04-02 17:32:09 [main] [32mINFO [m [PodUtils:277] Wait for at least one pod with prefix: my-cluster-c976521b-zookeeper will be in pending phase
2022-04-02 17:32:09 [main] [32mINFO [m [RollingUpdateST:130] Verifying stability of zookeeper pods except the one, which is in pending phase
2022-04-02 17:32:09 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-c976521b-zookeeper are stable
2022-04-02 17:32:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-02 17:32:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-02 17:32:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-02 17:32:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-02 17:32:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-02 17:32:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-02 17:32:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-02 17:32:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-02 17:32:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-02 17:32:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-02 17:32:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-02 17:32:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-02 17:32:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-02 17:32:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-02 17:32:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-02 17:32:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-02 17:32:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-02 17:32:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-02 17:32:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-02 17:32:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-02 17:32:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-02 17:32:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-02 17:32:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-02 17:32:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-02 17:32:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-02 17:32:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-02 17:32:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-02 17:32:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-02 17:32:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-02 17:32:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-02 17:32:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-02 17:32:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-02 17:32:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-02 17:32:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-02 17:32:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-02 17:32:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-02 17:32:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-02 17:32:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-02 17:32:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-02 17:32:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-02 17:32:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-02 17:32:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-02 17:32:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-02 17:32:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-02 17:32:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-02 17:32:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-02 17:32:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-02 17:32:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-02 17:32:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-02 17:32:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-02 17:32:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-02 17:32:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-02 17:32:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-02 17:32:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-02 17:32:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-02 17:32:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-02 17:32:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-02 17:32:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-02 17:32:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-02 17:32:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-02 17:32:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-02 17:32:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-02 17:32:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-02 17:32:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-02 17:32:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-02 17:32:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-02 17:32:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-02 17:32:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-02 17:32:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-02 17:32:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-02 17:32:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-02 17:32:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-02 17:32:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-02 17:32:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-02 17:32:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-02 17:32:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-02 17:32:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-02 17:32:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-02 17:32:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-02 17:32:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-02 17:32:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-02 17:32:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-02 17:32:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-02 17:32:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-02 17:32:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-02 17:32:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-02 17:32:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-02 17:32:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-02 17:32:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-02 17:32:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-02 17:32:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-02 17:32:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-02 17:32:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-02 17:32:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-02 17:32:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-02 17:32:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-02 17:32:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-02 17:32:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-02 17:32:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-02 17:32:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-02 17:32:59 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-c976521b-zookeeper-1 ,my-cluster-c976521b-zookeeper-2
2022-04-02 17:32:59 [main] [32mINFO [m [RollingUpdateST:133] Verifying stability of kafka pods
2022-04-02 17:32:59 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-c976521b-kafka are stable
2022-04-02 17:32:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-02 17:32:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-02 17:32:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-02 17:32:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-clients-57764b4d5-97qkz is in the Running state. Remaining seconds pod to be stable 50
2022-04-02 17:33:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-02 17:33:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-02 17:33:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-02 17:33:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-clients-57764b4d5-97qkz is in the Running state. Remaining seconds pod to be stable 49
2022-04-02 17:33:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-02 17:33:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-02 17:33:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-02 17:33:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-clients-57764b4d5-97qkz is in the Running state. Remaining seconds pod to be stable 48
2022-04-02 17:33:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-02 17:33:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-02 17:33:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-02 17:33:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-clients-57764b4d5-97qkz is in the Running state. Remaining seconds pod to be stable 47
2022-04-02 17:33:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-02 17:33:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-02 17:33:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-02 17:33:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-clients-57764b4d5-97qkz is in the Running state. Remaining seconds pod to be stable 46
2022-04-02 17:33:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-02 17:33:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-02 17:33:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-02 17:33:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-clients-57764b4d5-97qkz is in the Running state. Remaining seconds pod to be stable 45
2022-04-02 17:33:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-02 17:33:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-02 17:33:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-02 17:33:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-clients-57764b4d5-97qkz is in the Running state. Remaining seconds pod to be stable 44
2022-04-02 17:33:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-02 17:33:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-02 17:33:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-02 17:33:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-clients-57764b4d5-97qkz is in the Running state. Remaining seconds pod to be stable 43
2022-04-02 17:33:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-02 17:33:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-02 17:33:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-02 17:33:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-clients-57764b4d5-97qkz is in the Running state. Remaining seconds pod to be stable 42
2022-04-02 17:33:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-02 17:33:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-02 17:33:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-02 17:33:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-clients-57764b4d5-97qkz is in the Running state. Remaining seconds pod to be stable 41
2022-04-02 17:33:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-02 17:33:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-02 17:33:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-02 17:33:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-clients-57764b4d5-97qkz is in the Running state. Remaining seconds pod to be stable 40
2022-04-02 17:33:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-02 17:33:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-02 17:33:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-02 17:33:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-clients-57764b4d5-97qkz is in the Running state. Remaining seconds pod to be stable 39
2022-04-02 17:33:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-02 17:33:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-02 17:33:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-02 17:33:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-clients-57764b4d5-97qkz is in the Running state. Remaining seconds pod to be stable 38
2022-04-02 17:33:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-02 17:33:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-02 17:33:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-02 17:33:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-clients-57764b4d5-97qkz is in the Running state. Remaining seconds pod to be stable 37
2022-04-02 17:33:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-02 17:33:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-02 17:33:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-02 17:33:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-clients-57764b4d5-97qkz is in the Running state. Remaining seconds pod to be stable 36
2022-04-02 17:33:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-02 17:33:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-02 17:33:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-02 17:33:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-clients-57764b4d5-97qkz is in the Running state. Remaining seconds pod to be stable 35
2022-04-02 17:33:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-02 17:33:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-02 17:33:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-02 17:33:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-clients-57764b4d5-97qkz is in the Running state. Remaining seconds pod to be stable 34
2022-04-02 17:33:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-02 17:33:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-02 17:33:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-02 17:33:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-clients-57764b4d5-97qkz is in the Running state. Remaining seconds pod to be stable 33
2022-04-02 17:33:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-02 17:33:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-02 17:33:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-02 17:33:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-clients-57764b4d5-97qkz is in the Running state. Remaining seconds pod to be stable 32
2022-04-02 17:33:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-02 17:33:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-02 17:33:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-02 17:33:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-clients-57764b4d5-97qkz is in the Running state. Remaining seconds pod to be stable 31
2022-04-02 17:33:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-02 17:33:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-02 17:33:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-02 17:33:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-clients-57764b4d5-97qkz is in the Running state. Remaining seconds pod to be stable 30
2022-04-02 17:33:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-02 17:33:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-02 17:33:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-02 17:33:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-clients-57764b4d5-97qkz is in the Running state. Remaining seconds pod to be stable 29
2022-04-02 17:33:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-02 17:33:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-02 17:33:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-02 17:33:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-clients-57764b4d5-97qkz is in the Running state. Remaining seconds pod to be stable 28
2022-04-02 17:33:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-02 17:33:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-02 17:33:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-02 17:33:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-clients-57764b4d5-97qkz is in the Running state. Remaining seconds pod to be stable 27
2022-04-02 17:33:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-02 17:33:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-02 17:33:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-02 17:33:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-clients-57764b4d5-97qkz is in the Running state. Remaining seconds pod to be stable 26
2022-04-02 17:33:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-02 17:33:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-02 17:33:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-02 17:33:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-clients-57764b4d5-97qkz is in the Running state. Remaining seconds pod to be stable 25
2022-04-02 17:33:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-02 17:33:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-02 17:33:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-02 17:33:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-clients-57764b4d5-97qkz is in the Running state. Remaining seconds pod to be stable 24
2022-04-02 17:33:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-02 17:33:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-02 17:33:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-02 17:33:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-clients-57764b4d5-97qkz is in the Running state. Remaining seconds pod to be stable 23
2022-04-02 17:33:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-02 17:33:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-02 17:33:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-02 17:33:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-clients-57764b4d5-97qkz is in the Running state. Remaining seconds pod to be stable 22
2022-04-02 17:33:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-02 17:33:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-02 17:33:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-02 17:33:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-clients-57764b4d5-97qkz is in the Running state. Remaining seconds pod to be stable 21
2022-04-02 17:33:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-02 17:33:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-02 17:33:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-02 17:33:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-clients-57764b4d5-97qkz is in the Running state. Remaining seconds pod to be stable 20
2022-04-02 17:33:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-02 17:33:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-02 17:33:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-02 17:33:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-clients-57764b4d5-97qkz is in the Running state. Remaining seconds pod to be stable 19
2022-04-02 17:33:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-02 17:33:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-02 17:33:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-02 17:33:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-clients-57764b4d5-97qkz is in the Running state. Remaining seconds pod to be stable 18
2022-04-02 17:33:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-02 17:33:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-02 17:33:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-02 17:33:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-clients-57764b4d5-97qkz is in the Running state. Remaining seconds pod to be stable 17
2022-04-02 17:33:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-02 17:33:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-02 17:33:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-02 17:33:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-clients-57764b4d5-97qkz is in the Running state. Remaining seconds pod to be stable 16
2022-04-02 17:33:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-02 17:33:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-02 17:33:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-02 17:33:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-clients-57764b4d5-97qkz is in the Running state. Remaining seconds pod to be stable 15
2022-04-02 17:33:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-02 17:33:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-02 17:33:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-02 17:33:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-clients-57764b4d5-97qkz is in the Running state. Remaining seconds pod to be stable 14
2022-04-02 17:33:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-02 17:33:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-02 17:33:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-02 17:33:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-clients-57764b4d5-97qkz is in the Running state. Remaining seconds pod to be stable 13
2022-04-02 17:33:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-02 17:33:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-02 17:33:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-02 17:33:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-clients-57764b4d5-97qkz is in the Running state. Remaining seconds pod to be stable 12
2022-04-02 17:33:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-02 17:33:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-02 17:33:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-02 17:33:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-clients-57764b4d5-97qkz is in the Running state. Remaining seconds pod to be stable 11
2022-04-02 17:33:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-02 17:33:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-02 17:33:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-02 17:33:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-clients-57764b4d5-97qkz is in the Running state. Remaining seconds pod to be stable 10
2022-04-02 17:33:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-02 17:33:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-02 17:33:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-02 17:33:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-clients-57764b4d5-97qkz is in the Running state. Remaining seconds pod to be stable 9
2022-04-02 17:33:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-02 17:33:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-02 17:33:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-02 17:33:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-clients-57764b4d5-97qkz is in the Running state. Remaining seconds pod to be stable 8
2022-04-02 17:33:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-02 17:33:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-02 17:33:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-02 17:33:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-clients-57764b4d5-97qkz is in the Running state. Remaining seconds pod to be stable 7
2022-04-02 17:33:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-02 17:33:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-02 17:33:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-02 17:33:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-clients-57764b4d5-97qkz is in the Running state. Remaining seconds pod to be stable 6
2022-04-02 17:33:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-02 17:33:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-02 17:33:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-02 17:33:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-clients-57764b4d5-97qkz is in the Running state. Remaining seconds pod to be stable 5
2022-04-02 17:33:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-02 17:33:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-02 17:33:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-02 17:33:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-clients-57764b4d5-97qkz is in the Running state. Remaining seconds pod to be stable 4
2022-04-02 17:33:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-02 17:33:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-02 17:33:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-02 17:33:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-clients-57764b4d5-97qkz is in the Running state. Remaining seconds pod to be stable 3
2022-04-02 17:33:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-02 17:33:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-02 17:33:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-02 17:33:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-clients-57764b4d5-97qkz is in the Running state. Remaining seconds pod to be stable 2
2022-04-02 17:33:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-02 17:33:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-02 17:33:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-02 17:33:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c976521b-kafka-clients-57764b4d5-97qkz is in the Running state. Remaining seconds pod to be stable 1
2022-04-02 17:33:48 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-c976521b-kafka-0 ,my-cluster-c976521b-kafka-1 ,my-cluster-c976521b-kafka-2 ,my-cluster-c976521b-kafka-clients-57764b4d5-97qkz
2022-04-02 17:33:48 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-c976521b-zookeeper to be ready
2022-04-02 17:39:03 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-c976521b will have desired state: Ready
2022-04-02 17:39:03 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-c976521b is in desired state: Ready
2022-04-02 17:39:03 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-c976521b is ready
2022-04-02 17:39:03 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@2a6b3ed6, messages=[], arguments=[USER=my_user_841184228_135578693, --max-messages, 100, --group-instance-id, instance767870151, --group-id, my-consumer-group-104726991, --topic, my-topic-630724012-692873471, --bootstrap-server, my-cluster-c976521b-kafka-bootstrap.namespace-82.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-c976521b-kafka-clients-57764b4d5-97qkz', podNamespace='namespace-82', bootstrapServer='my-cluster-c976521b-kafka-bootstrap.namespace-82.svc:9093', topicName='my-topic-630724012-692873471', maxMessages=100, kafkaUsername='my-user-841184228-135578693', consumerGroupName='my-consumer-group-104726991', consumerInstanceId='instance767870151', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@29a53773}
2022-04-02 17:39:03 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-c976521b-kafka-bootstrap.namespace-82.svc:9093:my-topic-630724012-692873471 from pod my-cluster-c976521b-kafka-clients-57764b4d5-97qkz
2022-04-02 17:39:03 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-c976521b-kafka-clients-57764b4d5-97qkz -n namespace-82 -- /opt/kafka/consumer.sh USER=my_user_841184228_135578693 --max-messages 100 --group-instance-id instance767870151 --group-id my-consumer-group-104726991 --topic my-topic-630724012-692873471 --bootstrap-server my-cluster-c976521b-kafka-bootstrap.namespace-82.svc:9093
2022-04-02 17:39:10 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-02 17:39:10 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-02 17:39:10 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-905423-2014251934 in namespace namespace-82
2022-04-02 17:39:10 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-82
2022-04-02 17:39:10 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-905423-2014251934 will have desired state: Ready
2022-04-02 17:39:11 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-905423-2014251934 is in desired state: Ready
2022-04-02 17:39:11 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@7bc1ca36, messages=[], arguments=[USER=my_user_841184228_135578693, --max-messages, 100, --topic, my-topic-905423-2014251934, --bootstrap-server, my-cluster-c976521b-kafka-bootstrap.namespace-82.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-c976521b-kafka-clients-57764b4d5-97qkz', podNamespace='namespace-82', bootstrapServer='my-cluster-c976521b-kafka-bootstrap.namespace-82.svc:9093', topicName='my-topic-905423-2014251934', maxMessages=100, kafkaUsername='my-user-841184228-135578693', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7b5f7481}
2022-04-02 17:39:11 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-c976521b-kafka-bootstrap.namespace-82.svc:9093:my-topic-905423-2014251934 from pod my-cluster-c976521b-kafka-clients-57764b4d5-97qkz
2022-04-02 17:39:11 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-c976521b-kafka-clients-57764b4d5-97qkz -n namespace-82 -- /opt/kafka/producer.sh USER=my_user_841184228_135578693 --max-messages 100 --topic my-topic-905423-2014251934 --bootstrap-server my-cluster-c976521b-kafka-bootstrap.namespace-82.svc:9093
2022-04-02 17:39:15 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-02 17:39:15 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-02 17:39:15 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@55fc972e, messages=[], arguments=[USER=my_user_841184228_135578693, --max-messages, 100, --group-instance-id, instance1319209351, --group-id, my-consumer-group-1973668206, --topic, my-topic-905423-2014251934, --bootstrap-server, my-cluster-c976521b-kafka-bootstrap.namespace-82.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-c976521b-kafka-clients-57764b4d5-97qkz', podNamespace='namespace-82', bootstrapServer='my-cluster-c976521b-kafka-bootstrap.namespace-82.svc:9093', topicName='my-topic-905423-2014251934', maxMessages=100, kafkaUsername='my-user-841184228-135578693', consumerGroupName='my-consumer-group-1973668206', consumerInstanceId='instance1319209351', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@82fc616}
2022-04-02 17:39:15 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-c976521b-kafka-bootstrap.namespace-82.svc:9093:my-topic-905423-2014251934 from pod my-cluster-c976521b-kafka-clients-57764b4d5-97qkz
2022-04-02 17:39:15 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-c976521b-kafka-clients-57764b4d5-97qkz -n namespace-82 -- /opt/kafka/consumer.sh USER=my_user_841184228_135578693 --max-messages 100 --group-instance-id instance1319209351 --group-id my-consumer-group-1973668206 --topic my-topic-905423-2014251934 --bootstrap-server my-cluster-c976521b-kafka-bootstrap.namespace-82.svc:9093
2022-04-02 17:39:22 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-02 17:39:22 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-02 17:39:22 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 17:39:22 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryDuringZookeeperRollingUpdate
2022-04-02 17:39:22 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-841184228-135578693 in namespace namespace-82
2022-04-02 17:39:22 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-c976521b in namespace namespace-82
2022-04-02 17:39:22 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-630724012-692873471 in namespace namespace-82
2022-04-02 17:39:22 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-c976521b-kafka-clients in namespace namespace-82
2022-04-02 17:39:22 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-905423-2014251934 in namespace namespace-82
2022-04-02 17:40:12 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 17:40:12 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-82 for test case:testRecoveryDuringZookeeperRollingUpdate
2022-04-02 17:40:17 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testRecoveryDuringZookeeperRollingUpdate-FINISHED
2022-04-02 17:40:17 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 17:40:17 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 17:40:17 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testRecoveryDuringKafkaRollingUpdate-STARTED
2022-04-02 17:40:17 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 17:40:17 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-83 for test case:testRecoveryDuringKafkaRollingUpdate
2022-04-02 17:40:17 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-83
2022-04-02 17:40:17 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-83
2022-04-02 17:40:17 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-83
2022-04-02 17:40:17 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-f2a04f77 in namespace namespace-83
2022-04-02 17:40:17 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-83
2022-04-02 17:40:17 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-f2a04f77 will have desired state: Ready
2022-04-02 17:42:07 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-f2a04f77 is in desired state: Ready
2022-04-02 17:42:07 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1916789577-819935111 in namespace namespace-83
2022-04-02 17:42:07 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-83
2022-04-02 17:42:07 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1916789577-819935111 will have desired state: Ready
2022-04-02 17:42:08 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1916789577-819935111 is in desired state: Ready
2022-04-02 17:42:08 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1535549118-1326895758 in namespace namespace-83
2022-04-02 17:42:08 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-83
2022-04-02 17:42:08 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1535549118-1326895758 will have desired state: Ready
2022-04-02 17:42:09 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1535549118-1326895758 is in desired state: Ready
2022-04-02 17:42:09 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-f2a04f77-kafka-clients in namespace namespace-83
2022-04-02 17:42:09 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-83
2022-04-02 17:42:19 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-02 17:42:19 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@7a0edb7c, messages=[], arguments=[USER=my_user_1535549118_1326895758, --max-messages, 100, --topic, my-topic-1916789577-819935111, --bootstrap-server, my-cluster-f2a04f77-kafka-bootstrap.namespace-83.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg', podNamespace='namespace-83', bootstrapServer='my-cluster-f2a04f77-kafka-bootstrap.namespace-83.svc:9093', topicName='my-topic-1916789577-819935111', maxMessages=100, kafkaUsername='my-user-1535549118-1326895758', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6f1484cb}
2022-04-02 17:42:19 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-f2a04f77-kafka-bootstrap.namespace-83.svc:9093:my-topic-1916789577-819935111 from pod my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg
2022-04-02 17:42:19 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg -n namespace-83 -- /opt/kafka/producer.sh USER=my_user_1535549118_1326895758 --max-messages 100 --topic my-topic-1916789577-819935111 --bootstrap-server my-cluster-f2a04f77-kafka-bootstrap.namespace-83.svc:9093
2022-04-02 17:42:22 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-02 17:42:22 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-02 17:42:22 [main] [32mINFO [m [RollingUpdateST:203] Update resources for pods
2022-04-02 17:42:22 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@1104e1b2, messages=[], arguments=[USER=my_user_1535549118_1326895758, --max-messages, 100, --group-instance-id, instance2116086516, --group-id, my-consumer-group-642256580, --topic, my-topic-1916789577-819935111, --bootstrap-server, my-cluster-f2a04f77-kafka-bootstrap.namespace-83.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg', podNamespace='namespace-83', bootstrapServer='my-cluster-f2a04f77-kafka-bootstrap.namespace-83.svc:9093', topicName='my-topic-1916789577-819935111', maxMessages=100, kafkaUsername='my-user-1535549118-1326895758', consumerGroupName='my-consumer-group-642256580', consumerInstanceId='instance2116086516', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1d5d0c5e}
2022-04-02 17:42:22 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-f2a04f77-kafka-bootstrap.namespace-83.svc:9093:my-topic-1916789577-819935111 from pod my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg
2022-04-02 17:42:22 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg -n namespace-83 -- /opt/kafka/consumer.sh USER=my_user_1535549118_1326895758 --max-messages 100 --group-instance-id instance2116086516 --group-id my-consumer-group-642256580 --topic my-topic-1916789577-819935111 --bootstrap-server my-cluster-f2a04f77-kafka-bootstrap.namespace-83.svc:9093
2022-04-02 17:42:29 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-02 17:42:29 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-02 17:42:29 [main] [32mINFO [m [ClientUtils:45] Consumer successfully consumed 100 messages for the 1 time
2022-04-02 17:42:29 [main] [32mINFO [m [PodUtils:277] Wait for at least one pod with prefix: my-cluster-f2a04f77-kafka will be in pending phase
2022-04-02 17:42:31 [main] [32mINFO [m [RollingUpdateST:220] Verifying stability of kafka pods except the one, which is in pending phase
2022-04-02 17:42:31 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-f2a04f77-kafka are stable
2022-04-02 17:42:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-02 17:42:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-02 17:42:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg is in the Running state. Remaining seconds pod to be stable 50
2022-04-02 17:42:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-02 17:42:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-02 17:42:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg is in the Running state. Remaining seconds pod to be stable 49
2022-04-02 17:42:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-02 17:42:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-02 17:42:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg is in the Running state. Remaining seconds pod to be stable 48
2022-04-02 17:42:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-02 17:42:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-02 17:42:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg is in the Running state. Remaining seconds pod to be stable 47
2022-04-02 17:42:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-02 17:42:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-02 17:42:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg is in the Running state. Remaining seconds pod to be stable 46
2022-04-02 17:42:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-02 17:42:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-02 17:42:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg is in the Running state. Remaining seconds pod to be stable 45
2022-04-02 17:42:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-02 17:42:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-02 17:42:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg is in the Running state. Remaining seconds pod to be stable 44
2022-04-02 17:42:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-02 17:42:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-02 17:42:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg is in the Running state. Remaining seconds pod to be stable 43
2022-04-02 17:42:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-02 17:42:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-02 17:42:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg is in the Running state. Remaining seconds pod to be stable 42
2022-04-02 17:42:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-02 17:42:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-02 17:42:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg is in the Running state. Remaining seconds pod to be stable 41
2022-04-02 17:42:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-02 17:42:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-02 17:42:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg is in the Running state. Remaining seconds pod to be stable 40
2022-04-02 17:42:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-02 17:42:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-02 17:42:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg is in the Running state. Remaining seconds pod to be stable 39
2022-04-02 17:42:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-02 17:42:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-02 17:42:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg is in the Running state. Remaining seconds pod to be stable 38
2022-04-02 17:42:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-02 17:42:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-02 17:42:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg is in the Running state. Remaining seconds pod to be stable 37
2022-04-02 17:42:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-02 17:42:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-02 17:42:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg is in the Running state. Remaining seconds pod to be stable 36
2022-04-02 17:42:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-02 17:42:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-02 17:42:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg is in the Running state. Remaining seconds pod to be stable 35
2022-04-02 17:42:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-02 17:42:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-02 17:42:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg is in the Running state. Remaining seconds pod to be stable 34
2022-04-02 17:42:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-02 17:42:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-02 17:42:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg is in the Running state. Remaining seconds pod to be stable 33
2022-04-02 17:42:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-02 17:42:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-02 17:42:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg is in the Running state. Remaining seconds pod to be stable 32
2022-04-02 17:42:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-02 17:42:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-02 17:42:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg is in the Running state. Remaining seconds pod to be stable 31
2022-04-02 17:42:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-02 17:42:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-02 17:42:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg is in the Running state. Remaining seconds pod to be stable 30
2022-04-02 17:42:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-02 17:42:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-02 17:42:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg is in the Running state. Remaining seconds pod to be stable 29
2022-04-02 17:42:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-02 17:42:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-02 17:42:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg is in the Running state. Remaining seconds pod to be stable 28
2022-04-02 17:42:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-02 17:42:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-02 17:42:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg is in the Running state. Remaining seconds pod to be stable 27
2022-04-02 17:42:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-02 17:42:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-02 17:42:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg is in the Running state. Remaining seconds pod to be stable 26
2022-04-02 17:42:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-02 17:42:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-02 17:42:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg is in the Running state. Remaining seconds pod to be stable 25
2022-04-02 17:42:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-02 17:42:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-02 17:42:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg is in the Running state. Remaining seconds pod to be stable 24
2022-04-02 17:42:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-02 17:42:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-02 17:42:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg is in the Running state. Remaining seconds pod to be stable 23
2022-04-02 17:42:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-02 17:42:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-02 17:42:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg is in the Running state. Remaining seconds pod to be stable 22
2022-04-02 17:43:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-02 17:43:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-02 17:43:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg is in the Running state. Remaining seconds pod to be stable 21
2022-04-02 17:43:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-02 17:43:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-02 17:43:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg is in the Running state. Remaining seconds pod to be stable 20
2022-04-02 17:43:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-02 17:43:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-02 17:43:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg is in the Running state. Remaining seconds pod to be stable 19
2022-04-02 17:43:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-02 17:43:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-02 17:43:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg is in the Running state. Remaining seconds pod to be stable 18
2022-04-02 17:43:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-02 17:43:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-02 17:43:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg is in the Running state. Remaining seconds pod to be stable 17
2022-04-02 17:43:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-02 17:43:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-02 17:43:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg is in the Running state. Remaining seconds pod to be stable 16
2022-04-02 17:43:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-02 17:43:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-02 17:43:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg is in the Running state. Remaining seconds pod to be stable 15
2022-04-02 17:43:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-02 17:43:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-02 17:43:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg is in the Running state. Remaining seconds pod to be stable 14
2022-04-02 17:43:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-02 17:43:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-02 17:43:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg is in the Running state. Remaining seconds pod to be stable 13
2022-04-02 17:43:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-02 17:43:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-02 17:43:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg is in the Running state. Remaining seconds pod to be stable 12
2022-04-02 17:43:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-02 17:43:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-02 17:43:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg is in the Running state. Remaining seconds pod to be stable 11
2022-04-02 17:43:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-02 17:43:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-02 17:43:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg is in the Running state. Remaining seconds pod to be stable 10
2022-04-02 17:43:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-02 17:43:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-02 17:43:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg is in the Running state. Remaining seconds pod to be stable 9
2022-04-02 17:43:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-02 17:43:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-02 17:43:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg is in the Running state. Remaining seconds pod to be stable 8
2022-04-02 17:43:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-02 17:43:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-02 17:43:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg is in the Running state. Remaining seconds pod to be stable 7
2022-04-02 17:43:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-02 17:43:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-02 17:43:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg is in the Running state. Remaining seconds pod to be stable 6
2022-04-02 17:43:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-02 17:43:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-02 17:43:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg is in the Running state. Remaining seconds pod to be stable 5
2022-04-02 17:43:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-02 17:43:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-02 17:43:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg is in the Running state. Remaining seconds pod to be stable 4
2022-04-02 17:43:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-02 17:43:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-02 17:43:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg is in the Running state. Remaining seconds pod to be stable 3
2022-04-02 17:43:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-02 17:43:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-02 17:43:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg is in the Running state. Remaining seconds pod to be stable 2
2022-04-02 17:43:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-02 17:43:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-02 17:43:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg is in the Running state. Remaining seconds pod to be stable 1
2022-04-02 17:43:21 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-f2a04f77-kafka-0 ,my-cluster-f2a04f77-kafka-2 ,my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg
2022-04-02 17:43:21 [main] [32mINFO [m [RollingUpdateST:223] Verifying stability of zookeeper pods
2022-04-02 17:43:21 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-f2a04f77-zookeeper are stable
2022-04-02 17:43:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-02 17:43:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-02 17:43:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-02 17:43:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-02 17:43:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-02 17:43:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-02 17:43:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-02 17:43:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-02 17:43:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-02 17:43:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-02 17:43:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-02 17:43:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-02 17:43:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-02 17:43:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-02 17:43:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-02 17:43:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-02 17:43:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-02 17:43:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-02 17:43:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-02 17:43:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-02 17:43:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-02 17:43:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-02 17:43:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-02 17:43:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-02 17:43:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-02 17:43:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-02 17:43:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-02 17:43:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-02 17:43:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-02 17:43:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-02 17:43:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-02 17:43:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-02 17:43:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-02 17:43:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-02 17:43:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-02 17:43:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-02 17:43:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-02 17:43:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-02 17:43:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-02 17:43:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-02 17:43:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-02 17:43:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-02 17:43:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-02 17:43:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-02 17:43:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-02 17:43:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-02 17:43:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-02 17:43:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-02 17:43:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-02 17:43:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-02 17:43:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-02 17:43:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-02 17:43:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-02 17:43:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-02 17:43:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-02 17:43:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-02 17:43:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-02 17:43:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-02 17:43:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-02 17:43:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-02 17:43:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-02 17:43:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-02 17:43:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-02 17:43:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-02 17:43:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-02 17:43:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-02 17:43:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-02 17:43:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-02 17:43:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-02 17:43:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-02 17:43:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-02 17:43:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-02 17:43:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-02 17:43:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-02 17:43:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-02 17:43:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-02 17:43:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-02 17:43:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-02 17:43:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-02 17:43:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-02 17:43:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-02 17:43:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-02 17:43:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-02 17:43:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-02 17:43:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-02 17:43:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-02 17:43:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-02 17:43:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-02 17:43:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-02 17:43:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-02 17:43:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-02 17:43:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-02 17:43:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-02 17:43:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-02 17:43:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-02 17:43:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-02 17:43:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-02 17:43:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-02 17:43:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-02 17:43:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-02 17:43:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-02 17:43:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-02 17:43:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-02 17:43:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-02 17:43:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-02 17:43:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-02 17:43:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-02 17:43:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-02 17:43:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-02 17:43:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-02 17:43:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-02 17:43:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-02 17:43:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-02 17:43:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-02 17:43:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-02 17:43:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-02 17:43:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-02 17:44:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-02 17:44:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-02 17:44:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-02 17:44:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-02 17:44:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-02 17:44:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-02 17:44:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-02 17:44:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-02 17:44:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-02 17:44:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-02 17:44:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-02 17:44:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-02 17:44:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-02 17:44:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-02 17:44:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-02 17:44:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-02 17:44:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-02 17:44:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-02 17:44:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-02 17:44:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-02 17:44:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-02 17:44:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-02 17:44:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-02 17:44:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-02 17:44:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-02 17:44:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-02 17:44:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-02 17:44:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-02 17:44:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-02 17:44:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-02 17:44:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-02 17:44:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-02 17:44:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f2a04f77-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-02 17:44:10 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-f2a04f77-zookeeper-0 ,my-cluster-f2a04f77-zookeeper-1 ,my-cluster-f2a04f77-zookeeper-2
2022-04-02 17:44:10 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@430e2300, messages=[], arguments=[USER=my_user_1535549118_1326895758, --max-messages, 100, --group-instance-id, instance1929497665, --group-id, my-consumer-group-1647797944, --topic, my-topic-1916789577-819935111, --bootstrap-server, my-cluster-f2a04f77-kafka-bootstrap.namespace-83.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg', podNamespace='namespace-83', bootstrapServer='my-cluster-f2a04f77-kafka-bootstrap.namespace-83.svc:9093', topicName='my-topic-1916789577-819935111', maxMessages=100, kafkaUsername='my-user-1535549118-1326895758', consumerGroupName='my-consumer-group-1647797944', consumerInstanceId='instance1929497665', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@321fd54e}
2022-04-02 17:44:10 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-f2a04f77-kafka-bootstrap.namespace-83.svc:9093:my-topic-1916789577-819935111 from pod my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg
2022-04-02 17:44:10 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg -n namespace-83 -- /opt/kafka/consumer.sh USER=my_user_1535549118_1326895758 --max-messages 100 --group-instance-id instance1929497665 --group-id my-consumer-group-1647797944 --topic my-topic-1916789577-819935111 --bootstrap-server my-cluster-f2a04f77-kafka-bootstrap.namespace-83.svc:9093
2022-04-02 17:44:17 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-02 17:44:17 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-02 17:44:17 [main] [32mINFO [m [ClientUtils:45] Consumer successfully consumed 100 messages for the 1 time
2022-04-02 17:44:17 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-f2a04f77-kafka to be ready
2022-04-02 17:49:32 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-f2a04f77 will have desired state: Ready
2022-04-02 17:49:32 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-f2a04f77 is in desired state: Ready
2022-04-02 17:49:32 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-f2a04f77 is ready
2022-04-02 17:49:32 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@7e26aa8f, messages=[], arguments=[USER=my_user_1535549118_1326895758, --max-messages, 100, --group-instance-id, instance77347702, --group-id, my-consumer-group-1381484024, --topic, my-topic-1916789577-819935111, --bootstrap-server, my-cluster-f2a04f77-kafka-bootstrap.namespace-83.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg', podNamespace='namespace-83', bootstrapServer='my-cluster-f2a04f77-kafka-bootstrap.namespace-83.svc:9093', topicName='my-topic-1916789577-819935111', maxMessages=100, kafkaUsername='my-user-1535549118-1326895758', consumerGroupName='my-consumer-group-1381484024', consumerInstanceId='instance77347702', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@4c82863c}
2022-04-02 17:49:32 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-f2a04f77-kafka-bootstrap.namespace-83.svc:9093:my-topic-1916789577-819935111 from pod my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg
2022-04-02 17:49:32 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg -n namespace-83 -- /opt/kafka/consumer.sh USER=my_user_1535549118_1326895758 --max-messages 100 --group-instance-id instance77347702 --group-id my-consumer-group-1381484024 --topic my-topic-1916789577-819935111 --bootstrap-server my-cluster-f2a04f77-kafka-bootstrap.namespace-83.svc:9093
2022-04-02 17:49:39 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-02 17:49:39 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-02 17:49:39 [main] [32mINFO [m [ClientUtils:45] Consumer successfully consumed 100 messages for the 1 time
2022-04-02 17:49:39 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-2003258465-44688625 in namespace namespace-83
2022-04-02 17:49:39 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-83
2022-04-02 17:49:39 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-2003258465-44688625 will have desired state: Ready
2022-04-02 17:49:40 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-2003258465-44688625 is in desired state: Ready
2022-04-02 17:49:40 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@6b4f922e, messages=[], arguments=[USER=my_user_1535549118_1326895758, --max-messages, 100, --topic, my-topic-2003258465-44688625, --bootstrap-server, my-cluster-f2a04f77-kafka-bootstrap.namespace-83.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg', podNamespace='namespace-83', bootstrapServer='my-cluster-f2a04f77-kafka-bootstrap.namespace-83.svc:9093', topicName='my-topic-2003258465-44688625', maxMessages=100, kafkaUsername='my-user-1535549118-1326895758', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@33244110}
2022-04-02 17:49:40 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-f2a04f77-kafka-bootstrap.namespace-83.svc:9093:my-topic-2003258465-44688625 from pod my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg
2022-04-02 17:49:40 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg -n namespace-83 -- /opt/kafka/producer.sh USER=my_user_1535549118_1326895758 --max-messages 100 --topic my-topic-2003258465-44688625 --bootstrap-server my-cluster-f2a04f77-kafka-bootstrap.namespace-83.svc:9093
2022-04-02 17:49:44 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-02 17:49:44 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-02 17:49:44 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@65bd327b, messages=[], arguments=[USER=my_user_1535549118_1326895758, --max-messages, 100, --group-instance-id, instance1071542757, --group-id, my-consumer-group-314732678, --topic, my-topic-2003258465-44688625, --bootstrap-server, my-cluster-f2a04f77-kafka-bootstrap.namespace-83.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg', podNamespace='namespace-83', bootstrapServer='my-cluster-f2a04f77-kafka-bootstrap.namespace-83.svc:9093', topicName='my-topic-2003258465-44688625', maxMessages=100, kafkaUsername='my-user-1535549118-1326895758', consumerGroupName='my-consumer-group-314732678', consumerInstanceId='instance1071542757', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@20762f1a}
2022-04-02 17:49:44 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-f2a04f77-kafka-bootstrap.namespace-83.svc:9093:my-topic-2003258465-44688625 from pod my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg
2022-04-02 17:49:44 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-f2a04f77-kafka-clients-6b79fc6b94-wrppg -n namespace-83 -- /opt/kafka/consumer.sh USER=my_user_1535549118_1326895758 --max-messages 100 --group-instance-id instance1071542757 --group-id my-consumer-group-314732678 --topic my-topic-2003258465-44688625 --bootstrap-server my-cluster-f2a04f77-kafka-bootstrap.namespace-83.svc:9093
2022-04-02 17:49:51 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-02 17:49:51 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-02 17:49:51 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 17:49:51 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryDuringKafkaRollingUpdate
2022-04-02 17:49:51 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1535549118-1326895758 in namespace namespace-83
2022-04-02 17:49:51 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-f2a04f77-kafka-clients in namespace namespace-83
2022-04-02 17:49:51 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-2003258465-44688625 in namespace namespace-83
2022-04-02 17:49:51 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-f2a04f77 in namespace namespace-83
2022-04-02 17:49:51 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1916789577-819935111 in namespace namespace-83
2022-04-02 17:50:51 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 17:50:51 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-83 for test case:testRecoveryDuringKafkaRollingUpdate
2022-04-02 17:50:56 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testRecoveryDuringKafkaRollingUpdate-FINISHED
2022-04-02 17:50:56 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 17:50:56 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 17:50:56 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testClusterOperatorFinishAllRollingUpdates-STARTED
2022-04-02 17:50:56 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 17:50:56 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-0ad59d56 in namespace rolling-update-st
2022-04-02 17:50:56 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-0ad59d56 will have desired state: Ready
2022-04-02 17:52:50 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-0ad59d56 is in desired state: Ready
2022-04-02 17:55:50 [main] [1;31mERROR[m [TestExecutionWatcher:28] RollingUpdateST - Exception Timeout after 180000 ms waiting for rolling update starts has been thrown in @Test. Going to collect logs from components.
2022-04-02 17:55:50 [main] [32mINFO [m [LogCollector:252] Collecting events in Namespace infra-namespace
2022-04-02 17:55:50 [main] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace infra-namespace
2022-04-02 17:55:50 [main] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace infra-namespace
2022-04-02 17:56:00 [main] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace infra-namespace
2022-04-02 17:56:01 [main] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace infra-namespace
2022-04-02 17:56:01 [main] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace infra-namespace
2022-04-02 17:56:01 [main] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace infra-namespace
2022-04-02 17:56:01 [main] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-04-02 17:56:01 [main] [32mINFO [m [LogCollector:252] Collecting events in Namespace rolling-update-st
2022-04-02 17:56:01 [main] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace rolling-update-st
2022-04-02 17:56:01 [main] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace rolling-update-st
2022-04-02 17:56:03 [main] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace rolling-update-st
2022-04-02 17:56:03 [main] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace rolling-update-st
2022-04-02 17:56:03 [main] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace rolling-update-st
2022-04-02 17:56:03 [main] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace rolling-update-st
2022-04-02 17:56:03 [main] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-04-02 17:56:03 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 17:56:03 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testClusterOperatorFinishAllRollingUpdates
2022-04-02 17:56:03 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-0ad59d56 in namespace rolling-update-st
2022-04-02 17:56:13 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 17:56:13 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testClusterOperatorFinishAllRollingUpdates-FINISHED
2022-04-02 17:56:13 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 17:56:13 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 17:56:13 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testKafkaAndZookeeperScaleUpScaleDown-STARTED
2022-04-02 17:56:13 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 17:56:13 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-84 for test case:testKafkaAndZookeeperScaleUpScaleDown
2022-04-02 17:56:13 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-84
2022-04-02 17:56:13 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-84
2022-04-02 17:56:13 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-84
2022-04-02 17:56:13 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-8fe58c69 in namespace namespace-84
2022-04-02 17:56:13 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-84
2022-04-02 17:56:13 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-8fe58c69 will have desired state: Ready
2022-04-02 17:58:29 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-8fe58c69 is in desired state: Ready
2022-04-02 17:58:29 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-962700039-1727799403 in namespace namespace-84
2022-04-02 17:58:29 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-84
2022-04-02 17:58:29 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-962700039-1727799403 will have desired state: Ready
2022-04-02 17:58:30 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-962700039-1727799403 is in desired state: Ready
2022-04-02 17:58:30 [main] [32mINFO [m [AbstractST:489] Verifying docker image names
2022-04-02 17:58:30 [main] [32mINFO [m [AbstractST:172] strimzi-cluster-operator
2022-04-02 17:58:30 [main] [32mINFO [m [AbstractST:525] Docker images verified
2022-04-02 17:58:30 [main] [32mINFO [m [RollingUpdateST:292] Running kafkaScaleUpScaleDown my-cluster-8fe58c69
2022-04-02 17:58:30 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-2049253682-1465107859 in namespace namespace-84
2022-04-02 17:58:30 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-84
2022-04-02 17:58:30 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-2049253682-1465107859 will have desired state: Ready
2022-04-02 17:58:31 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-2049253682-1465107859 is in desired state: Ready
2022-04-02 17:58:31 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-8fe58c69-kafka-clients in namespace namespace-84
2022-04-02 17:58:31 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-84
2022-04-02 17:58:41 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-02 17:58:41 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@15178a2, messages=[], arguments=[USER=my_user_962700039_1727799403, --max-messages, 100, --topic, my-topic-2049253682-1465107859, --bootstrap-server, my-cluster-8fe58c69-kafka-bootstrap.namespace-84.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-8fe58c69-kafka-clients-bc967fc4-k8trf', podNamespace='namespace-84', bootstrapServer='my-cluster-8fe58c69-kafka-bootstrap.namespace-84.svc:9093', topicName='my-topic-2049253682-1465107859', maxMessages=100, kafkaUsername='my-user-962700039-1727799403', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@4e99ce41}
2022-04-02 17:58:41 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-8fe58c69-kafka-bootstrap.namespace-84.svc:9093:my-topic-2049253682-1465107859 from pod my-cluster-8fe58c69-kafka-clients-bc967fc4-k8trf
2022-04-02 17:58:41 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-8fe58c69-kafka-clients-bc967fc4-k8trf -n namespace-84 -- /opt/kafka/producer.sh USER=my_user_962700039_1727799403 --max-messages 100 --topic my-topic-2049253682-1465107859 --bootstrap-server my-cluster-8fe58c69-kafka-bootstrap.namespace-84.svc:9093
2022-04-02 17:58:45 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-02 17:58:45 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-02 17:58:45 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@3fe75058, messages=[], arguments=[USER=my_user_962700039_1727799403, --max-messages, 100, --group-instance-id, instance680743669, --group-id, my-consumer-group-124141328, --topic, my-topic-2049253682-1465107859, --bootstrap-server, my-cluster-8fe58c69-kafka-bootstrap.namespace-84.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-8fe58c69-kafka-clients-bc967fc4-k8trf', podNamespace='namespace-84', bootstrapServer='my-cluster-8fe58c69-kafka-bootstrap.namespace-84.svc:9093', topicName='my-topic-2049253682-1465107859', maxMessages=100, kafkaUsername='my-user-962700039-1727799403', consumerGroupName='my-consumer-group-124141328', consumerInstanceId='instance680743669', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@4ba1e8ff}
2022-04-02 17:58:45 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-8fe58c69-kafka-bootstrap.namespace-84.svc:9093:my-topic-2049253682-1465107859 from pod my-cluster-8fe58c69-kafka-clients-bc967fc4-k8trf
2022-04-02 17:58:45 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-8fe58c69-kafka-clients-bc967fc4-k8trf -n namespace-84 -- /opt/kafka/consumer.sh USER=my_user_962700039_1727799403 --max-messages 100 --group-instance-id instance680743669 --group-id my-consumer-group-124141328 --topic my-topic-2049253682-1465107859 --bootstrap-server my-cluster-8fe58c69-kafka-bootstrap.namespace-84.svc:9093
2022-04-02 17:58:52 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-02 17:58:52 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-02 17:58:52 [main] [32mINFO [m [RollingUpdateST:317] Scale up Kafka to 7
2022-04-02 17:58:52 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-8fe58c69-kafka rolling update
2022-04-02 18:00:02 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-8fe58c69-kafka has been successfully rolled
2022-04-02 18:00:02 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 7 Pod(s) of my-cluster-8fe58c69-kafka to be ready
2022-04-02 18:00:54 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-8fe58c69 will have desired state: Ready
2022-04-02 18:00:54 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-8fe58c69 is in desired state: Ready
2022-04-02 18:00:54 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-8fe58c69 is ready
2022-04-02 18:00:54 [main] [32mINFO [m [RollingUpdateST:327] Kafka scale up to 7 finished
2022-04-02 18:00:54 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@56bc404e, messages=[], arguments=[USER=my_user_962700039_1727799403, --max-messages, 100, --group-instance-id, instance67520539, --group-id, my-consumer-group-635076906, --topic, my-topic-2049253682-1465107859, --bootstrap-server, my-cluster-8fe58c69-kafka-bootstrap.namespace-84.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-8fe58c69-kafka-clients-bc967fc4-k8trf', podNamespace='namespace-84', bootstrapServer='my-cluster-8fe58c69-kafka-bootstrap.namespace-84.svc:9093', topicName='my-topic-2049253682-1465107859', maxMessages=100, kafkaUsername='my-user-962700039-1727799403', consumerGroupName='my-consumer-group-635076906', consumerInstanceId='instance67520539', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3c21c6fd}
2022-04-02 18:00:54 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-8fe58c69-kafka-bootstrap.namespace-84.svc:9093:my-topic-2049253682-1465107859 from pod my-cluster-8fe58c69-kafka-clients-bc967fc4-k8trf
2022-04-02 18:00:54 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-8fe58c69-kafka-clients-bc967fc4-k8trf -n namespace-84 -- /opt/kafka/consumer.sh USER=my_user_962700039_1727799403 --max-messages 100 --group-instance-id instance67520539 --group-id my-consumer-group-635076906 --topic my-topic-2049253682-1465107859 --bootstrap-server my-cluster-8fe58c69-kafka-bootstrap.namespace-84.svc:9093
2022-04-02 18:01:01 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-02 18:01:01 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-02 18:01:01 [main] [32mINFO [m [RollingUpdateST:339] Scale up Zookeeper to 5
2022-04-02 18:01:01 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 5 Pod(s) of my-cluster-8fe58c69-zookeeper to be ready
2022-04-02 18:02:05 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-8fe58c69 will have desired state: Ready
2022-04-02 18:02:05 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-8fe58c69 is in desired state: Ready
2022-04-02 18:02:05 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-8fe58c69 is ready
2022-04-02 18:02:05 [main] [32mINFO [m [RollingUpdateST:342] Kafka scale up to 5 finished
2022-04-02 18:02:05 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@56c64329, messages=[], arguments=[USER=my_user_962700039_1727799403, --max-messages, 100, --group-instance-id, instance1125776182, --group-id, my-consumer-group-530469636, --topic, my-topic-2049253682-1465107859, --bootstrap-server, my-cluster-8fe58c69-kafka-bootstrap.namespace-84.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-8fe58c69-kafka-clients-bc967fc4-k8trf', podNamespace='namespace-84', bootstrapServer='my-cluster-8fe58c69-kafka-bootstrap.namespace-84.svc:9093', topicName='my-topic-2049253682-1465107859', maxMessages=100, kafkaUsername='my-user-962700039-1727799403', consumerGroupName='my-consumer-group-530469636', consumerInstanceId='instance1125776182', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@9614d5f}
2022-04-02 18:02:05 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-8fe58c69-kafka-bootstrap.namespace-84.svc:9093:my-topic-2049253682-1465107859 from pod my-cluster-8fe58c69-kafka-clients-bc967fc4-k8trf
2022-04-02 18:02:05 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-8fe58c69-kafka-clients-bc967fc4-k8trf -n namespace-84 -- /opt/kafka/consumer.sh USER=my_user_962700039_1727799403 --max-messages 100 --group-instance-id instance1125776182 --group-id my-consumer-group-530469636 --topic my-topic-2049253682-1465107859 --bootstrap-server my-cluster-8fe58c69-kafka-bootstrap.namespace-84.svc:9093
2022-04-02 18:02:12 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-02 18:02:12 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-02 18:02:12 [main] [32mINFO [m [RollingUpdateST:351] Scale down Kafka to 3
2022-04-02 18:02:12 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-8fe58c69-kafka rolling update
2022-04-02 18:03:57 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-8fe58c69-kafka has been successfully rolled
2022-04-02 18:03:57 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-8fe58c69-kafka to be ready
2022-04-02 18:04:21 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-8fe58c69 will have desired state: Ready
2022-04-02 18:04:21 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-8fe58c69 is in desired state: Ready
2022-04-02 18:04:21 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-8fe58c69 is ready
2022-04-02 18:04:21 [main] [32mINFO [m [RollingUpdateST:356] Kafka scale down to 3 finished
2022-04-02 18:04:21 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@6dd9c4d3, messages=[], arguments=[USER=my_user_962700039_1727799403, --max-messages, 100, --group-instance-id, instance270915200, --group-id, my-consumer-group-1970578392, --topic, my-topic-2049253682-1465107859, --bootstrap-server, my-cluster-8fe58c69-kafka-bootstrap.namespace-84.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-8fe58c69-kafka-clients-bc967fc4-k8trf', podNamespace='namespace-84', bootstrapServer='my-cluster-8fe58c69-kafka-bootstrap.namespace-84.svc:9093', topicName='my-topic-2049253682-1465107859', maxMessages=100, kafkaUsername='my-user-962700039-1727799403', consumerGroupName='my-consumer-group-1970578392', consumerInstanceId='instance270915200', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@20a8ef5d}
2022-04-02 18:04:21 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-8fe58c69-kafka-bootstrap.namespace-84.svc:9093:my-topic-2049253682-1465107859 from pod my-cluster-8fe58c69-kafka-clients-bc967fc4-k8trf
2022-04-02 18:04:21 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-8fe58c69-kafka-clients-bc967fc4-k8trf -n namespace-84 -- /opt/kafka/consumer.sh USER=my_user_962700039_1727799403 --max-messages 100 --group-instance-id instance270915200 --group-id my-consumer-group-1970578392 --topic my-topic-2049253682-1465107859 --bootstrap-server my-cluster-8fe58c69-kafka-bootstrap.namespace-84.svc:9093
2022-04-02 18:04:28 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-02 18:04:28 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-02 18:04:28 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1786083967-1721686555 in namespace namespace-84
2022-04-02 18:04:28 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-84
2022-04-02 18:04:28 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1786083967-1721686555 will have desired state: Ready
2022-04-02 18:06:16 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1786083967-1721686555 is in desired state: Ready
2022-04-02 18:06:16 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@7264c900, messages=[], arguments=[USER=my_user_962700039_1727799403, --max-messages, 100, --topic, my-topic-1786083967-1721686555, --bootstrap-server, my-cluster-8fe58c69-kafka-bootstrap.namespace-84.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-8fe58c69-kafka-clients-bc967fc4-k8trf', podNamespace='namespace-84', bootstrapServer='my-cluster-8fe58c69-kafka-bootstrap.namespace-84.svc:9093', topicName='my-topic-1786083967-1721686555', maxMessages=100, kafkaUsername='my-user-962700039-1727799403', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@51b860b8}
2022-04-02 18:06:16 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-8fe58c69-kafka-bootstrap.namespace-84.svc:9093:my-topic-1786083967-1721686555 from pod my-cluster-8fe58c69-kafka-clients-bc967fc4-k8trf
2022-04-02 18:06:16 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-8fe58c69-kafka-clients-bc967fc4-k8trf -n namespace-84 -- /opt/kafka/producer.sh USER=my_user_962700039_1727799403 --max-messages 100 --topic my-topic-1786083967-1721686555 --bootstrap-server my-cluster-8fe58c69-kafka-bootstrap.namespace-84.svc:9093
2022-04-02 18:06:19 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-02 18:06:19 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-02 18:06:19 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@42d2bbac, messages=[], arguments=[USER=my_user_962700039_1727799403, --max-messages, 100, --group-instance-id, instance536699462, --group-id, my-consumer-group-679542432, --topic, my-topic-1786083967-1721686555, --bootstrap-server, my-cluster-8fe58c69-kafka-bootstrap.namespace-84.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-8fe58c69-kafka-clients-bc967fc4-k8trf', podNamespace='namespace-84', bootstrapServer='my-cluster-8fe58c69-kafka-bootstrap.namespace-84.svc:9093', topicName='my-topic-1786083967-1721686555', maxMessages=100, kafkaUsername='my-user-962700039-1727799403', consumerGroupName='my-consumer-group-679542432', consumerInstanceId='instance536699462', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@50fdbcab}
2022-04-02 18:06:19 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-8fe58c69-kafka-bootstrap.namespace-84.svc:9093:my-topic-1786083967-1721686555 from pod my-cluster-8fe58c69-kafka-clients-bc967fc4-k8trf
2022-04-02 18:06:19 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-8fe58c69-kafka-clients-bc967fc4-k8trf -n namespace-84 -- /opt/kafka/consumer.sh USER=my_user_962700039_1727799403 --max-messages 100 --group-instance-id instance536699462 --group-id my-consumer-group-679542432 --topic my-topic-1786083967-1721686555 --bootstrap-server my-cluster-8fe58c69-kafka-bootstrap.namespace-84.svc:9093
2022-04-02 18:06:26 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-02 18:06:26 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-02 18:06:26 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 18:06:26 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaAndZookeeperScaleUpScaleDown
2022-04-02 18:06:26 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-2049253682-1465107859 in namespace namespace-84
2022-04-02 18:06:26 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-962700039-1727799403 in namespace namespace-84
2022-04-02 18:06:26 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-8fe58c69 in namespace namespace-84
2022-04-02 18:06:26 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-8fe58c69-kafka-clients in namespace namespace-84
2022-04-02 18:06:26 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1786083967-1721686555 in namespace namespace-84
2022-04-02 18:07:07 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 18:07:07 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-84 for test case:testKafkaAndZookeeperScaleUpScaleDown
2022-04-02 18:07:13 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testKafkaAndZookeeperScaleUpScaleDown-FINISHED
2022-04-02 18:07:13 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 18:07:13 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 18:07:13 [main] [32mINFO [m [ResourceManager:346] In context RollingUpdateST is everything deleted.
2022-04-02 18:07:13 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;31mERROR[m] Tests run: 9, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 3,998.079 s <<< FAILURE! - in io.strimzi.systemtest.rollingupdate.RollingUpdateST
[[1;31mERROR[m] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testClusterOperatorFinishAllRollingUpdates(ExtensionContext)  Time elapsed: 317.191 s  <<< ERROR!
io.strimzi.test.WaitException: Timeout after 180000 ms waiting for rolling update starts
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.rollingupdate.RollingUpdateST.testClusterOperatorFinishAllRollingUpdates(RollingUpdateST.java:625)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)

[[1;34mINFO[m] Running io.strimzi.systemtest.log.LoggingChangeST
2022-04-02 18:07:20 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: logging-change-st
2022-04-02 18:07:20 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: logging-change-st
2022-04-02 18:07:20 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: logging-change-st
2022-04-02 18:07:20 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 18:07:20 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetClusterOperatorLoggingLevels-STARTED
2022-04-02 18:07:20 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 18:07:20 [main] [32mINFO [m [LoggingChangeST:617] Checking that original logging config is different from the new one
2022-04-02 18:07:20 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-9t6wn -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-02 18:07:20 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:07:20 [main] [32mINFO [m [LoggingChangeST:620] Changing logging for cluster-operator
2022-04-02 18:07:20 [main] [32mINFO [m [LoggingChangeST:623] Waiting for log4j2.properties will contain desired settings
2022-04-02 18:07:20 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-9t6wn -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-02 18:07:20 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:07:21 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-9t6wn -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-02 18:07:21 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:07:22 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-9t6wn -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-02 18:07:22 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:07:24 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-9t6wn -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-02 18:07:24 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:07:25 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-9t6wn -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-02 18:07:25 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:07:26 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-9t6wn -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-02 18:07:26 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:07:27 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-9t6wn -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-02 18:07:27 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:07:28 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-9t6wn -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-02 18:07:28 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:07:29 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-9t6wn -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-02 18:07:29 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:07:31 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-9t6wn -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-02 18:07:31 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:07:32 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-9t6wn -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-02 18:07:32 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:07:33 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-9t6wn -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-02 18:07:33 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:07:34 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-9t6wn -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-02 18:07:34 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:07:35 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-9t6wn -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-02 18:07:35 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:07:36 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-9t6wn -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-02 18:07:36 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:07:36 [main] [32mINFO [m [LoggingChangeST:628] Checking log4j2.properties in CO pod
2022-04-02 18:07:37 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-9t6wn -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-02 18:07:37 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:07:37 [main] [32mINFO [m [LoggingChangeST:632] Checking if CO rolled its pod
2022-04-02 18:07:39 [main] [33mWARN [m [LoggingChangeST:638] 2022-04-02 18:07:26 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *
2022-04-02 18:07:28 INFO  AbstractOperator:373 - Reconciliation #2020(watch) Kafka(namespace-84/my-cluster-8fe58c69): Reconciliation is in progress

2022-04-02 18:07:42 [main] [33mWARN [m [LoggingChangeST:638] 2022-04-02 18:07:26 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *
2022-04-02 18:07:28 INFO  AbstractOperator:373 - Reconciliation #2020(watch) Kafka(namespace-84/my-cluster-8fe58c69): Reconciliation is in progress

2022-04-02 18:07:45 [main] [33mWARN [m [LoggingChangeST:638] 2022-04-02 18:07:26 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *
2022-04-02 18:07:28 INFO  AbstractOperator:373 - Reconciliation #2020(watch) Kafka(namespace-84/my-cluster-8fe58c69): Reconciliation is in progress

2022-04-02 18:07:48 [main] [33mWARN [m [LoggingChangeST:638] 2022-04-02 18:07:26 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *
2022-04-02 18:07:28 INFO  AbstractOperator:373 - Reconciliation #2020(watch) Kafka(namespace-84/my-cluster-8fe58c69): Reconciliation is in progress

2022-04-02 18:07:50 [main] [33mWARN [m [LoggingChangeST:638] 2022-04-02 18:07:26 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *
2022-04-02 18:07:28 INFO  AbstractOperator:373 - Reconciliation #2020(watch) Kafka(namespace-84/my-cluster-8fe58c69): Reconciliation is in progress

2022-04-02 18:07:53 [main] [33mWARN [m [LoggingChangeST:638] 2022-04-02 18:07:26 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *
2022-04-02 18:07:28 INFO  AbstractOperator:373 - Reconciliation #2020(watch) Kafka(namespace-84/my-cluster-8fe58c69): Reconciliation is in progress

2022-04-02 18:07:56 [main] [33mWARN [m [LoggingChangeST:638] 2022-04-02 18:07:26 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *
2022-04-02 18:07:28 INFO  AbstractOperator:373 - Reconciliation #2020(watch) Kafka(namespace-84/my-cluster-8fe58c69): Reconciliation is in progress

2022-04-02 18:07:59 [main] [33mWARN [m [LoggingChangeST:638] 2022-04-02 18:07:26 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *
2022-04-02 18:07:28 INFO  AbstractOperator:373 - Reconciliation #2020(watch) Kafka(namespace-84/my-cluster-8fe58c69): Reconciliation is in progress

2022-04-02 18:08:01 [main] [33mWARN [m [LoggingChangeST:638] 
2022-04-02 18:08:01 [main] [32mINFO [m [LoggingChangeST:642] Changing all levels from OFF to INFO/WARN
2022-04-02 18:08:01 [main] [32mINFO [m [LoggingChangeST:646] Changing logging for cluster-operator
2022-04-02 18:08:01 [main] [32mINFO [m [LoggingChangeST:649] Waiting for log4j2.properties will contain desired settings
2022-04-02 18:08:02 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-9t6wn -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-02 18:08:02 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:08:03 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-9t6wn -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-02 18:08:03 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:08:04 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-9t6wn -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-02 18:08:04 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:08:05 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-9t6wn -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-02 18:08:05 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:08:06 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-9t6wn -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-02 18:08:06 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:08:08 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-9t6wn -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-02 18:08:08 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:08:09 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-9t6wn -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-02 18:08:09 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:08:10 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-9t6wn -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-02 18:08:10 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:08:11 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-9t6wn -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-02 18:08:11 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:08:12 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-9t6wn -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-02 18:08:12 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:08:13 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-9t6wn -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-02 18:08:13 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:08:15 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-9t6wn -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-02 18:08:15 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:08:16 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-9t6wn -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-02 18:08:16 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:08:17 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-9t6wn -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-02 18:08:17 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:08:18 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-9t6wn -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-02 18:08:18 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:08:19 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-9t6wn -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-02 18:08:19 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:08:20 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-9t6wn -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-02 18:08:20 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:08:22 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-9t6wn -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-02 18:08:22 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:08:23 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-9t6wn -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-02 18:08:23 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:08:24 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-9t6wn -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-02 18:08:24 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:08:25 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-9t6wn -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-02 18:08:25 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:08:26 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-9t6wn -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-02 18:08:26 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:08:28 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-9t6wn -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-02 18:08:28 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:08:29 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-9t6wn -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-02 18:08:29 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:08:30 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-9t6wn -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-02 18:08:30 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:08:31 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-9t6wn -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-02 18:08:31 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:08:32 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-9t6wn -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-02 18:08:32 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:08:33 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-9t6wn -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-02 18:08:33 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:08:35 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-9t6wn -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-02 18:08:35 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:08:36 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-9t6wn -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-02 18:08:36 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:08:37 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-9t6wn -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-02 18:08:37 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:08:38 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-9t6wn -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-02 18:08:38 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:08:39 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-9t6wn -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-02 18:08:39 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:08:41 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-9t6wn -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-02 18:08:41 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:08:42 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-9t6wn -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-02 18:08:42 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:08:43 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-9t6wn -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-02 18:08:43 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:08:44 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-9t6wn -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-02 18:08:44 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:08:45 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-9t6wn -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-02 18:08:45 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:08:46 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-9t6wn -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-02 18:08:46 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:08:46 [main] [32mINFO [m [LoggingChangeST:654] Checking log4j2.properties in CO pod
2022-04-02 18:08:47 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-9t6wn -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-02 18:08:47 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:08:47 [main] [32mINFO [m [LoggingChangeST:658] Checking if CO rolled its pod
2022-04-02 18:08:58 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 18:08:58 [main] [32mINFO [m [ResourceManager:346] In context testDynamicallySetClusterOperatorLoggingLevels is everything deleted.
2022-04-02 18:08:58 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 18:08:58 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetClusterOperatorLoggingLevels-FINISHED
2022-04-02 18:08:58 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 18:08:58 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 18:08:58 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetUnknownKafkaLogger-STARTED
2022-04-02 18:08:58 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 18:08:58 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-85 for test case:testDynamicallySetUnknownKafkaLogger
2022-04-02 18:08:58 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-85
2022-04-02 18:08:58 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-85
2022-04-02 18:08:58 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-85
2022-04-02 18:08:58 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-f9f4a7b4 in namespace namespace-85
2022-04-02 18:08:58 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-85
2022-04-02 18:08:58 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-f9f4a7b4 will have desired state: Ready
2022-04-02 18:10:19 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-f9f4a7b4 is in desired state: Ready
2022-04-02 18:10:19 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-f9f4a7b4-kafka rolling update
2022-04-02 18:11:34 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-f9f4a7b4-kafka has been successfully rolled
2022-04-02 18:11:37 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 18:11:37 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDynamicallySetUnknownKafkaLogger
2022-04-02 18:11:37 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-f9f4a7b4 in namespace namespace-85
2022-04-02 18:11:47 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 18:11:47 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-85 for test case:testDynamicallySetUnknownKafkaLogger
2022-04-02 18:12:30 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetUnknownKafkaLogger-FINISHED
2022-04-02 18:12:30 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 18:12:30 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 18:12:30 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetKafkaExternalLogging-STARTED
2022-04-02 18:12:30 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 18:12:30 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-86 for test case:testDynamicallySetKafkaExternalLogging
2022-04-02 18:12:30 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-86
2022-04-02 18:12:30 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-86
2022-04-02 18:12:30 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-86
2022-04-02 18:12:30 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-fb21e8d8 in namespace namespace-86
2022-04-02 18:12:30 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-86
2022-04-02 18:12:30 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-fb21e8d8 will have desired state: Ready
2022-04-02 18:13:44 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-fb21e8d8 is in desired state: Ready
2022-04-02 18:13:44 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-fb21e8d8-kafka-1=3a76c29f-87ec-4b63-b8e1-fb5ed754cdab, my-cluster-fb21e8d8-kafka-0=67d91025-21b8-4e83-8177-01f2a66b13f4, my-cluster-fb21e8d8-kafka-2=38e8c591-f75b-4d1f-be33-ca16b4f521e2} pods didn't roll. Remaining seconds for stability: 50
2022-04-02 18:13:45 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-fb21e8d8-kafka-1=3a76c29f-87ec-4b63-b8e1-fb5ed754cdab, my-cluster-fb21e8d8-kafka-0=67d91025-21b8-4e83-8177-01f2a66b13f4, my-cluster-fb21e8d8-kafka-2=38e8c591-f75b-4d1f-be33-ca16b4f521e2} pods didn't roll. Remaining seconds for stability: 49
2022-04-02 18:13:46 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-fb21e8d8-kafka-1=3a76c29f-87ec-4b63-b8e1-fb5ed754cdab, my-cluster-fb21e8d8-kafka-0=67d91025-21b8-4e83-8177-01f2a66b13f4, my-cluster-fb21e8d8-kafka-2=38e8c591-f75b-4d1f-be33-ca16b4f521e2} pods didn't roll. Remaining seconds for stability: 48
2022-04-02 18:13:47 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-fb21e8d8-kafka-1=3a76c29f-87ec-4b63-b8e1-fb5ed754cdab, my-cluster-fb21e8d8-kafka-0=67d91025-21b8-4e83-8177-01f2a66b13f4, my-cluster-fb21e8d8-kafka-2=38e8c591-f75b-4d1f-be33-ca16b4f521e2} pods didn't roll. Remaining seconds for stability: 47
2022-04-02 18:13:48 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-fb21e8d8-kafka-1=3a76c29f-87ec-4b63-b8e1-fb5ed754cdab, my-cluster-fb21e8d8-kafka-0=67d91025-21b8-4e83-8177-01f2a66b13f4, my-cluster-fb21e8d8-kafka-2=38e8c591-f75b-4d1f-be33-ca16b4f521e2} pods didn't roll. Remaining seconds for stability: 46
2022-04-02 18:13:49 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-fb21e8d8-kafka-1=3a76c29f-87ec-4b63-b8e1-fb5ed754cdab, my-cluster-fb21e8d8-kafka-0=67d91025-21b8-4e83-8177-01f2a66b13f4, my-cluster-fb21e8d8-kafka-2=38e8c591-f75b-4d1f-be33-ca16b4f521e2} pods didn't roll. Remaining seconds for stability: 45
2022-04-02 18:13:50 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-fb21e8d8-kafka-1=3a76c29f-87ec-4b63-b8e1-fb5ed754cdab, my-cluster-fb21e8d8-kafka-0=67d91025-21b8-4e83-8177-01f2a66b13f4, my-cluster-fb21e8d8-kafka-2=38e8c591-f75b-4d1f-be33-ca16b4f521e2} pods didn't roll. Remaining seconds for stability: 44
2022-04-02 18:13:51 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-fb21e8d8-kafka-1=3a76c29f-87ec-4b63-b8e1-fb5ed754cdab, my-cluster-fb21e8d8-kafka-0=67d91025-21b8-4e83-8177-01f2a66b13f4, my-cluster-fb21e8d8-kafka-2=38e8c591-f75b-4d1f-be33-ca16b4f521e2} pods didn't roll. Remaining seconds for stability: 43
2022-04-02 18:13:52 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-fb21e8d8-kafka-1=3a76c29f-87ec-4b63-b8e1-fb5ed754cdab, my-cluster-fb21e8d8-kafka-0=67d91025-21b8-4e83-8177-01f2a66b13f4, my-cluster-fb21e8d8-kafka-2=38e8c591-f75b-4d1f-be33-ca16b4f521e2} pods didn't roll. Remaining seconds for stability: 42
2022-04-02 18:13:53 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-fb21e8d8-kafka-1=3a76c29f-87ec-4b63-b8e1-fb5ed754cdab, my-cluster-fb21e8d8-kafka-0=67d91025-21b8-4e83-8177-01f2a66b13f4, my-cluster-fb21e8d8-kafka-2=38e8c591-f75b-4d1f-be33-ca16b4f521e2} pods didn't roll. Remaining seconds for stability: 41
2022-04-02 18:13:54 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-fb21e8d8-kafka-1=3a76c29f-87ec-4b63-b8e1-fb5ed754cdab, my-cluster-fb21e8d8-kafka-0=67d91025-21b8-4e83-8177-01f2a66b13f4, my-cluster-fb21e8d8-kafka-2=38e8c591-f75b-4d1f-be33-ca16b4f521e2} pods didn't roll. Remaining seconds for stability: 40
2022-04-02 18:13:55 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-fb21e8d8-kafka-1=3a76c29f-87ec-4b63-b8e1-fb5ed754cdab, my-cluster-fb21e8d8-kafka-0=67d91025-21b8-4e83-8177-01f2a66b13f4, my-cluster-fb21e8d8-kafka-2=38e8c591-f75b-4d1f-be33-ca16b4f521e2} pods didn't roll. Remaining seconds for stability: 39
2022-04-02 18:13:56 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-fb21e8d8-kafka-1=3a76c29f-87ec-4b63-b8e1-fb5ed754cdab, my-cluster-fb21e8d8-kafka-0=67d91025-21b8-4e83-8177-01f2a66b13f4, my-cluster-fb21e8d8-kafka-2=38e8c591-f75b-4d1f-be33-ca16b4f521e2} pods didn't roll. Remaining seconds for stability: 38
2022-04-02 18:13:57 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-fb21e8d8-kafka-1=3a76c29f-87ec-4b63-b8e1-fb5ed754cdab, my-cluster-fb21e8d8-kafka-0=67d91025-21b8-4e83-8177-01f2a66b13f4, my-cluster-fb21e8d8-kafka-2=38e8c591-f75b-4d1f-be33-ca16b4f521e2} pods didn't roll. Remaining seconds for stability: 37
2022-04-02 18:13:58 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-fb21e8d8-kafka-1=3a76c29f-87ec-4b63-b8e1-fb5ed754cdab, my-cluster-fb21e8d8-kafka-0=67d91025-21b8-4e83-8177-01f2a66b13f4, my-cluster-fb21e8d8-kafka-2=38e8c591-f75b-4d1f-be33-ca16b4f521e2} pods didn't roll. Remaining seconds for stability: 36
2022-04-02 18:13:59 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-fb21e8d8-kafka-1=3a76c29f-87ec-4b63-b8e1-fb5ed754cdab, my-cluster-fb21e8d8-kafka-0=67d91025-21b8-4e83-8177-01f2a66b13f4, my-cluster-fb21e8d8-kafka-2=38e8c591-f75b-4d1f-be33-ca16b4f521e2} pods didn't roll. Remaining seconds for stability: 35
2022-04-02 18:14:00 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-fb21e8d8-kafka-1=3a76c29f-87ec-4b63-b8e1-fb5ed754cdab, my-cluster-fb21e8d8-kafka-0=67d91025-21b8-4e83-8177-01f2a66b13f4, my-cluster-fb21e8d8-kafka-2=38e8c591-f75b-4d1f-be33-ca16b4f521e2} pods didn't roll. Remaining seconds for stability: 34
2022-04-02 18:14:01 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-fb21e8d8-kafka-1=3a76c29f-87ec-4b63-b8e1-fb5ed754cdab, my-cluster-fb21e8d8-kafka-0=67d91025-21b8-4e83-8177-01f2a66b13f4, my-cluster-fb21e8d8-kafka-2=38e8c591-f75b-4d1f-be33-ca16b4f521e2} pods didn't roll. Remaining seconds for stability: 33
2022-04-02 18:14:02 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-fb21e8d8-kafka-1=3a76c29f-87ec-4b63-b8e1-fb5ed754cdab, my-cluster-fb21e8d8-kafka-0=67d91025-21b8-4e83-8177-01f2a66b13f4, my-cluster-fb21e8d8-kafka-2=38e8c591-f75b-4d1f-be33-ca16b4f521e2} pods didn't roll. Remaining seconds for stability: 32
2022-04-02 18:14:03 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-fb21e8d8-kafka-1=3a76c29f-87ec-4b63-b8e1-fb5ed754cdab, my-cluster-fb21e8d8-kafka-0=67d91025-21b8-4e83-8177-01f2a66b13f4, my-cluster-fb21e8d8-kafka-2=38e8c591-f75b-4d1f-be33-ca16b4f521e2} pods didn't roll. Remaining seconds for stability: 31
2022-04-02 18:14:04 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-fb21e8d8-kafka-1=3a76c29f-87ec-4b63-b8e1-fb5ed754cdab, my-cluster-fb21e8d8-kafka-0=67d91025-21b8-4e83-8177-01f2a66b13f4, my-cluster-fb21e8d8-kafka-2=38e8c591-f75b-4d1f-be33-ca16b4f521e2} pods didn't roll. Remaining seconds for stability: 30
2022-04-02 18:14:05 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-fb21e8d8-kafka-1=3a76c29f-87ec-4b63-b8e1-fb5ed754cdab, my-cluster-fb21e8d8-kafka-0=67d91025-21b8-4e83-8177-01f2a66b13f4, my-cluster-fb21e8d8-kafka-2=38e8c591-f75b-4d1f-be33-ca16b4f521e2} pods didn't roll. Remaining seconds for stability: 29
2022-04-02 18:14:06 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-fb21e8d8-kafka-1=3a76c29f-87ec-4b63-b8e1-fb5ed754cdab, my-cluster-fb21e8d8-kafka-0=67d91025-21b8-4e83-8177-01f2a66b13f4, my-cluster-fb21e8d8-kafka-2=38e8c591-f75b-4d1f-be33-ca16b4f521e2} pods didn't roll. Remaining seconds for stability: 28
2022-04-02 18:14:07 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-fb21e8d8-kafka-1=3a76c29f-87ec-4b63-b8e1-fb5ed754cdab, my-cluster-fb21e8d8-kafka-0=67d91025-21b8-4e83-8177-01f2a66b13f4, my-cluster-fb21e8d8-kafka-2=38e8c591-f75b-4d1f-be33-ca16b4f521e2} pods didn't roll. Remaining seconds for stability: 27
2022-04-02 18:14:08 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-fb21e8d8-kafka-1=3a76c29f-87ec-4b63-b8e1-fb5ed754cdab, my-cluster-fb21e8d8-kafka-0=67d91025-21b8-4e83-8177-01f2a66b13f4, my-cluster-fb21e8d8-kafka-2=38e8c591-f75b-4d1f-be33-ca16b4f521e2} pods didn't roll. Remaining seconds for stability: 26
2022-04-02 18:14:09 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-fb21e8d8-kafka-1=3a76c29f-87ec-4b63-b8e1-fb5ed754cdab, my-cluster-fb21e8d8-kafka-0=67d91025-21b8-4e83-8177-01f2a66b13f4, my-cluster-fb21e8d8-kafka-2=38e8c591-f75b-4d1f-be33-ca16b4f521e2} pods didn't roll. Remaining seconds for stability: 25
2022-04-02 18:14:10 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-fb21e8d8-kafka-1=3a76c29f-87ec-4b63-b8e1-fb5ed754cdab, my-cluster-fb21e8d8-kafka-0=67d91025-21b8-4e83-8177-01f2a66b13f4, my-cluster-fb21e8d8-kafka-2=38e8c591-f75b-4d1f-be33-ca16b4f521e2} pods didn't roll. Remaining seconds for stability: 24
2022-04-02 18:14:11 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-fb21e8d8-kafka-1=3a76c29f-87ec-4b63-b8e1-fb5ed754cdab, my-cluster-fb21e8d8-kafka-0=67d91025-21b8-4e83-8177-01f2a66b13f4, my-cluster-fb21e8d8-kafka-2=38e8c591-f75b-4d1f-be33-ca16b4f521e2} pods didn't roll. Remaining seconds for stability: 23
2022-04-02 18:14:12 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-fb21e8d8-kafka-1=3a76c29f-87ec-4b63-b8e1-fb5ed754cdab, my-cluster-fb21e8d8-kafka-0=67d91025-21b8-4e83-8177-01f2a66b13f4, my-cluster-fb21e8d8-kafka-2=38e8c591-f75b-4d1f-be33-ca16b4f521e2} pods didn't roll. Remaining seconds for stability: 22
2022-04-02 18:14:13 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-fb21e8d8-kafka-1=3a76c29f-87ec-4b63-b8e1-fb5ed754cdab, my-cluster-fb21e8d8-kafka-0=67d91025-21b8-4e83-8177-01f2a66b13f4, my-cluster-fb21e8d8-kafka-2=38e8c591-f75b-4d1f-be33-ca16b4f521e2} pods didn't roll. Remaining seconds for stability: 21
2022-04-02 18:14:14 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-fb21e8d8-kafka-1=3a76c29f-87ec-4b63-b8e1-fb5ed754cdab, my-cluster-fb21e8d8-kafka-0=67d91025-21b8-4e83-8177-01f2a66b13f4, my-cluster-fb21e8d8-kafka-2=38e8c591-f75b-4d1f-be33-ca16b4f521e2} pods didn't roll. Remaining seconds for stability: 20
2022-04-02 18:14:15 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-fb21e8d8-kafka-1=3a76c29f-87ec-4b63-b8e1-fb5ed754cdab, my-cluster-fb21e8d8-kafka-0=67d91025-21b8-4e83-8177-01f2a66b13f4, my-cluster-fb21e8d8-kafka-2=38e8c591-f75b-4d1f-be33-ca16b4f521e2} pods didn't roll. Remaining seconds for stability: 19
2022-04-02 18:14:16 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-fb21e8d8-kafka-1=3a76c29f-87ec-4b63-b8e1-fb5ed754cdab, my-cluster-fb21e8d8-kafka-0=67d91025-21b8-4e83-8177-01f2a66b13f4, my-cluster-fb21e8d8-kafka-2=38e8c591-f75b-4d1f-be33-ca16b4f521e2} pods didn't roll. Remaining seconds for stability: 18
2022-04-02 18:14:17 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-fb21e8d8-kafka-1=3a76c29f-87ec-4b63-b8e1-fb5ed754cdab, my-cluster-fb21e8d8-kafka-0=67d91025-21b8-4e83-8177-01f2a66b13f4, my-cluster-fb21e8d8-kafka-2=38e8c591-f75b-4d1f-be33-ca16b4f521e2} pods didn't roll. Remaining seconds for stability: 17
2022-04-02 18:14:18 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-fb21e8d8-kafka-1=3a76c29f-87ec-4b63-b8e1-fb5ed754cdab, my-cluster-fb21e8d8-kafka-0=67d91025-21b8-4e83-8177-01f2a66b13f4, my-cluster-fb21e8d8-kafka-2=38e8c591-f75b-4d1f-be33-ca16b4f521e2} pods didn't roll. Remaining seconds for stability: 16
2022-04-02 18:14:19 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-fb21e8d8-kafka-1=3a76c29f-87ec-4b63-b8e1-fb5ed754cdab, my-cluster-fb21e8d8-kafka-0=67d91025-21b8-4e83-8177-01f2a66b13f4, my-cluster-fb21e8d8-kafka-2=38e8c591-f75b-4d1f-be33-ca16b4f521e2} pods didn't roll. Remaining seconds for stability: 15
2022-04-02 18:14:20 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-fb21e8d8-kafka-1=3a76c29f-87ec-4b63-b8e1-fb5ed754cdab, my-cluster-fb21e8d8-kafka-0=67d91025-21b8-4e83-8177-01f2a66b13f4, my-cluster-fb21e8d8-kafka-2=38e8c591-f75b-4d1f-be33-ca16b4f521e2} pods didn't roll. Remaining seconds for stability: 14
2022-04-02 18:14:21 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-fb21e8d8-kafka-1=3a76c29f-87ec-4b63-b8e1-fb5ed754cdab, my-cluster-fb21e8d8-kafka-0=67d91025-21b8-4e83-8177-01f2a66b13f4, my-cluster-fb21e8d8-kafka-2=38e8c591-f75b-4d1f-be33-ca16b4f521e2} pods didn't roll. Remaining seconds for stability: 13
2022-04-02 18:14:22 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-fb21e8d8-kafka-1=3a76c29f-87ec-4b63-b8e1-fb5ed754cdab, my-cluster-fb21e8d8-kafka-0=67d91025-21b8-4e83-8177-01f2a66b13f4, my-cluster-fb21e8d8-kafka-2=38e8c591-f75b-4d1f-be33-ca16b4f521e2} pods didn't roll. Remaining seconds for stability: 12
2022-04-02 18:14:23 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-fb21e8d8-kafka-1=3a76c29f-87ec-4b63-b8e1-fb5ed754cdab, my-cluster-fb21e8d8-kafka-0=67d91025-21b8-4e83-8177-01f2a66b13f4, my-cluster-fb21e8d8-kafka-2=38e8c591-f75b-4d1f-be33-ca16b4f521e2} pods didn't roll. Remaining seconds for stability: 11
2022-04-02 18:14:24 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-fb21e8d8-kafka-1=3a76c29f-87ec-4b63-b8e1-fb5ed754cdab, my-cluster-fb21e8d8-kafka-0=67d91025-21b8-4e83-8177-01f2a66b13f4, my-cluster-fb21e8d8-kafka-2=38e8c591-f75b-4d1f-be33-ca16b4f521e2} pods didn't roll. Remaining seconds for stability: 10
2022-04-02 18:14:25 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-fb21e8d8-kafka-1=3a76c29f-87ec-4b63-b8e1-fb5ed754cdab, my-cluster-fb21e8d8-kafka-0=67d91025-21b8-4e83-8177-01f2a66b13f4, my-cluster-fb21e8d8-kafka-2=38e8c591-f75b-4d1f-be33-ca16b4f521e2} pods didn't roll. Remaining seconds for stability: 9
2022-04-02 18:14:26 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-fb21e8d8-kafka-1=3a76c29f-87ec-4b63-b8e1-fb5ed754cdab, my-cluster-fb21e8d8-kafka-0=67d91025-21b8-4e83-8177-01f2a66b13f4, my-cluster-fb21e8d8-kafka-2=38e8c591-f75b-4d1f-be33-ca16b4f521e2} pods didn't roll. Remaining seconds for stability: 8
2022-04-02 18:14:27 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-fb21e8d8-kafka-1=3a76c29f-87ec-4b63-b8e1-fb5ed754cdab, my-cluster-fb21e8d8-kafka-0=67d91025-21b8-4e83-8177-01f2a66b13f4, my-cluster-fb21e8d8-kafka-2=38e8c591-f75b-4d1f-be33-ca16b4f521e2} pods didn't roll. Remaining seconds for stability: 7
2022-04-02 18:14:28 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-fb21e8d8-kafka-1=3a76c29f-87ec-4b63-b8e1-fb5ed754cdab, my-cluster-fb21e8d8-kafka-0=67d91025-21b8-4e83-8177-01f2a66b13f4, my-cluster-fb21e8d8-kafka-2=38e8c591-f75b-4d1f-be33-ca16b4f521e2} pods didn't roll. Remaining seconds for stability: 6
2022-04-02 18:14:29 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-fb21e8d8-kafka-1=3a76c29f-87ec-4b63-b8e1-fb5ed754cdab, my-cluster-fb21e8d8-kafka-0=67d91025-21b8-4e83-8177-01f2a66b13f4, my-cluster-fb21e8d8-kafka-2=38e8c591-f75b-4d1f-be33-ca16b4f521e2} pods didn't roll. Remaining seconds for stability: 5
2022-04-02 18:14:30 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-fb21e8d8-kafka-1=3a76c29f-87ec-4b63-b8e1-fb5ed754cdab, my-cluster-fb21e8d8-kafka-0=67d91025-21b8-4e83-8177-01f2a66b13f4, my-cluster-fb21e8d8-kafka-2=38e8c591-f75b-4d1f-be33-ca16b4f521e2} pods didn't roll. Remaining seconds for stability: 4
2022-04-02 18:14:31 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-fb21e8d8-kafka-1=3a76c29f-87ec-4b63-b8e1-fb5ed754cdab, my-cluster-fb21e8d8-kafka-0=67d91025-21b8-4e83-8177-01f2a66b13f4, my-cluster-fb21e8d8-kafka-2=38e8c591-f75b-4d1f-be33-ca16b4f521e2} pods didn't roll. Remaining seconds for stability: 3
2022-04-02 18:14:32 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-fb21e8d8-kafka-1=3a76c29f-87ec-4b63-b8e1-fb5ed754cdab, my-cluster-fb21e8d8-kafka-0=67d91025-21b8-4e83-8177-01f2a66b13f4, my-cluster-fb21e8d8-kafka-2=38e8c591-f75b-4d1f-be33-ca16b4f521e2} pods didn't roll. Remaining seconds for stability: 2
2022-04-02 18:14:33 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-fb21e8d8-kafka-1=3a76c29f-87ec-4b63-b8e1-fb5ed754cdab, my-cluster-fb21e8d8-kafka-0=67d91025-21b8-4e83-8177-01f2a66b13f4, my-cluster-fb21e8d8-kafka-2=38e8c591-f75b-4d1f-be33-ca16b4f521e2} pods didn't roll. Remaining seconds for stability: 1
2022-04-02 18:14:34 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-fb21e8d8-kafka-1=3a76c29f-87ec-4b63-b8e1-fb5ed754cdab, my-cluster-fb21e8d8-kafka-0=67d91025-21b8-4e83-8177-01f2a66b13f4, my-cluster-fb21e8d8-kafka-2=38e8c591-f75b-4d1f-be33-ca16b4f521e2} pods didn't roll. Remaining seconds for stability: 0
2022-04-02 18:14:37 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-fb21e8d8-kafka rolling update
2022-04-02 18:16:12 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-fb21e8d8-kafka has been successfully rolled
2022-04-02 18:16:19 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 18:16:19 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDynamicallySetKafkaExternalLogging
2022-04-02 18:16:19 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-fb21e8d8 in namespace namespace-86
2022-04-02 18:16:29 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 18:16:29 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-86 for test case:testDynamicallySetKafkaExternalLogging
2022-04-02 18:17:12 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetKafkaExternalLogging-FINISHED
2022-04-02 18:17:12 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 18:17:12 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 18:17:12 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testNotExistingCMSetsDefaultLogging-STARTED
2022-04-02 18:17:12 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 18:17:12 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-87 for test case:testNotExistingCMSetsDefaultLogging
2022-04-02 18:17:12 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-87
2022-04-02 18:17:12 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-87
2022-04-02 18:17:12 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-87
2022-04-02 18:17:12 [main] [32mINFO [m [TestUtils:197] /home/ec2-user/strimzi-kafka-operator/systemtest/../cluster-operator/src/main/resources/kafkaDefaultLoggingProperties
2022-04-02 18:17:12 [main] [32mINFO [m [LoggingChangeST:1321] Deploying Kafka with custom logging
2022-04-02 18:17:12 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-91a8eec3 in namespace namespace-87
2022-04-02 18:17:12 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-87
2022-04-02 18:17:12 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-91a8eec3 will have desired state: Ready
2022-04-02 18:18:26 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-91a8eec3 is in desired state: Ready
2022-04-02 18:18:27 [main] [32mINFO [m [LoggingChangeST:1345] Changing external logging's CM to not existing one
2022-04-02 18:18:27 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91a8eec3-kafka-2=6ab71da1-a706-4e68-8434-7d9f120f52f9, my-cluster-91a8eec3-kafka-1=43ebcbe9-3603-4993-b009-95e82ad403b3, my-cluster-91a8eec3-kafka-0=876f8524-6454-4a53-a55b-4394ddb04a77} pods didn't roll. Remaining seconds for stability: 50
2022-04-02 18:18:28 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91a8eec3-kafka-2=6ab71da1-a706-4e68-8434-7d9f120f52f9, my-cluster-91a8eec3-kafka-1=43ebcbe9-3603-4993-b009-95e82ad403b3, my-cluster-91a8eec3-kafka-0=876f8524-6454-4a53-a55b-4394ddb04a77} pods didn't roll. Remaining seconds for stability: 49
2022-04-02 18:18:29 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91a8eec3-kafka-2=6ab71da1-a706-4e68-8434-7d9f120f52f9, my-cluster-91a8eec3-kafka-1=43ebcbe9-3603-4993-b009-95e82ad403b3, my-cluster-91a8eec3-kafka-0=876f8524-6454-4a53-a55b-4394ddb04a77} pods didn't roll. Remaining seconds for stability: 48
2022-04-02 18:18:30 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91a8eec3-kafka-2=6ab71da1-a706-4e68-8434-7d9f120f52f9, my-cluster-91a8eec3-kafka-1=43ebcbe9-3603-4993-b009-95e82ad403b3, my-cluster-91a8eec3-kafka-0=876f8524-6454-4a53-a55b-4394ddb04a77} pods didn't roll. Remaining seconds for stability: 47
2022-04-02 18:18:31 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91a8eec3-kafka-2=6ab71da1-a706-4e68-8434-7d9f120f52f9, my-cluster-91a8eec3-kafka-1=43ebcbe9-3603-4993-b009-95e82ad403b3, my-cluster-91a8eec3-kafka-0=876f8524-6454-4a53-a55b-4394ddb04a77} pods didn't roll. Remaining seconds for stability: 46
2022-04-02 18:18:32 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91a8eec3-kafka-2=6ab71da1-a706-4e68-8434-7d9f120f52f9, my-cluster-91a8eec3-kafka-1=43ebcbe9-3603-4993-b009-95e82ad403b3, my-cluster-91a8eec3-kafka-0=876f8524-6454-4a53-a55b-4394ddb04a77} pods didn't roll. Remaining seconds for stability: 45
2022-04-02 18:18:33 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91a8eec3-kafka-2=6ab71da1-a706-4e68-8434-7d9f120f52f9, my-cluster-91a8eec3-kafka-1=43ebcbe9-3603-4993-b009-95e82ad403b3, my-cluster-91a8eec3-kafka-0=876f8524-6454-4a53-a55b-4394ddb04a77} pods didn't roll. Remaining seconds for stability: 44
2022-04-02 18:18:34 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91a8eec3-kafka-2=6ab71da1-a706-4e68-8434-7d9f120f52f9, my-cluster-91a8eec3-kafka-1=43ebcbe9-3603-4993-b009-95e82ad403b3, my-cluster-91a8eec3-kafka-0=876f8524-6454-4a53-a55b-4394ddb04a77} pods didn't roll. Remaining seconds for stability: 43
2022-04-02 18:18:35 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91a8eec3-kafka-2=6ab71da1-a706-4e68-8434-7d9f120f52f9, my-cluster-91a8eec3-kafka-1=43ebcbe9-3603-4993-b009-95e82ad403b3, my-cluster-91a8eec3-kafka-0=876f8524-6454-4a53-a55b-4394ddb04a77} pods didn't roll. Remaining seconds for stability: 42
2022-04-02 18:18:36 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91a8eec3-kafka-2=6ab71da1-a706-4e68-8434-7d9f120f52f9, my-cluster-91a8eec3-kafka-1=43ebcbe9-3603-4993-b009-95e82ad403b3, my-cluster-91a8eec3-kafka-0=876f8524-6454-4a53-a55b-4394ddb04a77} pods didn't roll. Remaining seconds for stability: 41
2022-04-02 18:18:37 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91a8eec3-kafka-2=6ab71da1-a706-4e68-8434-7d9f120f52f9, my-cluster-91a8eec3-kafka-1=43ebcbe9-3603-4993-b009-95e82ad403b3, my-cluster-91a8eec3-kafka-0=876f8524-6454-4a53-a55b-4394ddb04a77} pods didn't roll. Remaining seconds for stability: 40
2022-04-02 18:18:38 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91a8eec3-kafka-2=6ab71da1-a706-4e68-8434-7d9f120f52f9, my-cluster-91a8eec3-kafka-1=43ebcbe9-3603-4993-b009-95e82ad403b3, my-cluster-91a8eec3-kafka-0=876f8524-6454-4a53-a55b-4394ddb04a77} pods didn't roll. Remaining seconds for stability: 39
2022-04-02 18:18:39 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91a8eec3-kafka-2=6ab71da1-a706-4e68-8434-7d9f120f52f9, my-cluster-91a8eec3-kafka-1=43ebcbe9-3603-4993-b009-95e82ad403b3, my-cluster-91a8eec3-kafka-0=876f8524-6454-4a53-a55b-4394ddb04a77} pods didn't roll. Remaining seconds for stability: 38
2022-04-02 18:18:40 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91a8eec3-kafka-2=6ab71da1-a706-4e68-8434-7d9f120f52f9, my-cluster-91a8eec3-kafka-1=43ebcbe9-3603-4993-b009-95e82ad403b3, my-cluster-91a8eec3-kafka-0=876f8524-6454-4a53-a55b-4394ddb04a77} pods didn't roll. Remaining seconds for stability: 37
2022-04-02 18:18:41 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91a8eec3-kafka-2=6ab71da1-a706-4e68-8434-7d9f120f52f9, my-cluster-91a8eec3-kafka-1=43ebcbe9-3603-4993-b009-95e82ad403b3, my-cluster-91a8eec3-kafka-0=876f8524-6454-4a53-a55b-4394ddb04a77} pods didn't roll. Remaining seconds for stability: 36
2022-04-02 18:18:42 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91a8eec3-kafka-2=6ab71da1-a706-4e68-8434-7d9f120f52f9, my-cluster-91a8eec3-kafka-1=43ebcbe9-3603-4993-b009-95e82ad403b3, my-cluster-91a8eec3-kafka-0=876f8524-6454-4a53-a55b-4394ddb04a77} pods didn't roll. Remaining seconds for stability: 35
2022-04-02 18:18:43 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91a8eec3-kafka-2=6ab71da1-a706-4e68-8434-7d9f120f52f9, my-cluster-91a8eec3-kafka-1=43ebcbe9-3603-4993-b009-95e82ad403b3, my-cluster-91a8eec3-kafka-0=876f8524-6454-4a53-a55b-4394ddb04a77} pods didn't roll. Remaining seconds for stability: 34
2022-04-02 18:18:44 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91a8eec3-kafka-2=6ab71da1-a706-4e68-8434-7d9f120f52f9, my-cluster-91a8eec3-kafka-1=43ebcbe9-3603-4993-b009-95e82ad403b3, my-cluster-91a8eec3-kafka-0=876f8524-6454-4a53-a55b-4394ddb04a77} pods didn't roll. Remaining seconds for stability: 33
2022-04-02 18:18:45 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91a8eec3-kafka-2=6ab71da1-a706-4e68-8434-7d9f120f52f9, my-cluster-91a8eec3-kafka-1=43ebcbe9-3603-4993-b009-95e82ad403b3, my-cluster-91a8eec3-kafka-0=876f8524-6454-4a53-a55b-4394ddb04a77} pods didn't roll. Remaining seconds for stability: 32
2022-04-02 18:18:46 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91a8eec3-kafka-2=6ab71da1-a706-4e68-8434-7d9f120f52f9, my-cluster-91a8eec3-kafka-1=43ebcbe9-3603-4993-b009-95e82ad403b3, my-cluster-91a8eec3-kafka-0=876f8524-6454-4a53-a55b-4394ddb04a77} pods didn't roll. Remaining seconds for stability: 31
2022-04-02 18:18:47 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91a8eec3-kafka-2=6ab71da1-a706-4e68-8434-7d9f120f52f9, my-cluster-91a8eec3-kafka-1=43ebcbe9-3603-4993-b009-95e82ad403b3, my-cluster-91a8eec3-kafka-0=876f8524-6454-4a53-a55b-4394ddb04a77} pods didn't roll. Remaining seconds for stability: 30
2022-04-02 18:18:48 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91a8eec3-kafka-2=6ab71da1-a706-4e68-8434-7d9f120f52f9, my-cluster-91a8eec3-kafka-1=43ebcbe9-3603-4993-b009-95e82ad403b3, my-cluster-91a8eec3-kafka-0=876f8524-6454-4a53-a55b-4394ddb04a77} pods didn't roll. Remaining seconds for stability: 29
2022-04-02 18:18:49 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91a8eec3-kafka-2=6ab71da1-a706-4e68-8434-7d9f120f52f9, my-cluster-91a8eec3-kafka-1=43ebcbe9-3603-4993-b009-95e82ad403b3, my-cluster-91a8eec3-kafka-0=876f8524-6454-4a53-a55b-4394ddb04a77} pods didn't roll. Remaining seconds for stability: 28
2022-04-02 18:18:50 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91a8eec3-kafka-2=6ab71da1-a706-4e68-8434-7d9f120f52f9, my-cluster-91a8eec3-kafka-1=43ebcbe9-3603-4993-b009-95e82ad403b3, my-cluster-91a8eec3-kafka-0=876f8524-6454-4a53-a55b-4394ddb04a77} pods didn't roll. Remaining seconds for stability: 27
2022-04-02 18:18:51 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91a8eec3-kafka-2=6ab71da1-a706-4e68-8434-7d9f120f52f9, my-cluster-91a8eec3-kafka-1=43ebcbe9-3603-4993-b009-95e82ad403b3, my-cluster-91a8eec3-kafka-0=876f8524-6454-4a53-a55b-4394ddb04a77} pods didn't roll. Remaining seconds for stability: 26
2022-04-02 18:18:52 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91a8eec3-kafka-2=6ab71da1-a706-4e68-8434-7d9f120f52f9, my-cluster-91a8eec3-kafka-1=43ebcbe9-3603-4993-b009-95e82ad403b3, my-cluster-91a8eec3-kafka-0=876f8524-6454-4a53-a55b-4394ddb04a77} pods didn't roll. Remaining seconds for stability: 25
2022-04-02 18:18:53 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91a8eec3-kafka-2=6ab71da1-a706-4e68-8434-7d9f120f52f9, my-cluster-91a8eec3-kafka-1=43ebcbe9-3603-4993-b009-95e82ad403b3, my-cluster-91a8eec3-kafka-0=876f8524-6454-4a53-a55b-4394ddb04a77} pods didn't roll. Remaining seconds for stability: 24
2022-04-02 18:18:54 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91a8eec3-kafka-2=6ab71da1-a706-4e68-8434-7d9f120f52f9, my-cluster-91a8eec3-kafka-1=43ebcbe9-3603-4993-b009-95e82ad403b3, my-cluster-91a8eec3-kafka-0=876f8524-6454-4a53-a55b-4394ddb04a77} pods didn't roll. Remaining seconds for stability: 23
2022-04-02 18:18:55 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91a8eec3-kafka-2=6ab71da1-a706-4e68-8434-7d9f120f52f9, my-cluster-91a8eec3-kafka-1=43ebcbe9-3603-4993-b009-95e82ad403b3, my-cluster-91a8eec3-kafka-0=876f8524-6454-4a53-a55b-4394ddb04a77} pods didn't roll. Remaining seconds for stability: 22
2022-04-02 18:18:56 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91a8eec3-kafka-2=6ab71da1-a706-4e68-8434-7d9f120f52f9, my-cluster-91a8eec3-kafka-1=43ebcbe9-3603-4993-b009-95e82ad403b3, my-cluster-91a8eec3-kafka-0=876f8524-6454-4a53-a55b-4394ddb04a77} pods didn't roll. Remaining seconds for stability: 21
2022-04-02 18:18:57 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91a8eec3-kafka-2=6ab71da1-a706-4e68-8434-7d9f120f52f9, my-cluster-91a8eec3-kafka-1=43ebcbe9-3603-4993-b009-95e82ad403b3, my-cluster-91a8eec3-kafka-0=876f8524-6454-4a53-a55b-4394ddb04a77} pods didn't roll. Remaining seconds for stability: 20
2022-04-02 18:18:58 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91a8eec3-kafka-2=6ab71da1-a706-4e68-8434-7d9f120f52f9, my-cluster-91a8eec3-kafka-1=43ebcbe9-3603-4993-b009-95e82ad403b3, my-cluster-91a8eec3-kafka-0=876f8524-6454-4a53-a55b-4394ddb04a77} pods didn't roll. Remaining seconds for stability: 19
2022-04-02 18:18:59 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91a8eec3-kafka-2=6ab71da1-a706-4e68-8434-7d9f120f52f9, my-cluster-91a8eec3-kafka-1=43ebcbe9-3603-4993-b009-95e82ad403b3, my-cluster-91a8eec3-kafka-0=876f8524-6454-4a53-a55b-4394ddb04a77} pods didn't roll. Remaining seconds for stability: 18
2022-04-02 18:19:00 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91a8eec3-kafka-2=6ab71da1-a706-4e68-8434-7d9f120f52f9, my-cluster-91a8eec3-kafka-1=43ebcbe9-3603-4993-b009-95e82ad403b3, my-cluster-91a8eec3-kafka-0=876f8524-6454-4a53-a55b-4394ddb04a77} pods didn't roll. Remaining seconds for stability: 17
2022-04-02 18:19:01 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91a8eec3-kafka-2=6ab71da1-a706-4e68-8434-7d9f120f52f9, my-cluster-91a8eec3-kafka-1=43ebcbe9-3603-4993-b009-95e82ad403b3, my-cluster-91a8eec3-kafka-0=876f8524-6454-4a53-a55b-4394ddb04a77} pods didn't roll. Remaining seconds for stability: 16
2022-04-02 18:19:02 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91a8eec3-kafka-2=6ab71da1-a706-4e68-8434-7d9f120f52f9, my-cluster-91a8eec3-kafka-1=43ebcbe9-3603-4993-b009-95e82ad403b3, my-cluster-91a8eec3-kafka-0=876f8524-6454-4a53-a55b-4394ddb04a77} pods didn't roll. Remaining seconds for stability: 15
2022-04-02 18:19:03 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91a8eec3-kafka-2=6ab71da1-a706-4e68-8434-7d9f120f52f9, my-cluster-91a8eec3-kafka-1=43ebcbe9-3603-4993-b009-95e82ad403b3, my-cluster-91a8eec3-kafka-0=876f8524-6454-4a53-a55b-4394ddb04a77} pods didn't roll. Remaining seconds for stability: 14
2022-04-02 18:19:04 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91a8eec3-kafka-2=6ab71da1-a706-4e68-8434-7d9f120f52f9, my-cluster-91a8eec3-kafka-1=43ebcbe9-3603-4993-b009-95e82ad403b3, my-cluster-91a8eec3-kafka-0=876f8524-6454-4a53-a55b-4394ddb04a77} pods didn't roll. Remaining seconds for stability: 13
2022-04-02 18:19:05 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91a8eec3-kafka-2=6ab71da1-a706-4e68-8434-7d9f120f52f9, my-cluster-91a8eec3-kafka-1=43ebcbe9-3603-4993-b009-95e82ad403b3, my-cluster-91a8eec3-kafka-0=876f8524-6454-4a53-a55b-4394ddb04a77} pods didn't roll. Remaining seconds for stability: 12
2022-04-02 18:19:06 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91a8eec3-kafka-2=6ab71da1-a706-4e68-8434-7d9f120f52f9, my-cluster-91a8eec3-kafka-1=43ebcbe9-3603-4993-b009-95e82ad403b3, my-cluster-91a8eec3-kafka-0=876f8524-6454-4a53-a55b-4394ddb04a77} pods didn't roll. Remaining seconds for stability: 11
2022-04-02 18:19:07 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91a8eec3-kafka-2=6ab71da1-a706-4e68-8434-7d9f120f52f9, my-cluster-91a8eec3-kafka-1=43ebcbe9-3603-4993-b009-95e82ad403b3, my-cluster-91a8eec3-kafka-0=876f8524-6454-4a53-a55b-4394ddb04a77} pods didn't roll. Remaining seconds for stability: 10
2022-04-02 18:19:08 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91a8eec3-kafka-2=6ab71da1-a706-4e68-8434-7d9f120f52f9, my-cluster-91a8eec3-kafka-1=43ebcbe9-3603-4993-b009-95e82ad403b3, my-cluster-91a8eec3-kafka-0=876f8524-6454-4a53-a55b-4394ddb04a77} pods didn't roll. Remaining seconds for stability: 9
2022-04-02 18:19:09 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91a8eec3-kafka-2=6ab71da1-a706-4e68-8434-7d9f120f52f9, my-cluster-91a8eec3-kafka-1=43ebcbe9-3603-4993-b009-95e82ad403b3, my-cluster-91a8eec3-kafka-0=876f8524-6454-4a53-a55b-4394ddb04a77} pods didn't roll. Remaining seconds for stability: 8
2022-04-02 18:19:10 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91a8eec3-kafka-2=6ab71da1-a706-4e68-8434-7d9f120f52f9, my-cluster-91a8eec3-kafka-1=43ebcbe9-3603-4993-b009-95e82ad403b3, my-cluster-91a8eec3-kafka-0=876f8524-6454-4a53-a55b-4394ddb04a77} pods didn't roll. Remaining seconds for stability: 7
2022-04-02 18:19:11 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91a8eec3-kafka-2=6ab71da1-a706-4e68-8434-7d9f120f52f9, my-cluster-91a8eec3-kafka-1=43ebcbe9-3603-4993-b009-95e82ad403b3, my-cluster-91a8eec3-kafka-0=876f8524-6454-4a53-a55b-4394ddb04a77} pods didn't roll. Remaining seconds for stability: 6
2022-04-02 18:19:12 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91a8eec3-kafka-2=6ab71da1-a706-4e68-8434-7d9f120f52f9, my-cluster-91a8eec3-kafka-1=43ebcbe9-3603-4993-b009-95e82ad403b3, my-cluster-91a8eec3-kafka-0=876f8524-6454-4a53-a55b-4394ddb04a77} pods didn't roll. Remaining seconds for stability: 5
2022-04-02 18:19:13 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91a8eec3-kafka-2=6ab71da1-a706-4e68-8434-7d9f120f52f9, my-cluster-91a8eec3-kafka-1=43ebcbe9-3603-4993-b009-95e82ad403b3, my-cluster-91a8eec3-kafka-0=876f8524-6454-4a53-a55b-4394ddb04a77} pods didn't roll. Remaining seconds for stability: 4
2022-04-02 18:19:14 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91a8eec3-kafka-2=6ab71da1-a706-4e68-8434-7d9f120f52f9, my-cluster-91a8eec3-kafka-1=43ebcbe9-3603-4993-b009-95e82ad403b3, my-cluster-91a8eec3-kafka-0=876f8524-6454-4a53-a55b-4394ddb04a77} pods didn't roll. Remaining seconds for stability: 3
2022-04-02 18:19:15 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91a8eec3-kafka-2=6ab71da1-a706-4e68-8434-7d9f120f52f9, my-cluster-91a8eec3-kafka-1=43ebcbe9-3603-4993-b009-95e82ad403b3, my-cluster-91a8eec3-kafka-0=876f8524-6454-4a53-a55b-4394ddb04a77} pods didn't roll. Remaining seconds for stability: 2
2022-04-02 18:19:16 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91a8eec3-kafka-2=6ab71da1-a706-4e68-8434-7d9f120f52f9, my-cluster-91a8eec3-kafka-1=43ebcbe9-3603-4993-b009-95e82ad403b3, my-cluster-91a8eec3-kafka-0=876f8524-6454-4a53-a55b-4394ddb04a77} pods didn't roll. Remaining seconds for stability: 1
2022-04-02 18:19:17 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91a8eec3-kafka-2=6ab71da1-a706-4e68-8434-7d9f120f52f9, my-cluster-91a8eec3-kafka-1=43ebcbe9-3603-4993-b009-95e82ad403b3, my-cluster-91a8eec3-kafka-0=876f8524-6454-4a53-a55b-4394ddb04a77} pods didn't roll. Remaining seconds for stability: 0
2022-04-02 18:19:17 [main] [32mINFO [m [LoggingChangeST:1359] Checking that log4j.properties in custom-config isn't empty and configuration is default
2022-04-02 18:19:17 [main] [32mINFO [m [LoggingChangeST:1367] Checking if Kafka:my-cluster-91a8eec3 contains error about non-existing CM
2022-04-02 18:19:17 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 18:19:17 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testNotExistingCMSetsDefaultLogging
2022-04-02 18:19:17 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-91a8eec3 in namespace namespace-87
2022-04-02 18:19:27 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 18:19:27 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-87 for test case:testNotExistingCMSetsDefaultLogging
2022-04-02 18:19:54 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testNotExistingCMSetsDefaultLogging-FINISHED
2022-04-02 18:19:54 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 18:19:54 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 18:19:54 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetConnectLoggingLevels-STARTED
2022-04-02 18:19:54 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 18:19:54 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-88 for test case:testDynamicallySetConnectLoggingLevels
2022-04-02 18:19:54 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-88
2022-04-02 18:19:54 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-88
2022-04-02 18:19:54 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-88
2022-04-02 18:19:54 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-8fcd6b4e in namespace namespace-88
2022-04-02 18:19:54 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-88
2022-04-02 18:19:54 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-8fcd6b4e-kafka-clients in namespace namespace-88
2022-04-02 18:19:54 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-88
2022-04-02 18:19:54 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-8fcd6b4e will have desired state: Ready
2022-04-02 18:21:07 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-8fcd6b4e is in desired state: Ready
2022-04-02 18:21:07 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-8fcd6b4e-scraper in namespace namespace-88
2022-04-02 18:21:07 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-88
2022-04-02 18:21:07 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-8fcd6b4e-scraper will be ready
2022-04-02 18:21:09 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-8fcd6b4e-scraper is ready
2022-04-02 18:21:09 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-8fcd6b4e-scraper to be ready
2022-04-02 18:21:19 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-8fcd6b4e-scraper is ready
2022-04-02 18:21:19 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-8fcd6b4e-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-02 18:21:19 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-8fcd6b4e-allow in namespace namespace-88
2022-04-02 18:21:19 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-88
2022-04-02 18:21:19 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-02 18:21:19 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-8fcd6b4e in namespace namespace-88
2022-04-02 18:21:19 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-88
2022-04-02 18:21:19 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-8fcd6b4e will have desired state: Ready
2022-04-02 18:22:26 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-8fcd6b4e is in desired state: Ready
2022-04-02 18:22:26 [main] [32mINFO [m [LoggingChangeST:704] Asserting if log is without records
2022-04-02 18:22:26 [main] [32mINFO [m [LoggingChangeST:707] Changing rootLogger level to DEBUG with inline logging
2022-04-02 18:22:26 [main] [32mINFO [m [LoggingChangeST:716] Waiting for log4j.properties will contain desired settings
2022-04-02 18:22:26 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-88 exec my-cluster-8fcd6b4e-kafka-clients-65fdcf75f-sxvhp -- curl http://my-cluster-8fcd6b4e-connect-api:8083/admin/loggers/root
2022-04-02 18:22:26 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:22:26 [main] [32mINFO [m [LoggingChangeST:761] Setting log level of Connect to OFF
2022-04-02 18:22:26 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-88 exec my-cluster-8fcd6b4e-kafka-clients-65fdcf75f-sxvhp -- curl http://my-cluster-8fcd6b4e-connect-api:8083/admin/loggers/root
2022-04-02 18:22:26 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:22:56 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 18:22:56 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDynamicallySetConnectLoggingLevels
2022-04-02 18:22:56 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-8fcd6b4e-scraper in namespace namespace-88
2022-04-02 18:22:56 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-8fcd6b4e in namespace namespace-88
2022-04-02 18:22:56 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-8fcd6b4e in namespace namespace-88
2022-04-02 18:22:56 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-8fcd6b4e-allow in namespace namespace-88
2022-04-02 18:22:56 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-8fcd6b4e-kafka-clients in namespace namespace-88
2022-04-02 18:23:36 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 18:23:36 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-88 for test case:testDynamicallySetConnectLoggingLevels
2022-04-02 18:23:42 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetConnectLoggingLevels-FINISHED
2022-04-02 18:23:42 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 18:23:42 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 18:23:42 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testMM2LoggingLevelsHierarchy-STARTED
2022-04-02 18:23:42 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 18:23:42 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-89 for test case:testMM2LoggingLevelsHierarchy
2022-04-02 18:23:42 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-89
2022-04-02 18:23:42 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-89
2022-04-02 18:23:42 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-89
2022-04-02 18:23:42 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-17fdd76b-source in namespace namespace-89
2022-04-02 18:23:42 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-89
2022-04-02 18:23:42 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-17fdd76b-source will have desired state: Ready
2022-04-02 18:24:54 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-17fdd76b-source is in desired state: Ready
2022-04-02 18:24:54 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-17fdd76b-target in namespace namespace-89
2022-04-02 18:24:54 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-89
2022-04-02 18:24:54 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-17fdd76b-target will have desired state: Ready
2022-04-02 18:26:07 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-17fdd76b-target is in desired state: Ready
2022-04-02 18:26:07 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-17fdd76b-kafka-clients in namespace namespace-89
2022-04-02 18:26:07 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-89
2022-04-02 18:26:07 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-17fdd76b in namespace namespace-89
2022-04-02 18:26:07 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-89
2022-04-02 18:26:07 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-17fdd76b will have desired state: Ready
2022-04-02 18:27:15 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-17fdd76b is in desired state: Ready
2022-04-02 18:27:15 [main] [32mINFO [m [LoggingChangeST:1254] Waiting for log4j.properties will contain desired settings
2022-04-02 18:27:15 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-17fdd76b-mirrormaker2-9c8bbff69-47zfv -- curl http://localhost:8083/admin/loggers/root
2022-04-02 18:27:15 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:27:15 [main] [32mINFO [m [LoggingChangeST:1259] Changing log levels
2022-04-02 18:27:15 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-17fdd76b-mirrormaker2-9c8bbff69-47zfv -- curl http://localhost:8083/admin/loggers/root
2022-04-02 18:27:15 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:27:16 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-17fdd76b-mirrormaker2-9c8bbff69-47zfv -- curl http://localhost:8083/admin/loggers/root
2022-04-02 18:27:16 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:27:18 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-17fdd76b-mirrormaker2-9c8bbff69-47zfv -- curl http://localhost:8083/admin/loggers/root
2022-04-02 18:27:18 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:27:19 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-17fdd76b-mirrormaker2-9c8bbff69-47zfv -- curl http://localhost:8083/admin/loggers/root
2022-04-02 18:27:19 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:27:20 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-17fdd76b-mirrormaker2-9c8bbff69-47zfv -- curl http://localhost:8083/admin/loggers/root
2022-04-02 18:27:20 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:27:21 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-17fdd76b-mirrormaker2-9c8bbff69-47zfv -- curl http://localhost:8083/admin/loggers/root
2022-04-02 18:27:21 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:27:22 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-17fdd76b-mirrormaker2-9c8bbff69-47zfv -- curl http://localhost:8083/admin/loggers/root
2022-04-02 18:27:22 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:27:24 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-17fdd76b-mirrormaker2-9c8bbff69-47zfv -- curl http://localhost:8083/admin/loggers/root
2022-04-02 18:27:24 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:27:25 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-17fdd76b-mirrormaker2-9c8bbff69-47zfv -- curl http://localhost:8083/admin/loggers/root
2022-04-02 18:27:25 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:27:26 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-17fdd76b-mirrormaker2-9c8bbff69-47zfv -- curl http://localhost:8083/admin/loggers/root
2022-04-02 18:27:26 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:27:27 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-17fdd76b-mirrormaker2-9c8bbff69-47zfv -- curl http://localhost:8083/admin/loggers/root
2022-04-02 18:27:27 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:27:27 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-17fdd76b-mirrormaker2-9c8bbff69-47zfv -- curl http://localhost:8083/admin/loggers/org.eclipse.jetty.util.thread.strategy.EatWhatYouKill
2022-04-02 18:27:27 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:27:28 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-17fdd76b-mirrormaker2-9c8bbff69-47zfv -- curl http://localhost:8083/admin/loggers/org.apache.kafka.connect.runtime.WorkerTask
2022-04-02 18:27:28 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:27:28 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 18:27:28 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMM2LoggingLevelsHierarchy
2022-04-02 18:27:28 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-17fdd76b-kafka-clients in namespace namespace-89
2022-04-02 18:27:28 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-17fdd76b in namespace namespace-89
2022-04-02 18:27:28 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-17fdd76b-source in namespace namespace-89
2022-04-02 18:27:28 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-17fdd76b-target in namespace namespace-89
2022-04-02 18:28:18 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 18:28:18 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-89 for test case:testMM2LoggingLevelsHierarchy
2022-04-02 18:28:24 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testMM2LoggingLevelsHierarchy-FINISHED
2022-04-02 18:28:24 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 18:28:24 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 18:28:24 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testLoggingHierarchy-STARTED
2022-04-02 18:28:24 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 18:28:24 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-90 for test case:testLoggingHierarchy
2022-04-02 18:28:24 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-90
2022-04-02 18:28:24 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-90
2022-04-02 18:28:24 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-90
2022-04-02 18:28:24 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-87a24261 in namespace namespace-90
2022-04-02 18:28:24 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-90
2022-04-02 18:28:24 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-87a24261-kafka-clients in namespace namespace-90
2022-04-02 18:28:24 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-90
2022-04-02 18:28:24 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-87a24261 will have desired state: Ready
2022-04-02 18:29:42 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-87a24261 is in desired state: Ready
2022-04-02 18:29:42 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-87a24261-kafka-clients will be ready
2022-04-02 18:29:42 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-87a24261-kafka-clients is ready
2022-04-02 18:29:42 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-87a24261-scraper in namespace namespace-90
2022-04-02 18:29:42 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-90
2022-04-02 18:29:42 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-87a24261-scraper will be ready
2022-04-02 18:29:44 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-87a24261-scraper is ready
2022-04-02 18:29:44 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-87a24261-scraper to be ready
2022-04-02 18:29:55 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-87a24261-scraper is ready
2022-04-02 18:29:55 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-87a24261-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-02 18:29:55 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-87a24261-allow in namespace namespace-90
2022-04-02 18:29:55 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-90
2022-04-02 18:29:55 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-02 18:29:55 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-87a24261 in namespace namespace-90
2022-04-02 18:29:55 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-90
2022-04-02 18:29:55 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-87a24261 in namespace namespace-90
2022-04-02 18:29:55 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-90
2022-04-02 18:29:55 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-87a24261 will have desired state: Ready
2022-04-02 18:31:03 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-87a24261 is in desired state: Ready
2022-04-02 18:31:03 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-87a24261 will have desired state: Ready
2022-04-02 18:31:03 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-87a24261 is in desired state: Ready
2022-04-02 18:31:03 [main] [32mINFO [m [LoggingChangeST:1401] Changing rootLogger level in KafkaConnector to ERROR with inline logging
2022-04-02 18:31:03 [main] [32mINFO [m [LoggingChangeST:1407] Waiting for Connect API loggers will contain desired settings
2022-04-02 18:31:03 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-87a24261-kafka-clients-68d48c7d7d-kdqj8 -- curl http://my-cluster-87a24261-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-02 18:31:03 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:31:03 [main] [32mINFO [m [LoggingChangeST:1413] Restarting Kafka connector my-cluster-87a24261 with class name org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-02 18:31:03 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-87a24261-kafka-clients-68d48c7d7d-kdqj8 -- curl -X POST http://my-cluster-87a24261-connect-api:8083/connectors/my-cluster-87a24261/restart
2022-04-02 18:31:03 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:31:03 [main] [32mINFO [m [KafkaConnectorUtils:168] Wait until KafkaConnector my-cluster-87a24261's worker will be in RUNNING state
2022-04-02 18:31:03 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-87a24261-kafka-clients-68d48c7d7d-kdqj8 -- curl GET http://my-cluster-87a24261-connect-api:8083/connectors/my-cluster-87a24261/status
2022-04-02 18:31:03 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:31:03 [main] [32mINFO [m [LoggingChangeST:1420] Checking that logger is same for connector with class name org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-02 18:31:04 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-87a24261-kafka-clients-68d48c7d7d-kdqj8 -- curl http://my-cluster-87a24261-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-02 18:31:04 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:31:04 [main] [32mINFO [m [LoggingChangeST:1426] Changing KafkaConnect's root logger to WARN, KafkaConnector: my-cluster-87a24261 shouldn't inherit it
2022-04-02 18:31:04 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-87a24261-kafka-clients-68d48c7d7d-kdqj8 -- curl http://my-cluster-87a24261-connect-api:8083/admin/loggers/root
2022-04-02 18:31:04 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:31:04 [main] [32mINFO [m [LoggingChangeST:1440] Checking if KafkaConnector org.apache.kafka.connect.file.FileStreamSourceConnector doesn't inherit logger from KafkaConnect
2022-04-02 18:31:04 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-87a24261-kafka-clients-68d48c7d7d-kdqj8 -- curl http://my-cluster-87a24261-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-02 18:31:04 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:31:04 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 49
2022-04-02 18:31:05 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-87a24261-kafka-clients-68d48c7d7d-kdqj8 -- curl http://my-cluster-87a24261-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-02 18:31:05 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:31:05 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 48
2022-04-02 18:31:06 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-87a24261-kafka-clients-68d48c7d7d-kdqj8 -- curl http://my-cluster-87a24261-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-02 18:31:06 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:31:06 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 47
2022-04-02 18:31:08 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-87a24261-kafka-clients-68d48c7d7d-kdqj8 -- curl http://my-cluster-87a24261-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-02 18:31:08 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:31:08 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 46
2022-04-02 18:31:09 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-87a24261-kafka-clients-68d48c7d7d-kdqj8 -- curl http://my-cluster-87a24261-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-02 18:31:09 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:31:09 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 45
2022-04-02 18:31:10 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-87a24261-kafka-clients-68d48c7d7d-kdqj8 -- curl http://my-cluster-87a24261-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-02 18:31:10 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:31:10 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 44
2022-04-02 18:31:11 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-87a24261-kafka-clients-68d48c7d7d-kdqj8 -- curl http://my-cluster-87a24261-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-02 18:31:11 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:31:11 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 43
2022-04-02 18:31:12 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-87a24261-kafka-clients-68d48c7d7d-kdqj8 -- curl http://my-cluster-87a24261-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-02 18:31:12 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:31:12 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 42
2022-04-02 18:31:14 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-87a24261-kafka-clients-68d48c7d7d-kdqj8 -- curl http://my-cluster-87a24261-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-02 18:31:14 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:31:14 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 41
2022-04-02 18:31:15 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-87a24261-kafka-clients-68d48c7d7d-kdqj8 -- curl http://my-cluster-87a24261-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-02 18:31:15 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:31:15 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 40
2022-04-02 18:31:16 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-87a24261-kafka-clients-68d48c7d7d-kdqj8 -- curl http://my-cluster-87a24261-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-02 18:31:16 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:31:16 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 39
2022-04-02 18:31:17 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-87a24261-kafka-clients-68d48c7d7d-kdqj8 -- curl http://my-cluster-87a24261-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-02 18:31:17 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:31:17 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 38
2022-04-02 18:31:18 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-87a24261-kafka-clients-68d48c7d7d-kdqj8 -- curl http://my-cluster-87a24261-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-02 18:31:18 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:31:18 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 37
2022-04-02 18:31:20 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-87a24261-kafka-clients-68d48c7d7d-kdqj8 -- curl http://my-cluster-87a24261-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-02 18:31:20 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:31:20 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 36
2022-04-02 18:31:21 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-87a24261-kafka-clients-68d48c7d7d-kdqj8 -- curl http://my-cluster-87a24261-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-02 18:31:21 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:31:21 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 35
2022-04-02 18:31:22 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-87a24261-kafka-clients-68d48c7d7d-kdqj8 -- curl http://my-cluster-87a24261-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-02 18:31:22 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:31:22 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 34
2022-04-02 18:31:23 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-87a24261-kafka-clients-68d48c7d7d-kdqj8 -- curl http://my-cluster-87a24261-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-02 18:31:23 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:31:23 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 33
2022-04-02 18:31:24 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-87a24261-kafka-clients-68d48c7d7d-kdqj8 -- curl http://my-cluster-87a24261-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-02 18:31:24 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:31:24 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 32
2022-04-02 18:31:26 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-87a24261-kafka-clients-68d48c7d7d-kdqj8 -- curl http://my-cluster-87a24261-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-02 18:31:26 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:31:26 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 31
2022-04-02 18:31:27 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-87a24261-kafka-clients-68d48c7d7d-kdqj8 -- curl http://my-cluster-87a24261-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-02 18:31:27 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:31:27 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 30
2022-04-02 18:31:28 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-87a24261-kafka-clients-68d48c7d7d-kdqj8 -- curl http://my-cluster-87a24261-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-02 18:31:28 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:31:28 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 29
2022-04-02 18:31:29 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-87a24261-kafka-clients-68d48c7d7d-kdqj8 -- curl http://my-cluster-87a24261-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-02 18:31:29 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:31:29 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 28
2022-04-02 18:31:30 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-87a24261-kafka-clients-68d48c7d7d-kdqj8 -- curl http://my-cluster-87a24261-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-02 18:31:30 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:31:30 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 27
2022-04-02 18:31:32 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-87a24261-kafka-clients-68d48c7d7d-kdqj8 -- curl http://my-cluster-87a24261-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-02 18:31:32 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:31:32 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 26
2022-04-02 18:31:33 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-87a24261-kafka-clients-68d48c7d7d-kdqj8 -- curl http://my-cluster-87a24261-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-02 18:31:33 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:31:33 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 25
2022-04-02 18:31:34 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-87a24261-kafka-clients-68d48c7d7d-kdqj8 -- curl http://my-cluster-87a24261-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-02 18:31:34 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:31:34 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 24
2022-04-02 18:31:35 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-87a24261-kafka-clients-68d48c7d7d-kdqj8 -- curl http://my-cluster-87a24261-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-02 18:31:35 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:31:35 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 23
2022-04-02 18:31:36 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-87a24261-kafka-clients-68d48c7d7d-kdqj8 -- curl http://my-cluster-87a24261-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-02 18:31:36 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:31:36 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 22
2022-04-02 18:31:38 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-87a24261-kafka-clients-68d48c7d7d-kdqj8 -- curl http://my-cluster-87a24261-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-02 18:31:38 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:31:38 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 21
2022-04-02 18:31:39 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-87a24261-kafka-clients-68d48c7d7d-kdqj8 -- curl http://my-cluster-87a24261-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-02 18:31:39 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:31:39 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 20
2022-04-02 18:31:40 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-87a24261-kafka-clients-68d48c7d7d-kdqj8 -- curl http://my-cluster-87a24261-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-02 18:31:40 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:31:40 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 19
2022-04-02 18:31:41 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-87a24261-kafka-clients-68d48c7d7d-kdqj8 -- curl http://my-cluster-87a24261-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-02 18:31:41 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:31:41 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 18
2022-04-02 18:31:42 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-87a24261-kafka-clients-68d48c7d7d-kdqj8 -- curl http://my-cluster-87a24261-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-02 18:31:42 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:31:42 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 17
2022-04-02 18:31:43 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-87a24261-kafka-clients-68d48c7d7d-kdqj8 -- curl http://my-cluster-87a24261-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-02 18:31:43 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:31:43 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 16
2022-04-02 18:31:45 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-87a24261-kafka-clients-68d48c7d7d-kdqj8 -- curl http://my-cluster-87a24261-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-02 18:31:45 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:31:45 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 15
2022-04-02 18:31:46 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-87a24261-kafka-clients-68d48c7d7d-kdqj8 -- curl http://my-cluster-87a24261-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-02 18:31:46 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:31:46 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 14
2022-04-02 18:31:47 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-87a24261-kafka-clients-68d48c7d7d-kdqj8 -- curl http://my-cluster-87a24261-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-02 18:31:47 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:31:47 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 13
2022-04-02 18:31:48 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-87a24261-kafka-clients-68d48c7d7d-kdqj8 -- curl http://my-cluster-87a24261-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-02 18:31:48 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:31:48 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 12
2022-04-02 18:31:49 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-87a24261-kafka-clients-68d48c7d7d-kdqj8 -- curl http://my-cluster-87a24261-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-02 18:31:49 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:31:49 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 11
2022-04-02 18:31:51 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-87a24261-kafka-clients-68d48c7d7d-kdqj8 -- curl http://my-cluster-87a24261-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-02 18:31:51 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:31:51 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 10
2022-04-02 18:31:52 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-87a24261-kafka-clients-68d48c7d7d-kdqj8 -- curl http://my-cluster-87a24261-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-02 18:31:52 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:31:52 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 9
2022-04-02 18:31:53 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-87a24261-kafka-clients-68d48c7d7d-kdqj8 -- curl http://my-cluster-87a24261-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-02 18:31:53 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:31:53 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 8
2022-04-02 18:31:54 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-87a24261-kafka-clients-68d48c7d7d-kdqj8 -- curl http://my-cluster-87a24261-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-02 18:31:54 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:31:54 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 7
2022-04-02 18:31:55 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-87a24261-kafka-clients-68d48c7d7d-kdqj8 -- curl http://my-cluster-87a24261-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-02 18:31:55 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:31:55 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 6
2022-04-02 18:31:57 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-87a24261-kafka-clients-68d48c7d7d-kdqj8 -- curl http://my-cluster-87a24261-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-02 18:31:57 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:31:57 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 5
2022-04-02 18:31:58 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-87a24261-kafka-clients-68d48c7d7d-kdqj8 -- curl http://my-cluster-87a24261-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-02 18:31:58 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:31:58 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 4
2022-04-02 18:31:59 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-87a24261-kafka-clients-68d48c7d7d-kdqj8 -- curl http://my-cluster-87a24261-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-02 18:31:59 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:31:59 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 3
2022-04-02 18:32:00 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-87a24261-kafka-clients-68d48c7d7d-kdqj8 -- curl http://my-cluster-87a24261-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-02 18:32:00 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:32:00 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 2
2022-04-02 18:32:01 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-87a24261-kafka-clients-68d48c7d7d-kdqj8 -- curl http://my-cluster-87a24261-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-02 18:32:01 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:32:01 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 1
2022-04-02 18:32:03 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-87a24261-kafka-clients-68d48c7d7d-kdqj8 -- curl http://my-cluster-87a24261-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-02 18:32:03 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:32:03 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 0
2022-04-02 18:32:03 [main] [32mINFO [m [KafkaConnectorUtils:196] Logger for connector org.apache.kafka.connect.file.FileStreamSourceConnector is stable
2022-04-02 18:32:03 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 18:32:03 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testLoggingHierarchy
2022-04-02 18:32:03 [main] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-87a24261-allow in namespace namespace-90
2022-04-02 18:32:03 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-87a24261 in namespace namespace-90
2022-04-02 18:32:03 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-87a24261 in namespace namespace-90
2022-04-02 18:32:03 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-87a24261-scraper in namespace namespace-90
2022-04-02 18:32:03 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-87a24261 in namespace namespace-90
2022-04-02 18:32:03 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-87a24261-kafka-clients in namespace namespace-90
2022-04-02 18:32:53 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 18:32:53 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-90 for test case:testLoggingHierarchy
2022-04-02 18:32:58 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testLoggingHierarchy-FINISHED
2022-04-02 18:32:58 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 18:32:58 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 18:32:58 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testJSONFormatLogging-STARTED
2022-04-02 18:32:58 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 18:32:58 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-91 for test case:testJSONFormatLogging
2022-04-02 18:32:58 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-91
2022-04-02 18:32:58 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-91
2022-04-02 18:32:58 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-91
2022-04-02 18:32:58 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-2317afcb in namespace namespace-91
2022-04-02 18:32:58 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-91
2022-04-02 18:32:58 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-2317afcb will have desired state: Ready
2022-04-02 18:34:52 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-2317afcb is in desired state: Ready
2022-04-02 18:34:52 [main] [32mINFO [m [StUtils:278] JSON format logging successfully set for pod: strimzi-cluster-operator-78689684d4-9t6wn
2022-04-02 18:34:52 [main] [32mINFO [m [StUtils:278] JSON format logging successfully set for pod: my-cluster-2317afcb-kafka-0
2022-04-02 18:34:52 [main] [32mINFO [m [StUtils:278] JSON format logging successfully set for pod: my-cluster-2317afcb-kafka-1
2022-04-02 18:34:52 [main] [32mINFO [m [StUtils:278] JSON format logging successfully set for pod: my-cluster-2317afcb-kafka-2
2022-04-02 18:34:52 [main] [32mINFO [m [StUtils:278] JSON format logging successfully set for pod: my-cluster-2317afcb-zookeeper-2
2022-04-02 18:34:52 [main] [32mINFO [m [StUtils:278] JSON format logging successfully set for pod: my-cluster-2317afcb-zookeeper-1
2022-04-02 18:34:52 [main] [32mINFO [m [StUtils:278] JSON format logging successfully set for pod: my-cluster-2317afcb-zookeeper-0
2022-04-02 18:34:52 [main] [32mINFO [m [StUtils:278] JSON format logging successfully set for pod: my-cluster-2317afcb-entity-operator-546d6cdbff-z5phc
2022-04-02 18:34:52 [main] [32mINFO [m [StUtils:278] JSON format logging successfully set for pod: my-cluster-2317afcb-entity-operator-546d6cdbff-z5phc
2022-04-02 18:34:52 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 18:34:52 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testJSONFormatLogging
2022-04-02 18:34:52 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-2317afcb in namespace namespace-91
2022-04-02 18:35:03 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 18:35:03 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-91 for test case:testJSONFormatLogging
2022-04-02 18:35:46 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testJSONFormatLogging-FINISHED
2022-04-02 18:35:46 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 18:35:46 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 18:35:46 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetKafkaLoggingLevels-STARTED
2022-04-02 18:35:46 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 18:35:46 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-92 for test case:testDynamicallySetKafkaLoggingLevels
2022-04-02 18:35:46 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-92
2022-04-02 18:35:46 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-92
2022-04-02 18:35:46 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-92
2022-04-02 18:35:46 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-09d6f1a7 in namespace namespace-92
2022-04-02 18:35:46 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-92
2022-04-02 18:35:46 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-09d6f1a7 will have desired state: Ready
2022-04-02 18:36:58 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-09d6f1a7 is in desired state: Ready
2022-04-02 18:36:58 [main] [32mINFO [m [LoggingChangeST:829] Changing rootLogger level to DEBUG with inline logging
2022-04-02 18:36:58 [main] [32mINFO [m [LoggingChangeST:836] Waiting for dynamic change in the kafka pod
2022-04-02 18:37:05 [main] [32mINFO [m [LoggingChangeST:854] Setting external logging INFO
2022-04-02 18:37:05 [main] [32mINFO [m [LoggingChangeST:890] Setting log level of kafka INFO
2022-04-02 18:37:05 [main] [32mINFO [m [LoggingChangeST:896] Waiting for dynamic change in the kafka pod
2022-04-02 18:37:08 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 18:37:08 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDynamicallySetKafkaLoggingLevels
2022-04-02 18:37:08 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-09d6f1a7 in namespace namespace-92
2022-04-02 18:37:18 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 18:37:18 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-92 for test case:testDynamicallySetKafkaLoggingLevels
2022-04-02 18:38:01 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetKafkaLoggingLevels-FINISHED
2022-04-02 18:38:01 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 18:38:01 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 18:38:01 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetEOloggingLevels-STARTED
2022-04-02 18:38:01 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 18:38:01 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-93 for test case:testDynamicallySetEOloggingLevels
2022-04-02 18:38:01 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-93
2022-04-02 18:38:01 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-93
2022-04-02 18:38:01 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-93
2022-04-02 18:38:01 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-c8a457e9 in namespace namespace-93
2022-04-02 18:38:01 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-93
2022-04-02 18:38:01 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-c8a457e9 will have desired state: Ready
2022-04-02 18:39:10 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-c8a457e9 is in desired state: Ready
2022-04-02 18:39:10 [main] [32mINFO [m [LoggingChangeST:284] Checking if EO pod contains any log (except configuration)
2022-04-02 18:39:10 [main] [32mINFO [m [LoggingChangeST:287] Changing rootLogger level to DEBUG with inline logging
2022-04-02 18:39:10 [main] [32mINFO [m [LoggingChangeST:295] Waiting for log4j2.properties will contain desired settings
2022-04-02 18:40:23 [main] [32mINFO [m [LoggingChangeST:312] Setting external logging OFF
2022-04-02 18:40:23 [main] [32mINFO [m [LoggingChangeST:370] Setting log level of TO and UO to OFF - records should not appear in log
2022-04-02 18:40:23 [main] [32mINFO [m [LoggingChangeST:377] Waiting for log4j2.properties will contain desired settings
2022-04-02 18:41:47 [main] [32mINFO [m [LoggingChangeST:395] Setting external logging OFF
2022-04-02 18:41:47 [main] [32mINFO [m [LoggingChangeST:431] Waiting for log4j2.properties will contain desired settings
2022-04-02 18:42:52 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 18:42:52 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDynamicallySetEOloggingLevels
2022-04-02 18:42:52 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-c8a457e9 in namespace namespace-93
2022-04-02 18:43:02 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 18:43:02 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-93 for test case:testDynamicallySetEOloggingLevels
2022-04-02 18:43:29 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetEOloggingLevels-FINISHED
2022-04-02 18:43:29 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 18:43:29 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 18:43:29 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetUnknownKafkaLoggerValue-STARTED
2022-04-02 18:43:29 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 18:43:29 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-94 for test case:testDynamicallySetUnknownKafkaLoggerValue
2022-04-02 18:43:29 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-94
2022-04-02 18:43:29 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-94
2022-04-02 18:43:29 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-94
2022-04-02 18:43:29 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-c0bdfb78 in namespace namespace-94
2022-04-02 18:43:29 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-94
2022-04-02 18:43:29 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-c0bdfb78 will have desired state: Ready
2022-04-02 18:44:35 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-c0bdfb78 is in desired state: Ready
2022-04-02 18:44:35 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c0bdfb78-kafka-1=bcd04a8d-2058-4d4d-bc43-b18ccfd57895, my-cluster-c0bdfb78-kafka-0=a77c7a73-7790-4040-81be-0a4c43bd9397, my-cluster-c0bdfb78-kafka-2=6761374a-a9e5-4786-82f3-13257c761a11} pods didn't roll. Remaining seconds for stability: 50
2022-04-02 18:44:36 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c0bdfb78-kafka-1=bcd04a8d-2058-4d4d-bc43-b18ccfd57895, my-cluster-c0bdfb78-kafka-0=a77c7a73-7790-4040-81be-0a4c43bd9397, my-cluster-c0bdfb78-kafka-2=6761374a-a9e5-4786-82f3-13257c761a11} pods didn't roll. Remaining seconds for stability: 49
2022-04-02 18:44:37 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c0bdfb78-kafka-1=bcd04a8d-2058-4d4d-bc43-b18ccfd57895, my-cluster-c0bdfb78-kafka-0=a77c7a73-7790-4040-81be-0a4c43bd9397, my-cluster-c0bdfb78-kafka-2=6761374a-a9e5-4786-82f3-13257c761a11} pods didn't roll. Remaining seconds for stability: 48
2022-04-02 18:44:38 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c0bdfb78-kafka-1=bcd04a8d-2058-4d4d-bc43-b18ccfd57895, my-cluster-c0bdfb78-kafka-0=a77c7a73-7790-4040-81be-0a4c43bd9397, my-cluster-c0bdfb78-kafka-2=6761374a-a9e5-4786-82f3-13257c761a11} pods didn't roll. Remaining seconds for stability: 47
2022-04-02 18:44:39 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c0bdfb78-kafka-1=bcd04a8d-2058-4d4d-bc43-b18ccfd57895, my-cluster-c0bdfb78-kafka-0=a77c7a73-7790-4040-81be-0a4c43bd9397, my-cluster-c0bdfb78-kafka-2=6761374a-a9e5-4786-82f3-13257c761a11} pods didn't roll. Remaining seconds for stability: 46
2022-04-02 18:44:40 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c0bdfb78-kafka-1=bcd04a8d-2058-4d4d-bc43-b18ccfd57895, my-cluster-c0bdfb78-kafka-0=a77c7a73-7790-4040-81be-0a4c43bd9397, my-cluster-c0bdfb78-kafka-2=6761374a-a9e5-4786-82f3-13257c761a11} pods didn't roll. Remaining seconds for stability: 45
2022-04-02 18:44:41 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c0bdfb78-kafka-1=bcd04a8d-2058-4d4d-bc43-b18ccfd57895, my-cluster-c0bdfb78-kafka-0=a77c7a73-7790-4040-81be-0a4c43bd9397, my-cluster-c0bdfb78-kafka-2=6761374a-a9e5-4786-82f3-13257c761a11} pods didn't roll. Remaining seconds for stability: 44
2022-04-02 18:44:42 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c0bdfb78-kafka-1=bcd04a8d-2058-4d4d-bc43-b18ccfd57895, my-cluster-c0bdfb78-kafka-0=a77c7a73-7790-4040-81be-0a4c43bd9397, my-cluster-c0bdfb78-kafka-2=6761374a-a9e5-4786-82f3-13257c761a11} pods didn't roll. Remaining seconds for stability: 43
2022-04-02 18:44:43 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c0bdfb78-kafka-1=bcd04a8d-2058-4d4d-bc43-b18ccfd57895, my-cluster-c0bdfb78-kafka-0=a77c7a73-7790-4040-81be-0a4c43bd9397, my-cluster-c0bdfb78-kafka-2=6761374a-a9e5-4786-82f3-13257c761a11} pods didn't roll. Remaining seconds for stability: 42
2022-04-02 18:44:44 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c0bdfb78-kafka-1=bcd04a8d-2058-4d4d-bc43-b18ccfd57895, my-cluster-c0bdfb78-kafka-0=a77c7a73-7790-4040-81be-0a4c43bd9397, my-cluster-c0bdfb78-kafka-2=6761374a-a9e5-4786-82f3-13257c761a11} pods didn't roll. Remaining seconds for stability: 41
2022-04-02 18:44:45 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c0bdfb78-kafka-1=bcd04a8d-2058-4d4d-bc43-b18ccfd57895, my-cluster-c0bdfb78-kafka-0=a77c7a73-7790-4040-81be-0a4c43bd9397, my-cluster-c0bdfb78-kafka-2=6761374a-a9e5-4786-82f3-13257c761a11} pods didn't roll. Remaining seconds for stability: 40
2022-04-02 18:44:46 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c0bdfb78-kafka-1=bcd04a8d-2058-4d4d-bc43-b18ccfd57895, my-cluster-c0bdfb78-kafka-0=a77c7a73-7790-4040-81be-0a4c43bd9397, my-cluster-c0bdfb78-kafka-2=6761374a-a9e5-4786-82f3-13257c761a11} pods didn't roll. Remaining seconds for stability: 39
2022-04-02 18:44:47 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c0bdfb78-kafka-1=bcd04a8d-2058-4d4d-bc43-b18ccfd57895, my-cluster-c0bdfb78-kafka-0=a77c7a73-7790-4040-81be-0a4c43bd9397, my-cluster-c0bdfb78-kafka-2=6761374a-a9e5-4786-82f3-13257c761a11} pods didn't roll. Remaining seconds for stability: 38
2022-04-02 18:44:48 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c0bdfb78-kafka-1=bcd04a8d-2058-4d4d-bc43-b18ccfd57895, my-cluster-c0bdfb78-kafka-0=a77c7a73-7790-4040-81be-0a4c43bd9397, my-cluster-c0bdfb78-kafka-2=6761374a-a9e5-4786-82f3-13257c761a11} pods didn't roll. Remaining seconds for stability: 37
2022-04-02 18:44:49 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c0bdfb78-kafka-1=bcd04a8d-2058-4d4d-bc43-b18ccfd57895, my-cluster-c0bdfb78-kafka-0=a77c7a73-7790-4040-81be-0a4c43bd9397, my-cluster-c0bdfb78-kafka-2=6761374a-a9e5-4786-82f3-13257c761a11} pods didn't roll. Remaining seconds for stability: 36
2022-04-02 18:44:50 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c0bdfb78-kafka-1=bcd04a8d-2058-4d4d-bc43-b18ccfd57895, my-cluster-c0bdfb78-kafka-0=a77c7a73-7790-4040-81be-0a4c43bd9397, my-cluster-c0bdfb78-kafka-2=6761374a-a9e5-4786-82f3-13257c761a11} pods didn't roll. Remaining seconds for stability: 35
2022-04-02 18:44:51 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c0bdfb78-kafka-1=bcd04a8d-2058-4d4d-bc43-b18ccfd57895, my-cluster-c0bdfb78-kafka-0=a77c7a73-7790-4040-81be-0a4c43bd9397, my-cluster-c0bdfb78-kafka-2=6761374a-a9e5-4786-82f3-13257c761a11} pods didn't roll. Remaining seconds for stability: 34
2022-04-02 18:44:52 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c0bdfb78-kafka-1=bcd04a8d-2058-4d4d-bc43-b18ccfd57895, my-cluster-c0bdfb78-kafka-0=a77c7a73-7790-4040-81be-0a4c43bd9397, my-cluster-c0bdfb78-kafka-2=6761374a-a9e5-4786-82f3-13257c761a11} pods didn't roll. Remaining seconds for stability: 33
2022-04-02 18:44:53 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c0bdfb78-kafka-1=bcd04a8d-2058-4d4d-bc43-b18ccfd57895, my-cluster-c0bdfb78-kafka-0=a77c7a73-7790-4040-81be-0a4c43bd9397, my-cluster-c0bdfb78-kafka-2=6761374a-a9e5-4786-82f3-13257c761a11} pods didn't roll. Remaining seconds for stability: 32
2022-04-02 18:44:54 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c0bdfb78-kafka-1=bcd04a8d-2058-4d4d-bc43-b18ccfd57895, my-cluster-c0bdfb78-kafka-0=a77c7a73-7790-4040-81be-0a4c43bd9397, my-cluster-c0bdfb78-kafka-2=6761374a-a9e5-4786-82f3-13257c761a11} pods didn't roll. Remaining seconds for stability: 31
2022-04-02 18:44:55 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c0bdfb78-kafka-1=bcd04a8d-2058-4d4d-bc43-b18ccfd57895, my-cluster-c0bdfb78-kafka-0=a77c7a73-7790-4040-81be-0a4c43bd9397, my-cluster-c0bdfb78-kafka-2=6761374a-a9e5-4786-82f3-13257c761a11} pods didn't roll. Remaining seconds for stability: 30
2022-04-02 18:44:56 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c0bdfb78-kafka-1=bcd04a8d-2058-4d4d-bc43-b18ccfd57895, my-cluster-c0bdfb78-kafka-0=a77c7a73-7790-4040-81be-0a4c43bd9397, my-cluster-c0bdfb78-kafka-2=6761374a-a9e5-4786-82f3-13257c761a11} pods didn't roll. Remaining seconds for stability: 29
2022-04-02 18:44:57 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c0bdfb78-kafka-1=bcd04a8d-2058-4d4d-bc43-b18ccfd57895, my-cluster-c0bdfb78-kafka-0=a77c7a73-7790-4040-81be-0a4c43bd9397, my-cluster-c0bdfb78-kafka-2=6761374a-a9e5-4786-82f3-13257c761a11} pods didn't roll. Remaining seconds for stability: 28
2022-04-02 18:44:58 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c0bdfb78-kafka-1=bcd04a8d-2058-4d4d-bc43-b18ccfd57895, my-cluster-c0bdfb78-kafka-0=a77c7a73-7790-4040-81be-0a4c43bd9397, my-cluster-c0bdfb78-kafka-2=6761374a-a9e5-4786-82f3-13257c761a11} pods didn't roll. Remaining seconds for stability: 27
2022-04-02 18:44:59 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c0bdfb78-kafka-1=bcd04a8d-2058-4d4d-bc43-b18ccfd57895, my-cluster-c0bdfb78-kafka-0=a77c7a73-7790-4040-81be-0a4c43bd9397, my-cluster-c0bdfb78-kafka-2=6761374a-a9e5-4786-82f3-13257c761a11} pods didn't roll. Remaining seconds for stability: 26
2022-04-02 18:45:00 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c0bdfb78-kafka-1=bcd04a8d-2058-4d4d-bc43-b18ccfd57895, my-cluster-c0bdfb78-kafka-0=a77c7a73-7790-4040-81be-0a4c43bd9397, my-cluster-c0bdfb78-kafka-2=6761374a-a9e5-4786-82f3-13257c761a11} pods didn't roll. Remaining seconds for stability: 25
2022-04-02 18:45:01 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c0bdfb78-kafka-1=bcd04a8d-2058-4d4d-bc43-b18ccfd57895, my-cluster-c0bdfb78-kafka-0=a77c7a73-7790-4040-81be-0a4c43bd9397, my-cluster-c0bdfb78-kafka-2=6761374a-a9e5-4786-82f3-13257c761a11} pods didn't roll. Remaining seconds for stability: 24
2022-04-02 18:45:02 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c0bdfb78-kafka-1=bcd04a8d-2058-4d4d-bc43-b18ccfd57895, my-cluster-c0bdfb78-kafka-0=a77c7a73-7790-4040-81be-0a4c43bd9397, my-cluster-c0bdfb78-kafka-2=6761374a-a9e5-4786-82f3-13257c761a11} pods didn't roll. Remaining seconds for stability: 23
2022-04-02 18:45:03 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c0bdfb78-kafka-1=bcd04a8d-2058-4d4d-bc43-b18ccfd57895, my-cluster-c0bdfb78-kafka-0=a77c7a73-7790-4040-81be-0a4c43bd9397, my-cluster-c0bdfb78-kafka-2=6761374a-a9e5-4786-82f3-13257c761a11} pods didn't roll. Remaining seconds for stability: 22
2022-04-02 18:45:04 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c0bdfb78-kafka-1=bcd04a8d-2058-4d4d-bc43-b18ccfd57895, my-cluster-c0bdfb78-kafka-0=a77c7a73-7790-4040-81be-0a4c43bd9397, my-cluster-c0bdfb78-kafka-2=6761374a-a9e5-4786-82f3-13257c761a11} pods didn't roll. Remaining seconds for stability: 21
2022-04-02 18:45:05 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c0bdfb78-kafka-1=bcd04a8d-2058-4d4d-bc43-b18ccfd57895, my-cluster-c0bdfb78-kafka-0=a77c7a73-7790-4040-81be-0a4c43bd9397, my-cluster-c0bdfb78-kafka-2=6761374a-a9e5-4786-82f3-13257c761a11} pods didn't roll. Remaining seconds for stability: 20
2022-04-02 18:45:06 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c0bdfb78-kafka-1=bcd04a8d-2058-4d4d-bc43-b18ccfd57895, my-cluster-c0bdfb78-kafka-0=a77c7a73-7790-4040-81be-0a4c43bd9397, my-cluster-c0bdfb78-kafka-2=6761374a-a9e5-4786-82f3-13257c761a11} pods didn't roll. Remaining seconds for stability: 19
2022-04-02 18:45:07 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c0bdfb78-kafka-1=bcd04a8d-2058-4d4d-bc43-b18ccfd57895, my-cluster-c0bdfb78-kafka-0=a77c7a73-7790-4040-81be-0a4c43bd9397, my-cluster-c0bdfb78-kafka-2=6761374a-a9e5-4786-82f3-13257c761a11} pods didn't roll. Remaining seconds for stability: 18
2022-04-02 18:45:08 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c0bdfb78-kafka-1=bcd04a8d-2058-4d4d-bc43-b18ccfd57895, my-cluster-c0bdfb78-kafka-0=a77c7a73-7790-4040-81be-0a4c43bd9397, my-cluster-c0bdfb78-kafka-2=6761374a-a9e5-4786-82f3-13257c761a11} pods didn't roll. Remaining seconds for stability: 17
2022-04-02 18:45:09 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c0bdfb78-kafka-1=bcd04a8d-2058-4d4d-bc43-b18ccfd57895, my-cluster-c0bdfb78-kafka-0=a77c7a73-7790-4040-81be-0a4c43bd9397, my-cluster-c0bdfb78-kafka-2=6761374a-a9e5-4786-82f3-13257c761a11} pods didn't roll. Remaining seconds for stability: 16
2022-04-02 18:45:10 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c0bdfb78-kafka-1=bcd04a8d-2058-4d4d-bc43-b18ccfd57895, my-cluster-c0bdfb78-kafka-0=a77c7a73-7790-4040-81be-0a4c43bd9397, my-cluster-c0bdfb78-kafka-2=6761374a-a9e5-4786-82f3-13257c761a11} pods didn't roll. Remaining seconds for stability: 15
2022-04-02 18:45:11 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c0bdfb78-kafka-1=bcd04a8d-2058-4d4d-bc43-b18ccfd57895, my-cluster-c0bdfb78-kafka-0=a77c7a73-7790-4040-81be-0a4c43bd9397, my-cluster-c0bdfb78-kafka-2=6761374a-a9e5-4786-82f3-13257c761a11} pods didn't roll. Remaining seconds for stability: 14
2022-04-02 18:45:12 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c0bdfb78-kafka-1=bcd04a8d-2058-4d4d-bc43-b18ccfd57895, my-cluster-c0bdfb78-kafka-0=a77c7a73-7790-4040-81be-0a4c43bd9397, my-cluster-c0bdfb78-kafka-2=6761374a-a9e5-4786-82f3-13257c761a11} pods didn't roll. Remaining seconds for stability: 13
2022-04-02 18:45:13 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c0bdfb78-kafka-1=bcd04a8d-2058-4d4d-bc43-b18ccfd57895, my-cluster-c0bdfb78-kafka-0=a77c7a73-7790-4040-81be-0a4c43bd9397, my-cluster-c0bdfb78-kafka-2=6761374a-a9e5-4786-82f3-13257c761a11} pods didn't roll. Remaining seconds for stability: 12
2022-04-02 18:45:14 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c0bdfb78-kafka-1=bcd04a8d-2058-4d4d-bc43-b18ccfd57895, my-cluster-c0bdfb78-kafka-0=a77c7a73-7790-4040-81be-0a4c43bd9397, my-cluster-c0bdfb78-kafka-2=6761374a-a9e5-4786-82f3-13257c761a11} pods didn't roll. Remaining seconds for stability: 11
2022-04-02 18:45:15 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c0bdfb78-kafka-1=bcd04a8d-2058-4d4d-bc43-b18ccfd57895, my-cluster-c0bdfb78-kafka-0=a77c7a73-7790-4040-81be-0a4c43bd9397, my-cluster-c0bdfb78-kafka-2=6761374a-a9e5-4786-82f3-13257c761a11} pods didn't roll. Remaining seconds for stability: 10
2022-04-02 18:45:16 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c0bdfb78-kafka-1=bcd04a8d-2058-4d4d-bc43-b18ccfd57895, my-cluster-c0bdfb78-kafka-0=a77c7a73-7790-4040-81be-0a4c43bd9397, my-cluster-c0bdfb78-kafka-2=6761374a-a9e5-4786-82f3-13257c761a11} pods didn't roll. Remaining seconds for stability: 9
2022-04-02 18:45:17 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c0bdfb78-kafka-1=bcd04a8d-2058-4d4d-bc43-b18ccfd57895, my-cluster-c0bdfb78-kafka-0=a77c7a73-7790-4040-81be-0a4c43bd9397, my-cluster-c0bdfb78-kafka-2=6761374a-a9e5-4786-82f3-13257c761a11} pods didn't roll. Remaining seconds for stability: 8
2022-04-02 18:45:18 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c0bdfb78-kafka-1=bcd04a8d-2058-4d4d-bc43-b18ccfd57895, my-cluster-c0bdfb78-kafka-0=a77c7a73-7790-4040-81be-0a4c43bd9397, my-cluster-c0bdfb78-kafka-2=6761374a-a9e5-4786-82f3-13257c761a11} pods didn't roll. Remaining seconds for stability: 7
2022-04-02 18:45:19 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c0bdfb78-kafka-1=bcd04a8d-2058-4d4d-bc43-b18ccfd57895, my-cluster-c0bdfb78-kafka-0=a77c7a73-7790-4040-81be-0a4c43bd9397, my-cluster-c0bdfb78-kafka-2=6761374a-a9e5-4786-82f3-13257c761a11} pods didn't roll. Remaining seconds for stability: 6
2022-04-02 18:45:20 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c0bdfb78-kafka-1=bcd04a8d-2058-4d4d-bc43-b18ccfd57895, my-cluster-c0bdfb78-kafka-0=a77c7a73-7790-4040-81be-0a4c43bd9397, my-cluster-c0bdfb78-kafka-2=6761374a-a9e5-4786-82f3-13257c761a11} pods didn't roll. Remaining seconds for stability: 5
2022-04-02 18:45:21 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c0bdfb78-kafka-1=bcd04a8d-2058-4d4d-bc43-b18ccfd57895, my-cluster-c0bdfb78-kafka-0=a77c7a73-7790-4040-81be-0a4c43bd9397, my-cluster-c0bdfb78-kafka-2=6761374a-a9e5-4786-82f3-13257c761a11} pods didn't roll. Remaining seconds for stability: 4
2022-04-02 18:45:22 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c0bdfb78-kafka-1=bcd04a8d-2058-4d4d-bc43-b18ccfd57895, my-cluster-c0bdfb78-kafka-0=a77c7a73-7790-4040-81be-0a4c43bd9397, my-cluster-c0bdfb78-kafka-2=6761374a-a9e5-4786-82f3-13257c761a11} pods didn't roll. Remaining seconds for stability: 3
2022-04-02 18:45:23 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c0bdfb78-kafka-1=bcd04a8d-2058-4d4d-bc43-b18ccfd57895, my-cluster-c0bdfb78-kafka-0=a77c7a73-7790-4040-81be-0a4c43bd9397, my-cluster-c0bdfb78-kafka-2=6761374a-a9e5-4786-82f3-13257c761a11} pods didn't roll. Remaining seconds for stability: 2
2022-04-02 18:45:24 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c0bdfb78-kafka-1=bcd04a8d-2058-4d4d-bc43-b18ccfd57895, my-cluster-c0bdfb78-kafka-0=a77c7a73-7790-4040-81be-0a4c43bd9397, my-cluster-c0bdfb78-kafka-2=6761374a-a9e5-4786-82f3-13257c761a11} pods didn't roll. Remaining seconds for stability: 1
2022-04-02 18:45:25 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c0bdfb78-kafka-1=bcd04a8d-2058-4d4d-bc43-b18ccfd57895, my-cluster-c0bdfb78-kafka-0=a77c7a73-7790-4040-81be-0a4c43bd9397, my-cluster-c0bdfb78-kafka-2=6761374a-a9e5-4786-82f3-13257c761a11} pods didn't roll. Remaining seconds for stability: 0
2022-04-02 18:45:25 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 18:45:25 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDynamicallySetUnknownKafkaLoggerValue
2022-04-02 18:45:25 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-c0bdfb78 in namespace namespace-94
2022-04-02 18:45:35 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 18:45:35 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-94 for test case:testDynamicallySetUnknownKafkaLoggerValue
2022-04-02 18:46:02 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetUnknownKafkaLoggerValue-FINISHED
2022-04-02 18:46:02 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 18:46:02 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 18:46:02 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetBridgeLoggingLevels-STARTED
2022-04-02 18:46:02 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 18:46:02 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-95 for test case:testDynamicallySetBridgeLoggingLevels
2022-04-02 18:46:02 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-95
2022-04-02 18:46:02 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-95
2022-04-02 18:46:02 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-95
2022-04-02 18:46:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-2a2649b0 in namespace namespace-95
2022-04-02 18:46:02 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-95
2022-04-02 18:46:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-2a2649b0-kafka-clients in namespace namespace-95
2022-04-02 18:46:02 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-95
2022-04-02 18:46:02 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge my-cluster-2a2649b0 in namespace namespace-95
2022-04-02 18:46:02 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-95
2022-04-02 18:46:02 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-2a2649b0 will have desired state: Ready
2022-04-02 18:47:19 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-2a2649b0 is in desired state: Ready
2022-04-02 18:47:19 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-2a2649b0-kafka-clients will be ready
2022-04-02 18:47:19 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-2a2649b0-kafka-clients is ready
2022-04-02 18:47:19 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: my-cluster-2a2649b0 will have desired state: Ready
2022-04-02 18:47:19 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: my-cluster-2a2649b0 is in desired state: Ready
2022-04-02 18:47:19 [main] [32mINFO [m [LoggingChangeST:484] Asserting if log is without records
2022-04-02 18:47:20 [main] [32mINFO [m [LoggingChangeST:487] Changing rootLogger level to DEBUG with inline logging
2022-04-02 18:47:20 [main] [32mINFO [m [LoggingChangeST:499] Waiting for log4j2.properties will contain desired settings
2022-04-02 18:48:16 [main] [32mINFO [m [LoggingChangeST:556] Setting log level of Bridge to OFF - records should not appear in the log
2022-04-02 18:48:16 [main] [32mINFO [m [LoggingChangeST:562] Waiting for log4j2.properties will contain desired settings
2022-04-02 18:50:16 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 18:50:16 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDynamicallySetBridgeLoggingLevels
2022-04-02 18:50:16 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-2a2649b0-kafka-clients in namespace namespace-95
2022-04-02 18:50:16 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge my-cluster-2a2649b0 in namespace namespace-95
2022-04-02 18:50:16 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-2a2649b0 in namespace namespace-95
2022-04-02 18:51:06 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 18:51:06 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-95 for test case:testDynamicallySetBridgeLoggingLevels
2022-04-02 18:51:11 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetBridgeLoggingLevels-FINISHED
2022-04-02 18:51:11 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 18:51:11 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 18:51:11 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetMM2LoggingLevels-STARTED
2022-04-02 18:51:11 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 18:51:11 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-96 for test case:testDynamicallySetMM2LoggingLevels
2022-04-02 18:51:11 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-96
2022-04-02 18:51:11 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-96
2022-04-02 18:51:11 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-96
2022-04-02 18:51:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-1659eff3-source in namespace namespace-96
2022-04-02 18:51:11 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-96
2022-04-02 18:51:11 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-1659eff3-source will have desired state: Ready
2022-04-02 18:52:29 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-1659eff3-source is in desired state: Ready
2022-04-02 18:52:29 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-1659eff3-target in namespace namespace-96
2022-04-02 18:52:29 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-96
2022-04-02 18:52:29 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-1659eff3-target will have desired state: Ready
2022-04-02 18:53:50 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-1659eff3-target is in desired state: Ready
2022-04-02 18:53:50 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-1659eff3-kafka-clients in namespace namespace-96
2022-04-02 18:53:50 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-96
2022-04-02 18:53:50 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-1659eff3 in namespace namespace-96
2022-04-02 18:53:50 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-96
2022-04-02 18:53:50 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-1659eff3 will have desired state: Ready
2022-04-02 18:54:55 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-1659eff3 is in desired state: Ready
2022-04-02 18:54:55 [main] [32mINFO [m [LoggingChangeST:1124] Changing rootLogger level to DEBUG with inline logging
2022-04-02 18:54:55 [main] [32mINFO [m [LoggingChangeST:1133] Waiting for log4j.properties will contain desired settings
2022-04-02 18:54:56 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-96 exec my-cluster-1659eff3-mirrormaker2-9c6589b65-sp8zb -- curl http://localhost:8083/admin/loggers/root
2022-04-02 18:54:56 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:54:56 [main] [32mINFO [m [LoggingChangeST:1177] Setting log level of MM2 to OFF
2022-04-02 18:54:56 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-96 exec my-cluster-1659eff3-mirrormaker2-9c6589b65-sp8zb -- curl http://localhost:8083/admin/loggers/root
2022-04-02 18:54:56 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:54:57 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-96 exec my-cluster-1659eff3-mirrormaker2-9c6589b65-sp8zb -- curl http://localhost:8083/admin/loggers/root
2022-04-02 18:54:57 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 18:54:57 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 18:54:57 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDynamicallySetMM2LoggingLevels
2022-04-02 18:54:57 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-1659eff3-kafka-clients in namespace namespace-96
2022-04-02 18:54:57 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-1659eff3 in namespace namespace-96
2022-04-02 18:54:57 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-1659eff3-source in namespace namespace-96
2022-04-02 18:54:57 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-1659eff3-target in namespace namespace-96
2022-04-02 18:55:58 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 18:55:58 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-96 for test case:testDynamicallySetMM2LoggingLevels
2022-04-02 18:56:04 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetMM2LoggingLevels-FINISHED
2022-04-02 18:56:04 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 18:56:04 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 18:56:04 [main] [32mINFO [m [ResourceManager:346] In context LoggingChangeST is everything deleted.
2022-04-02 18:56:04 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 13, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2,929.966 s - in io.strimzi.systemtest.log.LoggingChangeST
[[1;34mINFO[m] Running io.strimzi.systemtest.log.LogSettingST
2022-04-02 18:56:10 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: log-setting-st
2022-04-02 18:56:10 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: log-setting-st
2022-04-02 18:56:10 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: log-setting-st
2022-04-02 18:56:10 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka log-setting-cluster-name in namespace log-setting-st
2022-04-02 18:56:10 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka gc-set-logging in namespace log-setting-st
2022-04-02 18:56:10 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment shared-kafka-clients in namespace log-setting-st
2022-04-02 18:56:10 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: log-setting-cluster-name will have desired state: Ready
2022-04-02 18:58:02 [main] [32mINFO [m [ResourceManager:444] Kafka: log-setting-cluster-name is in desired state: Ready
2022-04-02 18:58:02 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: gc-set-logging will have desired state: Ready
2022-04-02 18:58:02 [main] [32mINFO [m [ResourceManager:444] Kafka: gc-set-logging is in desired state: Ready
2022-04-02 18:58:02 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: shared-kafka-clients will be ready
2022-04-02 18:58:02 [main] [32mINFO [m [DeploymentUtils:168] Deployment: shared-kafka-clients is ready
2022-04-02 18:58:02 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 18:58:02 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LogSettingST.testMirrorMaker2LogSetting-STARTED
2022-04-02 18:58:02 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 18:58:02 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-4de6e7d9-mirror-maker-2 in namespace log-setting-st
2022-04-02 18:58:02 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-4de6e7d9-mirror-maker-2 will have desired state: Ready
2022-04-02 18:59:14 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-4de6e7d9-mirror-maker-2 is in desired state: Ready
2022-04-02 18:59:14 [main] [32mINFO [m [LogSettingST:357] Checking if MirrorMaker2 has log level set properly
2022-04-02 18:59:14 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: mirrormaker.root.logger Expected: TRACE
2022-04-02 18:59:14 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: test.mirrormaker.logger.level Expected: TRACE
2022-04-02 18:59:14 [main] [32mINFO [m [LogSettingST:498] Checking deployment: my-cluster-4de6e7d9-mirror-maker-2-mirrormaker2
2022-04-02 18:59:14 [main] [32mINFO [m [LogSettingST:500] Checking container with name: my-cluster-4de6e7d9-mirror-maker-2-mirrormaker2
2022-04-02 18:59:14 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=true
2022-04-02 18:59:14 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-4de6e7d9-mirror-maker-2-mirrormaker2 rolling update
2022-04-02 19:00:34 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-4de6e7d9-mirror-maker-2-mirrormaker2 will be ready
2022-04-02 19:00:34 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-4de6e7d9-mirror-maker-2-mirrormaker2 is ready
2022-04-02 19:00:44 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-4de6e7d9-mirror-maker-2-mirrormaker2 rolling update finished
2022-04-02 19:00:44 [main] [32mINFO [m [LogSettingST:498] Checking deployment: my-cluster-4de6e7d9-mirror-maker-2-mirrormaker2
2022-04-02 19:00:44 [main] [32mINFO [m [LogSettingST:500] Checking container with name: my-cluster-4de6e7d9-mirror-maker-2-mirrormaker2
2022-04-02 19:00:44 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=false
2022-04-02 19:00:45 [main] [32mINFO [m [PodUtils:343] Waiting for Pod my-cluster-4de6e7d9-mirror-maker-2-mirrormaker2-584f6d95dchmmz8 container my-cluster-4de6e7d9-mirror-maker-2-mirrormaker2 will be ready
2022-04-02 19:00:45 [main] [32mINFO [m [PodUtils:347] Pod my-cluster-4de6e7d9-mirror-maker-2-mirrormaker2-584f6d95dchmmz8 container my-cluster-4de6e7d9-mirror-maker-2-mirrormaker2 is ready
2022-04-02 19:00:45 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod my-cluster-4de6e7d9-mirror-maker-2-mirrormaker2-584f6d95dchmmz8 with container my-cluster-4de6e7d9-mirror-maker-2-mirrormaker2
2022-04-02 19:00:45 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 19:00:45 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMirrorMaker2LogSetting
2022-04-02 19:00:45 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-4de6e7d9-mirror-maker-2 in namespace log-setting-st
2022-04-02 19:00:55 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 19:00:55 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LogSettingST.testMirrorMaker2LogSetting-FINISHED
2022-04-02 19:00:55 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 19:00:55 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 19:00:55 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LogSettingST.testCruiseControlLogChange-STARTED
2022-04-02 19:00:55 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 19:00:55 [main] [32mINFO [m [LogSettingST:409] Check that default/actual root logging level is info
2022-04-02 19:00:55 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace log-setting-st exec log-setting-cluster-name-cruise-control-86b69f9874-z6n64 -- grep -i rootlogger.level /opt/cruise-control/custom-config/log4j2.properties
2022-04-02 19:00:55 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 19:00:55 [main] [32mINFO [m [LogSettingST:414] Check logs in CruiseControl - make sure no DEBUG is found there.
2022-04-02 19:00:55 [main] [32mINFO [m [LogSettingST:422] Wait for change of root logger in log-setting-cluster-name-cruise-control-86b69f9874-z6n64.
2022-04-02 19:00:56 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace log-setting-st exec log-setting-cluster-name-cruise-control-86b69f9874-z6n64 -- grep -i rootlogger.level /opt/cruise-control/custom-config/log4j2.properties
2022-04-02 19:00:56 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 19:01:01 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace log-setting-st exec log-setting-cluster-name-cruise-control-86b69f9874-z6n64 -- grep -i rootlogger.level /opt/cruise-control/custom-config/log4j2.properties
2022-04-02 19:01:01 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 19:01:06 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace log-setting-st exec log-setting-cluster-name-cruise-control-86b69f9874-z6n64 -- grep -i rootlogger.level /opt/cruise-control/custom-config/log4j2.properties
2022-04-02 19:01:06 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 19:01:11 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace log-setting-st exec log-setting-cluster-name-cruise-control-86b69f9874-z6n64 -- grep -i rootlogger.level /opt/cruise-control/custom-config/log4j2.properties
2022-04-02 19:01:11 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 19:01:16 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace log-setting-st exec log-setting-cluster-name-cruise-control-86b69f9874-z6n64 -- grep -i rootlogger.level /opt/cruise-control/custom-config/log4j2.properties
2022-04-02 19:01:16 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 19:01:22 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace log-setting-st exec log-setting-cluster-name-cruise-control-86b69f9874-z6n64 -- grep -i rootlogger.level /opt/cruise-control/custom-config/log4j2.properties
2022-04-02 19:01:22 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 19:01:27 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace log-setting-st exec log-setting-cluster-name-cruise-control-86b69f9874-z6n64 -- grep -i rootlogger.level /opt/cruise-control/custom-config/log4j2.properties
2022-04-02 19:01:27 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 19:01:32 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace log-setting-st exec log-setting-cluster-name-cruise-control-86b69f9874-z6n64 -- grep -i rootlogger.level /opt/cruise-control/custom-config/log4j2.properties
2022-04-02 19:01:32 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 19:01:37 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace log-setting-st exec log-setting-cluster-name-cruise-control-86b69f9874-z6n64 -- grep -i rootlogger.level /opt/cruise-control/custom-config/log4j2.properties
2022-04-02 19:01:37 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 19:01:37 [main] [32mINFO [m [LogSettingST:428] Check cruise control logs in pod log-setting-cluster-name-cruise-control-86b69f9874-z6n64 and it's container cruise-control .
2022-04-02 19:01:58 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 19:01:58 [main] [32mINFO [m [ResourceManager:346] In context testCruiseControlLogChange is everything deleted.
2022-04-02 19:01:58 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 19:01:58 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LogSettingST.testCruiseControlLogChange-FINISHED
2022-04-02 19:01:58 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 19:01:58 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 19:01:58 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LogSettingST.testMirrorMakerLogSetting-STARTED
2022-04-02 19:01:58 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 19:01:58 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-8b2b27af-mirror-maker in namespace log-setting-st
2022-04-02 19:01:58 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-8b2b27af-mirror-maker will have desired state: Ready
2022-04-02 19:03:00 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-8b2b27af-mirror-maker is in desired state: Ready
2022-04-02 19:03:00 [main] [32mINFO [m [LogSettingST:322] Checking if MirrorMaker has log level set properly
2022-04-02 19:03:00 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: mirrormaker.root.logger Expected: TRACE
2022-04-02 19:03:00 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: test.mirrormaker.logger.level Expected: TRACE
2022-04-02 19:03:00 [main] [32mINFO [m [LogSettingST:498] Checking deployment: my-cluster-8b2b27af-mirror-maker-mirror-maker
2022-04-02 19:03:00 [main] [32mINFO [m [LogSettingST:500] Checking container with name: my-cluster-8b2b27af-mirror-maker-mirror-maker
2022-04-02 19:03:00 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=true
2022-04-02 19:03:00 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-8b2b27af-mirror-maker-mirror-maker rolling update
2022-04-02 19:04:15 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-8b2b27af-mirror-maker-mirror-maker will be ready
2022-04-02 19:04:15 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-8b2b27af-mirror-maker-mirror-maker is ready
2022-04-02 19:04:25 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-8b2b27af-mirror-maker-mirror-maker rolling update finished
2022-04-02 19:04:25 [main] [32mINFO [m [LogSettingST:498] Checking deployment: my-cluster-8b2b27af-mirror-maker-mirror-maker
2022-04-02 19:04:25 [main] [32mINFO [m [LogSettingST:500] Checking container with name: my-cluster-8b2b27af-mirror-maker-mirror-maker
2022-04-02 19:04:25 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=false
2022-04-02 19:04:25 [main] [32mINFO [m [PodUtils:343] Waiting for Pod my-cluster-8b2b27af-mirror-maker-mirror-maker-59f97cff65-hwplq container my-cluster-8b2b27af-mirror-maker-mirror-maker will be ready
2022-04-02 19:04:25 [main] [32mINFO [m [PodUtils:347] Pod my-cluster-8b2b27af-mirror-maker-mirror-maker-59f97cff65-hwplq container my-cluster-8b2b27af-mirror-maker-mirror-maker is ready
2022-04-02 19:04:25 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod my-cluster-8b2b27af-mirror-maker-mirror-maker-59f97cff65-hwplq with container my-cluster-8b2b27af-mirror-maker-mirror-maker
2022-04-02 19:04:26 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 19:04:26 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMirrorMakerLogSetting
2022-04-02 19:04:26 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-8b2b27af-mirror-maker in namespace log-setting-st
2022-04-02 19:04:36 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 19:04:36 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LogSettingST.testMirrorMakerLogSetting-FINISHED
2022-04-02 19:04:36 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 19:04:36 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 19:04:36 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LogSettingST.testConnectLogSetting-STARTED
2022-04-02 19:04:36 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 19:04:36 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-53974ff8-connect-scraper in namespace log-setting-st
2022-04-02 19:04:36 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-53974ff8-connect-scraper will be ready
2022-04-02 19:04:38 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-53974ff8-connect-scraper is ready
2022-04-02 19:04:38 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-53974ff8-connect-scraper to be ready
2022-04-02 19:04:48 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-53974ff8-connect-scraper is ready
2022-04-02 19:04:48 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-53974ff8-connect-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-02 19:04:48 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-53974ff8-connect-allow in namespace log-setting-st
2022-04-02 19:04:48 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-02 19:04:48 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-53974ff8-connect in namespace log-setting-st
2022-04-02 19:04:48 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-53974ff8-connect will have desired state: Ready
2022-04-02 19:05:53 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-53974ff8-connect is in desired state: Ready
2022-04-02 19:05:53 [main] [32mINFO [m [LogSettingST:287] Checking if Connect has log level set properly
2022-04-02 19:05:53 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.org.I0Itec.zkclient Expected: ERROR
2022-04-02 19:05:53 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: connect.root.logger.level Expected: INFO
2022-04-02 19:05:53 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: test.connect.logger.level Expected: DEBUG
2022-04-02 19:05:53 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.org.reflections Expected: WARN
2022-04-02 19:05:53 [main] [32mINFO [m [LogSettingST:498] Checking deployment: my-cluster-53974ff8-connect-connect
2022-04-02 19:05:53 [main] [32mINFO [m [LogSettingST:500] Checking container with name: my-cluster-53974ff8-connect-connect
2022-04-02 19:05:53 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=true
2022-04-02 19:05:53 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-53974ff8-connect-connect rolling update
2022-04-02 19:07:03 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-53974ff8-connect-connect will be ready
2022-04-02 19:07:03 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-53974ff8-connect-connect is ready
2022-04-02 19:07:13 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-53974ff8-connect-connect rolling update finished
2022-04-02 19:07:13 [main] [32mINFO [m [LogSettingST:498] Checking deployment: my-cluster-53974ff8-connect-connect
2022-04-02 19:07:13 [main] [32mINFO [m [LogSettingST:500] Checking container with name: my-cluster-53974ff8-connect-connect
2022-04-02 19:07:13 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=false
2022-04-02 19:07:13 [main] [32mINFO [m [PodUtils:343] Waiting for Pod my-cluster-53974ff8-connect-connect-666f875774-plb76 container my-cluster-53974ff8-connect-connect will be ready
2022-04-02 19:07:13 [main] [32mINFO [m [PodUtils:347] Pod my-cluster-53974ff8-connect-connect-666f875774-plb76 container my-cluster-53974ff8-connect-connect is ready
2022-04-02 19:07:13 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod my-cluster-53974ff8-connect-connect-666f875774-plb76 with container my-cluster-53974ff8-connect-connect
2022-04-02 19:07:14 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 19:07:14 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testConnectLogSetting
2022-04-02 19:07:14 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-53974ff8-connect-scraper in namespace log-setting-st
2022-04-02 19:07:14 [main] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-53974ff8-connect-allow in namespace log-setting-st
2022-04-02 19:07:14 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-53974ff8-connect in namespace log-setting-st
2022-04-02 19:07:54 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 19:07:54 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LogSettingST.testConnectLogSetting-FINISHED
2022-04-02 19:07:54 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 19:07:54 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 19:07:54 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LogSettingST.testKafkaLogSetting-STARTED
2022-04-02 19:07:54 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 19:07:54 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-540720121-259310369 in namespace log-setting-st
2022-04-02 19:07:54 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-540720121-259310369 will have desired state: Ready
2022-04-02 19:07:55 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-540720121-259310369 is in desired state: Ready
2022-04-02 19:07:55 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1457037859-1807410062 in namespace log-setting-st
2022-04-02 19:07:55 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1457037859-1807410062 will have desired state: Ready
2022-04-02 19:07:56 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1457037859-1807410062 is in desired state: Ready
2022-04-02 19:07:56 [main] [32mINFO [m [LogSettingST:217] Checking if Kafka, Zookeeper, TO and UO of cluster:log-setting-cluster-name has log level set properly
2022-04-02 19:07:56 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.org.apache.zookeeper Expected: WARN
2022-04-02 19:07:56 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.kafka.network.Processor Expected: OFF
2022-04-02 19:07:56 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.kafka.request.logger Expected: FATAL
2022-04-02 19:07:56 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.kafka.controller Expected: WARN
2022-04-02 19:07:56 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: kafka.root.logger.level Expected: INFO
2022-04-02 19:07:56 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.state.change.logger Expected: DEBUG
2022-04-02 19:07:56 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.kafka.network.RequestChannel$ Expected: ERROR
2022-04-02 19:07:56 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.kafka.server.KafkaApis Expected: INFO
2022-04-02 19:07:56 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.kafka Expected: TRACE
2022-04-02 19:07:56 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.org.apache.kafka Expected: DEBUG
2022-04-02 19:07:56 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.kafka.authorizer.logger Expected: FATAL
2022-04-02 19:07:56 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.kafka.log.LogCleaner Expected: TRACE
2022-04-02 19:07:56 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.org.I0Itec.zkclient.ZkClient Expected: ERROR
2022-04-02 19:07:56 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: test.kafka.logger.level Expected: INFO
2022-04-02 19:07:56 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: zookeeper.root.logger Expected: OFF
2022-04-02 19:07:56 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: test.zookeeper.logger.level Expected: DEBUG
2022-04-02 19:07:56 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: rootLogger.level Expected: DEBUG
2022-04-02 19:07:56 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: test.operator.logger.level Expected: DEBUG
2022-04-02 19:07:56 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: rootLogger.level Expected: DEBUG
2022-04-02 19:07:56 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: test.operator.logger.level Expected: DEBUG
2022-04-02 19:07:56 [main] [32mINFO [m [LogSettingST:226] Checking if Kafka, Zookeeper, TO and UO of cluster:log-setting-cluster-name has GC logging enabled in stateful sets/deployments
2022-04-02 19:07:56 [main] [32mINFO [m [LogSettingST:512] Checking pods with selector: LabelSelector(matchExpressions=[], matchLabels={strimzi.io/name=log-setting-cluster-name-kafka, strimzi.io/cluster=log-setting-cluster-name, strimzi.io/kind=Kafka}, additionalProperties={})
2022-04-02 19:07:56 [main] [32mINFO [m [LogSettingST:516] Checking pod log-setting-cluster-name-kafka-0, container: kafka
2022-04-02 19:07:56 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=true
2022-04-02 19:07:56 [main] [32mINFO [m [LogSettingST:516] Checking pod log-setting-cluster-name-kafka-1, container: kafka
2022-04-02 19:07:56 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=true
2022-04-02 19:07:56 [main] [32mINFO [m [LogSettingST:516] Checking pod log-setting-cluster-name-kafka-2, container: kafka
2022-04-02 19:07:56 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=true
2022-04-02 19:07:56 [main] [32mINFO [m [LogSettingST:512] Checking pods with selector: LabelSelector(matchExpressions=[], matchLabels={strimzi.io/name=log-setting-cluster-name-zookeeper, strimzi.io/cluster=log-setting-cluster-name, strimzi.io/kind=Kafka}, additionalProperties={})
2022-04-02 19:07:56 [main] [32mINFO [m [LogSettingST:516] Checking pod log-setting-cluster-name-zookeeper-0, container: zookeeper
2022-04-02 19:07:56 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=true
2022-04-02 19:07:56 [main] [32mINFO [m [LogSettingST:490] Checking deployment: log-setting-cluster-name-entity-operator
2022-04-02 19:07:56 [main] [32mINFO [m [LogSettingST:493] Checking container with name: topic-operator
2022-04-02 19:07:56 [main] [32mINFO [m [LogSettingST:529] STRIMZI_GC_LOG_ENABLED=true
2022-04-02 19:07:56 [main] [32mINFO [m [LogSettingST:490] Checking deployment: log-setting-cluster-name-entity-operator
2022-04-02 19:07:56 [main] [32mINFO [m [LogSettingST:493] Checking container with name: user-operator
2022-04-02 19:07:56 [main] [32mINFO [m [LogSettingST:529] STRIMZI_GC_LOG_ENABLED=true
2022-04-02 19:07:56 [main] [32mINFO [m [LogSettingST:232] Changing JVM options - setting GC logging to false
2022-04-02 19:07:56 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: log-setting-cluster-name-zookeeper rolling update
2022-04-02 19:08:01 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: log-setting-cluster-name-zookeeper has been successfully rolled
2022-04-02 19:08:01 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 1 Pod(s) of log-setting-cluster-name-zookeeper to be ready
2022-04-02 19:08:33 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: log-setting-cluster-name-kafka rolling update
2022-04-02 19:10:03 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: log-setting-cluster-name-kafka has been successfully rolled
2022-04-02 19:10:03 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of log-setting-cluster-name-kafka to be ready
2022-04-02 19:10:34 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment log-setting-cluster-name-entity-operator rolling update
2022-04-02 19:10:34 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: log-setting-cluster-name-entity-operator will be ready
2022-04-02 19:16:00 [main] [32mINFO [m [DeploymentUtils:168] Deployment: log-setting-cluster-name-entity-operator is ready
2022-04-02 19:16:10 [main] [32mINFO [m [DeploymentUtils:141] Deployment log-setting-cluster-name-entity-operator rolling update finished
2022-04-02 19:16:10 [main] [32mINFO [m [LogSettingST:244] Checking if Kafka, Zookeeper, TO and UO of cluster: log-setting-cluster-name has GC logging disabled in stateful sets/deployments
2022-04-02 19:16:10 [main] [32mINFO [m [LogSettingST:512] Checking pods with selector: LabelSelector(matchExpressions=[], matchLabels={strimzi.io/name=log-setting-cluster-name-kafka, strimzi.io/cluster=log-setting-cluster-name, strimzi.io/kind=Kafka}, additionalProperties={})
2022-04-02 19:16:10 [main] [32mINFO [m [LogSettingST:516] Checking pod log-setting-cluster-name-kafka-0, container: kafka
2022-04-02 19:16:10 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=false
2022-04-02 19:16:10 [main] [32mINFO [m [LogSettingST:516] Checking pod log-setting-cluster-name-kafka-1, container: kafka
2022-04-02 19:16:10 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=false
2022-04-02 19:16:10 [main] [32mINFO [m [LogSettingST:516] Checking pod log-setting-cluster-name-kafka-2, container: kafka
2022-04-02 19:16:10 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=false
2022-04-02 19:16:10 [main] [32mINFO [m [LogSettingST:512] Checking pods with selector: LabelSelector(matchExpressions=[], matchLabels={strimzi.io/name=log-setting-cluster-name-zookeeper, strimzi.io/cluster=log-setting-cluster-name, strimzi.io/kind=Kafka}, additionalProperties={})
2022-04-02 19:16:10 [main] [32mINFO [m [LogSettingST:516] Checking pod log-setting-cluster-name-zookeeper-0, container: zookeeper
2022-04-02 19:16:10 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=false
2022-04-02 19:16:10 [main] [32mINFO [m [LogSettingST:490] Checking deployment: log-setting-cluster-name-entity-operator
2022-04-02 19:16:10 [main] [32mINFO [m [LogSettingST:493] Checking container with name: topic-operator
2022-04-02 19:16:10 [main] [32mINFO [m [LogSettingST:529] STRIMZI_GC_LOG_ENABLED=false
2022-04-02 19:16:10 [main] [32mINFO [m [LogSettingST:490] Checking deployment: log-setting-cluster-name-entity-operator
2022-04-02 19:16:10 [main] [32mINFO [m [LogSettingST:493] Checking container with name: user-operator
2022-04-02 19:16:10 [main] [32mINFO [m [LogSettingST:529] STRIMZI_GC_LOG_ENABLED=false
2022-04-02 19:16:10 [main] [32mINFO [m [LogSettingST:250] Checking if Kafka, Zookeeper, TO and UO of cluster: gc-set-logging has GC logging disabled in stateful sets/deployments
2022-04-02 19:16:10 [main] [32mINFO [m [LogSettingST:512] Checking pods with selector: LabelSelector(matchExpressions=[], matchLabels={strimzi.io/name=log-setting-cluster-name-kafka, strimzi.io/cluster=log-setting-cluster-name, strimzi.io/kind=Kafka}, additionalProperties={})
2022-04-02 19:16:10 [main] [32mINFO [m [LogSettingST:516] Checking pod log-setting-cluster-name-kafka-0, container: kafka
2022-04-02 19:16:10 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=false
2022-04-02 19:16:10 [main] [32mINFO [m [LogSettingST:516] Checking pod log-setting-cluster-name-kafka-1, container: kafka
2022-04-02 19:16:10 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=false
2022-04-02 19:16:10 [main] [32mINFO [m [LogSettingST:516] Checking pod log-setting-cluster-name-kafka-2, container: kafka
2022-04-02 19:16:10 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=false
2022-04-02 19:16:10 [main] [32mINFO [m [LogSettingST:512] Checking pods with selector: LabelSelector(matchExpressions=[], matchLabels={strimzi.io/name=log-setting-cluster-name-zookeeper, strimzi.io/cluster=log-setting-cluster-name, strimzi.io/kind=Kafka}, additionalProperties={})
2022-04-02 19:16:10 [main] [32mINFO [m [LogSettingST:516] Checking pod log-setting-cluster-name-zookeeper-0, container: zookeeper
2022-04-02 19:16:10 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=false
2022-04-02 19:16:10 [main] [32mINFO [m [LogSettingST:490] Checking deployment: log-setting-cluster-name-entity-operator
2022-04-02 19:16:10 [main] [32mINFO [m [LogSettingST:493] Checking container with name: topic-operator
2022-04-02 19:16:10 [main] [32mINFO [m [LogSettingST:529] STRIMZI_GC_LOG_ENABLED=false
2022-04-02 19:16:10 [main] [32mINFO [m [LogSettingST:490] Checking deployment: log-setting-cluster-name-entity-operator
2022-04-02 19:16:10 [main] [32mINFO [m [LogSettingST:493] Checking container with name: user-operator
2022-04-02 19:16:10 [main] [32mINFO [m [LogSettingST:529] STRIMZI_GC_LOG_ENABLED=false
2022-04-02 19:16:11 [main] [32mINFO [m [PodUtils:343] Waiting for Pod log-setting-cluster-name-cruise-control-86b69f9874-z6n64 container cruise-control will be ready
2022-04-02 19:16:11 [main] [32mINFO [m [PodUtils:347] Pod log-setting-cluster-name-cruise-control-86b69f9874-z6n64 container cruise-control is ready
2022-04-02 19:16:11 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod log-setting-cluster-name-cruise-control-86b69f9874-z6n64 with container cruise-control
2022-04-02 19:16:11 [main] [32mINFO [m [PodUtils:343] Waiting for Pod log-setting-cluster-name-cruise-control-86b69f9874-z6n64 container tls-sidecar will be ready
2022-04-02 19:16:11 [main] [32mINFO [m [PodUtils:347] Pod log-setting-cluster-name-cruise-control-86b69f9874-z6n64 container tls-sidecar is ready
2022-04-02 19:16:11 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod log-setting-cluster-name-cruise-control-86b69f9874-z6n64 with container tls-sidecar
2022-04-02 19:16:11 [main] [32mINFO [m [PodUtils:343] Waiting for Pod log-setting-cluster-name-entity-operator-d78c874cf-4rxf4 container topic-operator will be ready
2022-04-02 19:16:11 [main] [32mINFO [m [PodUtils:347] Pod log-setting-cluster-name-entity-operator-d78c874cf-4rxf4 container topic-operator is ready
2022-04-02 19:16:11 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod log-setting-cluster-name-entity-operator-d78c874cf-4rxf4 with container topic-operator
2022-04-02 19:16:11 [main] [32mINFO [m [PodUtils:343] Waiting for Pod log-setting-cluster-name-entity-operator-d78c874cf-4rxf4 container user-operator will be ready
2022-04-02 19:16:11 [main] [32mINFO [m [PodUtils:347] Pod log-setting-cluster-name-entity-operator-d78c874cf-4rxf4 container user-operator is ready
2022-04-02 19:16:11 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod log-setting-cluster-name-entity-operator-d78c874cf-4rxf4 with container user-operator
2022-04-02 19:16:12 [main] [32mINFO [m [PodUtils:343] Waiting for Pod log-setting-cluster-name-entity-operator-d78c874cf-4rxf4 container tls-sidecar will be ready
2022-04-02 19:16:12 [main] [32mINFO [m [PodUtils:347] Pod log-setting-cluster-name-entity-operator-d78c874cf-4rxf4 container tls-sidecar is ready
2022-04-02 19:16:12 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod log-setting-cluster-name-entity-operator-d78c874cf-4rxf4 with container tls-sidecar
2022-04-02 19:16:12 [main] [32mINFO [m [PodUtils:343] Waiting for Pod log-setting-cluster-name-kafka-0 container kafka will be ready
2022-04-02 19:16:12 [main] [32mINFO [m [PodUtils:347] Pod log-setting-cluster-name-kafka-0 container kafka is ready
2022-04-02 19:16:12 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod log-setting-cluster-name-kafka-0 with container kafka
2022-04-02 19:16:12 [main] [32mINFO [m [PodUtils:343] Waiting for Pod log-setting-cluster-name-kafka-1 container kafka will be ready
2022-04-02 19:16:12 [main] [32mINFO [m [PodUtils:347] Pod log-setting-cluster-name-kafka-1 container kafka is ready
2022-04-02 19:16:12 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod log-setting-cluster-name-kafka-1 with container kafka
2022-04-02 19:16:12 [main] [32mINFO [m [PodUtils:343] Waiting for Pod log-setting-cluster-name-kafka-2 container kafka will be ready
2022-04-02 19:16:12 [main] [32mINFO [m [PodUtils:347] Pod log-setting-cluster-name-kafka-2 container kafka is ready
2022-04-02 19:16:12 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod log-setting-cluster-name-kafka-2 with container kafka
2022-04-02 19:16:12 [main] [32mINFO [m [PodUtils:343] Waiting for Pod log-setting-cluster-name-kafka-exporter-7b59f7cd48-rhm8v container log-setting-cluster-name-kafka-exporter will be ready
2022-04-02 19:16:12 [main] [32mINFO [m [PodUtils:347] Pod log-setting-cluster-name-kafka-exporter-7b59f7cd48-rhm8v container log-setting-cluster-name-kafka-exporter is ready
2022-04-02 19:16:12 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod log-setting-cluster-name-kafka-exporter-7b59f7cd48-rhm8v with container log-setting-cluster-name-kafka-exporter
2022-04-02 19:16:12 [main] [32mINFO [m [PodUtils:343] Waiting for Pod log-setting-cluster-name-zookeeper-0 container zookeeper will be ready
2022-04-02 19:16:12 [main] [32mINFO [m [PodUtils:347] Pod log-setting-cluster-name-zookeeper-0 container zookeeper is ready
2022-04-02 19:16:12 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod log-setting-cluster-name-zookeeper-0 with container zookeeper
2022-04-02 19:16:13 [main] [32mINFO [m [PodUtils:343] Waiting for Pod gc-set-logging-entity-operator-6dccd5cb65-c2t98 container topic-operator will be ready
2022-04-02 19:16:13 [main] [32mINFO [m [PodUtils:347] Pod gc-set-logging-entity-operator-6dccd5cb65-c2t98 container topic-operator is ready
2022-04-02 19:16:13 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod gc-set-logging-entity-operator-6dccd5cb65-c2t98 with container topic-operator
2022-04-02 19:16:13 [main] [32mINFO [m [PodUtils:343] Waiting for Pod gc-set-logging-entity-operator-6dccd5cb65-c2t98 container user-operator will be ready
2022-04-02 19:16:13 [main] [32mINFO [m [PodUtils:347] Pod gc-set-logging-entity-operator-6dccd5cb65-c2t98 container user-operator is ready
2022-04-02 19:16:13 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod gc-set-logging-entity-operator-6dccd5cb65-c2t98 with container user-operator
2022-04-02 19:16:13 [main] [32mINFO [m [PodUtils:343] Waiting for Pod gc-set-logging-entity-operator-6dccd5cb65-c2t98 container tls-sidecar will be ready
2022-04-02 19:16:13 [main] [32mINFO [m [PodUtils:347] Pod gc-set-logging-entity-operator-6dccd5cb65-c2t98 container tls-sidecar is ready
2022-04-02 19:16:13 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod gc-set-logging-entity-operator-6dccd5cb65-c2t98 with container tls-sidecar
2022-04-02 19:16:13 [main] [32mINFO [m [PodUtils:343] Waiting for Pod gc-set-logging-kafka-0 container kafka will be ready
2022-04-02 19:16:13 [main] [32mINFO [m [PodUtils:347] Pod gc-set-logging-kafka-0 container kafka is ready
2022-04-02 19:16:13 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod gc-set-logging-kafka-0 with container kafka
2022-04-02 19:16:13 [main] [32mINFO [m [PodUtils:343] Waiting for Pod gc-set-logging-zookeeper-0 container zookeeper will be ready
2022-04-02 19:16:13 [main] [32mINFO [m [PodUtils:347] Pod gc-set-logging-zookeeper-0 container zookeeper is ready
2022-04-02 19:16:13 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod gc-set-logging-zookeeper-0 with container zookeeper
2022-04-02 19:16:14 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 19:16:14 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaLogSetting
2022-04-02 19:16:14 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1457037859-1807410062 in namespace log-setting-st
2022-04-02 19:16:14 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-540720121-259310369 in namespace log-setting-st
2022-04-02 19:16:24 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 19:16:24 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LogSettingST.testKafkaLogSetting-FINISHED
2022-04-02 19:16:24 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 19:16:24 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 19:16:24 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LogSettingST.testBridgeLogSetting-STARTED
2022-04-02 19:16:24 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 19:16:24 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge my-cluster-4c719903-bridge in namespace log-setting-st
2022-04-02 19:16:24 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: my-cluster-4c719903-bridge will have desired state: Ready
2022-04-02 19:16:46 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: my-cluster-4c719903-bridge is in desired state: Ready
2022-04-02 19:16:46 [main] [32mINFO [m [LogSettingST:392] Checking if Bridge has log level set properly
2022-04-02 19:16:46 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.subscribe.name Expected: http.openapi.operation.subscribe
2022-04-02 19:16:46 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.createConsumer.name Expected: http.openapi.operation.createConsumer
2022-04-02 19:16:46 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.createConsumer.level Expected: INFO
2022-04-02 19:16:46 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.deleteConsumer.name Expected: http.openapi.operation.deleteConsumer
2022-04-02 19:16:46 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.poll.name Expected: http.openapi.operation.poll
2022-04-02 19:16:46 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.sendToPartition.level Expected: TRACE
2022-04-02 19:16:46 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.unsubscribe.name Expected: http.openapi.operation.unsubscribe
2022-04-02 19:16:46 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.unsubscribe.level Expected: DEBUG
2022-04-02 19:16:46 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.ready.level Expected: WARN
2022-04-02 19:16:46 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.assign.name Expected: http.openapi.operation.assign
2022-04-02 19:16:46 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.seekToEnd.name Expected: http.openapi.operation.seekToEnd
2022-04-02 19:16:46 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.poll.level Expected: INFO
2022-04-02 19:16:46 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.deleteConsumer.level Expected: DEBUG
2022-04-02 19:16:46 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.subscribe.level Expected: TRACE
2022-04-02 19:16:46 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.openapi.level Expected: TRACE
2022-04-02 19:16:46 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.commit.name Expected: http.openapi.operation.commit
2022-04-02 19:16:46 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.send.level Expected: ERROR
2022-04-02 19:16:46 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.seek.name Expected: http.openapi.operation.seek
2022-04-02 19:16:46 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.healthy.level Expected: ERROR
2022-04-02 19:16:46 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.ready.name Expected: http.openapi.operation.ready
2022-04-02 19:16:46 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: test.logger.bridge.level Expected: ERROR
2022-04-02 19:16:46 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.seek.level Expected: INFO
2022-04-02 19:16:46 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.assign.level Expected: TRACE
2022-04-02 19:16:46 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.sendToPartition.name Expected: http.openapi.operation.sendToPartition
2022-04-02 19:16:46 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.send.name Expected: http.openapi.operation.send
2022-04-02 19:16:46 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.openapi.name Expected: http.openapi.operation.openapi
2022-04-02 19:16:46 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.healthy.name Expected: http.openapi.operation.healthy
2022-04-02 19:16:46 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.commit.level Expected: DEBUG
2022-04-02 19:16:46 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.seekToEnd.level Expected: WARN
2022-04-02 19:16:46 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.seekToBeginning.name Expected: http.openapi.operation.seekToBeginning
2022-04-02 19:16:46 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.seekToBeginning.level Expected: DEBUG
2022-04-02 19:16:46 [main] [32mINFO [m [LogSettingST:498] Checking deployment: my-cluster-4c719903-bridge-bridge
2022-04-02 19:16:46 [main] [32mINFO [m [LogSettingST:500] Checking container with name: my-cluster-4c719903-bridge-bridge
2022-04-02 19:16:46 [main] [32mINFO [m [LogSettingST:529] STRIMZI_GC_LOG_ENABLED=true
2022-04-02 19:16:46 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-4c719903-bridge-bridge rolling update
2022-04-02 19:17:11 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-4c719903-bridge-bridge will be ready
2022-04-02 19:17:11 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-4c719903-bridge-bridge is ready
2022-04-02 19:17:21 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-4c719903-bridge-bridge rolling update finished
2022-04-02 19:17:21 [main] [32mINFO [m [LogSettingST:498] Checking deployment: my-cluster-4c719903-bridge-bridge
2022-04-02 19:17:21 [main] [32mINFO [m [LogSettingST:500] Checking container with name: my-cluster-4c719903-bridge-bridge
2022-04-02 19:17:21 [main] [32mINFO [m [LogSettingST:529] STRIMZI_GC_LOG_ENABLED=false
2022-04-02 19:17:21 [main] [32mINFO [m [PodUtils:343] Waiting for Pod my-cluster-4c719903-bridge-bridge-64976ccdb7-cfzjw container my-cluster-4c719903-bridge-bridge will be ready
2022-04-02 19:17:21 [main] [32mINFO [m [PodUtils:347] Pod my-cluster-4c719903-bridge-bridge-64976ccdb7-cfzjw container my-cluster-4c719903-bridge-bridge is ready
2022-04-02 19:17:21 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod my-cluster-4c719903-bridge-bridge-64976ccdb7-cfzjw with container my-cluster-4c719903-bridge-bridge
2022-04-02 19:17:21 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 19:17:21 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testBridgeLogSetting
2022-04-02 19:17:21 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge my-cluster-4c719903-bridge in namespace log-setting-st
2022-04-02 19:17:31 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 19:17:31 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LogSettingST.testBridgeLogSetting-FINISHED
2022-04-02 19:17:31 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 19:17:31 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 19:17:31 [main] [32mINFO [m [ResourceManager:348] Delete all resources for LogSettingST
2022-04-02 19:17:31 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka gc-set-logging in namespace log-setting-st
2022-04-02 19:17:31 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka log-setting-cluster-name in namespace log-setting-st
2022-04-02 19:17:31 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Deployment shared-kafka-clients in namespace log-setting-st
2022-04-02 19:17:31 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace log-setting-st, for cruise control Kafka cluster log-setting-cluster-name
2022-04-02 19:18:21 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1,338.455 s - in io.strimzi.systemtest.log.LogSettingST
[[1;34mINFO[m] Running io.strimzi.systemtest.operators.FeatureGatesIsolatedST
2022-04-02 19:18:28 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-02 19:18:53 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 19:18:53 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.FeatureGatesIsolatedST.testSwitchingStrimziPodSetFeatureGateOnAndOff-STARTED
2022-04-02 19:18:53 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 19:18:53 [main] [32mINFO [m [FeatureGatesIsolatedST:270] Deploying CO with STS - SPS is disabled
2022-04-02 19:18:53 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-02 19:18:53 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-02 19:18:53 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-02 19:18:53 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 19:18:53 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-02 19:18:53 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 19:18:53 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 19:18:53 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 19:18:53 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 19:18:53 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 19:18:53 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 19:18:53 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 19:18:53 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 19:18:53 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 19:18:53 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 19:18:53 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 19:18:53 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 19:18:53 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 19:18:53 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 19:18:53 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 19:18:53 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 19:18:53 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-02 19:18:53 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 19:18:53 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 19:18:53 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 19:18:53 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 19:18:53 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 19:18:53 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 19:19:03 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 19:19:03 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 19:19:13 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 19:21:16 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7e2e5e3d
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
, extraEnvVars=[EnvVar(name=STRIMZI_FEATURE_GATES, value=-UseStrimziPodSets, valueFrom=null, additionalProperties={})]
2022-04-02 19:21:16 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-02 19:21:16 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-02 19:21:16 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-02 19:21:16 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 19:21:16 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 19:21:16 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 19:21:16 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 19:21:16 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 19:21:16 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 19:21:16 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 19:21:16 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 19:21:16 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 19:21:16 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 19:21:16 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 19:21:16 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 19:21:16 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 19:21:16 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 19:21:16 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 19:21:16 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 19:21:16 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 19:21:16 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-02 19:21:16 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 19:21:16 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 19:21:16 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-02 19:21:16 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 19:21:16 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-02 19:21:16 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 19:21:16 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 19:21:16 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 19:21:16 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-02 19:21:17 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 19:21:17 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-02 19:21:17 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-02 19:21:17 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 19:21:17 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-02 19:21:17 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 19:21:17 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-02 19:21:33 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-02 19:21:33 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-02 19:21:43 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-02 19:21:43 [main] [32mINFO [m [FeatureGatesIsolatedST:281] Deploying Kafka
2022-04-02 19:21:43 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-ed9aca39 in namespace infra-namespace
2022-04-02 19:21:43 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-ed9aca39 will have desired state: Ready
2022-04-02 19:23:08 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-ed9aca39 is in desired state: Ready
2022-04-02 19:23:08 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1151581100-216956038 in namespace infra-namespace
2022-04-02 19:23:08 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1151581100-216956038 will have desired state: Ready
2022-04-02 19:23:09 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1151581100-216956038 is in desired state: Ready
2022-04-02 19:23:09 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-02 19:23:09 [main] [32mINFO [m [ResourceManager:155] Create/Update Job producer-test-2144868143 in namespace infra-namespace
2022-04-02 19:23:09 [main] [32mINFO [m [ResourceManager:155] Create/Update Job consumer-test-1700025869 in namespace infra-namespace
2022-04-02 19:23:09 [main] [32mINFO [m [JobUtils:81] Waiting for job: producer-test-2144868143 will be in active state
2022-04-02 19:23:10 [main] [32mINFO [m [JobUtils:81] Waiting for job: consumer-test-1700025869 will be in active state
2022-04-02 19:23:10 [main] [32mINFO [m [FeatureGatesIsolatedST:304] Changing FG env variable to enable SPS
2022-04-02 19:23:10 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment strimzi-cluster-operator rolling update
2022-04-02 19:23:25 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-02 19:23:56 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-02 19:24:06 [main] [32mINFO [m [DeploymentUtils:141] Deployment strimzi-cluster-operator rolling update finished
2022-04-02 19:24:06 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-ed9aca39-zookeeper rolling update
2022-04-02 19:24:36 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-ed9aca39-zookeeper has been successfully rolled
2022-04-02 19:24:36 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-ed9aca39-zookeeper to be ready
2022-04-02 19:25:10 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-ed9aca39 will have desired state: Ready
2022-04-02 19:25:10 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-ed9aca39 is in desired state: Ready
2022-04-02 19:25:10 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-ed9aca39 is ready
2022-04-02 19:25:10 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-ed9aca39-kafka rolling update
2022-04-02 19:26:15 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-ed9aca39-kafka has been successfully rolled
2022-04-02 19:26:15 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-ed9aca39-kafka to be ready
2022-04-02 19:26:50 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-ed9aca39 will have desired state: Ready
2022-04-02 19:26:50 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-ed9aca39 is in desired state: Ready
2022-04-02 19:26:50 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-ed9aca39 is ready
2022-04-02 19:26:50 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-ed9aca39 will have desired state: Ready
2022-04-02 19:26:50 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-ed9aca39 is in desired state: Ready
2022-04-02 19:26:50 [main] [32mINFO [m [FeatureGatesIsolatedST:319] Changing FG env variable to disable again SPS
2022-04-02 19:26:50 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment strimzi-cluster-operator rolling update
2022-04-02 19:26:55 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-02 19:27:27 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-02 19:27:37 [main] [32mINFO [m [DeploymentUtils:141] Deployment strimzi-cluster-operator rolling update finished
2022-04-02 19:27:37 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-ed9aca39-zookeeper rolling update
2022-04-02 19:28:12 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-ed9aca39-zookeeper has been successfully rolled
2022-04-02 19:28:12 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-ed9aca39-zookeeper to be ready
2022-04-02 19:28:42 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-ed9aca39 will have desired state: Ready
2022-04-02 19:28:42 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-ed9aca39 is in desired state: Ready
2022-04-02 19:28:42 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-ed9aca39 is ready
2022-04-02 19:28:42 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-ed9aca39-kafka rolling update
2022-04-02 19:30:02 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-ed9aca39-kafka has been successfully rolled
2022-04-02 19:30:02 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-ed9aca39-kafka to be ready
2022-04-02 19:30:28 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-ed9aca39 will have desired state: Ready
2022-04-02 19:30:28 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-ed9aca39 is in desired state: Ready
2022-04-02 19:30:28 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-ed9aca39 is ready
2022-04-02 19:30:28 [main] [32mINFO [m [ClientUtils:61] Waiting till producer producer-test-2144868143 and consumer consumer-test-1700025869 finish
2022-04-02 19:32:19 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 19:32:19 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSwitchingStrimziPodSetFeatureGateOnAndOff
2022-04-02 19:32:19 [main] [32mINFO [m [ResourceManager:241] Delete of Job producer-test-2144868143 in namespace infra-namespace
2022-04-02 19:32:19 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Job consumer-test-1700025869 in namespace infra-namespace
2022-04-02 19:32:19 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1151581100-216956038 in namespace infra-namespace
2022-04-02 19:32:19 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-ed9aca39 in namespace infra-namespace
2022-04-02 19:32:30 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 19:32:30 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.FeatureGatesIsolatedST.testSwitchingStrimziPodSetFeatureGateOnAndOff-FINISHED
2022-04-02 19:32:30 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 19:32:30 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 19:32:30 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.FeatureGatesIsolatedST.testControlPlaneListenerFeatureGate-STARTED
2022-04-02 19:32:30 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 19:32:30 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-02 19:32:30 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-02 19:32:30 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-02 19:32:30 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 19:32:30 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-02 19:32:30 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 19:32:30 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 19:32:30 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 19:32:30 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 19:32:30 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 19:32:30 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 19:32:30 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 19:32:30 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 19:32:30 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 19:32:30 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 19:32:30 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 19:32:30 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 19:32:30 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-02 19:32:30 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 19:32:30 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 19:32:30 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 19:32:30 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 19:32:30 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 19:32:30 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 19:32:30 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 19:32:30 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 19:32:30 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 19:32:40 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 19:32:40 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 19:32:40 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 19:32:50 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 19:33:00 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7e2e5e3d
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
, extraEnvVars=[EnvVar(name=STRIMZI_FEATURE_GATES, value=-ControlPlaneListener, valueFrom=null, additionalProperties={})]
2022-04-02 19:33:00 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-02 19:33:00 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-02 19:33:01 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-02 19:33:01 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 19:33:01 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 19:33:01 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 19:33:01 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 19:33:01 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 19:33:01 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 19:33:01 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 19:33:01 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 19:33:01 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 19:33:01 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 19:33:01 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 19:33:01 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 19:33:01 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 19:33:01 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 19:33:01 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 19:33:01 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 19:33:01 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 19:33:01 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-02 19:33:01 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 19:33:01 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 19:33:01 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-02 19:33:01 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 19:33:01 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-02 19:33:01 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 19:33:01 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 19:33:01 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 19:33:01 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-02 19:33:01 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 19:33:01 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-02 19:33:01 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-02 19:33:01 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 19:33:01 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-02 19:33:01 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 19:33:01 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-02 19:33:37 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-02 19:33:37 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-02 19:33:47 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-02 19:33:47 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-9dd99d90 in namespace infra-namespace
2022-04-02 19:33:47 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-9dd99d90 will have desired state: Ready
2022-04-02 19:35:36 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-9dd99d90 is in desired state: Ready
2022-04-02 19:35:36 [main] [32mINFO [m [FeatureGatesIsolatedST:96] Check for presence of ContainerPort 9090/tcp (tcp-ctrlplane) in first Kafka pod.
2022-04-02 19:35:36 [main] [32mINFO [m [FeatureGatesIsolatedST:104] Try to send some messages to Kafka over next few minutes.
2022-04-02 19:35:36 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1201325922-334114724 in namespace infra-namespace
2022-04-02 19:35:36 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1201325922-334114724 will have desired state: Ready
2022-04-02 19:35:37 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1201325922-334114724 is in desired state: Ready
2022-04-02 19:35:37 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-02 19:35:37 [main] [32mINFO [m [ResourceManager:155] Create/Update Job producer-test-1036301408 in namespace infra-namespace
2022-04-02 19:35:37 [main] [32mINFO [m [JobUtils:81] Waiting for job: producer-test-1036301408 will be in active state
2022-04-02 19:35:38 [main] [32mINFO [m [ResourceManager:155] Create/Update Job consumer-test-247897549 in namespace infra-namespace
2022-04-02 19:35:38 [main] [32mINFO [m [JobUtils:81] Waiting for job: consumer-test-247897549 will be in active state
2022-04-02 19:35:38 [main] [32mINFO [m [JobUtils:81] Waiting for job: consumer-test-247897549 will be in active state
2022-04-02 19:35:38 [main] [32mINFO [m [FeatureGatesIsolatedST:127] Delete first found Kafka broker pod.
2022-04-02 19:35:38 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-9dd99d90-zookeeper to be ready
2022-04-02 19:35:48 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-9dd99d90 will have desired state: Ready
2022-04-02 19:35:48 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-9dd99d90 is in desired state: Ready
2022-04-02 19:35:48 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-9dd99d90 is ready
2022-04-02 19:35:48 [main] [32mINFO [m [FeatureGatesIsolatedST:131] Force Rolling Update of Kafka via annotation.
2022-04-02 19:35:48 [main] [32mINFO [m [FeatureGatesIsolatedST:139] Wait for next reconciliation to happen.
2022-04-02 19:35:48 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-9dd99d90-zookeeper rolling update
2022-04-02 19:37:23 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-9dd99d90-zookeeper has been successfully rolled
2022-04-02 19:37:23 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-9dd99d90-zookeeper to be ready
2022-04-02 19:37:51 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-9dd99d90 will have desired state: Ready
2022-04-02 19:37:51 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-9dd99d90 is in desired state: Ready
2022-04-02 19:37:51 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-9dd99d90 is ready
2022-04-02 19:37:51 [main] [32mINFO [m [FeatureGatesIsolatedST:142] Waiting for clients to finish sending/receiving messages.
2022-04-02 19:37:51 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:producer-test-1036301408 to finished
2022-04-02 19:38:18 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:consumer-test-247897549 to finished
2022-04-02 19:38:23 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 19:38:23 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testControlPlaneListenerFeatureGate
2022-04-02 19:38:23 [main] [32mINFO [m [ResourceManager:241] Delete of Job producer-test-1036301408 in namespace infra-namespace
2022-04-02 19:38:23 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job consumer-test-247897549 in namespace infra-namespace
2022-04-02 19:38:23 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1201325922-334114724 in namespace infra-namespace
2022-04-02 19:38:23 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-9dd99d90 in namespace infra-namespace
2022-04-02 19:38:33 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 19:38:33 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.FeatureGatesIsolatedST.testControlPlaneListenerFeatureGate-FINISHED
2022-04-02 19:38:33 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 19:38:33 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 19:38:33 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.FeatureGatesIsolatedST.testStrimziPodSetsFeatureGate-STARTED
2022-04-02 19:38:33 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 19:38:33 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-02 19:38:33 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-02 19:38:33 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-02 19:38:33 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 19:38:33 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-02 19:38:33 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 19:38:33 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 19:38:33 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 19:38:33 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 19:38:33 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 19:38:33 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 19:38:33 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 19:38:33 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 19:38:33 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 19:38:33 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 19:38:33 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 19:38:33 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 19:38:33 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 19:38:33 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 19:38:33 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 19:38:33 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 19:38:33 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 19:38:33 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 19:38:34 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-02 19:38:34 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 19:38:43 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 19:38:43 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 19:38:43 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 19:38:43 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 19:38:43 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 19:38:53 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 19:38:59 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7e2e5e3d
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
, extraEnvVars=[EnvVar(name=STRIMZI_FEATURE_GATES, value=+UseStrimziPodSets, valueFrom=null, additionalProperties={})]
2022-04-02 19:38:59 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-02 19:38:59 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-02 19:38:59 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-02 19:38:59 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 19:38:59 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 19:38:59 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 19:38:59 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 19:38:59 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 19:38:59 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 19:38:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 19:38:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 19:38:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 19:38:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 19:38:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 19:38:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 19:38:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 19:38:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 19:38:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 19:38:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 19:38:59 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 19:38:59 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-02 19:38:59 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 19:38:59 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 19:38:59 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-02 19:38:59 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 19:38:59 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-02 19:38:59 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 19:38:59 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 19:38:59 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 19:38:59 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-02 19:38:59 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 19:38:59 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-02 19:38:59 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-02 19:38:59 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 19:38:59 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-02 19:38:59 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 19:38:59 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-02 19:39:29 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-02 19:39:29 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-02 19:39:39 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-02 19:39:39 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-60a19b17 in namespace infra-namespace
2022-04-02 19:39:39 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-60a19b17 will have desired state: Ready
2022-04-02 19:41:51 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-60a19b17 is in desired state: Ready
2022-04-02 19:41:51 [main] [32mINFO [m [FeatureGatesIsolatedST:182] Try to send some messages to Kafka over next few minutes.
2022-04-02 19:41:51 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-354012227-1286349046 in namespace infra-namespace
2022-04-02 19:41:51 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-354012227-1286349046 will have desired state: Ready
2022-04-02 19:41:52 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-354012227-1286349046 is in desired state: Ready
2022-04-02 19:41:52 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-02 19:41:52 [main] [32mINFO [m [ResourceManager:155] Create/Update Job producer-test-840500578 in namespace infra-namespace
2022-04-02 19:41:52 [main] [32mINFO [m [JobUtils:81] Waiting for job: producer-test-840500578 will be in active state
2022-04-02 19:41:53 [main] [32mINFO [m [ResourceManager:155] Create/Update Job consumer-test-1223893525 in namespace infra-namespace
2022-04-02 19:41:53 [main] [32mINFO [m [JobUtils:81] Waiting for job: consumer-test-1223893525 will be in active state
2022-04-02 19:41:54 [main] [32mINFO [m [JobUtils:81] Waiting for job: consumer-test-1223893525 will be in active state
2022-04-02 19:41:54 [main] [32mINFO [m [FeatureGatesIsolatedST:207] Delete first found ZooKeeper pod my-cluster-60a19b17-zookeeper-0
2022-04-02 19:41:54 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-60a19b17-zookeeper to be ready
2022-04-02 19:42:26 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-60a19b17 will have desired state: Ready
2022-04-02 19:42:26 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-60a19b17 is in desired state: Ready
2022-04-02 19:42:26 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-60a19b17 is ready
2022-04-02 19:42:26 [main] [32mINFO [m [FeatureGatesIsolatedST:213] Delete first found Kafka broker pod my-cluster-60a19b17-kafka-0
2022-04-02 19:42:26 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-60a19b17-kafka to be ready
2022-04-02 19:43:08 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-60a19b17 will have desired state: Ready
2022-04-02 19:43:08 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-60a19b17 is in desired state: Ready
2022-04-02 19:43:08 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-60a19b17 is ready
2022-04-02 19:43:08 [main] [32mINFO [m [FeatureGatesIsolatedST:218] Force Rolling Update of ZooKeeper via annotation.
2022-04-02 19:43:08 [main] [32mINFO [m [FeatureGatesIsolatedST:228] Wait for next reconciliation to happen.
2022-04-02 19:43:08 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-60a19b17-zookeeper rolling update
2022-04-02 19:44:53 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-60a19b17-zookeeper has been successfully rolled
2022-04-02 19:44:53 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-60a19b17-zookeeper to be ready
2022-04-02 19:45:17 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-60a19b17 will have desired state: Ready
2022-04-02 19:45:17 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-60a19b17 is in desired state: Ready
2022-04-02 19:45:17 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-60a19b17 is ready
2022-04-02 19:45:17 [main] [32mINFO [m [FeatureGatesIsolatedST:232] Force Rolling Update of Kafka via annotation.
2022-04-02 19:45:17 [main] [32mINFO [m [FeatureGatesIsolatedST:242] Wait for next reconciliation to happen.
2022-04-02 19:45:17 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-60a19b17-kafka rolling update
2022-04-02 19:46:47 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-60a19b17-kafka has been successfully rolled
2022-04-02 19:46:47 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-60a19b17-kafka to be ready
2022-04-02 19:47:18 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-60a19b17 will have desired state: Ready
2022-04-02 19:47:18 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-60a19b17 is in desired state: Ready
2022-04-02 19:47:18 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-60a19b17 is ready
2022-04-02 19:47:18 [main] [32mINFO [m [FeatureGatesIsolatedST:245] Waiting for clients to finish sending/receiving messages.
2022-04-02 19:47:18 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:producer-test-840500578 to finished
2022-04-02 19:47:23 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:consumer-test-1223893525 to finished
2022-04-02 19:47:28 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 19:47:28 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testStrimziPodSetsFeatureGate
2022-04-02 19:47:28 [main] [32mINFO [m [ResourceManager:241] Delete of Job producer-test-840500578 in namespace infra-namespace
2022-04-02 19:47:28 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Job consumer-test-1223893525 in namespace infra-namespace
2022-04-02 19:47:28 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-354012227-1286349046 in namespace infra-namespace
2022-04-02 19:47:28 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-60a19b17 in namespace infra-namespace
2022-04-02 19:47:38 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 19:47:38 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.FeatureGatesIsolatedST.testStrimziPodSetsFeatureGate-FINISHED
2022-04-02 19:47:38 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 19:47:38 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 19:47:38 [main] [32mINFO [m [ResourceManager:346] In context FeatureGatesIsolatedST is everything deleted.
2022-04-02 19:47:38 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1,750.168 s - in io.strimzi.systemtest.operators.FeatureGatesIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.operators.NamespaceRbacScopeOperatorIsolatedST
2022-04-02 19:47:38 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-02 19:48:03 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 19:48:03 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.NamespaceRbacScopeOperatorIsolatedST.testNamespacedRbacScopeDeploysRoles-STARTED
2022-04-02 19:48:03 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 19:48:03 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-02 19:48:03 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-02 19:48:03 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-02 19:48:03 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 19:48:03 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-02 19:48:03 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 19:48:03 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 19:48:03 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 19:48:03 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 19:48:03 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 19:48:03 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 19:48:03 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 19:48:03 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 19:48:03 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 19:48:03 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 19:48:03 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 19:48:03 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 19:48:03 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 19:48:03 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 19:48:03 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 19:48:03 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 19:48:03 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 19:48:03 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 19:48:03 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-02 19:48:03 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 19:48:03 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 19:48:03 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 19:48:13 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 19:48:13 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 19:48:13 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 19:48:23 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 19:48:29 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7e2e5e3d
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
, extraEnvVars=[EnvVar(name=STRIMZI_RBAC_SCOPE, value=NAMESPACE, valueFrom=null, additionalProperties={})]
2022-04-02 19:48:29 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-02 19:48:29 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-02 19:48:29 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-02 19:48:29 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 19:48:29 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-ClusterRole-strimzi-cluster-operator-role.yaml
2022-04-02 19:48:29 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-cluster-operator-namespaced in namespace infra-namespace
2022-04-02 19:48:29 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRole-strimzi-cluster-operator-role.yaml
2022-04-02 19:48:29 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-cluster-operator-global in namespace infra-namespace
2022-04-02 19:48:29 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRole-strimzi-kafka-broker.yaml
2022-04-02 19:48:29 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-kafka-broker in namespace infra-namespace
2022-04-02 19:48:29 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-ClusterRole-strimzi-entity-operator.yaml
2022-04-02 19:48:29 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-entity-operator in namespace infra-namespace
2022-04-02 19:48:29 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRole-strimzi-kafka-client.yaml
2022-04-02 19:48:29 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-kafka-client in namespace infra-namespace
2022-04-02 19:48:29 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 19:48:29 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 19:48:29 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 19:48:29 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 19:48:29 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 19:48:29 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 19:48:29 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 19:48:29 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 19:48:29 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 19:48:29 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 19:48:29 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 19:48:29 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-02 19:48:29 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 19:48:29 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 19:48:29 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-02 19:48:29 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 19:48:29 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-02 19:48:29 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 19:48:29 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml
2022-04-02 19:48:29 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /tmp/020-Role-strimzi-cluster-operator5290771750969913668.yaml in namespace infra-namespace
2022-04-02 19:48:29 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 19:48:29 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml
2022-04-02 19:48:29 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /tmp/031-Role-strimzi-cluster-operator-entity-operator-delegation811293614773816487.yaml in namespace infra-namespace
2022-04-02 19:48:29 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 19:48:29 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 19:48:29 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-02 19:48:45 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-02 19:48:45 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-02 19:48:55 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-02 19:48:55 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-5f2b131f in namespace infra-namespace
2022-04-02 19:48:55 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-5f2b131f will have desired state: Ready
2022-04-02 19:50:19 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-5f2b131f is in desired state: Ready
2022-04-02 19:50:19 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-5f2b131f will have desired state: Ready
2022-04-02 19:50:19 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-5f2b131f is in desired state: Ready
2022-04-02 19:50:19 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 19:50:19 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testNamespacedRbacScopeDeploysRoles
2022-04-02 19:50:19 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-5f2b131f in namespace infra-namespace
2022-04-02 19:50:29 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 19:50:29 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.NamespaceRbacScopeOperatorIsolatedST.testNamespacedRbacScopeDeploysRoles-FINISHED
2022-04-02 19:50:29 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 19:50:29 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 19:50:29 [main] [32mINFO [m [ResourceManager:346] In context NamespaceRbacScopeOperatorIsolatedST is everything deleted.
2022-04-02 19:50:29 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 170.73 s - in io.strimzi.systemtest.operators.NamespaceRbacScopeOperatorIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.operators.RecoveryIsolatedST
2022-04-02 19:50:29 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-02 19:50:54 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 19:50:54 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromZookeeperMetricsConfigDeletion-STARTED
2022-04-02 19:50:54 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 19:50:54 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-02 19:50:54 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-02 19:50:54 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-02 19:50:54 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 19:50:54 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-02 19:50:54 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 19:50:54 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 19:50:54 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-kafka-client in namespace infra-namespace
2022-04-02 19:50:54 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 19:50:54 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 19:50:54 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-cluster-operator-global in namespace infra-namespace
2022-04-02 19:50:54 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 19:50:54 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 19:50:54 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 19:50:54 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-entity-operator in namespace infra-namespace
2022-04-02 19:50:54 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 19:50:54 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-kafka-broker in namespace infra-namespace
2022-04-02 19:50:54 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-cluster-operator-namespaced in namespace infra-namespace
2022-04-02 19:50:54 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 19:50:54 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 19:50:54 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 19:51:04 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 19:51:04 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 19:51:04 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 19:51:04 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 19:51:04 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 19:51:04 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 19:51:04 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 19:51:14 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 19:51:19 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7e2e5e3d
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-02 19:51:19 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-02 19:51:19 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-02 19:51:19 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-02 19:51:19 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 19:51:19 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 19:51:19 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 19:51:19 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 19:51:19 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 19:51:19 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 19:51:19 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 19:51:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 19:51:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 19:51:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 19:51:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 19:51:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 19:51:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 19:51:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 19:51:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 19:51:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 19:51:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 19:51:20 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-02 19:51:20 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 19:51:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 19:51:20 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-02 19:51:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 19:51:20 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-02 19:51:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 19:51:20 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 19:51:20 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 19:51:20 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-02 19:51:20 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 19:51:20 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 19:51:20 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-02 19:51:44 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-02 19:51:44 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-02 19:51:54 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-02 19:51:54 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-489791076 in namespace infra-namespace
2022-04-02 19:51:54 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-489791076 will have desired state: Ready
2022-04-02 19:53:52 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-489791076 is in desired state: Ready
2022-04-02 19:53:52 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-489791076 in namespace infra-namespace
2022-04-02 19:53:52 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-489791076 will be ready
2022-04-02 19:53:53 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-489791076 is ready
2022-04-02 19:53:53 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-489791076 in namespace infra-namespace
2022-04-02 19:53:53 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-489791076 will have desired state: Ready
2022-04-02 19:54:17 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-489791076 is in desired state: Ready
2022-04-02 19:54:17 [main] [32mINFO [m [RecoveryIsolatedST:191] Running deleteZookeeperMetricsConfig with cluster recovery-cluster-489791076
2022-04-02 19:54:17 [main] [32mINFO [m [RecoveryIsolatedST:199] Waiting for creation recovery-cluster-489791076-zookeeper-config
2022-04-02 19:54:17 [main] [32mINFO [m [ConfigMapUtils:30] Waiting for config map recovery-cluster-489791076-zookeeper-config-8dc15857-8eed-4306-84b5-153a76dc21d9 recovery in namespace infra-namespace
2022-04-02 19:54:27 [main] [32mINFO [m [ConfigMapUtils:33] Config map recovery-cluster-489791076-zookeeper-config was recovered
2022-04-02 19:54:27 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 19:54:27 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromZookeeperMetricsConfigDeletion
2022-04-02 19:54:27 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-489791076 in namespace infra-namespace
2022-04-02 19:54:27 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-489791076 in namespace infra-namespace
2022-04-02 19:54:27 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-489791076 in namespace infra-namespace
2022-04-02 19:55:07 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 19:55:07 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromZookeeperMetricsConfigDeletion-FINISHED
2022-04-02 19:55:07 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 19:55:07 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 19:55:07 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaBridgeServiceDeletion-STARTED
2022-04-02 19:55:07 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 19:55:07 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-02 19:55:07 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-02 19:55:07 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-02 19:55:07 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 19:55:07 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-02 19:55:07 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 19:55:07 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 19:55:07 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 19:55:07 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 19:55:07 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 19:55:07 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 19:55:07 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 19:55:07 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 19:55:07 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 19:55:07 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 19:55:07 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 19:55:07 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 19:55:07 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 19:55:07 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 19:55:07 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 19:55:07 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 19:55:07 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 19:55:07 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 19:55:07 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 19:55:17 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 19:55:17 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 19:55:17 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 19:55:17 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 19:55:27 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 19:55:32 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7e2e5e3d
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-02 19:55:32 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-02 19:55:32 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-02 19:55:32 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-02 19:55:32 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 19:55:32 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 19:55:32 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 19:55:32 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 19:55:32 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 19:55:32 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 19:55:32 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 19:55:33 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 19:55:33 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 19:55:33 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 19:55:33 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 19:55:33 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 19:55:33 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 19:55:33 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 19:55:33 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 19:55:33 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 19:55:33 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 19:55:33 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-02 19:55:33 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 19:55:33 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 19:55:33 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-02 19:55:33 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 19:55:33 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-02 19:55:33 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 19:55:33 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 19:55:33 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 19:55:33 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-02 19:55:33 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 19:55:33 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 19:55:33 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-02 19:55:54 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-02 19:55:54 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-02 19:56:04 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-02 19:56:04 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-1884480914 in namespace infra-namespace
2022-04-02 19:56:04 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-1884480914 will have desired state: Ready
2022-04-02 19:58:21 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-1884480914 is in desired state: Ready
2022-04-02 19:58:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-1884480914 in namespace infra-namespace
2022-04-02 19:58:21 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-1884480914 will be ready
2022-04-02 19:58:22 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-1884480914 is ready
2022-04-02 19:58:22 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-1884480914 in namespace infra-namespace
2022-04-02 19:58:22 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-1884480914 will have desired state: Ready
2022-04-02 19:58:43 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-1884480914 is in desired state: Ready
2022-04-02 19:58:43 [main] [32mINFO [m [RecoveryIsolatedST:222] Running deleteKafkaBridgeService with cluster recovery-cluster-1884480914
2022-04-02 19:58:44 [main] [32mINFO [m [RecoveryIsolatedST:227] Waiting for service recovery-cluster-1884480914-bridge-service recovery
2022-04-02 19:58:44 [main] [32mINFO [m [ServiceUtils:58] Waiting when Service recovery-cluster-1884480914-bridge-service-cf89b4cc-cf1a-4ad0-b6b1-9bad4538bcda in namespace infra-namespace will be recovered
2022-04-02 19:59:10 [main] [32mINFO [m [ServiceUtils:62] recovery-cluster-1884480914-bridge-service in namespace infra-namespace is recovered
2022-04-02 19:59:10 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 19:59:10 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromKafkaBridgeServiceDeletion
2022-04-02 19:59:10 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-1884480914 in namespace infra-namespace
2022-04-02 19:59:10 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-1884480914 in namespace infra-namespace
2022-04-02 19:59:10 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-1884480914 in namespace infra-namespace
2022-04-02 20:00:10 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 20:00:10 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaBridgeServiceDeletion-FINISHED
2022-04-02 20:00:10 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 20:00:10 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 20:00:10 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaHeadlessServiceDeletion-STARTED
2022-04-02 20:00:10 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 20:00:10 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-02 20:00:10 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-02 20:00:10 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-02 20:00:10 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 20:00:10 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-02 20:00:10 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 20:00:10 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:00:10 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 20:00:10 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 20:00:10 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 20:00:10 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 20:00:10 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 20:00:10 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 20:00:10 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:00:10 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 20:00:10 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 20:00:10 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 20:00:10 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:00:10 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 20:00:10 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 20:00:20 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 20:00:20 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 20:00:20 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 20:00:20 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 20:00:20 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 20:00:20 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:00:20 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 20:00:20 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 20:00:30 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 20:00:35 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7e2e5e3d
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-02 20:00:35 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-02 20:00:35 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-02 20:00:35 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-02 20:00:35 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:00:35 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 20:00:35 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 20:00:35 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 20:00:35 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 20:00:35 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 20:00:35 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 20:00:36 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 20:00:36 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 20:00:36 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 20:00:36 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 20:00:36 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 20:00:36 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 20:00:36 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 20:00:36 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 20:00:36 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 20:00:36 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:00:36 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-02 20:00:36 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 20:00:36 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 20:00:36 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-02 20:00:36 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 20:00:36 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-02 20:00:36 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 20:00:36 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 20:00:36 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:00:36 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-02 20:00:36 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 20:00:36 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:00:36 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-02 20:01:11 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-02 20:01:11 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-02 20:01:21 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-02 20:01:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-792158236 in namespace infra-namespace
2022-04-02 20:01:21 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-792158236 will have desired state: Ready
2022-04-02 20:02:47 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-792158236 is in desired state: Ready
2022-04-02 20:02:47 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-792158236 in namespace infra-namespace
2022-04-02 20:02:47 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-792158236 will be ready
2022-04-02 20:02:49 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-792158236 is ready
2022-04-02 20:02:49 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-792158236 in namespace infra-namespace
2022-04-02 20:02:49 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-792158236 will have desired state: Ready
2022-04-02 20:03:14 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-792158236 is in desired state: Ready
2022-04-02 20:03:14 [main] [32mINFO [m [RecoveryIsolatedST:143] Running deleteKafkaHeadlessService with cluster recovery-cluster-792158236
2022-04-02 20:03:14 [main] [32mINFO [m [RecoveryIsolatedST:150] Waiting for creation recovery-cluster-792158236-kafka-brokers
2022-04-02 20:03:14 [main] [32mINFO [m [ServiceUtils:58] Waiting when Service recovery-cluster-792158236-kafka-brokers-49eaeac6-fe7b-42b7-8a34-e92b1cf81084 in namespace infra-namespace will be recovered
2022-04-02 20:03:45 [main] [32mINFO [m [ServiceUtils:62] recovery-cluster-792158236-kafka-brokers in namespace infra-namespace is recovered
2022-04-02 20:03:45 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 20:03:45 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromKafkaHeadlessServiceDeletion
2022-04-02 20:03:45 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-792158236 in namespace infra-namespace
2022-04-02 20:03:45 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-792158236 in namespace infra-namespace
2022-04-02 20:03:45 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-792158236 in namespace infra-namespace
2022-04-02 20:04:35 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 20:04:35 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaHeadlessServiceDeletion-FINISHED
2022-04-02 20:04:35 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 20:04:35 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 20:04:35 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaStatefulSetDeletion-STARTED
2022-04-02 20:04:35 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 20:04:35 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-02 20:04:35 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-02 20:04:35 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-02 20:04:35 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 20:04:35 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-02 20:04:35 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 20:04:35 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 20:04:35 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:04:35 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 20:04:35 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 20:04:35 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 20:04:35 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 20:04:35 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 20:04:35 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 20:04:35 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 20:04:35 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 20:04:35 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:04:35 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 20:04:35 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 20:04:35 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 20:04:35 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:04:35 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 20:04:35 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 20:04:35 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 20:04:45 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 20:04:45 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:04:45 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 20:04:45 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 20:04:55 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 20:05:00 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7e2e5e3d
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-02 20:05:00 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-02 20:05:00 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-02 20:05:00 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-02 20:05:00 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:05:00 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 20:05:00 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 20:05:00 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 20:05:00 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 20:05:00 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 20:05:00 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 20:05:00 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 20:05:00 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 20:05:00 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 20:05:00 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 20:05:00 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 20:05:01 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 20:05:01 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 20:05:01 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 20:05:01 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 20:05:01 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:05:01 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-02 20:05:01 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 20:05:01 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 20:05:01 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-02 20:05:01 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 20:05:01 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-02 20:05:01 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 20:05:01 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 20:05:01 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:05:01 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-02 20:05:01 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 20:05:01 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:05:01 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-02 20:05:31 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-02 20:05:31 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-02 20:05:41 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-02 20:05:41 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-1042494046 in namespace infra-namespace
2022-04-02 20:05:41 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-1042494046 will have desired state: Ready
2022-04-02 20:07:30 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-1042494046 is in desired state: Ready
2022-04-02 20:07:30 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-1042494046 in namespace infra-namespace
2022-04-02 20:07:30 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-1042494046 will be ready
2022-04-02 20:07:32 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-1042494046 is ready
2022-04-02 20:07:32 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-1042494046 in namespace infra-namespace
2022-04-02 20:07:32 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-1042494046 will have desired state: Ready
2022-04-02 20:07:57 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-1042494046 is in desired state: Ready
2022-04-02 20:07:57 [main] [32mINFO [m [PodUtils:121] Waiting when all Pods with prefix recovery-cluster-1042494046-kafka will be deleted
2022-04-02 20:07:57 [main] [32mINFO [m [PodUtils:154] Waiting when Pod recovery-cluster-1042494046-kafka-0 will be deleted
2022-04-02 20:08:12 [main] [32mINFO [m [PodUtils:171] Pod recovery-cluster-1042494046-kafka-0 deleted
2022-04-02 20:08:12 [main] [32mINFO [m [PodUtils:154] Waiting when Pod recovery-cluster-1042494046-kafka-1 will be deleted
2022-04-02 20:08:23 [main] [32mINFO [m [PodUtils:171] Pod recovery-cluster-1042494046-kafka-1 deleted
2022-04-02 20:08:23 [main] [32mINFO [m [PodUtils:154] Waiting when Pod recovery-cluster-1042494046-kafka-2 will be deleted
2022-04-02 20:08:23 [main] [32mINFO [m [PodUtils:171] Pod recovery-cluster-1042494046-kafka-2 deleted
2022-04-02 20:08:23 [main] [32mINFO [m [RecoveryIsolatedST:90] Waiting for recovery recovery-cluster-1042494046-kafka
2022-04-02 20:08:23 [main] [32mINFO [m [StatefulSetUtils:73] Waiting for StatefulSet recovery-cluster-1042494046-kafka-2d970155-3c09-4c74-8aea-c3f8e3d13923 recovery in namespace infra-namespace
2022-04-02 20:08:35 [main] [32mINFO [m [StatefulSetUtils:76] StatefulSet recovery-cluster-1042494046-kafka was recovered
2022-04-02 20:08:35 [main] [32mINFO [m [StatefulSetUtils:39] Waiting for StatefulSet recovery-cluster-1042494046-kafka to be ready
2022-04-02 20:08:59 [main] [32mINFO [m [StatefulSetUtils:44] Waiting for 3 Pod(s) of StatefulSet recovery-cluster-1042494046-kafka to be ready
2022-04-02 20:09:09 [main] [32mINFO [m [StatefulSetUtils:47] StatefulSet recovery-cluster-1042494046-kafka is ready
2022-04-02 20:09:09 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 20:09:09 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromKafkaStatefulSetDeletion
2022-04-02 20:09:09 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-1042494046 in namespace infra-namespace
2022-04-02 20:09:09 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-1042494046 in namespace infra-namespace
2022-04-02 20:09:09 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-1042494046 in namespace infra-namespace
2022-04-02 20:09:49 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 20:09:49 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaStatefulSetDeletion-FINISHED
2022-04-02 20:09:49 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 20:09:49 [main] [32mINFO [m [StrimziPodSetTestCondition:23] According to STRIMZI_FEATURE_GATES env variable with value: , the StatefulSets are used, skipping this StrimziPodSet related test
2022-04-02 20:09:49 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 20:09:49 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromEntityOperatorDeletion-STARTED
2022-04-02 20:09:49 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 20:09:49 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-02 20:09:49 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-02 20:09:49 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-02 20:09:49 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 20:09:49 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-02 20:09:49 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 20:09:49 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 20:09:49 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 20:09:49 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 20:09:49 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 20:09:49 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:09:49 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:09:49 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 20:09:49 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 20:09:49 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 20:09:49 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:09:49 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 20:09:49 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 20:09:49 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:09:49 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 20:09:59 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 20:09:59 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 20:09:59 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 20:09:59 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 20:09:59 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 20:09:59 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 20:09:59 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 20:09:59 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 20:10:09 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 20:10:15 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7e2e5e3d
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-02 20:10:15 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-02 20:10:15 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-02 20:10:15 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-02 20:10:15 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:10:15 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 20:10:15 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 20:10:15 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 20:10:15 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 20:10:15 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 20:10:15 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 20:10:15 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 20:10:15 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 20:10:15 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 20:10:15 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 20:10:15 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 20:10:15 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 20:10:15 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 20:10:15 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 20:10:15 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 20:10:15 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:10:15 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-02 20:10:15 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 20:10:15 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 20:10:15 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-02 20:10:15 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 20:10:15 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-02 20:10:15 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 20:10:15 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 20:10:15 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:10:15 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-02 20:10:15 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 20:10:15 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:10:15 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-02 20:10:36 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-02 20:10:36 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-02 20:10:46 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-02 20:10:46 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-1491257461 in namespace infra-namespace
2022-04-02 20:10:46 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-1491257461 will have desired state: Ready
2022-04-02 20:13:09 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-1491257461 is in desired state: Ready
2022-04-02 20:13:09 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-1491257461 in namespace infra-namespace
2022-04-02 20:13:09 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-1491257461 will be ready
2022-04-02 20:13:11 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-1491257461 is ready
2022-04-02 20:13:11 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-1491257461 in namespace infra-namespace
2022-04-02 20:13:11 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-1491257461 will have desired state: Ready
2022-04-02 20:13:35 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-1491257461 is in desired state: Ready
2022-04-02 20:13:35 [main] [32mINFO [m [RecoveryIsolatedST:64] Running testRecoveryFromEntityOperatorDeletion with cluster recovery-cluster-1491257461
2022-04-02 20:13:35 [main] [32mINFO [m [PodUtils:121] Waiting when all Pods with prefix recovery-cluster-1491257461-entity-operator will be deleted
2022-04-02 20:13:35 [main] [32mINFO [m [PodUtils:154] Waiting when Pod recovery-cluster-1491257461-entity-operator-5c4d4cfc5f-s7rk5 will be deleted
2022-04-02 20:13:45 [main] [32mINFO [m [PodUtils:171] Pod recovery-cluster-1491257461-entity-operator-5c4d4cfc5f-s7rk5 deleted
2022-04-02 20:13:45 [main] [32mINFO [m [RecoveryIsolatedST:72] Waiting for recovery recovery-cluster-1491257461-entity-operator
2022-04-02 20:13:45 [main] [32mINFO [m [DeploymentUtils:154] Waiting for Deployment recovery-cluster-1491257461-entity-operator-abe5b241-6b39-4f82-ac2f-95d3c6ada8e3 recovery in namespace infra-namespace
2022-04-02 20:13:54 [main] [32mINFO [m [DeploymentUtils:157] Deployment recovery-cluster-1491257461-entity-operator was recovered
2022-04-02 20:13:54 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: recovery-cluster-1491257461-entity-operator will be ready
2022-04-02 20:14:25 [main] [32mINFO [m [DeploymentUtils:168] Deployment: recovery-cluster-1491257461-entity-operator is ready
2022-04-02 20:14:25 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment recovery-cluster-1491257461-entity-operator to be ready
2022-04-02 20:14:35 [main] [32mINFO [m [DeploymentUtils:197] Deployment recovery-cluster-1491257461-entity-operator is ready
2022-04-02 20:14:35 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 20:14:35 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromEntityOperatorDeletion
2022-04-02 20:14:35 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-1491257461 in namespace infra-namespace
2022-04-02 20:14:35 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-1491257461 in namespace infra-namespace
2022-04-02 20:14:35 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-1491257461 in namespace infra-namespace
2022-04-02 20:15:25 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 20:15:25 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromEntityOperatorDeletion-FINISHED
2022-04-02 20:15:25 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 20:15:25 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 20:15:25 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaBridgeDeploymentDeletion-STARTED
2022-04-02 20:15:25 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 20:15:25 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-02 20:15:25 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-02 20:15:25 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-02 20:15:25 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 20:15:25 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-02 20:15:25 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 20:15:25 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 20:15:25 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 20:15:25 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 20:15:25 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 20:15:25 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 20:15:25 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:15:25 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:15:25 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:15:25 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 20:15:25 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 20:15:25 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 20:15:25 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 20:15:25 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 20:15:25 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 20:15:25 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 20:15:25 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:15:25 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 20:15:35 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 20:15:35 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 20:15:35 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 20:15:35 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 20:15:35 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 20:15:45 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 20:15:51 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7e2e5e3d
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-02 20:15:51 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-02 20:15:51 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-02 20:15:51 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-02 20:15:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:15:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 20:15:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 20:15:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 20:15:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 20:15:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 20:15:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 20:15:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 20:15:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 20:15:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 20:15:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 20:15:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 20:15:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 20:15:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 20:15:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 20:15:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 20:15:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:15:51 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-02 20:15:51 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 20:15:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 20:15:51 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-02 20:15:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 20:15:51 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-02 20:15:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 20:15:51 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 20:15:51 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:15:51 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-02 20:15:51 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 20:15:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:15:51 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-02 20:16:17 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-02 20:16:17 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-02 20:16:28 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-02 20:16:28 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-1653447044 in namespace infra-namespace
2022-04-02 20:16:28 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-1653447044 will have desired state: Ready
2022-04-02 20:18:47 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-1653447044 is in desired state: Ready
2022-04-02 20:18:47 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-1653447044 in namespace infra-namespace
2022-04-02 20:18:47 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-1653447044 will be ready
2022-04-02 20:18:49 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-1653447044 is ready
2022-04-02 20:18:49 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-1653447044 in namespace infra-namespace
2022-04-02 20:18:49 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-1653447044 will have desired state: Ready
2022-04-02 20:19:07 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-1653447044 is in desired state: Ready
2022-04-02 20:19:07 [main] [32mINFO [m [RecoveryIsolatedST:206] Running deleteKafkaBridgeDeployment with cluster recovery-cluster-1653447044
2022-04-02 20:19:07 [main] [32mINFO [m [PodUtils:121] Waiting when all Pods with prefix recovery-cluster-1653447044-bridge will be deleted
2022-04-02 20:19:07 [main] [32mINFO [m [PodUtils:154] Waiting when Pod recovery-cluster-1653447044-bridge-7d6b8b68b9-68n2d will be deleted
2022-04-02 20:19:12 [main] [32mINFO [m [PodUtils:171] Pod recovery-cluster-1653447044-bridge-7d6b8b68b9-68n2d deleted
2022-04-02 20:19:12 [main] [32mINFO [m [RecoveryIsolatedST:215] Waiting for deployment recovery-cluster-1653447044-bridge recovery
2022-04-02 20:19:12 [main] [32mINFO [m [DeploymentUtils:154] Waiting for Deployment recovery-cluster-1653447044-bridge-e47fa0ff-023f-4df7-b6ee-1dff4ed39970 recovery in namespace infra-namespace
2022-04-02 20:19:28 [main] [32mINFO [m [DeploymentUtils:157] Deployment recovery-cluster-1653447044-bridge was recovered
2022-04-02 20:19:28 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 20:19:28 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromKafkaBridgeDeploymentDeletion
2022-04-02 20:19:28 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-1653447044 in namespace infra-namespace
2022-04-02 20:19:28 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-1653447044 in namespace infra-namespace
2022-04-02 20:19:28 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-1653447044 in namespace infra-namespace
2022-04-02 20:20:08 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 20:20:08 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaBridgeDeploymentDeletion-FINISHED
2022-04-02 20:20:08 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 20:20:08 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 20:20:08 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaServiceDeletion-STARTED
2022-04-02 20:20:08 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 20:20:08 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-02 20:20:08 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-02 20:20:08 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-02 20:20:08 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 20:20:08 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-02 20:20:08 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 20:20:08 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 20:20:08 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 20:20:08 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 20:20:08 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:20:08 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 20:20:08 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 20:20:08 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 20:20:08 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:20:08 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 20:20:08 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 20:20:08 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 20:20:08 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:20:08 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 20:20:08 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 20:20:18 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 20:20:18 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 20:20:18 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 20:20:18 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 20:20:18 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:20:18 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 20:20:18 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 20:20:18 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 20:20:28 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 20:20:34 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7e2e5e3d
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-02 20:20:34 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-02 20:20:34 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-02 20:20:34 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-02 20:20:34 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:20:34 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 20:20:34 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 20:20:34 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 20:20:34 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 20:20:34 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 20:20:34 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 20:20:34 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 20:20:34 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 20:20:34 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 20:20:34 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 20:20:34 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 20:20:34 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 20:20:34 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 20:20:34 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 20:20:34 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 20:20:34 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:20:34 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-02 20:20:34 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 20:20:34 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 20:20:34 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-02 20:20:34 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 20:20:34 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-02 20:20:34 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 20:20:34 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 20:20:34 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:20:34 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-02 20:20:34 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 20:20:34 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:20:34 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-02 20:21:01 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-02 20:21:01 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-02 20:21:11 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-02 20:21:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-1893688657 in namespace infra-namespace
2022-04-02 20:21:11 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-1893688657 will have desired state: Ready
2022-04-02 20:22:35 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-1893688657 is in desired state: Ready
2022-04-02 20:22:35 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-1893688657 in namespace infra-namespace
2022-04-02 20:22:35 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-1893688657 will be ready
2022-04-02 20:22:37 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-1893688657 is ready
2022-04-02 20:22:37 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-1893688657 in namespace infra-namespace
2022-04-02 20:22:37 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-1893688657 will have desired state: Ready
2022-04-02 20:23:00 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-1893688657 is in desired state: Ready
2022-04-02 20:23:00 [main] [32mINFO [m [RecoveryIsolatedST:115] Running deleteKafkaService with cluster recovery-cluster-1893688657
2022-04-02 20:23:00 [main] [32mINFO [m [RecoveryIsolatedST:122] Waiting for creation recovery-cluster-1893688657-kafka-bootstrap
2022-04-02 20:23:00 [main] [32mINFO [m [ServiceUtils:58] Waiting when Service recovery-cluster-1893688657-kafka-bootstrap-81549811-bb1b-4ac0-91c8-219ad6d3718d in namespace infra-namespace will be recovered
2022-04-02 20:23:13 [main] [32mINFO [m [ServiceUtils:62] recovery-cluster-1893688657-kafka-bootstrap in namespace infra-namespace is recovered
2022-04-02 20:23:13 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 20:23:13 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromKafkaServiceDeletion
2022-04-02 20:23:13 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-1893688657 in namespace infra-namespace
2022-04-02 20:23:13 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-1893688657 in namespace infra-namespace
2022-04-02 20:23:13 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-1893688657 in namespace infra-namespace
2022-04-02 20:24:03 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 20:24:03 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaServiceDeletion-FINISHED
2022-04-02 20:24:03 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 20:24:03 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 20:24:03 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromZookeeperStatefulSetDeletion-STARTED
2022-04-02 20:24:03 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 20:24:03 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-02 20:24:03 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-02 20:24:03 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-02 20:24:03 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 20:24:03 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-02 20:24:03 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 20:24:03 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 20:24:03 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 20:24:03 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 20:24:03 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 20:24:03 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:24:03 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 20:24:03 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:24:03 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 20:24:03 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 20:24:03 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 20:24:03 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:24:03 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 20:24:03 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 20:24:03 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:24:03 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 20:24:13 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 20:24:13 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 20:24:13 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 20:24:13 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 20:24:13 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 20:24:13 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 20:24:13 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 20:24:23 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 20:24:29 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7e2e5e3d
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-02 20:24:29 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-02 20:24:29 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-02 20:24:29 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-02 20:24:29 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:24:29 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 20:24:29 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 20:24:29 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 20:24:29 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 20:24:29 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 20:24:29 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 20:24:29 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 20:24:29 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 20:24:29 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 20:24:29 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 20:24:29 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 20:24:29 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 20:24:29 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 20:24:29 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 20:24:29 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 20:24:29 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:24:29 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-02 20:24:29 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 20:24:29 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 20:24:29 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-02 20:24:29 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 20:24:29 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-02 20:24:29 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 20:24:29 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 20:24:29 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:24:29 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-02 20:24:29 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 20:24:29 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:24:29 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-02 20:25:00 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-02 20:25:00 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-02 20:25:10 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-02 20:25:10 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-946501509 in namespace infra-namespace
2022-04-02 20:25:10 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-946501509 will have desired state: Ready
2022-04-02 20:26:32 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-946501509 is in desired state: Ready
2022-04-02 20:26:32 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-946501509 in namespace infra-namespace
2022-04-02 20:26:33 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-946501509 will be ready
2022-04-02 20:26:34 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-946501509 is ready
2022-04-02 20:26:34 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-946501509 in namespace infra-namespace
2022-04-02 20:26:34 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-946501509 will have desired state: Ready
2022-04-02 20:26:52 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-946501509 is in desired state: Ready
2022-04-02 20:26:52 [main] [32mINFO [m [PodUtils:121] Waiting when all Pods with prefix recovery-cluster-946501509-zookeeper will be deleted
2022-04-02 20:26:52 [main] [32mINFO [m [PodUtils:154] Waiting when Pod recovery-cluster-946501509-zookeeper-0 will be deleted
2022-04-02 20:27:02 [main] [32mINFO [m [PodUtils:171] Pod recovery-cluster-946501509-zookeeper-0 deleted
2022-04-02 20:27:02 [main] [32mINFO [m [PodUtils:154] Waiting when Pod recovery-cluster-946501509-zookeeper-1 will be deleted
2022-04-02 20:27:02 [main] [32mINFO [m [PodUtils:171] Pod recovery-cluster-946501509-zookeeper-1 deleted
2022-04-02 20:27:02 [main] [32mINFO [m [PodUtils:154] Waiting when Pod recovery-cluster-946501509-zookeeper-2 will be deleted
2022-04-02 20:27:02 [main] [32mINFO [m [PodUtils:171] Pod recovery-cluster-946501509-zookeeper-2 deleted
2022-04-02 20:27:02 [main] [32mINFO [m [RecoveryIsolatedST:107] Waiting for recovery recovery-cluster-946501509-zookeeper
2022-04-02 20:27:02 [main] [32mINFO [m [StatefulSetUtils:73] Waiting for StatefulSet recovery-cluster-946501509-zookeeper-05fe1529-7cf9-4b8f-a215-d756b7e8e1a0 recovery in namespace infra-namespace
2022-04-02 20:27:11 [main] [32mINFO [m [StatefulSetUtils:76] StatefulSet recovery-cluster-946501509-zookeeper was recovered
2022-04-02 20:27:11 [main] [32mINFO [m [StatefulSetUtils:39] Waiting for StatefulSet recovery-cluster-946501509-zookeeper to be ready
2022-04-02 20:27:36 [main] [32mINFO [m [StatefulSetUtils:44] Waiting for 3 Pod(s) of StatefulSet recovery-cluster-946501509-zookeeper to be ready
2022-04-02 20:27:46 [main] [32mINFO [m [StatefulSetUtils:47] StatefulSet recovery-cluster-946501509-zookeeper is ready
2022-04-02 20:27:46 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 20:27:46 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromZookeeperStatefulSetDeletion
2022-04-02 20:27:46 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-946501509 in namespace infra-namespace
2022-04-02 20:27:46 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-946501509 in namespace infra-namespace
2022-04-02 20:27:46 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-946501509 in namespace infra-namespace
2022-04-02 20:28:36 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 20:28:36 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromZookeeperStatefulSetDeletion-FINISHED
2022-04-02 20:28:36 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 20:28:36 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 20:28:36 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaBridgeMetricsConfigDeletion-STARTED
2022-04-02 20:28:36 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 20:28:36 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-02 20:28:36 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-02 20:28:36 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-02 20:28:36 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 20:28:36 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-02 20:28:36 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 20:28:36 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 20:28:36 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 20:28:36 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:28:36 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 20:28:36 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:28:36 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 20:28:36 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 20:28:36 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 20:28:36 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:28:36 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 20:28:36 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 20:28:36 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 20:28:36 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 20:28:36 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 20:28:36 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 20:28:36 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 20:28:36 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 20:28:36 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 20:28:46 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:28:46 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 20:28:46 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 20:28:46 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 20:28:56 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 20:29:07 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7e2e5e3d
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-02 20:29:07 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-02 20:29:07 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-02 20:29:07 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-02 20:29:07 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:29:07 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 20:29:07 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 20:29:07 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 20:29:07 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 20:29:07 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 20:29:07 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 20:29:07 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 20:29:07 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 20:29:07 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 20:29:07 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 20:29:07 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 20:29:07 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 20:29:07 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 20:29:07 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 20:29:07 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 20:29:07 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:29:07 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-02 20:29:07 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 20:29:07 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 20:29:07 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-02 20:29:07 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 20:29:07 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-02 20:29:07 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 20:29:07 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 20:29:07 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:29:07 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-02 20:29:07 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 20:29:08 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:29:08 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-02 20:29:42 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-02 20:29:42 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-02 20:29:52 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-02 20:29:52 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-679715965 in namespace infra-namespace
2022-04-02 20:29:52 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-679715965 will have desired state: Ready
2022-04-02 20:31:48 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-679715965 is in desired state: Ready
2022-04-02 20:31:48 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-679715965 in namespace infra-namespace
2022-04-02 20:31:48 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-679715965 will be ready
2022-04-02 20:31:50 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-679715965 is ready
2022-04-02 20:31:50 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-679715965 in namespace infra-namespace
2022-04-02 20:31:50 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-679715965 will have desired state: Ready
2022-04-02 20:32:12 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-679715965 is in desired state: Ready
2022-04-02 20:32:12 [main] [32mINFO [m [RecoveryIsolatedST:234] Running deleteKafkaBridgeMetricsConfig with cluster recovery-cluster-679715965
2022-04-02 20:32:12 [main] [32mINFO [m [RecoveryIsolatedST:239] Waiting for metric config recovery-cluster-679715965-bridge-config re-creation
2022-04-02 20:32:12 [main] [32mINFO [m [ConfigMapUtils:30] Waiting for config map recovery-cluster-679715965-bridge-config-05aae934-cf57-4055-9cc6-260b99345b3c recovery in namespace infra-namespace
2022-04-02 20:32:14 [main] [32mINFO [m [ConfigMapUtils:33] Config map recovery-cluster-679715965-bridge-config was recovered
2022-04-02 20:32:14 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 20:32:14 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromKafkaBridgeMetricsConfigDeletion
2022-04-02 20:32:14 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-679715965 in namespace infra-namespace
2022-04-02 20:32:14 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-679715965 in namespace infra-namespace
2022-04-02 20:32:14 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-679715965 in namespace infra-namespace
2022-04-02 20:33:04 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 20:33:04 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaBridgeMetricsConfigDeletion-FINISHED
2022-04-02 20:33:04 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 20:33:04 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 20:33:04 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromZookeeperHeadlessServiceDeletion-STARTED
2022-04-02 20:33:04 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 20:33:04 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-02 20:33:04 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-02 20:33:04 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-02 20:33:04 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 20:33:04 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-02 20:33:04 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 20:33:04 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 20:33:04 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 20:33:04 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 20:33:04 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 20:33:04 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:33:04 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 20:33:04 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 20:33:04 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 20:33:04 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:33:04 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 20:33:04 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 20:33:04 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 20:33:04 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 20:33:04 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 20:33:04 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:33:04 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 20:33:04 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 20:33:04 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 20:33:14 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 20:33:14 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 20:33:14 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:33:14 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 20:33:24 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 20:33:30 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7e2e5e3d
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-02 20:33:30 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-02 20:33:30 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-02 20:33:30 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-02 20:33:30 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:33:30 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 20:33:30 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 20:33:30 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 20:33:30 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 20:33:30 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 20:33:30 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 20:33:30 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 20:33:30 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 20:33:30 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 20:33:30 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 20:33:30 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 20:33:30 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 20:33:30 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 20:33:30 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 20:33:30 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 20:33:30 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:33:30 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-02 20:33:30 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 20:33:30 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 20:33:30 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-02 20:33:30 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 20:33:30 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-02 20:33:30 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 20:33:30 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 20:33:30 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:33:30 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-02 20:33:30 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 20:33:30 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:33:30 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-02 20:33:45 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-02 20:33:45 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-02 20:33:55 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-02 20:33:55 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-569242989 in namespace infra-namespace
2022-04-02 20:33:55 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-569242989 will have desired state: Ready
2022-04-02 20:36:12 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-569242989 is in desired state: Ready
2022-04-02 20:36:12 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-569242989 in namespace infra-namespace
2022-04-02 20:36:12 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-569242989 will be ready
2022-04-02 20:36:14 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-569242989 is ready
2022-04-02 20:36:14 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-569242989 in namespace infra-namespace
2022-04-02 20:36:14 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-569242989 will have desired state: Ready
2022-04-02 20:36:40 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-569242989 is in desired state: Ready
2022-04-02 20:36:40 [main] [32mINFO [m [RecoveryIsolatedST:157] Running deleteKafkaHeadlessService with cluster recovery-cluster-569242989
2022-04-02 20:36:40 [main] [32mINFO [m [RecoveryIsolatedST:164] Waiting for creation recovery-cluster-569242989-zookeeper-nodes
2022-04-02 20:36:40 [main] [32mINFO [m [ServiceUtils:58] Waiting when Service recovery-cluster-569242989-zookeeper-nodes-6bfc4b1a-3f30-4d6c-98f4-f5149cc6c9cf in namespace infra-namespace will be recovered
2022-04-02 20:37:07 [main] [32mINFO [m [ServiceUtils:62] recovery-cluster-569242989-zookeeper-nodes in namespace infra-namespace is recovered
2022-04-02 20:37:07 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 20:37:07 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromZookeeperHeadlessServiceDeletion
2022-04-02 20:37:07 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-569242989 in namespace infra-namespace
2022-04-02 20:37:07 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-569242989 in namespace infra-namespace
2022-04-02 20:37:07 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-569242989 in namespace infra-namespace
2022-04-02 20:37:57 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 20:37:57 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromZookeeperHeadlessServiceDeletion-FINISHED
2022-04-02 20:37:57 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 20:37:57 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 20:37:57 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaMetricsConfigDeletion-STARTED
2022-04-02 20:37:57 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 20:37:57 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-02 20:37:57 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-02 20:37:57 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-02 20:37:57 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 20:37:57 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-02 20:37:57 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 20:37:57 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:37:57 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 20:37:57 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 20:37:57 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 20:37:57 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 20:37:57 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 20:37:57 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 20:37:57 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:37:57 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:37:57 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 20:37:57 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 20:37:57 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 20:37:57 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 20:37:57 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 20:38:07 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 20:38:07 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 20:38:07 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 20:38:07 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:38:07 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 20:38:07 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 20:38:07 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 20:38:07 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 20:38:17 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 20:38:22 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7e2e5e3d
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-02 20:38:22 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-02 20:38:22 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-02 20:38:23 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-02 20:38:23 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:38:23 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 20:38:23 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 20:38:23 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 20:38:23 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 20:38:23 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 20:38:23 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 20:38:23 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 20:38:23 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 20:38:23 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 20:38:23 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 20:38:23 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 20:38:23 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 20:38:23 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 20:38:23 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 20:38:23 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 20:38:23 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:38:23 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-02 20:38:23 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 20:38:23 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 20:38:23 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-02 20:38:23 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 20:38:23 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-02 20:38:23 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 20:38:23 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 20:38:23 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:38:23 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-02 20:38:23 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 20:38:23 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:38:23 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-02 20:38:42 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-02 20:38:42 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-02 20:38:52 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-02 20:38:52 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-1938544096 in namespace infra-namespace
2022-04-02 20:38:52 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-1938544096 will have desired state: Ready
2022-04-02 20:40:42 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-1938544096 is in desired state: Ready
2022-04-02 20:40:42 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-1938544096 in namespace infra-namespace
2022-04-02 20:40:42 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-1938544096 will be ready
2022-04-02 20:40:44 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-1938544096 is ready
2022-04-02 20:40:44 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-1938544096 in namespace infra-namespace
2022-04-02 20:40:44 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-1938544096 will have desired state: Ready
2022-04-02 20:41:05 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-1938544096 is in desired state: Ready
2022-04-02 20:41:05 [main] [32mINFO [m [RecoveryIsolatedST:171] Running deleteKafkaMetricsConfig with cluster recovery-cluster-1938544096
2022-04-02 20:41:05 [main] [32mINFO [m [RecoveryIsolatedST:185] Waiting for creation recovery-cluster-1938544096-kafka-config
2022-04-02 20:41:05 [main] [32mINFO [m [ConfigMapUtils:30] Waiting for config map recovery-cluster-1938544096-kafka-config-baaeda06-ed9f-47ab-b8b4-e95c330a5fd1 recovery in namespace infra-namespace
2022-04-02 20:41:32 [main] [32mINFO [m [ConfigMapUtils:33] Config map recovery-cluster-1938544096-kafka-config was recovered
2022-04-02 20:41:32 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 20:41:32 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromKafkaMetricsConfigDeletion
2022-04-02 20:41:32 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-1938544096 in namespace infra-namespace
2022-04-02 20:41:32 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-1938544096 in namespace infra-namespace
2022-04-02 20:41:32 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-1938544096 in namespace infra-namespace
2022-04-02 20:42:22 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 20:42:22 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaMetricsConfigDeletion-FINISHED
2022-04-02 20:42:22 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 20:42:22 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 20:42:22 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromZookeeperServiceDeletion-STARTED
2022-04-02 20:42:22 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 20:42:22 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-02 20:42:22 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-02 20:42:22 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-02 20:42:22 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 20:42:22 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-02 20:42:22 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 20:42:22 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:42:22 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 20:42:22 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:42:22 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 20:42:22 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 20:42:22 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 20:42:22 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 20:42:22 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 20:42:22 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 20:42:22 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:42:22 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 20:42:22 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 20:42:22 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:42:22 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 20:42:22 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 20:42:32 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 20:42:32 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 20:42:32 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 20:42:32 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 20:42:32 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 20:42:32 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 20:42:32 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 20:42:42 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 20:42:47 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7e2e5e3d
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-02 20:42:47 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-02 20:42:47 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-02 20:42:47 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-02 20:42:47 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:42:47 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 20:42:47 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 20:42:48 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 20:42:48 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 20:42:48 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 20:42:48 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 20:42:48 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 20:42:48 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 20:42:48 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 20:42:48 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 20:42:48 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 20:42:48 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 20:42:48 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 20:42:48 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 20:42:48 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 20:42:48 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:42:48 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-02 20:42:48 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 20:42:48 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 20:42:48 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-02 20:42:48 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 20:42:48 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-02 20:42:48 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 20:42:48 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 20:42:48 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:42:48 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-02 20:42:48 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 20:42:48 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:42:48 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-02 20:43:13 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-02 20:43:13 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-02 20:43:23 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-02 20:43:23 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-1729244136 in namespace infra-namespace
2022-04-02 20:43:23 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-1729244136 will have desired state: Ready
2022-04-02 20:45:38 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-1729244136 is in desired state: Ready
2022-04-02 20:45:38 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-1729244136 in namespace infra-namespace
2022-04-02 20:45:38 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-1729244136 will be ready
2022-04-02 20:45:40 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-1729244136 is ready
2022-04-02 20:45:40 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-1729244136 in namespace infra-namespace
2022-04-02 20:45:41 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-1729244136 will have desired state: Ready
2022-04-02 20:46:05 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-1729244136 is in desired state: Ready
2022-04-02 20:46:05 [main] [32mINFO [m [RecoveryIsolatedST:129] Running deleteKafkaService with cluster recovery-cluster-1729244136
2022-04-02 20:46:05 [main] [32mINFO [m [RecoveryIsolatedST:136] Waiting for creation recovery-cluster-1729244136-zookeeper-client
2022-04-02 20:46:05 [main] [32mINFO [m [ServiceUtils:58] Waiting when Service recovery-cluster-1729244136-zookeeper-client-286ea451-7044-4b48-8994-2b71673c5312 in namespace infra-namespace will be recovered
2022-04-02 20:46:25 [main] [32mINFO [m [ServiceUtils:62] recovery-cluster-1729244136-zookeeper-client in namespace infra-namespace is recovered
2022-04-02 20:46:25 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 20:46:25 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromZookeeperServiceDeletion
2022-04-02 20:46:25 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-1729244136 in namespace infra-namespace
2022-04-02 20:46:25 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-1729244136 in namespace infra-namespace
2022-04-02 20:46:25 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-1729244136 in namespace infra-namespace
2022-04-02 20:47:15 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 20:47:15 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromZookeeperServiceDeletion-FINISHED
2022-04-02 20:47:15 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 20:47:15 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 20:47:15 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromImpossibleMemoryRequest-STARTED
2022-04-02 20:47:15 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 20:47:15 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-02 20:47:15 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-02 20:47:15 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-02 20:47:15 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 20:47:15 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-02 20:47:15 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 20:47:15 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 20:47:15 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 20:47:15 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 20:47:15 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 20:47:15 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:47:15 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 20:47:15 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 20:47:15 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 20:47:15 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:47:15 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 20:47:15 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 20:47:15 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 20:47:15 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:47:15 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:47:15 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 20:47:15 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 20:47:25 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 20:47:25 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 20:47:25 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 20:47:25 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 20:47:25 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 20:47:25 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 20:47:35 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 20:47:40 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7e2e5e3d
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-02 20:47:40 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-02 20:47:40 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-02 20:47:40 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-02 20:47:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:47:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 20:47:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 20:47:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 20:47:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 20:47:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 20:47:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 20:47:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 20:47:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 20:47:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 20:47:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 20:47:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 20:47:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 20:47:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 20:47:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 20:47:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 20:47:41 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:47:41 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-02 20:47:41 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 20:47:41 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 20:47:41 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-02 20:47:41 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 20:47:41 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-02 20:47:41 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 20:47:41 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 20:47:41 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:47:41 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-02 20:47:41 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 20:47:41 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:47:41 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-02 20:48:00 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-02 20:48:00 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-02 20:48:10 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-02 20:48:10 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-1278327593 in namespace infra-namespace
2022-04-02 20:48:10 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-1278327593 will have desired state: Ready
2022-04-02 20:49:29 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-1278327593 is in desired state: Ready
2022-04-02 20:49:29 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-1278327593 in namespace infra-namespace
2022-04-02 20:49:29 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-1278327593 will be ready
2022-04-02 20:49:31 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-1278327593 is ready
2022-04-02 20:49:31 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-1278327593 in namespace infra-namespace
2022-04-02 20:49:31 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-1278327593 will have desired state: Ready
2022-04-02 20:49:48 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-1278327593 is in desired state: Ready
2022-04-02 20:49:48 [main] [32mINFO [m [PodUtils:277] Wait for at least one pod with prefix: recovery-cluster-1278327593-kafka will be in pending phase
2022-04-02 20:50:01 [main] [32mINFO [m [PodUtils:306] Verify that all pods with prefix: recovery-cluster-1278327593-kafka are stable in pending phase
2022-04-02 20:50:01 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1278327593-kafka-0 is in the Pending state. Remaining seconds pod to be stable 50
2022-04-02 20:50:02 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1278327593-kafka-0 is in the Pending state. Remaining seconds pod to be stable 49
2022-04-02 20:50:03 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1278327593-kafka-0 is in the Pending state. Remaining seconds pod to be stable 48
2022-04-02 20:50:04 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1278327593-kafka-0 is in the Pending state. Remaining seconds pod to be stable 47
2022-04-02 20:50:05 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1278327593-kafka-0 is in the Pending state. Remaining seconds pod to be stable 46
2022-04-02 20:50:06 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1278327593-kafka-0 is in the Pending state. Remaining seconds pod to be stable 45
2022-04-02 20:50:07 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1278327593-kafka-0 is in the Pending state. Remaining seconds pod to be stable 44
2022-04-02 20:50:08 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1278327593-kafka-0 is in the Pending state. Remaining seconds pod to be stable 43
2022-04-02 20:50:09 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1278327593-kafka-0 is in the Pending state. Remaining seconds pod to be stable 42
2022-04-02 20:50:10 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1278327593-kafka-0 is in the Pending state. Remaining seconds pod to be stable 41
2022-04-02 20:50:11 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1278327593-kafka-0 is in the Pending state. Remaining seconds pod to be stable 40
2022-04-02 20:50:12 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1278327593-kafka-0 is in the Pending state. Remaining seconds pod to be stable 39
2022-04-02 20:50:13 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1278327593-kafka-0 is in the Pending state. Remaining seconds pod to be stable 38
2022-04-02 20:50:14 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1278327593-kafka-0 is in the Pending state. Remaining seconds pod to be stable 37
2022-04-02 20:50:15 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1278327593-kafka-0 is in the Pending state. Remaining seconds pod to be stable 36
2022-04-02 20:50:16 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1278327593-kafka-0 is in the Pending state. Remaining seconds pod to be stable 35
2022-04-02 20:50:17 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1278327593-kafka-0 is in the Pending state. Remaining seconds pod to be stable 34
2022-04-02 20:50:18 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1278327593-kafka-0 is in the Pending state. Remaining seconds pod to be stable 33
2022-04-02 20:50:19 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1278327593-kafka-0 is in the Pending state. Remaining seconds pod to be stable 32
2022-04-02 20:50:20 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1278327593-kafka-0 is in the Pending state. Remaining seconds pod to be stable 31
2022-04-02 20:50:21 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1278327593-kafka-0 is in the Pending state. Remaining seconds pod to be stable 30
2022-04-02 20:50:22 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1278327593-kafka-0 is in the Pending state. Remaining seconds pod to be stable 29
2022-04-02 20:50:23 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1278327593-kafka-0 is in the Pending state. Remaining seconds pod to be stable 28
2022-04-02 20:50:24 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1278327593-kafka-0 is in the Pending state. Remaining seconds pod to be stable 27
2022-04-02 20:50:25 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1278327593-kafka-0 is in the Pending state. Remaining seconds pod to be stable 26
2022-04-02 20:50:26 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1278327593-kafka-0 is in the Pending state. Remaining seconds pod to be stable 25
2022-04-02 20:50:27 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1278327593-kafka-0 is in the Pending state. Remaining seconds pod to be stable 24
2022-04-02 20:50:28 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1278327593-kafka-0 is in the Pending state. Remaining seconds pod to be stable 23
2022-04-02 20:50:29 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1278327593-kafka-0 is in the Pending state. Remaining seconds pod to be stable 22
2022-04-02 20:50:30 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1278327593-kafka-0 is in the Pending state. Remaining seconds pod to be stable 21
2022-04-02 20:50:31 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1278327593-kafka-0 is in the Pending state. Remaining seconds pod to be stable 20
2022-04-02 20:50:32 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1278327593-kafka-0 is in the Pending state. Remaining seconds pod to be stable 19
2022-04-02 20:50:33 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1278327593-kafka-0 is in the Pending state. Remaining seconds pod to be stable 18
2022-04-02 20:50:34 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1278327593-kafka-0 is in the Pending state. Remaining seconds pod to be stable 17
2022-04-02 20:50:35 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1278327593-kafka-0 is in the Pending state. Remaining seconds pod to be stable 16
2022-04-02 20:50:36 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1278327593-kafka-0 is in the Pending state. Remaining seconds pod to be stable 15
2022-04-02 20:50:37 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1278327593-kafka-0 is in the Pending state. Remaining seconds pod to be stable 14
2022-04-02 20:50:38 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1278327593-kafka-0 is in the Pending state. Remaining seconds pod to be stable 13
2022-04-02 20:50:39 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1278327593-kafka-0 is in the Pending state. Remaining seconds pod to be stable 12
2022-04-02 20:50:40 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1278327593-kafka-0 is in the Pending state. Remaining seconds pod to be stable 11
2022-04-02 20:50:41 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1278327593-kafka-0 is in the Pending state. Remaining seconds pod to be stable 10
2022-04-02 20:50:42 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1278327593-kafka-0 is in the Pending state. Remaining seconds pod to be stable 9
2022-04-02 20:50:43 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1278327593-kafka-0 is in the Pending state. Remaining seconds pod to be stable 8
2022-04-02 20:50:44 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1278327593-kafka-0 is in the Pending state. Remaining seconds pod to be stable 7
2022-04-02 20:50:45 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1278327593-kafka-0 is in the Pending state. Remaining seconds pod to be stable 6
2022-04-02 20:50:46 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1278327593-kafka-0 is in the Pending state. Remaining seconds pod to be stable 5
2022-04-02 20:50:47 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1278327593-kafka-0 is in the Pending state. Remaining seconds pod to be stable 4
2022-04-02 20:50:48 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1278327593-kafka-0 is in the Pending state. Remaining seconds pod to be stable 3
2022-04-02 20:50:50 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1278327593-kafka-0 is in the Pending state. Remaining seconds pod to be stable 2
2022-04-02 20:50:51 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1278327593-kafka-0 is in the Pending state. Remaining seconds pod to be stable 1
2022-04-02 20:50:51 [main] [32mINFO [m [PodUtils:335] All pods are stable recovery-cluster-1278327593-kafka-0
2022-04-02 20:50:51 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of recovery-cluster-1278327593-kafka to be ready
2022-04-02 20:56:53 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-1278327593 will have desired state: Ready
2022-04-02 20:56:53 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-1278327593 is in desired state: Ready
2022-04-02 20:56:53 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: recovery-cluster-1278327593 is ready
2022-04-02 20:56:53 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-1278327593 will have desired state: Ready
2022-04-02 20:56:53 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-1278327593 is in desired state: Ready
2022-04-02 20:56:53 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 20:56:53 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromImpossibleMemoryRequest
2022-04-02 20:56:53 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-1278327593 in namespace infra-namespace
2022-04-02 20:56:53 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-1278327593 in namespace infra-namespace
2022-04-02 20:56:53 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-1278327593 in namespace infra-namespace
2022-04-02 20:57:33 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 20:57:33 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromImpossibleMemoryRequest-FINISHED
2022-04-02 20:57:33 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 20:57:33 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 20:57:33 [main] [32mINFO [m [ResourceManager:346] In context RecoveryIsolatedST is everything deleted.
2022-04-02 20:57:33 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;33mWARNING[m] Tests run: 14, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 4,024.251 s - in io.strimzi.systemtest.operators.RecoveryIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST
2022-04-02 20:57:33 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-02 20:57:58 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-02 20:57:58 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-02 20:57:58 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-02 20:57:58 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 20:57:58 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-02 20:57:58 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 20:57:58 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:57:58 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 20:57:58 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:57:58 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 20:57:58 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 20:57:58 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 20:57:58 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 20:57:58 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 20:57:58 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 20:57:58 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 20:57:58 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:57:58 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 20:57:58 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 20:57:58 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 20:57:58 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 20:57:58 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 20:57:58 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:57:58 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 20:57:58 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 20:58:08 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 20:58:08 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 20:58:08 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 20:58:18 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 20:58:24 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7e2e5e3d
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=30000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-02 20:58:24 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-02 20:58:24 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-02 20:58:24 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-02 20:58:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:58:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 20:58:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 20:58:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 20:58:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 20:58:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 20:58:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 20:58:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 20:58:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 20:58:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 20:58:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 20:58:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 20:58:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 20:58:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 20:58:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 20:58:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 20:58:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:58:24 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-02 20:58:24 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 20:58:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 20:58:24 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-02 20:58:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 20:58:24 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-02 20:58:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 20:58:24 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 20:58:24 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:58:24 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-02 20:58:24 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 20:58:24 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 20:58:24 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-02 20:58:55 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-02 20:58:55 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-02 20:59:06 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-02 20:59:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka custom-resource-status-cluster-name in namespace infra-namespace
2022-04-02 20:59:06 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: custom-resource-status-cluster-name will have desired state: Ready
2022-04-02 21:00:32 [main] [32mINFO [m [ResourceManager:444] Kafka: custom-resource-status-cluster-name is in desired state: Ready
2022-04-02 21:00:32 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-467311057-683530871 in namespace infra-namespace
2022-04-02 21:00:32 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-467311057-683530871 will have desired state: Ready
2022-04-02 21:00:33 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-467311057-683530871 is in desired state: Ready
2022-04-02 21:00:33 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment infra-namespace-shared-kafka-clients in namespace infra-namespace
2022-04-02 21:00:33 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: infra-namespace-shared-kafka-clients will be ready
2022-04-02 21:00:35 [main] [32mINFO [m [DeploymentUtils:168] Deployment: infra-namespace-shared-kafka-clients is ready
2022-04-02 21:00:35 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 21:00:35 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaTopicChangingInSyncReplicasStatus-STARTED
2022-04-02 21:00:35 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 21:00:35 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-327208882-51065513 in namespace infra-namespace
2022-04-02 21:00:35 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-327208882-51065513 will have desired state: Ready
2022-04-02 21:00:36 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-327208882-51065513 is in desired state: Ready
2022-04-02 21:00:36 [main] [32mINFO [m [CustomResourceStatusIsolatedST:481] Changing min.insync.replicas to random char
2022-04-02 21:00:36 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-327208882-51065513 will have desired state: NotReady
2022-04-02 21:00:37 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-327208882-51065513 is in desired state: NotReady
2022-04-02 21:00:37 [main] [32mINFO [m [CustomResourceStatusIsolatedST:488] Wait 245000 ms for next reconciliation
2022-04-02 21:04:42 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 21:04:42 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaTopicChangingInSyncReplicasStatus
2022-04-02 21:04:42 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-327208882-51065513 in namespace infra-namespace
2022-04-02 21:04:52 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 21:04:52 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaTopicChangingInSyncReplicasStatus-FINISHED
2022-04-02 21:04:52 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 21:04:52 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 21:04:52 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaUserStatusNotReady-STARTED
2022-04-02 21:04:52 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 21:04:52 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser sasl-use-rabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef in namespace infra-namespace
2022-04-02 21:04:52 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: sasl-use-rabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef will have desired state: NotReady
2022-04-02 21:04:53 [main] [32mINFO [m [ResourceManager:444] KafkaUser: sasl-use-rabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef is in desired state: NotReady
2022-04-02 21:04:53 [main] [32mINFO [m [CustomResourceStatusIsolatedST:179] Checking status of deployed KafkaUser sasl-use-rabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef
2022-04-02 21:04:53 [main] [32mINFO [m [CustomResourceStatusIsolatedST:181] KafkaUser Status: True
2022-04-02 21:04:53 [main] [32mINFO [m [CustomResourceStatusIsolatedST:182] KafkaUser Type: NotReady
2022-04-02 21:04:53 [main] [32mINFO [m [CustomResourceStatusIsolatedST:183] KafkaUser Message: Spec cannot be null
2022-04-02 21:04:53 [main] [32mINFO [m [CustomResourceStatusIsolatedST:184] KafkaUser Reason: InvalidResourceException
2022-04-02 21:04:53 [main] [32mINFO [m [CustomResourceStatusIsolatedST:186] KafkaUser sasl-use-rabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef is in desired state: NotReady
2022-04-02 21:04:53 [main] [32mINFO [m [KafkaUserUtils:62] Waiting for KafkaUser deletion sasl-use-rabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef
2022-04-02 21:04:53 [main] [32mINFO [m [KafkaUserUtils:75] KafkaUser sasl-use-rabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef deleted
2022-04-02 21:04:53 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 21:04:53 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaUserStatusNotReady
2022-04-02 21:04:53 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser sasl-use-rabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef in namespace infra-namespace
2022-04-02 21:04:53 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 21:04:53 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaUserStatusNotReady-FINISHED
2022-04-02 21:04:53 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 21:04:53 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 21:04:53 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaUserStatus-STARTED
2022-04-02 21:04:53 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 21:04:53 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1214902124-1768824444 in namespace infra-namespace
2022-04-02 21:04:53 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1214902124-1768824444 will have desired state: Ready
2022-04-02 21:04:54 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1214902124-1768824444 is in desired state: Ready
2022-04-02 21:04:54 [main] [32mINFO [m [CustomResourceStatusIsolatedST:162] Checking status of deployed KafkaUser
2022-04-02 21:04:54 [main] [32mINFO [m [CustomResourceStatusIsolatedST:164] KafkaUser Status: True
2022-04-02 21:04:54 [main] [32mINFO [m [CustomResourceStatusIsolatedST:165] KafkaUser Type: Ready
2022-04-02 21:04:54 [main] [32mINFO [m [CustomResourceStatusIsolatedST:167] KafkaUser is in desired state: Ready
2022-04-02 21:04:54 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 21:04:54 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaUserStatus
2022-04-02 21:04:54 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1214902124-1768824444 in namespace infra-namespace
2022-04-02 21:05:04 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 21:05:04 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaUserStatus-FINISHED
2022-04-02 21:05:04 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 21:05:04 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 21:05:04 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaTopicStatusNotReady-STARTED
2022-04-02 21:05:04 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 21:05:04 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-22368186-250108743 in namespace infra-namespace
2022-04-02 21:05:04 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-22368186-250108743 will have desired state: NotReady
2022-04-02 21:05:05 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-22368186-250108743 is in desired state: NotReady
2022-04-02 21:05:05 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic my-topic-22368186-250108743 deletion
2022-04-02 21:05:05 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 21:05:05 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaTopicStatusNotReady
2022-04-02 21:05:05 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-22368186-250108743 in namespace infra-namespace
2022-04-02 21:05:05 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 21:05:05 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaTopicStatusNotReady-FINISHED
2022-04-02 21:05:05 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 21:05:05 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 21:05:05 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaStatusCertificate-STARTED
2022-04-02 21:05:05 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 21:05:05 [main] [32mINFO [m [CustomResourceStatusIsolatedST:381] Check if KafkaStatus certificates are the same as secret certificates
2022-04-02 21:05:05 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 21:05:05 [main] [32mINFO [m [ResourceManager:346] In context testKafkaStatusCertificate is everything deleted.
2022-04-02 21:05:05 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 21:05:05 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaStatusCertificate-FINISHED
2022-04-02 21:05:05 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 21:05:05 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 21:05:05 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaBridgeStatus-STARTED
2022-04-02 21:05:05 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 21:05:05 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge custom-resource-status-cluster-name in namespace infra-namespace
2022-04-02 21:05:05 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: custom-resource-status-cluster-name will have desired state: Ready
2022-04-02 21:05:27 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: custom-resource-status-cluster-name is in desired state: Ready
2022-04-02 21:05:27 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: custom-resource-status-cluster-name will have desired state: Ready
2022-04-02 21:05:27 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: custom-resource-status-cluster-name is in desired state: Ready
2022-04-02 21:05:27 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: custom-resource-status-cluster-name will have desired state: NotReady
2022-04-02 21:05:58 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: custom-resource-status-cluster-name is in desired state: NotReady
2022-04-02 21:05:59 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: custom-resource-status-cluster-name will have desired state: Ready
2022-04-02 21:06:54 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: custom-resource-status-cluster-name is in desired state: Ready
2022-04-02 21:06:54 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 21:06:54 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaBridgeStatus
2022-04-02 21:06:54 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge custom-resource-status-cluster-name in namespace infra-namespace
2022-04-02 21:07:04 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 21:07:04 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaBridgeStatus-FINISHED
2022-04-02 21:07:04 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 21:07:04 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 21:07:04 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaTopicStatus-STARTED
2022-04-02 21:07:04 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 21:07:04 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1683781631-1467988319 in namespace infra-namespace
2022-04-02 21:07:04 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1683781631-1467988319 will have desired state: Ready
2022-04-02 21:07:05 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1683781631-1467988319 is in desired state: Ready
2022-04-02 21:07:05 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1683781631-1467988319 will have desired state: Ready
2022-04-02 21:07:05 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1683781631-1467988319 is in desired state: Ready
2022-04-02 21:07:05 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 21:07:05 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaTopicStatus
2022-04-02 21:07:05 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1683781631-1467988319 in namespace infra-namespace
2022-04-02 21:07:15 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 21:07:15 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaTopicStatus-FINISHED
2022-04-02 21:07:15 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 21:07:15 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 21:07:15 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaMirrorMaker2Status-STARTED
2022-04-02 21:07:15 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 21:07:15 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-76611f78 in namespace infra-namespace
2022-04-02 21:07:15 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-76611f78 will have desired state: Ready
2022-04-02 21:08:20 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-76611f78 is in desired state: Ready
2022-04-02 21:08:20 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-76611f78-mirror-maker-2 in namespace infra-namespace
2022-04-02 21:08:20 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-76611f78-mirror-maker-2 will have desired state: Ready
2022-04-02 21:09:33 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-76611f78-mirror-maker-2 is in desired state: Ready
2022-04-02 21:09:33 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-76611f78-mirror-maker-2 will have desired state: Ready
2022-04-02 21:09:33 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-76611f78-mirror-maker-2 is in desired state: Ready
2022-04-02 21:09:33 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-76611f78-mirror-maker-2 will have desired state: NotReady
2022-04-02 21:10:05 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-76611f78-mirror-maker-2 is in desired state: NotReady
2022-04-02 21:10:05 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-76611f78-mirror-maker-2 will have desired state: Ready
2022-04-02 21:11:43 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-76611f78-mirror-maker-2 is in desired state: Ready
2022-04-02 21:12:02 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-76611f78-mirror-maker-2-mirrormaker2 are stable
2022-04-02 21:12:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-76611f78-mirror-maker-2-mirrormaker2-6b6b58cb9fm9hv8 is in the Running state. Remaining seconds pod to be stable 50
2022-04-02 21:12:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-76611f78-mirror-maker-2-mirrormaker2-6b6b58cb9fm9hv8 is in the Running state. Remaining seconds pod to be stable 49
2022-04-02 21:12:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-76611f78-mirror-maker-2-mirrormaker2-6b6b58cb9fm9hv8 is in the Running state. Remaining seconds pod to be stable 48
2022-04-02 21:12:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-76611f78-mirror-maker-2-mirrormaker2-6b6b58cb9fm9hv8 is in the Running state. Remaining seconds pod to be stable 47
2022-04-02 21:12:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-76611f78-mirror-maker-2-mirrormaker2-6b6b58cb9fm9hv8 is in the Running state. Remaining seconds pod to be stable 46
2022-04-02 21:12:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-76611f78-mirror-maker-2-mirrormaker2-6b6b58cb9fm9hv8 is in the Running state. Remaining seconds pod to be stable 45
2022-04-02 21:12:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-76611f78-mirror-maker-2-mirrormaker2-6b6b58cb9fm9hv8 is in the Running state. Remaining seconds pod to be stable 44
2022-04-02 21:12:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-76611f78-mirror-maker-2-mirrormaker2-6b6b58cb9fm9hv8 is in the Running state. Remaining seconds pod to be stable 43
2022-04-02 21:12:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-76611f78-mirror-maker-2-mirrormaker2-6b6b58cb9fm9hv8 is in the Running state. Remaining seconds pod to be stable 42
2022-04-02 21:12:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-76611f78-mirror-maker-2-mirrormaker2-6b6b58cb9fm9hv8 is in the Running state. Remaining seconds pod to be stable 41
2022-04-02 21:12:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-76611f78-mirror-maker-2-mirrormaker2-6b6b58cb9fm9hv8 is in the Running state. Remaining seconds pod to be stable 40
2022-04-02 21:12:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-76611f78-mirror-maker-2-mirrormaker2-6b6b58cb9fm9hv8 is in the Running state. Remaining seconds pod to be stable 39
2022-04-02 21:12:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-76611f78-mirror-maker-2-mirrormaker2-6b6b58cb9fm9hv8 is in the Running state. Remaining seconds pod to be stable 38
2022-04-02 21:12:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-76611f78-mirror-maker-2-mirrormaker2-6b6b58cb9fm9hv8 is in the Running state. Remaining seconds pod to be stable 37
2022-04-02 21:12:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-76611f78-mirror-maker-2-mirrormaker2-6b6b58cb9fm9hv8 is in the Running state. Remaining seconds pod to be stable 36
2022-04-02 21:12:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-76611f78-mirror-maker-2-mirrormaker2-6b6b58cb9fm9hv8 is in the Running state. Remaining seconds pod to be stable 35
2022-04-02 21:12:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-76611f78-mirror-maker-2-mirrormaker2-6b6b58cb9fm9hv8 is in the Running state. Remaining seconds pod to be stable 34
2022-04-02 21:12:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-76611f78-mirror-maker-2-mirrormaker2-6b6b58cb9fm9hv8 is in the Running state. Remaining seconds pod to be stable 33
2022-04-02 21:12:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-76611f78-mirror-maker-2-mirrormaker2-6b6b58cb9fm9hv8 is in the Running state. Remaining seconds pod to be stable 32
2022-04-02 21:12:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-76611f78-mirror-maker-2-mirrormaker2-6b6b58cb9fm9hv8 is in the Running state. Remaining seconds pod to be stable 31
2022-04-02 21:12:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-76611f78-mirror-maker-2-mirrormaker2-6b6b58cb9fm9hv8 is in the Running state. Remaining seconds pod to be stable 30
2022-04-02 21:12:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-76611f78-mirror-maker-2-mirrormaker2-6b6b58cb9fm9hv8 is in the Running state. Remaining seconds pod to be stable 29
2022-04-02 21:12:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-76611f78-mirror-maker-2-mirrormaker2-6b6b58cb9fm9hv8 is in the Running state. Remaining seconds pod to be stable 28
2022-04-02 21:12:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-76611f78-mirror-maker-2-mirrormaker2-6b6b58cb9fm9hv8 is in the Running state. Remaining seconds pod to be stable 27
2022-04-02 21:12:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-76611f78-mirror-maker-2-mirrormaker2-6b6b58cb9fm9hv8 is in the Running state. Remaining seconds pod to be stable 26
2022-04-02 21:12:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-76611f78-mirror-maker-2-mirrormaker2-6b6b58cb9fm9hv8 is in the Running state. Remaining seconds pod to be stable 25
2022-04-02 21:12:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-76611f78-mirror-maker-2-mirrormaker2-6b6b58cb9fm9hv8 is in the Running state. Remaining seconds pod to be stable 24
2022-04-02 21:12:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-76611f78-mirror-maker-2-mirrormaker2-6b6b58cb9fm9hv8 is in the Running state. Remaining seconds pod to be stable 23
2022-04-02 21:12:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-76611f78-mirror-maker-2-mirrormaker2-6b6b58cb9fm9hv8 is in the Running state. Remaining seconds pod to be stable 22
2022-04-02 21:12:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-76611f78-mirror-maker-2-mirrormaker2-6b6b58cb9fm9hv8 is in the Running state. Remaining seconds pod to be stable 21
2022-04-02 21:12:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-76611f78-mirror-maker-2-mirrormaker2-6b6b58cb9fm9hv8 is in the Running state. Remaining seconds pod to be stable 20
2022-04-02 21:12:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-76611f78-mirror-maker-2-mirrormaker2-6b6b58cb9fm9hv8 is in the Running state. Remaining seconds pod to be stable 19
2022-04-02 21:12:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-76611f78-mirror-maker-2-mirrormaker2-6b6b58cb9fm9hv8 is in the Running state. Remaining seconds pod to be stable 18
2022-04-02 21:12:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-76611f78-mirror-maker-2-mirrormaker2-6b6b58cb9fm9hv8 is in the Running state. Remaining seconds pod to be stable 17
2022-04-02 21:12:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-76611f78-mirror-maker-2-mirrormaker2-6b6b58cb9fm9hv8 is in the Running state. Remaining seconds pod to be stable 16
2022-04-02 21:12:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-76611f78-mirror-maker-2-mirrormaker2-6b6b58cb9fm9hv8 is in the Running state. Remaining seconds pod to be stable 15
2022-04-02 21:12:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-76611f78-mirror-maker-2-mirrormaker2-6b6b58cb9fm9hv8 is in the Running state. Remaining seconds pod to be stable 14
2022-04-02 21:12:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-76611f78-mirror-maker-2-mirrormaker2-6b6b58cb9fm9hv8 is in the Running state. Remaining seconds pod to be stable 13
2022-04-02 21:12:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-76611f78-mirror-maker-2-mirrormaker2-6b6b58cb9fm9hv8 is in the Running state. Remaining seconds pod to be stable 12
2022-04-02 21:12:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-76611f78-mirror-maker-2-mirrormaker2-6b6b58cb9fm9hv8 is in the Running state. Remaining seconds pod to be stable 11
2022-04-02 21:12:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-76611f78-mirror-maker-2-mirrormaker2-6b6b58cb9fm9hv8 is in the Running state. Remaining seconds pod to be stable 10
2022-04-02 21:12:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-76611f78-mirror-maker-2-mirrormaker2-6b6b58cb9fm9hv8 is in the Running state. Remaining seconds pod to be stable 9
2022-04-02 21:12:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-76611f78-mirror-maker-2-mirrormaker2-6b6b58cb9fm9hv8 is in the Running state. Remaining seconds pod to be stable 8
2022-04-02 21:12:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-76611f78-mirror-maker-2-mirrormaker2-6b6b58cb9fm9hv8 is in the Running state. Remaining seconds pod to be stable 7
2022-04-02 21:12:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-76611f78-mirror-maker-2-mirrormaker2-6b6b58cb9fm9hv8 is in the Running state. Remaining seconds pod to be stable 6
2022-04-02 21:12:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-76611f78-mirror-maker-2-mirrormaker2-6b6b58cb9fm9hv8 is in the Running state. Remaining seconds pod to be stable 5
2022-04-02 21:12:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-76611f78-mirror-maker-2-mirrormaker2-6b6b58cb9fm9hv8 is in the Running state. Remaining seconds pod to be stable 4
2022-04-02 21:12:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-76611f78-mirror-maker-2-mirrormaker2-6b6b58cb9fm9hv8 is in the Running state. Remaining seconds pod to be stable 3
2022-04-02 21:12:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-76611f78-mirror-maker-2-mirrormaker2-6b6b58cb9fm9hv8 is in the Running state. Remaining seconds pod to be stable 2
2022-04-02 21:12:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-76611f78-mirror-maker-2-mirrormaker2-6b6b58cb9fm9hv8 is in the Running state. Remaining seconds pod to be stable 1
2022-04-02 21:12:51 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-76611f78-mirror-maker-2-mirrormaker2-6b6b58cb9fm9hv8
2022-04-02 21:12:51 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 21:12:51 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaMirrorMaker2Status
2022-04-02 21:12:51 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-76611f78-mirror-maker-2 in namespace infra-namespace
2022-04-02 21:12:51 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-76611f78 in namespace infra-namespace
2022-04-02 21:13:01 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 21:13:01 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaMirrorMaker2Status-FINISHED
2022-04-02 21:13:01 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 21:13:01 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 21:13:01 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaConnectorWithoutClusterConfig-STARTED
2022-04-02 21:13:01 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 21:13:01 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-27baab4e in namespace infra-namespace
2022-04-02 21:13:01 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-27baab4e will have desired state: NotReady
2022-04-02 21:13:02 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-27baab4e is in desired state: NotReady
2022-04-02 21:13:02 [main] [32mINFO [m [KafkaConnectorUtils:98] KafkaConnector: my-cluster-27baab4e is not deleted yet, triggering force delete
2022-04-02 21:13:03 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 21:13:03 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaConnectorWithoutClusterConfig
2022-04-02 21:13:03 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-27baab4e in namespace infra-namespace
2022-04-02 21:13:03 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 21:13:03 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaConnectorWithoutClusterConfig-FINISHED
2022-04-02 21:13:03 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 21:13:03 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 21:13:03 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaMirrorMakerStatusWrongBootstrap-STARTED
2022-04-02 21:13:03 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 21:13:03 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-84ae6e02 in namespace infra-namespace
2022-04-02 21:13:03 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-84ae6e02 will have desired state: Ready
2022-04-02 21:14:09 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-84ae6e02 is in desired state: Ready
2022-04-02 21:14:09 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-84ae6e02 will have desired state: Ready
2022-04-02 21:14:09 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-84ae6e02 is in desired state: Ready
2022-04-02 21:14:09 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-84ae6e02 will have desired state: NotReady
2022-04-02 21:14:40 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-84ae6e02 is in desired state: NotReady
2022-04-02 21:14:40 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-84ae6e02 will have desired state: Ready
2022-04-02 21:15:11 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-84ae6e02 is in desired state: Ready
2022-04-02 21:15:11 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 21:15:11 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaMirrorMakerStatusWrongBootstrap
2022-04-02 21:15:11 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-84ae6e02 in namespace infra-namespace
2022-04-02 21:15:22 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 21:15:22 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaMirrorMakerStatusWrongBootstrap-FINISHED
2022-04-02 21:15:22 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 21:15:22 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 21:15:22 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaConnectAndConnectorStatus-STARTED
2022-04-02 21:15:22 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 21:15:22 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment custom-resource-status-cluster-name-scraper in namespace infra-namespace
2022-04-02 21:15:22 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: custom-resource-status-cluster-name-scraper will be ready
2022-04-02 21:15:24 [main] [32mINFO [m [DeploymentUtils:168] Deployment: custom-resource-status-cluster-name-scraper is ready
2022-04-02 21:15:24 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment custom-resource-status-cluster-name-scraper to be ready
2022-04-02 21:15:34 [main] [32mINFO [m [DeploymentUtils:197] Deployment custom-resource-status-cluster-name-scraper is ready
2022-04-02 21:15:34 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to custom-resource-status-cluster-name-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-02 21:15:34 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy custom-resource-status-cluster-name-allow in namespace infra-namespace
2022-04-02 21:15:34 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-02 21:15:34 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect custom-resource-status-cluster-name in namespace infra-namespace
2022-04-02 21:15:34 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: custom-resource-status-cluster-name will have desired state: Ready
2022-04-02 21:16:42 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: custom-resource-status-cluster-name is in desired state: Ready
2022-04-02 21:16:42 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector custom-resource-status-cluster-name in namespace infra-namespace
2022-04-02 21:16:42 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: custom-resource-status-cluster-name will have desired state: Ready
2022-04-02 21:16:43 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: custom-resource-status-cluster-name is in desired state: Ready
2022-04-02 21:16:43 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: custom-resource-status-cluster-name will have desired state: NotReady
2022-04-02 21:17:15 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: custom-resource-status-cluster-name is in desired state: NotReady
2022-04-02 21:17:15 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: custom-resource-status-cluster-name will have desired state: Ready
2022-04-02 21:19:11 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: custom-resource-status-cluster-name is in desired state: Ready
2022-04-02 21:19:11 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: custom-resource-status-cluster-name will have desired state: NotReady
2022-04-02 21:19:12 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: custom-resource-status-cluster-name is in desired state: NotReady
2022-04-02 21:19:12 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: custom-resource-status-cluster-name will have desired state: Ready
2022-04-02 21:19:13 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: custom-resource-status-cluster-name is in desired state: Ready
2022-04-02 21:19:13 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: custom-resource-status-cluster-name will have desired state: NotReady
2022-04-02 21:19:14 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: custom-resource-status-cluster-name is in desired state: NotReady
2022-04-02 21:19:14 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: custom-resource-status-cluster-name will have desired state: Ready
2022-04-02 21:19:15 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: custom-resource-status-cluster-name is in desired state: Ready
2022-04-02 21:19:15 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 21:19:15 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaConnectAndConnectorStatus
2022-04-02 21:19:15 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect custom-resource-status-cluster-name in namespace infra-namespace
2022-04-02 21:19:15 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector custom-resource-status-cluster-name in namespace infra-namespace
2022-04-02 21:19:15 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy custom-resource-status-cluster-name-allow in namespace infra-namespace
2022-04-02 21:19:15 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment custom-resource-status-cluster-name-scraper in namespace infra-namespace
2022-04-02 21:19:55 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 21:19:55 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaConnectAndConnectorStatus-FINISHED
2022-04-02 21:19:55 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 21:19:55 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 21:19:55 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaMirrorMaker2WrongBootstrap-STARTED
2022-04-02 21:19:55 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 21:19:55 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-75875be9-mirror-maker-2 in namespace infra-namespace
2022-04-02 21:19:55 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-75875be9-mirror-maker-2 will have desired state: NotReady
2022-04-02 21:20:26 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-75875be9-mirror-maker-2 is in desired state: NotReady
2022-04-02 21:20:26 [main] [33mWARN [m [DeploymentUtils:213] Deployment my-cluster-75875be9-mirror-maker-2-mirrormaker2 is not deleted yet! Triggering force delete by cmd client!
2022-04-02 21:20:32 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 21:20:32 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaMirrorMaker2WrongBootstrap
2022-04-02 21:20:32 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-75875be9-mirror-maker-2 in namespace infra-namespace
2022-04-02 21:20:32 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 21:20:32 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaMirrorMaker2WrongBootstrap-FINISHED
2022-04-02 21:20:32 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 21:20:32 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 21:20:32 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaTopicDecreaseStatus-STARTED
2022-04-02 21:20:32 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 21:20:32 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1863709913-932276083 in namespace infra-namespace
2022-04-02 21:20:32 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1863709913-932276083 will have desired state: Ready
2022-04-02 21:20:33 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1863709913-932276083 is in desired state: Ready
2022-04-02 21:20:33 [main] [32mINFO [m [CustomResourceStatusIsolatedST:457] Decreasing number of partitions to 1
2022-04-02 21:20:33 [main] [32mINFO [m [KafkaTopicUtils:124] Waiting for KafkaTopic change my-topic-1863709913-932276083
2022-04-02 21:20:33 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1863709913-932276083 will have desired state: NotReady
2022-04-02 21:20:34 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1863709913-932276083 is in desired state: NotReady
2022-04-02 21:20:34 [main] [32mINFO [m [CustomResourceStatusIsolatedST:465] Wait 245000 ms for next reconciliation
2022-04-02 21:24:39 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 21:24:39 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaTopicDecreaseStatus
2022-04-02 21:24:39 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1863709913-932276083 in namespace infra-namespace
2022-04-02 21:24:49 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 21:24:49 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaTopicDecreaseStatus-FINISHED
2022-04-02 21:24:49 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 21:24:49 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 21:24:49 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaMirrorMakerStatus-STARTED
2022-04-02 21:24:49 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 21:24:49 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-1d4244c7-mirror-maker in namespace infra-namespace
2022-04-02 21:24:49 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-1d4244c7-mirror-maker will have desired state: Ready
2022-04-02 21:25:50 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-1d4244c7-mirror-maker is in desired state: Ready
2022-04-02 21:25:50 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-1d4244c7-mirror-maker will have desired state: Ready
2022-04-02 21:25:50 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-1d4244c7-mirror-maker is in desired state: Ready
2022-04-02 21:25:50 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-1d4244c7-mirror-maker will have desired state: NotReady
2022-04-02 21:26:21 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-1d4244c7-mirror-maker is in desired state: NotReady
2022-04-02 21:26:21 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-1d4244c7-mirror-maker will have desired state: Ready
2022-04-02 21:34:21,697 main ERROR Unable to write to stream systemtest/target/logs/strimzi-debug.log for appender RollingFile org.apache.logging.log4j.core.appender.AppenderLoggingException: Error writing to stream systemtest/target/logs/strimzi-debug.log
	at org.apache.logging.log4j.core.appender.OutputStreamManager.writeToDestination(OutputStreamManager.java:252)
	at org.apache.logging.log4j.core.appender.FileManager.writeToDestination(FileManager.java:277)
	at org.apache.logging.log4j.core.appender.rolling.RollingFileManager.writeToDestination(RollingFileManager.java:275)
	at org.apache.logging.log4j.core.appender.OutputStreamManager.flushBuffer(OutputStreamManager.java:283)
	at org.apache.logging.log4j.core.appender.OutputStreamManager.flush(OutputStreamManager.java:294)
	at org.apache.logging.log4j.core.appender.AbstractOutputStreamAppender.directEncodeEvent(AbstractOutputStreamAppender.java:217)
	at org.apache.logging.log4j.core.appender.AbstractOutputStreamAppender.tryAppend(AbstractOutputStreamAppender.java:208)
	at org.apache.logging.log4j.core.appender.AbstractOutputStreamAppender.append(AbstractOutputStreamAppender.java:199)
	at org.apache.logging.log4j.core.appender.RollingFileAppender.append(RollingFileAppender.java:312)
	at org.apache.logging.log4j.core.config.AppenderControl.tryCallAppender(AppenderControl.java:161)
	at org.apache.logging.log4j.core.config.AppenderControl.callAppender0(AppenderControl.java:134)
	at org.apache.logging.log4j.core.config.AppenderControl.callAppenderPreventRecursion(AppenderControl.java:125)
	at org.apache.logging.log4j.core.config.AppenderControl.callAppender(AppenderControl.java:89)
	at org.apache.logging.log4j.core.config.LoggerConfig.callAppenders(LoggerConfig.java:675)
	at org.apache.logging.log4j.core.config.LoggerConfig.processLogEvent(LoggerConfig.java:633)
	at org.apache.logging.log4j.core.config.LoggerConfig.log(LoggerConfig.java:616)
	at org.apache.logging.log4j.core.config.LoggerConfig.log(LoggerConfig.java:552)
	at org.apache.logging.log4j.core.config.AwaitCompletionReliabilityStrategy.log(AwaitCompletionReliabilityStrategy.java:82)
	at org.apache.logging.log4j.core.Logger.log(Logger.java:161)
	at org.apache.logging.log4j.spi.AbstractLogger.tryLogMessage(AbstractLogger.java:2205)
	at org.apache.logging.log4j.spi.AbstractLogger.logMessageTrackRecursion(AbstractLogger.java:2159)
	at org.apache.logging.log4j.spi.AbstractLogger.logMessageSafely(AbstractLogger.java:2142)
	at org.apache.logging.log4j.spi.AbstractLogger.logMessage(AbstractLogger.java:2034)
	at org.apache.logging.log4j.spi.AbstractLogger.logIfEnabled(AbstractLogger.java:1899)
	at org.apache.logging.log4j.spi.AbstractLogger.info(AbstractLogger.java:1444)
	at io.strimzi.systemtest.resources.ResourceManager.logCurrentResourceStatus(ResourceManager.java:414)
	at io.strimzi.systemtest.resources.ResourceManager.lambda$waitForResourceStatus$6(ResourceManager.java:440)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:169)
	at io.strimzi.systemtest.resources.ResourceManager.waitForResourceStatus(ResourceManager.java:435)
	at io.strimzi.systemtest.resources.ResourceManager.waitForResourceStatus(ResourceManager.java:428)
	at io.strimzi.systemtest.resources.ResourceManager.waitForResourceStatus(ResourceManager.java:450)
	at io.strimzi.systemtest.utils.kafkaUtils.KafkaMirrorMakerUtils.waitForKafkaMirrorMakerStatus(KafkaMirrorMakerUtils.java:29)
	at io.strimzi.systemtest.utils.kafkaUtils.KafkaMirrorMakerUtils.waitForKafkaMirrorMakerReady(KafkaMirrorMakerUtils.java:37)
	at io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKaf2022-04-02 21:34:21,697 main ERROR Unable to write to stream systemtest/target/logs/strimzi-debug.log for appender RollingFile org.apache.logging.log4j.core.appender.AppenderLoggingException: Error writing to stream systemtest/target/logs/strimzi-debug.log
	at org.apache.logging.log4j.core.appender.OutputStreamManager.writeToDestination(OutputStreamManager.java:252)
	at org.apache.logging.log4j.core.appender.FileManager.writeToDestination(FileManager.java:277)
	at org.apache.logging.log4j.core.appender.rolling.RollingFileManager.writeToDestination(RollingFileManager.java:275)
	at org.apache.logging.log4j.core.appender.OutputStreamManager.flushBuffer(OutputStreamManager.java:283)
	at org.apache.logging.log4j.core.appender.OutputStreamManager.flush(OutputStreamManager.java:294)
	at org.apache.logging.log4j.core.appender.AbstractOutputStreamAppender.directEncodeEvent(AbstractOutputStreamAppender.java:217)
	at org.apache.logging.log4j.core.appender.AbstractOutputStreamAppender.tryAppend(AbstractOutputStreamAppender.java:208)
	at org.apache.logging.log4j.core.appender.AbstractOutputStreamAppender.append(AbstractOutputStreamAppender.java:199)
	at org.apache.logging.log4j.core.appender.RollingFileAppender.append(RollingFileAppender.java:312)
	at org.apache.logging.log4j.core.config.AppenderControl.tryCallAppender(AppenderControl.java:161)
	at org.apache.logging.log4j.core.config.AppenderControl.callAppender0(AppenderControl.java:134)
	at org.apache.logging.log4j.core.config.AppenderControl.callAppenderPreventRecursion(AppenderControl.java:125)
	at org.apache.logging.log4j.core.config.AppenderControl.callAppender(AppenderControl.java:89)
	at org.apache.logging.log4j.core.config.LoggerConfig.callAppenders(LoggerConfig.java:675)
	at org.apache.logging.log4j.core.config.LoggerConfig.processLogEvent(LoggerConfig.java:633)
	at org.apache.logging.log4j.core.config.LoggerConfig.log(LoggerConfig.java:616)
	at org.apache.logging.log4j.core.config.LoggerConfig.log(LoggerConfig.java:552)
	at org.apache.logging.log4j.core.config.AwaitCompletionReliabilityStrategy.log(AwaitCompletionReliabilityStrategy.java:82)
	at org.apache.logging.log4j.core.Logger.log(Logger.java:161)
	at org.apache.logging.log4j.spi.AbstractLogger.tryLogMessage(AbstractLogger.java:2205)
	at org.apache.logging.log4j.spi.AbstractLogger.logMessageTrackRecursion(AbstractLogger.java:2159)
	at org.apache.logging.log4j.spi.AbstractLogger.logMessageSafely(AbstractLogger.java:2142)
	at org.apache.logging.log4j.spi.AbstractLogger.logMessage(AbstractLogger.java:2034)
	at org.apache.logging.log4j.spi.AbstractLogger.logIfEnabled(AbstractLogger.java:1899)
	at org.apache.logging.log4j.spi.AbstractLogger.info(AbstractLogger.java:1444)
	at io.strimzi.systemtest.resources.ResourceManager.logCurrentResourceStatus(ResourceManager.java:414)
	at io.strimzi.systemtest.resources.ResourceManager.lambda$waitForResourceStatus$6(ResourceManager.java:440)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:169)
	at io.strimzi.systemtest.resources.ResourceManager.waitForResourceStatus(ResourceManager.java:435)
	at io.strimzi.systemtest.resources.ResourceManager.waitForResourceStatus(ResourceManager.java:428)
	at io.strimzi.systemtest.resources.ResourceManager.waitForResourceStatus(ResourceManager.java:450)
	at io.strimzi.systemtest.utils.kafkaUtils.KafkaMirrorMakerUtils.waitForKafkaMirrorMakerStatus(KafkaMirrorMakerUtils.java:29)
	at io.strimzi.systemtest.utils.kafkaUtils.KafkaMirrorMakerUtils.waitForKafkaMirrorMakerReady(KafkaMirrorMakerUtils.java:37)
	at io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaMirrorMakerStatus(CustomResourceStatusIsolatedST.java:211)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.j2022-04-02 21:35:11 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;31mERROR[m] Tests run: 14, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 2,258.217 s <<< FAILURE! - in io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST
[[1;31mERROR[m] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaMirrorMakerStatus(ExtensionContext)  Time elapsed: 582.426 s  <<< ERROR!
java.io.IOException: Unable to create path
	at io.strimzi.systemtest.logs.LogCollector.<init>(LogCollector.java:110)
	at io.strimzi.systemtest.logs.TestExecutionWatcher.collectLogs(TestExecutionWatcher.java:88)
	at io.strimzi.systemtest.logs.TestExecutionWatcher.handleTestExecutionException(TestExecutionWatcher.java:32)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestExecutionExceptionHandlers$8(TestMethodTestDescriptor.java:228)
	at org.junit.jupiter.engine.descriptor.JupiterTestDescriptor.invokeExecutionExceptionHandlers(JupiterTestDescriptor.java:123)
	at org.junit.jupiter.engine.descriptor.JupiterTestDescriptor.invokeExecutionExceptionHandlers(JupiterTestDescriptor.java:110)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestExecutionExceptionHandlers(TestMethodTestDescriptor.java:227)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:219)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)

[[1;34mINFO[m] Running io.strimzi.systemtest.operators.MultipleClusterOperatorsIsolatedST
2022-04-02 21:35:11 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-02 21:35:36 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-02 21:35:36 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-02 21:35:36 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-02 21:35:36 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 21:35:36 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-02 21:35:36 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 21:35:36 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 21:35:36 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 21:35:36 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 21:35:36 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 21:35:36 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 21:35:36 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 21:35:36 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 21:35:36 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 21:35:36 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 21:35:36 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 21:35:36 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 21:35:36 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 21:35:36 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 21:35:37 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 21:35:37 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 21:35:37 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 21:35:37 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 21:35:37 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 21:35:46 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 21:35:46 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 21:35:46 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 21:35:46 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 21:35:57 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 21:36:02 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 21:36:02 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.MultipleClusterOperatorsIsolatedST.testKafkaCCAndRebalanceWithMultipleCOs-STARTED
2022-04-02 21:36:02 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 21:36:02 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:230] Creating first-strimzi-cluster-operator in multiple-co-cluster-test namespace
2022-04-02 21:36:02 [main] [32mINFO [m [SetupClusterOperator:223] Cluster operator installation configuration:
SetupClusterOperator{cluster=io.strimzi.test.k8s.KubeClusterResource@38874b68, extensionContext=org.junit.jupiter.engine.descriptor.MethodExtensionContext@6506610b, clusterOperatorName='first-strimzi-cluster-operator', namespaceInstallTo='multiple-co-cluster-test', namespaceToWatch='multiple-co-cluster-test', bindingsNamespaces=[multiple-co-cluster-test], operationTimeout=300000, reconciliationInterval=30000, extraEnvVars=[EnvVar(name=STRIMZI_CUSTOM_RESOURCE_SELECTOR, value=app.kubernetes.io/operator=first-strimzi-cluster-operator, valueFrom=null, additionalProperties={})], extraLabels={app.kubernetes.io/operator=first-strimzi-cluster-operator}, clusterOperatorRBACType=CLUSTER, testClassName='null', testMethodName='null'}
2022-04-02 21:36:02 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-02 21:36:02 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: multiple-co-cluster-test
2022-04-02 21:36:03 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: multiple-co-cluster-test
2022-04-02 21:36:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-02 21:36:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 21:36:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 21:36:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 21:36:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 21:36:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 21:36:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 21:36:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 21:36:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 21:36:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 21:36:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 21:36:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 21:36:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 21:36:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 21:36:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 21:36:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 21:36:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-02 21:36:03 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: multiple-co-cluster-test
2022-04-02 21:36:03 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace multiple-co-cluster-test
2022-04-02 21:36:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 21:36:03 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace multiple-co-cluster-test
2022-04-02 21:36:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 21:36:03 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace multiple-co-cluster-test
2022-04-02 21:36:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 21:36:03 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace multiple-co-cluster-test
2022-04-02 21:36:03 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-02 21:36:03 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace multiple-co-cluster-test
2022-04-02 21:36:03 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace multiple-co-cluster-test
2022-04-02 21:36:03 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment first-strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-02 21:36:03 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: first-strimzi-cluster-operator will be ready
2022-04-02 21:36:34 [main] [32mINFO [m [DeploymentUtils:168] Deployment: first-strimzi-cluster-operator is ready
2022-04-02 21:36:34 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment first-strimzi-cluster-operator to be ready
2022-04-02 21:36:44 [main] [32mINFO [m [DeploymentUtils:197] Deployment first-strimzi-cluster-operator is ready
2022-04-02 21:36:44 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:230] Creating second-strimzi-cluster-operator in multiple-co-cluster-test namespace
2022-04-02 21:36:44 [main] [32mINFO [m [SetupClusterOperator:223] Cluster operator installation configuration:
SetupClusterOperator{cluster=io.strimzi.test.k8s.KubeClusterResource@38874b68, extensionContext=org.junit.jupiter.engine.descriptor.MethodExtensionContext@6506610b, clusterOperatorName='second-strimzi-cluster-operator', namespaceInstallTo='multiple-co-cluster-test', namespaceToWatch='multiple-co-cluster-test', bindingsNamespaces=[multiple-co-cluster-test], operationTimeout=300000, reconciliationInterval=30000, extraEnvVars=[EnvVar(name=STRIMZI_CUSTOM_RESOURCE_SELECTOR, value=app.kubernetes.io/operator=second-strimzi-cluster-operator, valueFrom=null, additionalProperties={})], extraLabels={app.kubernetes.io/operator=second-strimzi-cluster-operator}, clusterOperatorRBACType=CLUSTER, testClassName='null', testMethodName='null'}
2022-04-02 21:36:44 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-02 21:36:44 [main] [32mINFO [m [SetupClusterOperator:254] Environment for ClusterOperator was already prepared! Going to install it now.
2022-04-02 21:36:44 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-02 21:36:44 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 21:36:44 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 21:36:44 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 21:36:44 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 21:36:44 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 21:36:44 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 21:36:44 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 21:36:45 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 21:36:45 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 21:36:45 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 21:36:45 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 21:36:45 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 21:36:45 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 21:36:45 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 21:36:45 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 21:36:45 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-02 21:36:45 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: multiple-co-cluster-test
2022-04-02 21:36:45 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace multiple-co-cluster-test
2022-04-02 21:36:45 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 21:36:45 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace multiple-co-cluster-test
2022-04-02 21:36:45 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 21:36:45 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace multiple-co-cluster-test
2022-04-02 21:36:45 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 21:36:45 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace multiple-co-cluster-test
2022-04-02 21:36:45 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-02 21:36:45 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace multiple-co-cluster-test
2022-04-02 21:36:45 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace multiple-co-cluster-test
2022-04-02 21:36:45 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment second-strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-02 21:36:45 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: second-strimzi-cluster-operator will be ready
2022-04-02 21:37:04 [main] [32mINFO [m [DeploymentUtils:168] Deployment: second-strimzi-cluster-operator is ready
2022-04-02 21:37:04 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment second-strimzi-cluster-operator to be ready
2022-04-02 21:37:14 [main] [32mINFO [m [DeploymentUtils:197] Deployment second-strimzi-cluster-operator is ready
2022-04-02 21:37:14 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:171] Deploying Kafka with {app.kubernetes.io/operator=first-strimzi-cluster-operator} selector of first-strimzi-cluster-operator
2022-04-02 21:37:14 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-8e8c768d in namespace multiple-co-cluster-test
2022-04-02 21:37:14 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-8e8c768d will have desired state: Ready
2022-04-02 21:39:06 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-8e8c768d is in desired state: Ready
2022-04-02 21:39:06 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:180] Removing CR selector from Kafka and increasing number of replicas to 4, new pod should not appear
2022-04-02 21:39:06 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:188] Creating KafkaRebalance when CC doesn't have label for CO, the KR should be ignored
2022-04-02 21:39:06 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaRebalance my-cluster-8e8c768d in namespace multiple-co-cluster-test
2022-04-02 21:39:06 [main] [32mINFO [m [KafkaUtils:180] Waiting for cluster stability
2022-04-02 21:40:08 [main] [32mINFO [m [KafkaUtils:208] Kafka cluster is stable after 61 polls.
2022-04-02 21:40:08 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:204] Checking if KafkaRebalance is still ignored, after the cluster stability wait
2022-04-02 21:40:08 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:209] Adding {app.kubernetes.io/operator=second-strimzi-cluster-operator} selector of second-strimzi-cluster-operator to Kafka
2022-04-02 21:40:08 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:212] Waiting for Kafka to scales pods to 4
2022-04-02 21:40:08 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 4 Pod(s) of my-cluster-8e8c768d-kafka to be ready
2022-04-02 21:43:40 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-8e8c768d will have desired state: Ready
2022-04-02 21:43:40 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-8e8c768d is in desired state: Ready
2022-04-02 21:43:40 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-8e8c768d is ready
2022-04-02 21:43:40 [main] [32mINFO [m [KafkaRebalanceUtils:75] Reconciliation #8(test) KafkaRebalance(second-co-namespace/my-cluster-8e8c768d): ============================================================================
2022-04-02 21:43:40 [main] [32mINFO [m [KafkaRebalanceUtils:76] Reconciliation #8(test) KafkaRebalance(second-co-namespace/my-cluster-8e8c768d): ProposalReady
2022-04-02 21:43:40 [main] [32mINFO [m [KafkaRebalanceUtils:77] Reconciliation #8(test) KafkaRebalance(second-co-namespace/my-cluster-8e8c768d): ============================================================================
2022-04-02 21:43:40 [main] [32mINFO [m [KafkaRebalanceUtils:90] Reconciliation #8(test) KafkaRebalance(second-co-namespace/my-cluster-8e8c768d): ============================================================================
2022-04-02 21:43:40 [main] [32mINFO [m [KafkaRebalanceUtils:91] Reconciliation #8(test) KafkaRebalance(second-co-namespace/my-cluster-8e8c768d): ProposalReady
2022-04-02 21:43:40 [main] [32mINFO [m [KafkaRebalanceUtils:92] Reconciliation #8(test) KafkaRebalance(second-co-namespace/my-cluster-8e8c768d): ============================================================================
2022-04-02 21:43:40 [main] [32mINFO [m [KafkaRebalanceUtils:94] Reconciliation #8(test) KafkaRebalance(second-co-namespace/my-cluster-8e8c768d): Triggering the rebalance with annotation strimzi.io/rebalance=approve of KafkaRebalance resource
2022-04-02 21:43:40 [main] [32mINFO [m [KafkaRebalanceUtils:63] Reconciliation #8(test) KafkaRebalance(second-co-namespace/my-cluster-8e8c768d): Annotating KafkaRebalance:my-cluster-8e8c768d with annotation approve
2022-04-02 21:43:41 [main] [32mINFO [m [KafkaRebalanceUtils:98] Reconciliation #8(test) KafkaRebalance(second-co-namespace/my-cluster-8e8c768d): Response from the annotation process kafkarebalance.kafka.strimzi.io/my-cluster-8e8c768d annotated
2022-04-02 21:43:41 [main] [32mINFO [m [KafkaRebalanceUtils:100] Reconciliation #8(test) KafkaRebalance(second-co-namespace/my-cluster-8e8c768d): Verifying that annotation triggers the Rebalancing state
2022-04-02 21:43:41 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-8e8c768d will have desired state: Rebalancing
2022-04-02 21:43:42 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-8e8c768d is in desired state: Rebalancing
2022-04-02 21:43:42 [main] [32mINFO [m [KafkaRebalanceUtils:104] Reconciliation #8(test) KafkaRebalance(second-co-namespace/my-cluster-8e8c768d): Verifying that KafkaRebalance is in the Ready state
2022-04-02 21:43:42 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-8e8c768d will have desired state: Ready
2022-04-02 21:43:47 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-8e8c768d is in desired state: Ready
2022-04-02 21:43:47 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 21:43:47 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaCCAndRebalanceWithMultipleCOs
2022-04-02 21:43:47 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 21:43:47 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 21:43:47 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 21:43:47 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 21:43:47 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-02 21:43:47 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 21:43:47 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 21:43:47 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 21:43:47 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace multiple-co-cluster-test
2022-04-02 21:43:47 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 21:43:47 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 21:43:47 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-8e8c768d in namespace multiple-co-cluster-test
2022-04-02 21:43:47 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace multiple-co-cluster-test, for cruise control Kafka cluster my-cluster-8e8c768d
2022-04-02 21:43:47 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaRebalance my-cluster-8e8c768d in namespace multiple-co-cluster-test
2022-04-02 21:43:47 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment second-strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-02 21:43:57 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 21:43:57 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 21:43:57 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 21:43:57 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace multiple-co-cluster-test
2022-04-02 21:43:57 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 21:43:57 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-02 21:43:57 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-02 21:43:57 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 21:43:57 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 21:43:57 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment first-strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-02 21:43:57 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 21:43:57 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 21:43:57 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 21:43:57 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-02 21:43:57 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 21:43:57 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 21:43:57 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 21:43:57 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 21:43:57 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 21:43:57 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 21:43:57 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 21:43:57 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 21:43:57 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 21:43:57 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-02 21:43:57 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-02 21:43:57 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 21:43:57 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 21:43:57 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 21:43:57 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 21:43:57 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 21:43:57 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 21:43:57 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 21:43:57 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 21:43:57 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 21:44:07 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 21:44:07 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.MultipleClusterOperatorsIsolatedST.testKafkaCCAndRebalanceWithMultipleCOs-FINISHED
2022-04-02 21:44:07 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 21:44:07 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 21:44:07 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.MultipleClusterOperatorsIsolatedST.testMultipleCOsInDifferentNamespaces-STARTED
2022-04-02 21:44:07 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 21:44:07 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-02 21:44:07 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding first-strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 21:44:07 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding first-strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-02 21:44:07 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:230] Creating first-strimzi-cluster-operator in first-co-namespace namespace
2022-04-02 21:44:07 [main] [32mINFO [m [SetupClusterOperator:223] Cluster operator installation configuration:
SetupClusterOperator{cluster=io.strimzi.test.k8s.KubeClusterResource@38874b68, extensionContext=org.junit.jupiter.engine.descriptor.MethodExtensionContext@43eee868, clusterOperatorName='first-strimzi-cluster-operator', namespaceInstallTo='first-co-namespace', namespaceToWatch='*', bindingsNamespaces=[first-co-namespace], operationTimeout=300000, reconciliationInterval=30000, extraEnvVars=[EnvVar(name=STRIMZI_CUSTOM_RESOURCE_SELECTOR, value=app.kubernetes.io/operator=first-strimzi-cluster-operator, valueFrom=null, additionalProperties={})], extraLabels={app.kubernetes.io/operator=first-strimzi-cluster-operator}, clusterOperatorRBACType=CLUSTER, testClassName='null', testMethodName='null'}
2022-04-02 21:44:07 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-02 21:44:07 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: first-co-namespace
2022-04-02 21:44:07 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: first-co-namespace
2022-04-02 21:44:07 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace first-co-namespace
2022-04-02 21:44:07 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 21:44:07 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 21:44:07 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 21:44:07 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 21:44:07 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 21:44:07 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 21:44:07 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 21:44:07 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 21:44:07 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 21:44:07 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 21:44:07 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 21:44:07 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 21:44:07 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 21:44:07 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 21:44:07 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 21:44:07 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace first-co-namespace
2022-04-02 21:44:07 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: first-co-namespace
2022-04-02 21:44:07 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testMultipleCOsInDifferentNamespaces from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace first-co-namespace
2022-04-02 21:44:07 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 21:44:07 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testMultipleCOsInDifferentNamespaces from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace first-co-namespace
2022-04-02 21:44:07 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 21:44:07 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testMultipleCOsInDifferentNamespaces from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace first-co-namespace
2022-04-02 21:44:07 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 21:44:07 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case testMultipleCOsInDifferentNamespaces from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace first-co-namespace
2022-04-02 21:44:07 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace first-co-namespace
2022-04-02 21:44:07 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case testMultipleCOsInDifferentNamespaces from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace first-co-namespace
2022-04-02 21:44:07 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace first-co-namespace
2022-04-02 21:44:07 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-02 21:44:07 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-02 21:44:07 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 21:44:07 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-02 21:44:07 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment first-strimzi-cluster-operator in namespace first-co-namespace
2022-04-02 21:44:07 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: first-strimzi-cluster-operator will be ready
2022-04-02 21:44:32 [main] [32mINFO [m [DeploymentUtils:168] Deployment: first-strimzi-cluster-operator is ready
2022-04-02 21:44:32 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment first-strimzi-cluster-operator to be ready
2022-04-02 21:44:42 [main] [32mINFO [m [DeploymentUtils:197] Deployment first-strimzi-cluster-operator is ready
2022-04-02 21:44:42 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-02 21:44:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding second-strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 21:44:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding second-strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-02 21:44:42 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:230] Creating second-strimzi-cluster-operator in second-co-namespace namespace
2022-04-02 21:44:42 [main] [32mINFO [m [SetupClusterOperator:223] Cluster operator installation configuration:
SetupClusterOperator{cluster=io.strimzi.test.k8s.KubeClusterResource@38874b68, extensionContext=org.junit.jupiter.engine.descriptor.MethodExtensionContext@43eee868, clusterOperatorName='second-strimzi-cluster-operator', namespaceInstallTo='second-co-namespace', namespaceToWatch='*', bindingsNamespaces=[second-co-namespace], operationTimeout=300000, reconciliationInterval=30000, extraEnvVars=[EnvVar(name=STRIMZI_CUSTOM_RESOURCE_SELECTOR, value=app.kubernetes.io/operator=second-strimzi-cluster-operator, valueFrom=null, additionalProperties={})], extraLabels={app.kubernetes.io/operator=second-strimzi-cluster-operator}, clusterOperatorRBACType=CLUSTER, testClassName='null', testMethodName='null'}
2022-04-02 21:44:42 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-02 21:44:42 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: second-co-namespace
2022-04-02 21:44:42 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-co-namespace
2022-04-02 21:44:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace second-co-namespace
2022-04-02 21:44:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 21:44:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 21:44:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 21:44:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 21:44:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 21:44:42 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 21:44:42 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 21:44:42 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 21:44:42 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 21:44:42 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 21:44:42 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 21:44:42 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 21:44:42 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 21:44:42 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 21:44:42 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 21:44:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace second-co-namespace
2022-04-02 21:44:42 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: second-co-namespace
2022-04-02 21:44:42 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testMultipleCOsInDifferentNamespaces from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace second-co-namespace
2022-04-02 21:44:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 21:44:42 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testMultipleCOsInDifferentNamespaces from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace second-co-namespace
2022-04-02 21:44:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 21:44:42 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testMultipleCOsInDifferentNamespaces from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace second-co-namespace
2022-04-02 21:44:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 21:44:42 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case testMultipleCOsInDifferentNamespaces from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace second-co-namespace
2022-04-02 21:44:42 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace second-co-namespace
2022-04-02 21:44:42 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case testMultipleCOsInDifferentNamespaces from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace second-co-namespace
2022-04-02 21:44:42 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace second-co-namespace
2022-04-02 21:44:42 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-02 21:44:42 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-02 21:44:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 21:44:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-02 21:44:42 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment second-strimzi-cluster-operator in namespace second-co-namespace
2022-04-02 21:44:42 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: second-strimzi-cluster-operator will be ready
2022-04-02 21:45:00 [main] [32mINFO [m [DeploymentUtils:168] Deployment: second-strimzi-cluster-operator is ready
2022-04-02 21:45:00 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment second-strimzi-cluster-operator to be ready
2022-04-02 21:45:10 [main] [32mINFO [m [DeploymentUtils:197] Deployment second-strimzi-cluster-operator is ready
2022-04-02 21:45:10 [main] [33mWARN [m [KubeClusterResource:151] Namespace multiple-co-cluster-test is already created, going to delete it
2022-04-02 21:45:17 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: multiple-co-cluster-test
2022-04-02 21:45:17 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: multiple-co-cluster-test
2022-04-02 21:45:17 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: multiple-co-cluster-test
2022-04-02 21:45:17 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:100] Deploying Kafka without CR selector
2022-04-02 21:45:17 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-312e3443 in namespace multiple-co-cluster-test
2022-04-02 21:45:17 [main] [32mINFO [m [PodUtils:209] Wait until Pod my-cluster-312e3443 will have stable 0 replicas
2022-04-02 21:45:17 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 19 polls
2022-04-02 21:45:18 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 18 polls
2022-04-02 21:45:19 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 17 polls
2022-04-02 21:45:20 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 16 polls
2022-04-02 21:45:21 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 15 polls
2022-04-02 21:45:22 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 14 polls
2022-04-02 21:45:23 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 13 polls
2022-04-02 21:45:24 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 12 polls
2022-04-02 21:45:25 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 11 polls
2022-04-02 21:45:26 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 10 polls
2022-04-02 21:45:27 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 9 polls
2022-04-02 21:45:28 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 8 polls
2022-04-02 21:45:29 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 7 polls
2022-04-02 21:45:30 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 6 polls
2022-04-02 21:45:31 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 5 polls
2022-04-02 21:45:32 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 4 polls
2022-04-02 21:45:33 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 3 polls
2022-04-02 21:45:34 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 2 polls
2022-04-02 21:45:35 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 1 polls
2022-04-02 21:45:36 [main] [32mINFO [m [PodUtils:217] Pod replicas are stable for 20 polls intervals
2022-04-02 21:45:36 [main] [32mINFO [m [PodUtils:228] Pod my-cluster-312e3443 has 0 replicas
2022-04-02 21:45:36 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:110] Adding {app.kubernetes.io/operator=first-strimzi-cluster-operator} selector of first-strimzi-cluster-operator into Kafka CR
2022-04-02 21:45:36 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-312e3443 will have desired state: Ready
2022-04-02 21:46:58 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-312e3443 is in desired state: Ready
2022-04-02 21:46:58 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-423285569-1613830346 in namespace multiple-co-cluster-test
2022-04-02 21:46:58 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-312e3443 in namespace multiple-co-cluster-test
2022-04-02 21:46:58 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-423285569-1613830346 will have desired state: Ready
2022-04-02 21:46:59 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-423285569-1613830346 is in desired state: Ready
2022-04-02 21:46:59 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-312e3443 will have desired state: Ready
2022-04-02 21:48:04 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-312e3443 is in desired state: Ready
2022-04-02 21:48:04 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:130] Deploying KafkaConnector with file sink and CR selector - {app.kubernetes.io/operator=second-strimzi-cluster-operator} - different than selector in Kafka
2022-04-02 21:48:04 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-312e3443 in namespace multiple-co-cluster-test
2022-04-02 21:48:04 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-312e3443 will have desired state: Ready
2022-04-02 21:48:05 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-312e3443 is in desired state: Ready
2022-04-02 21:48:05 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-02 21:48:05 [main] [32mINFO [m [ResourceManager:155] Create/Update Job hello-world-producer in namespace multiple-co-cluster-test
2022-04-02 21:48:05 [main] [32mINFO [m [JobUtils:81] Waiting for job: hello-world-producer will be in active state
2022-04-02 21:48:06 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:hello-world-producer to finished
2022-04-02 21:48:14 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-312e3443-connect-c799cf998-mmm87
2022-04-02 21:48:14 [main] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-312e3443-connect-c799cf998-mmm87
2022-04-02 21:48:14 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 21:48:14 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMultipleCOsInDifferentNamespaces
2022-04-02 21:48:14 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 21:48:14 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 21:48:14 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 21:48:14 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 21:48:14 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 21:48:14 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 21:48:14 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-02 21:48:14 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Deployment second-strimzi-cluster-operator in namespace second-co-namespace
2022-04-02 21:48:14 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment first-strimzi-cluster-operator in namespace first-co-namespace
2022-04-02 21:48:14 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 21:48:14 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace first-co-namespace
2022-04-02 21:48:14 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding second-strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 21:48:14 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-312e3443 in namespace multiple-co-cluster-test
2022-04-02 21:48:14 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 21:48:14 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 21:48:14 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding second-strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-02 21:48:14 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 21:48:14 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace first-co-namespace
2022-04-02 21:48:14 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 21:48:14 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 21:48:14 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 21:48:14 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 21:48:14 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 21:48:14 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 21:48:14 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 21:48:14 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace second-co-namespace
2022-04-02 21:48:14 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 21:48:14 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 21:48:15 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 21:48:15 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 21:48:15 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding first-strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-02 21:48:15 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace first-co-namespace
2022-04-02 21:48:15 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding first-strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 21:48:15 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 21:48:15 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 21:48:24 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 21:48:24 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace first-co-namespace
2022-04-02 21:48:24 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 21:48:24 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 21:48:24 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 21:48:24 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 21:48:24 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 21:48:24 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-02 21:48:24 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace second-co-namespace
2022-04-02 21:48:24 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-312e3443 in namespace multiple-co-cluster-test
2022-04-02 21:48:24 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace second-co-namespace
2022-04-02 21:48:24 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Job hello-world-producer in namespace multiple-co-cluster-test
2022-04-02 21:48:24 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-423285569-1613830346 in namespace multiple-co-cluster-test
2022-04-02 21:48:24 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-312e3443 in namespace multiple-co-cluster-test
2022-04-02 21:48:24 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace second-co-namespace
2022-04-02 21:48:24 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 21:48:24 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 21:48:24 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 21:48:24 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 21:48:24 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 21:48:24 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 21:48:24 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 21:48:34 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 21:48:34 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 21:48:34 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 21:48:34 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.MultipleClusterOperatorsIsolatedST.testMultipleCOsInDifferentNamespaces-FINISHED
2022-04-02 21:48:34 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 21:48:34 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 21:48:34 [main] [32mINFO [m [ResourceManager:346] In context MultipleClusterOperatorsIsolatedST is everything deleted.
2022-04-02 21:48:34 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 803.065 s - in io.strimzi.systemtest.operators.MultipleClusterOperatorsIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.operators.ClusterOperatorRbacIsolatedST
2022-04-02 21:48:34 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-02 21:48:59 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 21:48:59 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.ClusterOperatorRbacIsolatedST.testCRBDeletionErrorsWhenRackAwarenessIsEnabled-STARTED
2022-04-02 21:48:59 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 21:48:59 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-02 21:48:59 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-02 21:48:59 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-02 21:48:59 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 21:48:59 [main] [32mINFO [m [ResourceManager:346] In context JUnit Jupiter is everything deleted.
2022-04-02 21:48:59 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 21:49:25 [main] [32mINFO [m [SetupClusterOperator:223] Cluster operator installation configuration:
SetupClusterOperator{cluster=io.strimzi.test.k8s.KubeClusterResource@38874b68, extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7e2e5e3d, clusterOperatorName='strimzi-cluster-operator', namespaceInstallTo='infra-namespace', namespaceToWatch='infra-namespace', bindingsNamespaces=[infra-namespace], operationTimeout=300000, reconciliationInterval=30000, extraEnvVars=[], extraLabels={}, clusterOperatorRBACType=NAMESPACE, testClassName='null', testMethodName='null'}
2022-04-02 21:49:25 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-02 21:49:25 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-02 21:49:25 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-02 21:49:25 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 21:49:25 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-ClusterRole-strimzi-cluster-operator-role.yaml
2022-04-02 21:49:25 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-cluster-operator-namespaced in namespace infra-namespace
2022-04-02 21:49:25 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRole-strimzi-cluster-operator-role.yaml
2022-04-02 21:49:25 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-cluster-operator-global in namespace infra-namespace
2022-04-02 21:49:25 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRole-strimzi-kafka-broker.yaml
2022-04-02 21:49:25 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-kafka-broker in namespace infra-namespace
2022-04-02 21:49:25 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-ClusterRole-strimzi-entity-operator.yaml
2022-04-02 21:49:25 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-entity-operator in namespace infra-namespace
2022-04-02 21:49:25 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRole-strimzi-kafka-client.yaml
2022-04-02 21:49:25 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-kafka-client in namespace infra-namespace
2022-04-02 21:49:25 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 21:49:26 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 21:49:26 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 21:49:26 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 21:49:26 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 21:49:26 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 21:49:26 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 21:49:26 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 21:49:26 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 21:49:26 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 21:49:26 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 21:49:26 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-02 21:49:26 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-ClusterRole-strimzi-cluster-operator-role.yaml
2022-04-02 21:49:26 [main] [32mINFO [m [RoleResource:43] Creating Role from /tmp/020-Role-strimzi-cluster-operator-role1842982137322229091.yaml in namespace infra-namespace
2022-04-02 21:49:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-cluster-operator-namespaced in namespace infra-namespace
2022-04-02 21:49:26 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRole-strimzi-cluster-operator-role.yaml
2022-04-02 21:49:26 [main] [32mINFO [m [RoleResource:43] Creating Role from /tmp/021-Role-strimzi-cluster-operator-role12451308438768750337.yaml in namespace infra-namespace
2022-04-02 21:49:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-cluster-operator-global in namespace infra-namespace
2022-04-02 21:49:26 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRole-strimzi-kafka-broker.yaml
2022-04-02 21:49:26 [main] [32mINFO [m [RoleResource:43] Creating Role from /tmp/030-Role-strimzi-kafka-broker11180251144536845041.yaml in namespace infra-namespace
2022-04-02 21:49:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-kafka-broker in namespace infra-namespace
2022-04-02 21:49:26 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-ClusterRole-strimzi-entity-operator.yaml
2022-04-02 21:49:26 [main] [32mINFO [m [RoleResource:43] Creating Role from /tmp/031-Role-strimzi-entity-operator4770446492045593050.yaml in namespace infra-namespace
2022-04-02 21:49:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-entity-operator in namespace infra-namespace
2022-04-02 21:49:26 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRole-strimzi-kafka-client.yaml
2022-04-02 21:49:26 [main] [32mINFO [m [RoleResource:43] Creating Role from /tmp/033-Role-strimzi-kafka-client775855026429050540.yaml in namespace infra-namespace
2022-04-02 21:49:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-kafka-client in namespace infra-namespace
2022-04-02 21:49:26 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml
2022-04-02 21:49:26 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /tmp/020-Role-strimzi-cluster-operator18013304257061688259.yaml in namespace infra-namespace
2022-04-02 21:49:26 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 21:49:26 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml
2022-04-02 21:49:26 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /tmp/031-Role-strimzi-cluster-operator-entity-operator-delegation15008261662602916652.yaml in namespace infra-namespace
2022-04-02 21:49:26 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 21:49:26 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml
2022-04-02 21:49:26 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /tmp/020-Role-strimzi-cluster-operator18063667235782305156.yaml in namespace infra-namespace
2022-04-02 21:49:26 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 21:49:26 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml
2022-04-02 21:49:26 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /tmp/031-Role-strimzi-cluster-operator-entity-operator-delegation9629124653211819221.yaml in namespace infra-namespace
2022-04-02 21:49:26 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 21:49:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 21:49:26 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-02 21:49:47 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-02 21:49:47 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-02 21:49:57 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-02 21:49:57 [main] [32mINFO [m [ClusterOperatorRbacIsolatedST:99] Deploying Kafka: my-cluster-bea7a30e, which should not be deployed and error should be present in CR status message
2022-04-02 21:49:57 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-bea7a30e in namespace infra-namespace
2022-04-02 21:50:29 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-bea7a30e-kafka-clients in namespace infra-namespace
2022-04-02 21:50:29 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-bea7a30e-kafka-clients will be ready
2022-04-02 21:50:31 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-bea7a30e-kafka-clients is ready
2022-04-02 21:50:31 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-bea7a30e-scraper in namespace infra-namespace
2022-04-02 21:50:31 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-bea7a30e-scraper will be ready
2022-04-02 21:50:33 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-bea7a30e-scraper is ready
2022-04-02 21:50:33 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-bea7a30e-scraper to be ready
2022-04-02 21:50:43 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-bea7a30e-scraper is ready
2022-04-02 21:50:43 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-bea7a30e-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-02 21:50:43 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-bea7a30e-allow in namespace infra-namespace
2022-04-02 21:50:43 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-02 21:50:43 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-bea7a30e in namespace infra-namespace
2022-04-02 21:50:44 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 21:50:44 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCRBDeletionErrorsWhenRackAwarenessIsEnabled
2022-04-02 21:50:44 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-bea7a30e-scraper in namespace infra-namespace
2022-04-02 21:50:44 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-bea7a30e-kafka-clients in namespace infra-namespace
2022-04-02 21:50:44 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-bea7a30e in namespace infra-namespace
2022-04-02 21:50:44 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-bea7a30e in namespace infra-namespace
2022-04-02 21:50:44 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-bea7a30e-allow in namespace infra-namespace
2022-04-02 21:51:34 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 21:51:34 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.ClusterOperatorRbacIsolatedST.testCRBDeletionErrorsWhenRackAwarenessIsEnabled-FINISHED
2022-04-02 21:51:34 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 21:51:34 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 21:51:34 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.ClusterOperatorRbacIsolatedST.testCRBDeletionErrorIsIgnoredWhenRackAwarenessIsNotEnabled-STARTED
2022-04-02 21:51:34 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 21:51:34 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-02 21:51:34 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-02 21:51:34 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-02 21:51:34 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 21:51:34 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-02 21:51:34 [main] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-cluster-operator-namespaced in namespace infra-namespace
2022-04-02 21:51:34 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-kafka-client in namespace infra-namespace
2022-04-02 21:51:34 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-entity-operator in namespace infra-namespace
2022-04-02 21:51:34 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 21:51:34 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 21:51:34 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-kafka-broker in namespace infra-namespace
2022-04-02 21:51:34 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 21:51:34 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-kafka-broker in namespace infra-namespace
2022-04-02 21:51:34 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 21:51:34 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 21:51:34 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-cluster-operator-global in namespace infra-namespace
2022-04-02 21:51:34 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 21:51:34 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 21:51:34 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 21:51:34 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 21:51:34 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-kafka-client in namespace infra-namespace
2022-04-02 21:51:34 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 21:51:34 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-cluster-operator-namespaced in namespace infra-namespace
2022-04-02 21:51:34 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-entity-operator in namespace infra-namespace
2022-04-02 21:51:34 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-cluster-operator-global in namespace infra-namespace
2022-04-02 21:51:34 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 21:51:35 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 21:51:35 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 21:51:44 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 21:51:44 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 21:51:44 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 21:51:44 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 21:51:55 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 21:52:00 [main] [32mINFO [m [SetupClusterOperator:223] Cluster operator installation configuration:
SetupClusterOperator{cluster=io.strimzi.test.k8s.KubeClusterResource@38874b68, extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7e2e5e3d, clusterOperatorName='strimzi-cluster-operator', namespaceInstallTo='infra-namespace', namespaceToWatch='infra-namespace', bindingsNamespaces=[infra-namespace], operationTimeout=300000, reconciliationInterval=30000, extraEnvVars=[], extraLabels={}, clusterOperatorRBACType=NAMESPACE, testClassName='null', testMethodName='null'}
2022-04-02 21:52:00 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-02 21:52:00 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-02 21:52:00 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-02 21:52:00 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 21:52:00 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-ClusterRole-strimzi-cluster-operator-role.yaml
2022-04-02 21:52:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-cluster-operator-namespaced in namespace infra-namespace
2022-04-02 21:52:00 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRole-strimzi-cluster-operator-role.yaml
2022-04-02 21:52:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-cluster-operator-global in namespace infra-namespace
2022-04-02 21:52:00 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRole-strimzi-kafka-broker.yaml
2022-04-02 21:52:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-kafka-broker in namespace infra-namespace
2022-04-02 21:52:00 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-ClusterRole-strimzi-entity-operator.yaml
2022-04-02 21:52:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-entity-operator in namespace infra-namespace
2022-04-02 21:52:00 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRole-strimzi-kafka-client.yaml
2022-04-02 21:52:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-kafka-client in namespace infra-namespace
2022-04-02 21:52:00 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 21:52:00 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 21:52:00 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 21:52:00 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 21:52:00 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 21:52:00 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 21:52:00 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 21:52:00 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 21:52:00 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 21:52:00 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 21:52:00 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 21:52:00 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-02 21:52:00 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-ClusterRole-strimzi-cluster-operator-role.yaml
2022-04-02 21:52:00 [main] [32mINFO [m [RoleResource:43] Creating Role from /tmp/020-Role-strimzi-cluster-operator-role7137016003071500536.yaml in namespace infra-namespace
2022-04-02 21:52:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-cluster-operator-namespaced in namespace infra-namespace
2022-04-02 21:52:00 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRole-strimzi-cluster-operator-role.yaml
2022-04-02 21:52:00 [main] [32mINFO [m [RoleResource:43] Creating Role from /tmp/021-Role-strimzi-cluster-operator-role12038334303748216716.yaml in namespace infra-namespace
2022-04-02 21:52:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-cluster-operator-global in namespace infra-namespace
2022-04-02 21:52:00 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRole-strimzi-kafka-broker.yaml
2022-04-02 21:52:00 [main] [32mINFO [m [RoleResource:43] Creating Role from /tmp/030-Role-strimzi-kafka-broker1050494751447203737.yaml in namespace infra-namespace
2022-04-02 21:52:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-kafka-broker in namespace infra-namespace
2022-04-02 21:52:00 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-ClusterRole-strimzi-entity-operator.yaml
2022-04-02 21:52:00 [main] [32mINFO [m [RoleResource:43] Creating Role from /tmp/031-Role-strimzi-entity-operator1867843518978124020.yaml in namespace infra-namespace
2022-04-02 21:52:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-entity-operator in namespace infra-namespace
2022-04-02 21:52:00 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRole-strimzi-kafka-client.yaml
2022-04-02 21:52:00 [main] [32mINFO [m [RoleResource:43] Creating Role from /tmp/033-Role-strimzi-kafka-client13995303373840946763.yaml in namespace infra-namespace
2022-04-02 21:52:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-kafka-client in namespace infra-namespace
2022-04-02 21:52:00 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml
2022-04-02 21:52:00 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /tmp/020-Role-strimzi-cluster-operator4368213444165112144.yaml in namespace infra-namespace
2022-04-02 21:52:00 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 21:52:00 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml
2022-04-02 21:52:00 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /tmp/031-Role-strimzi-cluster-operator-entity-operator-delegation18328223106776900788.yaml in namespace infra-namespace
2022-04-02 21:52:00 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 21:52:00 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml
2022-04-02 21:52:00 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /tmp/020-Role-strimzi-cluster-operator6274487954062988552.yaml in namespace infra-namespace
2022-04-02 21:52:00 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 21:52:00 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml
2022-04-02 21:52:00 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /tmp/031-Role-strimzi-cluster-operator-entity-operator-delegation3966053436587043514.yaml in namespace infra-namespace
2022-04-02 21:52:00 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 21:52:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 21:52:00 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-02 21:52:34 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-02 21:52:34 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-02 21:52:44 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-02 21:52:44 [main] [32mINFO [m [ClusterOperatorRbacIsolatedST:63] Deploying Kafka: my-cluster-9049bfc4, which should be deployed even the CRBs are not present
2022-04-02 21:52:44 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-9049bfc4 in namespace infra-namespace
2022-04-02 21:52:44 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-9049bfc4 will have desired state: Ready
2022-04-02 21:54:01 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-9049bfc4 is in desired state: Ready
2022-04-02 21:54:01 [main] [32mINFO [m [ClusterOperatorRbacIsolatedST:67] CO log should contain some information about ignoring forbidden access to CRB for Kafka
2022-04-02 21:54:01 [main] [32mINFO [m [ClusterOperatorRbacIsolatedST:71] Deploying KafkaConnect: my-cluster-9049bfc4 without rack awareness, the CR should be deployed without error
2022-04-02 21:54:01 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-9049bfc4 in namespace infra-namespace
2022-04-02 21:54:01 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-9049bfc4 will have desired state: Ready
2022-04-02 21:55:05 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-9049bfc4 is in desired state: Ready
2022-04-02 21:55:05 [main] [32mINFO [m [ClusterOperatorRbacIsolatedST:74] CO log should contain some information about ignoring forbidden access to CRB for KafkaConnect
2022-04-02 21:55:05 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 21:55:05 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCRBDeletionErrorIsIgnoredWhenRackAwarenessIsNotEnabled
2022-04-02 21:55:05 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-9049bfc4 in namespace infra-namespace
2022-04-02 21:55:05 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-9049bfc4 in namespace infra-namespace
2022-04-02 21:55:15 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 21:55:15 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.ClusterOperatorRbacIsolatedST.testCRBDeletionErrorIsIgnoredWhenRackAwarenessIsNotEnabled-FINISHED
2022-04-02 21:55:15 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 21:55:15 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 21:55:15 [main] [32mINFO [m [ResourceManager:346] In context ClusterOperatorRbacIsolatedST is everything deleted.
2022-04-02 21:55:15 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 401.008 s - in io.strimzi.systemtest.operators.ClusterOperatorRbacIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.bridge.HttpBridgeIsolatedST
2022-04-02 21:55:15 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-02 21:55:40 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-02 21:55:40 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-02 21:55:40 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-02 21:55:40 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 21:55:40 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-02 21:55:40 [main] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-cluster-operator-namespaced in namespace infra-namespace
2022-04-02 21:55:40 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 21:55:40 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 21:55:40 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-kafka-client in namespace infra-namespace
2022-04-02 21:55:40 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 21:55:40 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 21:55:40 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-entity-operator in namespace infra-namespace
2022-04-02 21:55:40 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-kafka-broker in namespace infra-namespace
2022-04-02 21:55:40 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 21:55:40 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 21:55:40 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 21:55:40 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-cluster-operator-global in namespace infra-namespace
2022-04-02 21:55:41 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-kafka-broker in namespace infra-namespace
2022-04-02 21:55:41 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-cluster-operator-namespaced in namespace infra-namespace
2022-04-02 21:55:41 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 21:55:41 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 21:55:41 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-cluster-operator-global in namespace infra-namespace
2022-04-02 21:55:41 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-kafka-client in namespace infra-namespace
2022-04-02 21:55:41 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 21:55:41 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-entity-operator in namespace infra-namespace
2022-04-02 21:55:41 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 21:55:41 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 21:55:41 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 21:55:50 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 21:55:50 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 21:55:51 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 21:55:51 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 21:56:01 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 21:56:06 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7e2e5e3d
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
, extraEnvVars=[EnvVar(name=STRIMZI_CUSTOM_KAFKA_BRIDGE_SERVICE_LABELS, value=app=bar, valueFrom=null, additionalProperties={}), EnvVar(name=STRIMZI_CUSTOM_KAFKA_BRIDGE_SERVICE_ANNOTATIONS, value=bar=app, valueFrom=null, additionalProperties={})]
2022-04-02 21:56:06 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-02 21:56:06 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-02 21:56:06 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-02 21:56:06 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 21:56:06 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 21:56:06 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 21:56:06 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 21:56:06 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 21:56:06 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 21:56:06 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 21:56:06 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 21:56:06 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 21:56:06 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 21:56:06 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 21:56:06 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 21:56:06 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 21:56:06 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 21:56:06 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 21:56:06 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 21:56:06 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 21:56:06 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-02 21:56:06 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 21:56:06 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 21:56:06 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-02 21:56:06 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 21:56:06 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-02 21:56:06 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 21:56:06 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 21:56:06 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 21:56:06 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-02 21:56:06 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 21:56:06 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-02 21:56:06 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-02 21:56:06 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 21:56:06 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-02 21:56:07 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 21:56:07 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-02 21:56:47 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-02 21:56:47 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-02 21:56:57 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-02 21:56:57 [main] [32mINFO [m [HttpBridgeIsolatedST:434] Deploy Kafka and KafkaBridge before tests
2022-04-02 21:56:57 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka http-bridge-cluster-name in namespace infra-namespace
2022-04-02 21:56:57 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: http-bridge-cluster-name will have desired state: Ready
2022-04-02 21:58:14 [main] [32mINFO [m [ResourceManager:444] Kafka: http-bridge-cluster-name is in desired state: Ready
2022-04-02 21:58:14 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment infra-namespace-shared-kafka-clients in namespace infra-namespace
2022-04-02 21:58:14 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: infra-namespace-shared-kafka-clients will be ready
2022-04-02 21:58:16 [main] [32mINFO [m [DeploymentUtils:168] Deployment: infra-namespace-shared-kafka-clients is ready
2022-04-02 21:58:16 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge http-bridge-cluster-name in namespace infra-namespace
2022-04-02 21:58:16 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: http-bridge-cluster-name will have desired state: Ready
2022-04-02 21:58:36 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: http-bridge-cluster-name is in desired state: Ready
2022-04-02 21:58:36 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 21:58:36 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testReceiveSimpleMessage-STARTED
2022-04-02 21:58:36 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 21:58:36 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1327365380-311629952 in namespace infra-namespace
2022-04-02 21:58:36 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1327365380-311629952 will have desired state: Ready
2022-04-02 21:58:37 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1327365380-311629952 is in desired state: Ready
2022-04-02 21:58:37 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-02 21:58:37 [main] [32mINFO [m [ResourceManager:155] Create/Update Job consumer-359589395 in namespace infra-namespace
2022-04-02 21:58:37 [main] [32mINFO [m [JobUtils:81] Waiting for job: consumer-359589395 will be in active state
2022-04-02 21:58:38 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-02 21:58:38 [main] [32mINFO [m [ResourceManager:155] Create/Update Job producer-1674478479 in namespace infra-namespace
2022-04-02 21:58:38 [main] [32mINFO [m [JobUtils:81] Waiting for job: producer-1674478479 will be in active state
2022-04-02 21:58:39 [main] [32mINFO [m [ClientUtils:61] Waiting till producer producer-1674478479 and consumer consumer-359589395 finish
2022-04-02 21:58:50 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 21:58:50 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testReceiveSimpleMessage
2022-04-02 21:58:50 [main] [32mINFO [m [ResourceManager:241] Delete of Job consumer-359589395 in namespace infra-namespace
2022-04-02 21:58:50 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job producer-1674478479 in namespace infra-namespace
2022-04-02 21:58:50 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1327365380-311629952 in namespace infra-namespace
2022-04-02 21:59:00 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 21:59:00 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testReceiveSimpleMessage-FINISHED
2022-04-02 21:59:00 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 21:59:00 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 21:59:00 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testConfigureDeploymentStrategy-STARTED
2022-04-02 21:59:00 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 21:59:00 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge example-bridge in namespace infra-namespace
2022-04-02 21:59:00 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: example-bridge will have desired state: Ready
2022-04-02 21:59:26 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: example-bridge is in desired state: Ready
2022-04-02 21:59:26 [main] [32mINFO [m [HttpBridgeIsolatedST:351] Adding label to KafkaBridge resource, the CR should be recreated
2022-04-02 21:59:26 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: example-bridge-bridge will be ready
2022-04-02 21:59:26 [main] [32mINFO [m [DeploymentUtils:168] Deployment: example-bridge-bridge is ready
2022-04-02 21:59:26 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment example-bridge-bridge to be ready
2022-04-02 22:00:05 [main] [32mINFO [m [DeploymentUtils:197] Deployment example-bridge-bridge is ready
2022-04-02 22:00:05 [main] [32mINFO [m [HttpBridgeIsolatedST:358] Checking that observed gen. is still on 1 (recreation) and new label is present
2022-04-02 22:00:05 [main] [32mINFO [m [HttpBridgeIsolatedST:363] Changing deployment strategy to ROLLING_UPDATE
2022-04-02 22:00:05 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: example-bridge will have desired state: Ready
2022-04-02 22:00:05 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: example-bridge is in desired state: Ready
2022-04-02 22:00:05 [main] [32mINFO [m [HttpBridgeIsolatedST:368] Adding another label to KafkaBridge resource, pods should be rolled
2022-04-02 22:00:05 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: example-bridge-bridge will be ready
2022-04-02 22:00:05 [main] [32mINFO [m [DeploymentUtils:168] Deployment: example-bridge-bridge is ready
2022-04-02 22:00:05 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment example-bridge-bridge to be ready
2022-04-02 22:00:50 [main] [32mINFO [m [DeploymentUtils:197] Deployment example-bridge-bridge is ready
2022-04-02 22:00:50 [main] [32mINFO [m [HttpBridgeIsolatedST:372] Checking that observed gen. higher (rolling update) and label is changed
2022-04-02 22:00:50 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 22:00:50 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testConfigureDeploymentStrategy
2022-04-02 22:00:50 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge example-bridge in namespace infra-namespace
2022-04-02 22:01:00 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 22:01:00 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testConfigureDeploymentStrategy-FINISHED
2022-04-02 22:01:00 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 22:01:00 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 22:01:00 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testScaleBridgeToZero-STARTED
2022-04-02 22:01:00 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 22:01:00 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge scaling-bridge-down in namespace infra-namespace
2022-04-02 22:01:00 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: scaling-bridge-down will have desired state: Ready
2022-04-02 22:01:21 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: scaling-bridge-down is in desired state: Ready
2022-04-02 22:01:21 [main] [32mINFO [m [HttpBridgeIsolatedST:285] Scaling KafkaBridge to zero replicas
2022-04-02 22:01:21 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: http-bridge-cluster-name will have desired state: Ready
2022-04-02 22:01:21 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: http-bridge-cluster-name is in desired state: Ready
2022-04-02 22:01:24 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 22:01:24 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testScaleBridgeToZero
2022-04-02 22:01:24 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge scaling-bridge-down in namespace infra-namespace
2022-04-02 22:01:34 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 22:01:34 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testScaleBridgeToZero-FINISHED
2022-04-02 22:01:34 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 22:01:34 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 22:01:34 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testDiscoveryAnnotation-STARTED
2022-04-02 22:01:34 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 22:01:34 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 22:01:34 [main] [32mINFO [m [ResourceManager:346] In context testDiscoveryAnnotation is everything deleted.
2022-04-02 22:01:34 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 22:01:34 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testDiscoveryAnnotation-FINISHED
2022-04-02 22:01:34 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 22:01:34 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 22:01:34 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testCustomBridgeLabelsAreProperlySet-STARTED
2022-04-02 22:01:34 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 22:01:34 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge bridge-my-cluster-d395bd3a in namespace infra-namespace
2022-04-02 22:01:34 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: bridge-my-cluster-d395bd3a will have desired state: Ready
2022-04-02 22:01:52 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: bridge-my-cluster-d395bd3a is in desired state: Ready
2022-04-02 22:01:52 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 22:01:52 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCustomBridgeLabelsAreProperlySet
2022-04-02 22:01:52 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge bridge-my-cluster-d395bd3a in namespace infra-namespace
2022-04-02 22:02:02 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 22:02:02 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testCustomBridgeLabelsAreProperlySet-FINISHED
2022-04-02 22:02:02 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 22:02:02 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 22:02:02 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testScaleBridgeSubresource-STARTED
2022-04-02 22:02:02 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 22:02:02 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge scaling-bridge-up in namespace infra-namespace
2022-04-02 22:02:02 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: scaling-bridge-up will have desired state: Ready
2022-04-02 22:02:29 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: scaling-bridge-up is in desired state: Ready
2022-04-02 22:02:29 [main] [32mINFO [m [HttpBridgeIsolatedST:312] -------> Scaling KafkaBridge subresource <-------
2022-04-02 22:02:29 [main] [32mINFO [m [HttpBridgeIsolatedST:313] Scaling subresource replicas to 4
2022-04-02 22:02:29 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: scaling-bridge-up-bridge will be ready
2022-04-02 22:02:29 [main] [32mINFO [m [DeploymentUtils:168] Deployment: scaling-bridge-up-bridge is ready
2022-04-02 22:02:29 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 4 Pod(s) of Deployment scaling-bridge-up-bridge to be ready
2022-04-02 22:03:04 [main] [32mINFO [m [DeploymentUtils:197] Deployment scaling-bridge-up-bridge is ready
2022-04-02 22:03:04 [main] [32mINFO [m [HttpBridgeIsolatedST:317] Check if replicas is set to 4, naming prefix should be same and observed generation higher
2022-04-02 22:03:04 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 22:03:04 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testScaleBridgeSubresource
2022-04-02 22:03:04 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge scaling-bridge-up in namespace infra-namespace
2022-04-02 22:03:14 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 22:03:14 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testScaleBridgeSubresource-FINISHED
2022-04-02 22:03:14 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 22:03:14 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 22:03:14 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testCustomAndUpdatedValues-STARTED
2022-04-02 22:03:14 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 22:03:14 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge custom-bridge in namespace infra-namespace
2022-04-02 22:03:14 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: custom-bridge will have desired state: Ready
2022-04-02 22:03:50 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: custom-bridge is in desired state: Ready
2022-04-02 22:03:50 [main] [32mINFO [m [HttpBridgeIsolatedST:225] Verify values before update
2022-04-02 22:03:50 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix custom-bridge-bridge in pod name
2022-04-02 22:03:50 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container custom-bridge-bridge
2022-04-02 22:03:50 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name custom-bridge-bridge
2022-04-02 22:03:50 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container custom-bridge-bridge
2022-04-02 22:03:50 [main] [32mINFO [m [HttpBridgeIsolatedST:230] Check if actual env variable KAFKA_BRIDGE_PRODUCER_CONFIG has different value than test.value
2022-04-02 22:03:50 [main] [32mINFO [m [HttpBridgeIsolatedST:236] Updating values in Bridge container
2022-04-02 22:03:50 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment custom-bridge-bridge rolling update
2022-04-02 22:04:36 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: custom-bridge-bridge will be ready
2022-04-02 22:04:36 [main] [32mINFO [m [DeploymentUtils:168] Deployment: custom-bridge-bridge is ready
2022-04-02 22:04:46 [main] [32mINFO [m [DeploymentUtils:141] Deployment custom-bridge-bridge rolling update finished
2022-04-02 22:04:46 [main] [32mINFO [m [HttpBridgeIsolatedST:253] Verify values after update
2022-04-02 22:04:46 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix custom-bridge-bridge in pod name
2022-04-02 22:04:46 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container custom-bridge-bridge
2022-04-02 22:04:46 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name custom-bridge-bridge
2022-04-02 22:04:46 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container custom-bridge-bridge
2022-04-02 22:04:46 [main] [32mINFO [m [AbstractST:190] Getting pods by prefix in name custom-bridge-bridge
2022-04-02 22:04:46 [main] [32mINFO [m [AbstractST:194] Testing configuration for container custom-bridge-bridge
2022-04-02 22:04:46 [main] [32mINFO [m [AbstractST:190] Getting pods by prefix in name custom-bridge-bridge
2022-04-02 22:04:46 [main] [32mINFO [m [AbstractST:194] Testing configuration for container custom-bridge-bridge
2022-04-02 22:04:46 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 22:04:46 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCustomAndUpdatedValues
2022-04-02 22:04:46 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge custom-bridge in namespace infra-namespace
2022-04-02 22:04:56 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 22:04:56 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testCustomAndUpdatedValues-FINISHED
2022-04-02 22:04:56 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 22:04:56 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 22:04:56 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testSendSimpleMessage-STARTED
2022-04-02 22:04:56 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 22:04:56 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-02 22:04:56 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1066501876-1812334230 in namespace infra-namespace
2022-04-02 22:04:56 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1066501876-1812334230 will have desired state: Ready
2022-04-02 22:04:57 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1066501876-1812334230 is in desired state: Ready
2022-04-02 22:04:57 [main] [32mINFO [m [ResourceManager:155] Create/Update Job producer-42960152 in namespace infra-namespace
2022-04-02 22:04:57 [main] [32mINFO [m [JobUtils:81] Waiting for job: producer-42960152 will be in active state
2022-04-02 22:04:58 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:producer-42960152 to finished
2022-04-02 22:06:46 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-02 22:06:46 [main] [32mINFO [m [ResourceManager:155] Create/Update Job consumer-897570410 in namespace infra-namespace
2022-04-02 22:06:46 [main] [32mINFO [m [JobUtils:81] Waiting for job: consumer-897570410 will be in active state
2022-04-02 22:06:47 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:consumer-897570410 to finished
2022-04-02 22:06:57 [main] [32mINFO [m [AbstractST:311] Verifying labels on pod type my-bridge
2022-04-02 22:06:57 [main] [32mINFO [m [AbstractST:356] Verifying labels for Kafka Connect Services
2022-04-02 22:06:57 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 22:06:57 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSendSimpleMessage
2022-04-02 22:06:57 [main] [32mINFO [m [ResourceManager:241] Delete of Job producer-42960152 in namespace infra-namespace
2022-04-02 22:06:57 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job consumer-897570410 in namespace infra-namespace
2022-04-02 22:06:57 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1066501876-1812334230 in namespace infra-namespace
2022-04-02 22:07:07 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 22:07:07 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testSendSimpleMessage-FINISHED
2022-04-02 22:07:07 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 22:07:07 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 22:07:07 [main] [32mINFO [m [ResourceManager:348] Delete all resources for HttpBridgeIsolatedST
2022-04-02 22:07:07 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment infra-namespace-shared-kafka-clients in namespace infra-namespace
2022-04-02 22:07:07 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge http-bridge-cluster-name in namespace infra-namespace
2022-04-02 22:07:07 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka http-bridge-cluster-name in namespace infra-namespace
2022-04-02 22:07:57 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 761.778 s - in io.strimzi.systemtest.bridge.HttpBridgeIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.specific.HelmChartIsolatedST
2022-04-02 22:07:57 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-02 22:08:22 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-02 22:08:22 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-02 22:08:22 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-02 22:08:22 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 22:08:22 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-02 22:08:22 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 22:08:22 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 22:08:22 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 22:08:22 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 22:08:22 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 22:08:22 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 22:08:22 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 22:08:22 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 22:08:22 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 22:08:22 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 22:08:22 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 22:08:22 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 22:08:22 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 22:08:22 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 22:08:22 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 22:08:22 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 22:08:22 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 22:08:22 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 22:08:22 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 22:08:32 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 22:08:32 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-02 22:08:32 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 22:08:32 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 22:08:32 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 22:08:32 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 22:08:42 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 22:08:48 [main] [32mINFO [m [HelmChartIsolatedST:67] Creating resources before the test class
2022-04-02 22:08:48 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-02 22:08:48 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-02 22:08:48 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: kube-system
2022-04-02 22:08:48 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace kube-system apply -f -
2022-04-02 22:08:48 [main] [32mINFO [m [Exec:417] Input: apiVersion: v1
kind: ServiceAccount
metadata:
  name: tiller
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: tiller
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
  - kind: ServiceAccount
    name: tiller
    namespace: kube-system
2022-04-02 22:08:48 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 22:08:48 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-02 22:08:48 [main] [1;31mERROR[m [TestExecutionWatcher:39] HelmChartIsolatedST - Exception No helm client found on $PATH. $PATH=/home/ec2-user/.sdkman/candidates/maven/current/bin:/home/ec2-user/.local/bin:/home/ec2-user/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin has been thrown in @BeforeAll. Going to collect logs from components.
2022-04-02 22:08:48 [main] [32mINFO [m [LogCollector:252] Collecting events in Namespace infra-namespace
2022-04-02 22:08:48 [main] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace infra-namespace
2022-04-02 22:08:48 [main] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace infra-namespace
2022-04-02 22:08:48 [main] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace infra-namespace
2022-04-02 22:08:48 [main] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace infra-namespace
2022-04-02 22:08:49 [main] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace infra-namespace
2022-04-02 22:08:49 [main] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace infra-namespace
2022-04-02 22:08:49 [main] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-04-02 22:08:49 [main] [1;31mERROR[m [TestExecutionWatcher:70] HelmChartIsolatedST - Exception No helm client found on $PATH. $PATH=/home/ec2-user/.sdkman/candidates/maven/current/bin:/home/ec2-user/.local/bin:/home/ec2-user/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin has been thrown in @AfterAll. Going to collect logs from components.
2022-04-02 22:08:49 [main] [32mINFO [m [LogCollector:252] Collecting events in Namespace infra-namespace
2022-04-02 22:08:49 [main] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace infra-namespace
2022-04-02 22:08:49 [main] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace infra-namespace
2022-04-02 22:08:49 [main] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace infra-namespace
2022-04-02 22:08:49 [main] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace infra-namespace
2022-04-02 22:08:49 [main] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace infra-namespace
2022-04-02 22:08:49 [main] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace infra-namespace
2022-04-02 22:08:49 [main] [32mINFO [m [LogCollector:287] Collecting cluster status
[[1;31mERROR[m] Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 52.274 s <<< FAILURE! - in io.strimzi.systemtest.specific.HelmChartIsolatedST
[[1;31mERROR[m] io.strimzi.systemtest.specific.HelmChartIsolatedST  Time elapsed: 52.274 s  <<< ERROR!
java.lang.RuntimeException: No helm client found on $PATH. $PATH=/home/ec2-user/.sdkman/candidates/maven/current/bin:/home/ec2-user/.local/bin:/home/ec2-user/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin
	at io.strimzi.test.k8s.HelmClient.findClient(HelmClient.java:108)
	at io.strimzi.test.k8s.KubeClusterResource.helmClient(KubeClusterResource.java:354)
	at io.strimzi.test.k8s.KubeClusterResource.helmClusterClient(KubeClusterResource.java:129)
	at io.strimzi.systemtest.resources.ResourceManager.helmClient(ResourceManager.java:116)
	at io.strimzi.systemtest.resources.operator.specific.HelmResource.clusterOperator(HelmResource.java:104)
	at io.strimzi.systemtest.resources.operator.specific.HelmResource.create(HelmResource.java:55)
	at io.strimzi.systemtest.resources.operator.specific.HelmResource.create(HelmResource.java:49)
	at io.strimzi.systemtest.specific.HelmChartIsolatedST.setup(HelmChartIsolatedST.java:70)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptLifecycleMethod(TimeoutExtension.java:126)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptBeforeAllMethod(TimeoutExtension.java:68)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$invokeBeforeAllMethods$11(ClassBasedTestDescriptor.java:397)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.invokeBeforeAllMethods(ClassBasedTestDescriptor.java:395)
	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.before(ClassBasedTestDescriptor.java:209)
	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.before(ClassBasedTestDescriptor.java:80)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:148)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
	Suppressed: java.lang.RuntimeException: No helm client found on $PATH. $PATH=/home/ec2-user/.sdkman/candidates/maven/current/bin:/home/ec2-user/.local/bin:/home/ec2-user/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin
		at io.strimzi.test.k8s.HelmClient.findClient(HelmClient.java:108)
		at io.strimzi.test.k8s.KubeClusterResource.helmClient(KubeClusterResource.java:354)
		at io.strimzi.test.k8s.KubeClusterResource.helmClusterClient(KubeClusterResource.java:129)
		at io.strimzi.systemtest.resources.ResourceManager.helmClient(ResourceManager.java:116)
		at io.strimzi.systemtest.resources.operator.specific.HelmResource.deleteClusterOperator(HelmResource.java:129)
		at io.strimzi.systemtest.resources.operator.specific.HelmResource.delete(HelmResource.java:60)
		at io.strimzi.systemtest.specific.HelmChartIsolatedST.afterAllMayOverride(HelmChartIsolatedST.java:76)
		at io.strimzi.systemtest.AbstractST.tearDownTestSuite(AbstractST.java:691)
		at jdk.internal.reflect.GeneratedMethodAccessor1239.invoke(Unknown Source)
		at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
		at java.base/java.lang.reflect.Method.invoke(Method.java:566)
		at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
		at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
		at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
		at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
		at org.junit.jupiter.engine.extension.TimeoutExtension.interceptLifecycleMethod(TimeoutExtension.java:126)
		at org.junit.jupiter.engine.extension.TimeoutExtension.interceptAfterAllMethod(TimeoutExtension.java:116)
		at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
		at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
		at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
		at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
		at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
		at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
		at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
		at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
		at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$invokeAfterAllMethods$13(ClassBasedTestDescriptor.java:425)
		at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
		at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$invokeAfterAllMethods$14(ClassBasedTestDescriptor.java:423)
		at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
		at java.base/java.util.Collections$UnmodifiableCollection.forEach(Collections.java:1085)
		at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.invokeAfterAllMethods(ClassBasedTestDescriptor.java:423)
		at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.after(ClassBasedTestDescriptor.java:225)
		at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.after(ClassBasedTestDescriptor.java:80)
		at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$7(NodeTestTask.java:161)
		at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
		at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:161)
		... 64 more

[[1;34mINFO[m] Running io.strimzi.systemtest.specific.SpecificIsolatedST
2022-04-02 22:08:50 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-02 22:09:15 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-02 22:09:15 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-02 22:09:15 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-02 22:09:15 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 22:09:15 [main] [32mINFO [m [ResourceManager:346] In context JUnit Jupiter is everything deleted.
2022-04-02 22:09:15 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 22:09:20 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7e2e5e3d
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-02 22:09:20 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-02 22:09:20 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-02 22:09:20 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-02 22:09:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 22:09:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 22:09:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 22:09:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 22:09:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 22:09:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 22:09:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 22:09:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 22:09:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 22:09:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 22:09:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 22:09:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 22:09:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 22:09:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 22:09:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 22:09:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 22:09:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 22:09:20 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-02 22:09:20 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 22:09:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 22:09:20 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-02 22:09:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 22:09:20 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-02 22:09:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 22:09:20 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 22:09:20 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 22:09:20 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-02 22:09:20 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 22:09:20 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-02 22:09:20 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-02 22:09:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 22:09:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-02 22:09:20 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 22:09:20 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-02 22:09:43 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-02 22:09:43 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-02 22:09:53 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-02 22:09:53 [main] [32mINFO [m [SpecificIsolatedST:508] 0.21.4
2022-04-02 22:09:53 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 22:09:53 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.specific.SpecificIsolatedST.testRackAware-STARTED
2022-04-02 22:09:53 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 22:09:53 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-fc35e275 in namespace infra-namespace
2022-04-02 22:09:53 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-fc35e275 will have desired state: Ready
2022-04-02 22:11:00 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-fc35e275 is in desired state: Ready
2022-04-02 22:11:00 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-fc35e275-kafka-0 -- /bin/bash -c cat /opt/kafka/init/rack.id
2022-04-02 22:11:00 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 22:11:00 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-fc35e275-kafka-0 -- /bin/bash -c cat /tmp/strimzi.properties | grep broker.rack
2022-04-02 22:11:00 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 22:11:00 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-02 22:11:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Job hello-world-producer in namespace infra-namespace
2022-04-02 22:11:00 [main] [32mINFO [m [JobUtils:81] Waiting for job: hello-world-producer will be in active state
2022-04-02 22:11:01 [main] [32mINFO [m [ResourceManager:155] Create/Update Job hello-world-consumer in namespace infra-namespace
2022-04-02 22:11:01 [main] [32mINFO [m [JobUtils:81] Waiting for job: hello-world-consumer will be in active state
2022-04-02 22:11:02 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 22:11:02 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRackAware
2022-04-02 22:11:02 [main] [32mINFO [m [ResourceManager:241] Delete of Job hello-world-producer in namespace infra-namespace
2022-04-02 22:11:02 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-fc35e275 in namespace infra-namespace
2022-04-02 22:11:02 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Job hello-world-consumer in namespace infra-namespace
2022-04-02 22:11:12 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 22:11:12 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.specific.SpecificIsolatedST.testRackAware-FINISHED
2022-04-02 22:11:12 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 22:11:12 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 22:11:12 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.specific.SpecificIsolatedST.testRackAwareConnectWrongDeployment-STARTED
2022-04-02 22:11:12 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 22:11:12 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-02 22:11:12 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-02 22:11:12 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-02 22:11:12 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 22:11:12 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-02 22:11:12 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 22:11:12 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 22:11:12 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 22:11:12 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 22:11:12 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 22:11:12 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 22:11:12 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 22:11:12 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 22:11:12 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 22:11:12 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 22:11:12 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 22:11:12 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 22:11:12 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 22:11:12 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 22:11:12 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 22:11:12 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 22:11:12 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 22:11:12 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 22:11:22 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 22:11:22 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 22:11:22 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 22:11:22 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-02 22:11:22 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 22:11:22 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 22:11:22 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 22:11:32 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 22:11:37 [main] [32mINFO [m [SetupClusterOperator:223] Cluster operator installation configuration:
SetupClusterOperator{cluster=io.strimzi.test.k8s.KubeClusterResource@38874b68, extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7e2e5e3d, clusterOperatorName='strimzi-cluster-operator', namespaceInstallTo='infra-namespace', namespaceToWatch='infra-namespace', bindingsNamespaces=[infra-namespace], operationTimeout=30000, reconciliationInterval=30000, extraEnvVars=[], extraLabels={}, clusterOperatorRBACType=CLUSTER, testClassName='null', testMethodName='null'}
2022-04-02 22:11:37 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-02 22:11:37 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-02 22:11:37 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-02 22:11:38 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 22:11:38 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 22:11:38 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 22:11:38 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 22:11:38 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 22:11:38 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 22:11:38 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 22:11:38 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 22:11:38 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 22:11:38 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 22:11:38 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 22:11:38 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 22:11:38 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 22:11:38 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 22:11:38 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 22:11:38 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 22:11:38 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 22:11:38 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-02 22:11:38 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 22:11:38 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 22:11:38 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-02 22:11:38 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 22:11:38 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-02 22:11:38 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 22:11:38 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 22:11:38 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 22:11:38 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-02 22:11:38 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 22:11:38 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 22:11:38 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-02 22:12:13 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-02 22:12:13 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-02 22:12:23 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-02 22:12:23 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment strimzi-cluster-operator rolling update
2022-04-02 22:12:23 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-02 22:12:23 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-02 22:12:33 [main] [32mINFO [m [DeploymentUtils:141] Deployment strimzi-cluster-operator rolling update finished
2022-04-02 22:12:33 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-40841ac1 in namespace infra-namespace
2022-04-02 22:12:33 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-40841ac1 will have desired state: Ready
2022-04-02 22:13:59 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-40841ac1 is in desired state: Ready
2022-04-02 22:13:59 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-40841ac1-kafka-clients in namespace infra-namespace
2022-04-02 22:13:59 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-40841ac1-kafka-clients will be ready
2022-04-02 22:14:00 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-40841ac1-kafka-clients is ready
2022-04-02 22:14:00 [main] [32mINFO [m [SpecificIsolatedST:196] Deploy KafkaConnect with wrong rack-aware topology key: wrong-key
2022-04-02 22:14:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-40841ac1-scraper in namespace infra-namespace
2022-04-02 22:14:00 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-40841ac1-scraper will be ready
2022-04-02 22:14:01 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-40841ac1-scraper is ready
2022-04-02 22:14:02 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-40841ac1-scraper to be ready
2022-04-02 22:14:12 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-40841ac1-scraper is ready
2022-04-02 22:14:12 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-40841ac1-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-02 22:14:12 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-40841ac1-allow in namespace infra-namespace
2022-04-02 22:14:12 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-02 22:14:12 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-40841ac1 in namespace infra-namespace
2022-04-02 22:14:12 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-40841ac1-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-02 22:14:12 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-40841ac1-allow in namespace infra-namespace
2022-04-02 22:14:12 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-02 22:14:12 [main] [32mINFO [m [PodUtils:277] Wait for at least one pod with prefix: my-cluster-40841ac1-connect will be in pending phase
2022-04-02 22:14:13 [main] [32mINFO [m [SpecificIsolatedST:227] Waiting for ClusterOperator to get timeout operation of incorrectly set up KafkaConnect
2022-04-02 22:14:44 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-40841ac1 will have desired state: Ready
2022-04-02 22:16:25 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-40841ac1 is in desired state: Ready
2022-04-02 22:16:25 [main] [32mINFO [m [SpecificIsolatedST:238] KafkaConnect is ready with changed rack key: 'rack-key'.
2022-04-02 22:16:25 [main] [32mINFO [m [SpecificIsolatedST:239] Verify KafkaConnect rack key update
2022-04-02 22:16:25 [main] [32mINFO [m [KafkaConnectUtils:156] Send and receive messages through KafkaConnect
2022-04-02 22:16:25 [main] [32mINFO [m [KafkaConnectUtils:63] Waiting until KafkaConnect API is available
2022-04-02 22:16:25 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-40841ac1-connect-c4b7cb586-w449h -- /bin/bash -c curl -I http://localhost:8083/connectors
2022-04-02 22:16:25 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 22:16:25 [main] [32mINFO [m [KafkaConnectUtils:66] KafkaConnect API is available
2022-04-02 22:16:26 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-40841ac1-scraper-c45584896-4kv76 -- /bin/bash -c curl -X POST -H "Content-Type: application/json" --data '{ "name": "sink-test", "config": { "connector.class": "FileStreamSink", "tasks.max": "1", "topics": "my-topic-467311057-683530871", "file": "/tmp/test-file-sink.txt" } }' http://my-cluster-40841ac1-connect-api.infra-namespace.svc:8083/connectors
2022-04-02 22:16:26 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 22:16:26 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-02 22:16:26 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@29d29602, messages=[], arguments=[--max-messages, 100, --topic, my-topic-467311057-683530871, --bootstrap-server, my-cluster-40841ac1-kafka-bootstrap.infra-namespace.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-40841ac1-kafka-clients-cdbf79f49-sxm7l', podNamespace='infra-namespace', bootstrapServer='my-cluster-40841ac1-kafka-bootstrap.infra-namespace.svc:9092', topicName='my-topic-467311057-683530871', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@4674c758}
2022-04-02 22:16:26 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-40841ac1-kafka-bootstrap.infra-namespace.svc:9092:my-topic-467311057-683530871 from pod my-cluster-40841ac1-kafka-clients-cdbf79f49-sxm7l
2022-04-02 22:16:26 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-40841ac1-kafka-clients-cdbf79f49-sxm7l -n infra-namespace -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-467311057-683530871 --bootstrap-server my-cluster-40841ac1-kafka-bootstrap.infra-namespace.svc:9092
2022-04-02 22:16:28 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-02 22:16:28 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-02 22:16:28 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@68a767e, messages=[], arguments=[--max-messages, 100, --group-instance-id, instance1328819279, --group-id, my-consumer-group-1143856111, --topic, my-topic-467311057-683530871, --bootstrap-server, my-cluster-40841ac1-kafka-bootstrap.infra-namespace.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-40841ac1-kafka-clients-cdbf79f49-sxm7l', podNamespace='infra-namespace', bootstrapServer='my-cluster-40841ac1-kafka-bootstrap.infra-namespace.svc:9092', topicName='my-topic-467311057-683530871', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1143856111', consumerInstanceId='instance1328819279', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3a69b298}
2022-04-02 22:16:28 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-40841ac1-kafka-bootstrap.infra-namespace.svc:9092#my-topic-467311057-683530871 from pod my-cluster-40841ac1-kafka-clients-cdbf79f49-sxm7l
2022-04-02 22:16:28 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-40841ac1-kafka-clients-cdbf79f49-sxm7l -n infra-namespace -- /opt/kafka/consumer.sh --max-messages 100 --group-instance-id instance1328819279 --group-id my-consumer-group-1143856111 --topic my-topic-467311057-683530871 --bootstrap-server my-cluster-40841ac1-kafka-bootstrap.infra-namespace.svc:9092
2022-04-02 22:16:34 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-02 22:16:34 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-02 22:16:34 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-40841ac1-connect-c4b7cb586-w449h
2022-04-02 22:16:34 [main] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-40841ac1-connect-c4b7cb586-w449h
2022-04-02 22:16:34 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-02 22:16:34 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-02 22:16:34 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-02 22:16:34 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 22:16:34 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-02 22:16:34 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 22:16:34 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 22:16:34 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 22:16:34 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 22:16:34 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 22:16:34 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 22:16:34 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 22:16:34 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 22:16:34 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 22:16:34 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 22:16:34 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 22:16:34 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 22:16:34 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 22:16:34 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 22:16:34 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 22:16:34 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 22:16:34 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 22:16:34 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 22:16:34 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 22:16:44 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 22:16:44 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 22:16:44 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 22:16:44 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 22:16:54 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 22:17:37 [main] [32mINFO [m [SetupClusterOperator:223] Cluster operator installation configuration:
SetupClusterOperator{cluster=io.strimzi.test.k8s.KubeClusterResource@38874b68, extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7e2e5e3d, clusterOperatorName='strimzi-cluster-operator', namespaceInstallTo='infra-namespace', namespaceToWatch='infra-namespace', bindingsNamespaces=[infra-namespace], operationTimeout=300000, reconciliationInterval=30000, extraEnvVars=[], extraLabels={}, clusterOperatorRBACType=CLUSTER, testClassName='null', testMethodName='null'}
2022-04-02 22:17:37 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-02 22:17:37 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-02 22:17:37 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-02 22:17:37 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 22:17:37 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 22:17:37 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 22:17:37 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 22:17:37 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 22:17:37 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 22:17:37 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 22:17:37 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 22:17:37 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 22:17:37 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 22:17:37 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 22:17:37 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 22:17:37 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 22:17:37 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 22:17:37 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 22:17:37 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 22:17:37 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 22:17:37 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-02 22:17:37 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 22:17:37 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 22:17:37 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-02 22:17:37 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 22:17:37 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-02 22:17:37 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 22:17:37 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 22:17:37 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 22:17:37 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-02 22:17:37 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 22:17:37 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 22:17:37 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-02 22:18:12 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-02 22:18:12 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-02 22:18:22 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-02 22:18:22 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment strimzi-cluster-operator rolling update
2022-04-02 22:18:22 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-02 22:18:22 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-02 22:18:33 [main] [32mINFO [m [DeploymentUtils:141] Deployment strimzi-cluster-operator rolling update finished
2022-04-02 22:18:33 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 22:18:33 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRackAwareConnectWrongDeployment
2022-04-02 22:18:33 [main] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-40841ac1-allow in namespace infra-namespace
2022-04-02 22:18:33 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-40841ac1-kafka-clients in namespace infra-namespace
2022-04-02 22:18:33 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-40841ac1-scraper in namespace infra-namespace
2022-04-02 22:18:33 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-40841ac1 in namespace infra-namespace
2022-04-02 22:18:33 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-40841ac1-allow in namespace infra-namespace
2022-04-02 22:18:33 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-40841ac1 in namespace infra-namespace
2022-04-02 22:18:33 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 22:18:33 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.specific.SpecificIsolatedST.testRackAwareConnectWrongDeployment-FINISHED
2022-04-02 22:18:33 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 22:18:33 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 22:18:33 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.specific.SpecificIsolatedST.testDeployUnsupportedKafka-STARTED
2022-04-02 22:18:33 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 22:18:33 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-1560cd87 in namespace infra-namespace
2022-04-02 22:18:33 [main] [32mINFO [m [SpecificIsolatedST:414] Kafka with version 6.6.6 deployed.
2022-04-02 22:18:33 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-1560cd87 will have desired state: NotReady
2022-04-02 22:18:34 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-1560cd87 is in desired state: NotReady
2022-04-02 22:18:37 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 22:18:37 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDeployUnsupportedKafka
2022-04-02 22:18:37 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-1560cd87 in namespace infra-namespace
2022-04-02 22:18:37 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 22:18:37 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.specific.SpecificIsolatedST.testDeployUnsupportedKafka-FINISHED
2022-04-02 22:18:37 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 22:18:37 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 22:18:37 [main] [32mINFO [m [ResourceManager:346] In context SpecificIsolatedST is everything deleted.
2022-04-02 22:18:37 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 587.063 s - in io.strimzi.systemtest.specific.SpecificIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.specific.DrainCleanerIsolatedST
2022-04-02 22:18:37 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-02 22:19:02 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-02 22:19:02 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-02 22:19:02 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-02 22:19:02 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 22:19:02 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-02 22:19:02 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 22:19:02 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 22:19:02 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 22:19:02 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 22:19:02 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 22:19:02 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 22:19:02 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 22:19:02 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 22:19:02 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 22:19:02 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 22:19:02 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 22:19:02 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 22:19:02 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 22:19:02 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 22:19:02 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 22:19:02 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 22:19:02 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 22:19:02 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 22:19:02 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 22:19:02 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 22:19:12 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 22:19:12 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 22:19:12 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 22:19:22 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 22:19:27 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7e2e5e3d
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=strimzi-drain-cleaner
namespaceToWatch=strimzi-drain-cleaner
bindingsNamespaces=[strimzi-drain-cleaner]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-02 22:19:27 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-02 22:19:27 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: strimzi-drain-cleaner
2022-04-02 22:19:27 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: strimzi-drain-cleaner
2022-04-02 22:19:27 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace strimzi-drain-cleaner
2022-04-02 22:19:27 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 22:19:27 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 22:19:27 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 22:19:27 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 22:19:27 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 22:19:27 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 22:19:27 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 22:19:27 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 22:19:27 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 22:19:27 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 22:19:27 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 22:19:27 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 22:19:27 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 22:19:27 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 22:19:27 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 22:19:28 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace strimzi-drain-cleaner
2022-04-02 22:19:28 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: strimzi-drain-cleaner
2022-04-02 22:19:28 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace strimzi-drain-cleaner
2022-04-02 22:19:28 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 22:19:28 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace strimzi-drain-cleaner
2022-04-02 22:19:28 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 22:19:28 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace strimzi-drain-cleaner
2022-04-02 22:19:28 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 22:19:28 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace strimzi-drain-cleaner
2022-04-02 22:19:28 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace strimzi-drain-cleaner
2022-04-02 22:19:28 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace strimzi-drain-cleaner
2022-04-02 22:19:28 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace strimzi-drain-cleaner
2022-04-02 22:19:28 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace strimzi-drain-cleaner
2022-04-02 22:19:28 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-02 22:20:01 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-02 22:20:01 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-02 22:20:11 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-02 22:20:11 [main] [32mINFO [m [MultiNodeClusterOnlyCondition:24] testDrainCleanerWithComponentsDuringNodeDraining is @MultiNodeClusterOnly, but the running cluster is not multi-node cluster: Ignoring testDrainCleanerWithComponentsDuringNodeDraining
2022-04-02 22:20:11 [main] [32mINFO [m [RequiredMinKubeApiVersionCondition:30] testDrainCleanerWithComponents is @RequiredMinKubeApiVersion with version 1.17, but the running on cluster with 1.16: Ignoring testDrainCleanerWithComponents
2022-04-02 22:20:11 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 22:20:11 [main] [32mINFO [m [ResourceManager:346] In context DrainCleanerIsolatedST is everything deleted.
2022-04-02 22:20:11 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;33mWARNING[m] Tests run: 2, Failures: 0, Errors: 0, Skipped: 2, Time elapsed: 94.323 s - in io.strimzi.systemtest.specific.DrainCleanerIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.watcher.MultipleNamespaceIsolatedST
2022-04-02 22:20:11 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-02 22:20:36 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-02 22:20:36 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-02 22:20:36 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-02 22:20:36 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 22:20:36 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-02 22:20:36 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 22:20:36 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 22:20:36 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 22:20:36 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 22:20:36 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 22:20:36 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 22:20:36 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace strimzi-drain-cleaner
2022-04-02 22:20:36 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace strimzi-drain-cleaner
2022-04-02 22:20:36 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 22:20:36 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace strimzi-drain-cleaner
2022-04-02 22:20:36 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 22:20:36 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 22:20:36 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 22:20:36 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace strimzi-drain-cleaner
2022-04-02 22:20:36 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace strimzi-drain-cleaner
2022-04-02 22:20:36 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 22:20:36 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 22:20:36 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 22:20:36 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 22:20:36 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 22:20:36 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 22:20:46 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 22:20:46 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 22:20:56 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 22:21:06 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7e2e5e3d
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace,second-namespace-test
bindingsNamespaces=[infra-namespace, second-namespace-test]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-02 22:21:06 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-02 22:21:06 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-02 22:21:06 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: second-namespace-test
2022-04-02 22:21:07 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-02 22:21:07 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 22:21:07 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 22:21:07 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 22:21:07 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 22:21:07 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 22:21:07 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 22:21:07 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 22:21:07 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 22:21:07 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 22:21:07 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 22:21:07 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 22:21:07 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 22:21:07 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 22:21:07 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 22:21:07 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 22:21:07 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 22:21:07 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 22:21:07 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-02 22:21:07 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: second-namespace-test
2022-04-02 22:21:07 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 22:21:07 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 22:21:07 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-02 22:21:07 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 22:21:07 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-02 22:21:07 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 22:21:07 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 22:21:07 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 22:21:07 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-02 22:21:07 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 22:21:07 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 22:21:07 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 22:21:07 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-02 22:21:07 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 22:21:07 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-02 22:21:07 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 22:21:07 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 22:21:07 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace second-namespace-test
2022-04-02 22:21:07 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-02 22:21:07 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace second-namespace-test
2022-04-02 22:21:07 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 22:21:07 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-02 22:21:43 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-02 22:21:43 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-02 22:21:53 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-02 22:21:53 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-namespace-test
2022-04-02 22:21:53 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster in namespace second-namespace-test
2022-04-02 22:21:53 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster will have desired state: Ready
2022-04-02 22:23:17 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster is in desired state: Ready
2022-04-02 22:23:17 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-02 22:23:17 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 22:23:17 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.watcher.MultipleNamespaceIsolatedST.testKafkaInDifferentNsThanClusterOperator-STARTED
2022-04-02 22:23:17 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 22:23:17 [main] [32mINFO [m [MultipleNamespaceIsolatedST:59] Deploying Kafka in different namespace than CO when CO watches multiple namespaces
2022-04-02 22:23:17 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-namespace-test
2022-04-02 22:23:17 [main] [32mINFO [m [AbstractNamespaceST:46] Check if Kafka Cluster my-cluster in namespace second-namespace-test
2022-04-02 22:23:17 [main] [32mINFO [m [AbstractNamespaceST:51] Kafka condition status: True
2022-04-02 22:23:17 [main] [32mINFO [m [AbstractNamespaceST:52] Kafka condition type: Ready
2022-04-02 22:23:17 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-02 22:23:17 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 22:23:17 [main] [32mINFO [m [ResourceManager:346] In context testKafkaInDifferentNsThanClusterOperator is everything deleted.
2022-04-02 22:23:17 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 22:23:17 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.watcher.MultipleNamespaceIsolatedST.testKafkaInDifferentNsThanClusterOperator-FINISHED
2022-04-02 22:23:17 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 22:23:17 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 22:23:17 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.watcher.MultipleNamespaceIsolatedST.testTopicOperatorWatchingOtherNamespace-STARTED
2022-04-02 22:23:17 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 22:23:17 [main] [32mINFO [m [MultipleNamespaceIsolatedST:45] Deploying TO to watch a different namespace that it is deployed in
2022-04-02 22:23:17 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-namespace-test
2022-04-02 22:23:20 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace second-namespace-test exec my-cluster-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-02 22:23:20 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 22:23:20 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1749724461-1041007001 in namespace infra-namespace
2022-04-02 22:23:20 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1749724461-1041007001 will have desired state: Ready
2022-04-02 22:23:21 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1749724461-1041007001 is in desired state: Ready
2022-04-02 22:23:21 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 22:23:21 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTopicOperatorWatchingOtherNamespace
2022-04-02 22:23:21 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1749724461-1041007001 in namespace infra-namespace
2022-04-02 22:23:31 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 22:23:31 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.watcher.MultipleNamespaceIsolatedST.testTopicOperatorWatchingOtherNamespace-FINISHED
2022-04-02 22:23:31 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 22:23:31 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 22:23:31 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.watcher.MultipleNamespaceIsolatedST.testDeployMirrorMakerAcrossMultipleNamespace-STARTED
2022-04-02 22:23:31 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 22:23:31 [main] [32mINFO [m [MultipleNamespaceIsolatedST:69] Deploying KafkaMirrorMaker in different namespace than CO when CO watches multiple namespaces
2022-04-02 22:23:31 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-namespace-test
2022-04-02 22:23:31 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-target in namespace second-namespace-test
2022-04-02 22:23:31 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-target will have desired state: Ready
2022-04-02 22:24:39 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-target is in desired state: Ready
2022-04-02 22:24:39 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster in namespace second-namespace-test
2022-04-02 22:24:39 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster will have desired state: Ready
2022-04-02 22:25:44 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster is in desired state: Ready
2022-04-02 22:25:44 [main] [32mINFO [m [AbstractNamespaceST:71] Waiting for creation my-cluster-mirror-maker in namespace second-namespace-test
2022-04-02 22:25:44 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster will have desired state: Ready
2022-04-02 22:25:44 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster is in desired state: Ready
2022-04-02 22:25:44 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-namespace-test
2022-04-02 22:25:44 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 22:25:44 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDeployMirrorMakerAcrossMultipleNamespace
2022-04-02 22:25:44 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster in namespace second-namespace-test
2022-04-02 22:25:44 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-target in namespace second-namespace-test
2022-04-02 22:25:54 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 22:25:54 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.watcher.MultipleNamespaceIsolatedST.testDeployMirrorMakerAcrossMultipleNamespace-FINISHED
2022-04-02 22:25:54 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 22:25:54 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 22:25:54 [main] [32mINFO [m [ResourceManager:348] Delete all resources for MultipleNamespaceIsolatedST
2022-04-02 22:25:54 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster in namespace second-namespace-test
2022-04-02 22:26:04 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 352.85 s - in io.strimzi.systemtest.watcher.MultipleNamespaceIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.watcher.AllNamespaceIsolatedST
2022-04-02 22:26:04 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-02 22:26:29 [main] [32mINFO [m [AllNamespaceIsolatedST:190] Creating resources before the test class
2022-04-02 22:26:29 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-02 22:26:29 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-02 22:26:29 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-02 22:26:29 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 22:26:29 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-02 22:26:29 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 22:26:29 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 22:26:29 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 22:26:29 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 22:26:29 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace second-namespace-test
2022-04-02 22:26:29 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 22:26:29 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 22:26:29 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 22:26:29 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 22:26:29 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 22:26:29 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 22:26:29 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 22:26:29 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 22:26:29 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 22:26:29 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace second-namespace-test
2022-04-02 22:26:29 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 22:26:29 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 22:26:29 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 22:26:29 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 22:26:29 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 22:26:39 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 22:26:39 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 22:26:39 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 22:26:39 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 22:26:39 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 22:26:39 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 22:26:39 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 22:26:39 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 22:26:49 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 22:26:54 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7e2e5e3d
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace, second-namespace-test, third-namespace-test]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-02 22:26:54 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-02 22:26:54 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-02 22:26:54 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: second-namespace-test
2022-04-02 22:26:54 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: third-namespace-test
2022-04-02 22:26:55 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-02 22:26:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 22:26:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 22:26:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 22:26:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 22:26:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 22:26:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 22:26:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 22:26:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 22:26:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 22:26:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 22:26:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 22:26:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 22:26:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 22:26:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 22:26:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 22:26:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 22:26:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 22:26:55 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-02 22:26:55 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: second-namespace-test
2022-04-02 22:26:55 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: third-namespace-test
2022-04-02 22:26:55 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 22:26:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 22:26:55 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-02 22:26:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 22:26:55 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-02 22:26:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 22:26:55 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 22:26:55 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 22:26:55 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-02 22:26:55 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 22:26:55 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 22:26:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 22:26:55 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-02 22:26:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 22:26:55 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-02 22:26:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 22:26:55 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 22:26:55 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace second-namespace-test
2022-04-02 22:26:55 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-02 22:26:55 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace second-namespace-test
2022-04-02 22:26:55 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 22:26:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 22:26:55 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-02 22:26:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 22:26:55 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-02 22:26:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 22:26:55 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 22:26:55 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace third-namespace-test
2022-04-02 22:26:55 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-02 22:26:55 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace third-namespace-test
2022-04-02 22:26:55 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-02 22:26:55 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-02 22:26:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 22:26:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-02 22:26:55 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 22:26:55 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-02 22:27:18 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-02 22:27:18 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-02 22:27:28 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-02 22:27:28 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: third-namespace-test
2022-04-02 22:27:28 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster in namespace third-namespace-test
2022-04-02 22:27:28 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster will have desired state: Ready
2022-04-02 22:28:45 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster is in desired state: Ready
2022-04-02 22:28:45 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-namespace-test
2022-04-02 22:28:45 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-second in namespace second-namespace-test
2022-04-02 22:28:45 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-second will have desired state: Ready
2022-04-02 22:29:58 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-second is in desired state: Ready
2022-04-02 22:29:58 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-02 22:29:58 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 22:29:58 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.watcher.AllNamespaceIsolatedST.testKafkaInDifferentNsThanClusterOperator-STARTED
2022-04-02 22:29:58 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 22:29:58 [main] [32mINFO [m [AllNamespaceIsolatedST:82] Deploying Kafka cluster in different namespace than CO when CO watches all namespaces
2022-04-02 22:29:58 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-namespace-test
2022-04-02 22:29:58 [main] [32mINFO [m [AbstractNamespaceST:46] Check if Kafka Cluster my-cluster-second in namespace second-namespace-test
2022-04-02 22:29:58 [main] [32mINFO [m [AbstractNamespaceST:51] Kafka condition status: True
2022-04-02 22:29:58 [main] [32mINFO [m [AbstractNamespaceST:52] Kafka condition type: Ready
2022-04-02 22:29:58 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-02 22:29:58 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 22:29:58 [main] [32mINFO [m [ResourceManager:346] In context testKafkaInDifferentNsThanClusterOperator is everything deleted.
2022-04-02 22:29:58 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 22:29:58 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.watcher.AllNamespaceIsolatedST.testKafkaInDifferentNsThanClusterOperator-FINISHED
2022-04-02 22:29:58 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 22:29:58 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 22:29:58 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.watcher.AllNamespaceIsolatedST.testTopicOperatorWatchingOtherNamespace-STARTED
2022-04-02 22:29:58 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 22:29:58 [main] [32mINFO [m [AllNamespaceIsolatedST:66] Deploying TO to watch a different namespace that it is deployed in
2022-04-02 22:29:58 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: third-namespace-test
2022-04-02 22:30:01 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace third-namespace-test exec my-cluster-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-02 22:30:01 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 22:30:01 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-215501485-613994140 in namespace second-namespace-test
2022-04-02 22:30:01 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-215501485-613994140 will have desired state: Ready
2022-04-02 22:30:02 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-215501485-613994140 is in desired state: Ready
2022-04-02 22:30:02 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-02 22:30:02 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 22:30:02 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTopicOperatorWatchingOtherNamespace
2022-04-02 22:30:02 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-215501485-613994140 in namespace second-namespace-test
2022-04-02 22:30:12 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 22:30:12 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.watcher.AllNamespaceIsolatedST.testTopicOperatorWatchingOtherNamespace-FINISHED
2022-04-02 22:30:12 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 22:30:12 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 22:30:12 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.watcher.AllNamespaceIsolatedST.testUOWatchingOtherNamespace-STARTED
2022-04-02 22:30:12 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 22:30:12 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-namespace-test
2022-04-02 22:30:12 [main] [32mINFO [m [AllNamespaceIsolatedST:121] Creating user in other namespace than CO and Kafka cluster with UO
2022-04-02 22:30:12 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-747685068-1146249779 in namespace second-namespace-test
2022-04-02 22:30:12 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-747685068-1146249779 will have desired state: Ready
2022-04-02 22:30:13 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-747685068-1146249779 is in desired state: Ready
2022-04-02 22:30:13 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-02 22:30:13 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 22:30:13 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testUOWatchingOtherNamespace
2022-04-02 22:30:13 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-747685068-1146249779 in namespace second-namespace-test
2022-04-02 22:30:13 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 22:30:13 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.watcher.AllNamespaceIsolatedST.testUOWatchingOtherNamespace-FINISHED
2022-04-02 22:30:13 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 22:30:13 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 22:30:13 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.watcher.AllNamespaceIsolatedST.testUserInDifferentNamespace-STARTED
2022-04-02 22:30:13 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 22:30:13 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-namespace-test
2022-04-02 22:30:13 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-747685068-1146249779 in namespace second-namespace-test
2022-04-02 22:30:13 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-747685068-1146249779 will have desired state: Ready
2022-04-02 22:30:14 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-747685068-1146249779 is in desired state: Ready
2022-04-02 22:30:14 [main] [32mINFO [m [AllNamespaceIsolatedST:137] KafkaUser condition status: True
2022-04-02 22:30:14 [main] [32mINFO [m [AllNamespaceIsolatedST:138] KafkaUser condition type: Ready
2022-04-02 22:30:14 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: third-namespace-test
2022-04-02 22:30:14 [main] [32mINFO [m [AllNamespaceIsolatedST:148] Copying secret Secret(apiVersion=v1, data={ca.crt=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, user.crt=LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUVJVENDQWdtZ0F3SUJBZ0lVQXYxa0lROUREREdWV1RrNmFpUXJQVy9hODhFd0RRWUpLb1pJaHZjTkFRRU4KQlFBd0xURVRNQkVHQTFVRUNnd0thVzh1YzNSeWFXMTZhVEVXTUJRR0ExVUVBd3dOWTJ4cFpXNTBjeTFqWVNCMgpNREFlRncweU1qQTBNREl5TWpNd01UTmFGdzB5TXpBME1ESXlNak13TVROYU1DY3hKVEFqQmdOVkJBTU1IRzE1CkxYVnpaWEl0TnpRM05qZzFNRFk0TFRFeE5EWXlORGszTnprd2dnRWlNQTBHQ1NxR1NJYjNEUUVCQVFVQUE0SUIKRHdBd2dnRUtBb0lCQVFDbWdaRGR3NVpnOXlRN2ptTHBOWmNKb3J6Z1JmbUx6UzB1OWU0bVBSZERVTXJ0TjFYSwovQlA2WklKaFZ3WmJ6NTZQSnU5bFNYVlR2emUwdTZQZXphY3pDeWFiOFZPbTBPcGhsdXpIWU5qOWRkbzlOeGZMCnNQWUFuLzF0b2dIQjh5SFVtcERyMkVZNEZuRjBNWkJYMkN0cnBqejFxcFZTaEd1RWlGOXBEV1BRVno5UktUYloKNmVwb1hjY1dTSjd0OC92dVVBck9va01jbm41NTBxYmlhSmVZcHJpRlVsam5BZ1dZc0pQckZ6WmdTWGJITVk0QQpNYmJqRjMydGtyL1dFVkw4VG56d21ZV0pPQklRQlFGUmZLdTdUV0RBZUFnOVN5eXViK25GWFg5VE1ZU0RORDJxCjFlTFAwdk9QaVpodnVCd1YyR3grd3F2OFdDU05CM3oyT0VxakFnTUJBQUdqUHpBOU1CMEdBMVVkRGdRV0JCU1cKb0FDSHpNUkNUeGh6NDZreGliUFlNSVBXNWpBTUJnTlZIUk1CQWY4RUFqQUFNQTRHQTFVZER3RUIvd1FFQXdJRgpvREFOQmdrcWhraUc5dzBCQVEwRkFBT0NBZ0VBZTVqbzc5dUsxMDZGelUvcXNsUENCQ2VON0ZZOXJKb1pYc1E1CklsTUhJOEVnWVFOcjVPMjNrdlZjb3JLQWhnbmxNZGp6SmJUK0dSVEltMVM3bVpMZW9oOERJSnRoK1Q4Wld6aXAKU0dyQ2lROFBxSXpPckEzV0tGTGtlRjV4VEEzbnorMjRUVTdlQmdQaTJPOUJrZDVTK0NKM2RxdjQwbjFLUGRLdQphTHErQlNJdUVPRkRTSUlCTExCUFE4Mktpa0lTbmlKU3BaMkN2UHlZYXlOZUNyWG9wME51WnlRV1FyV1ZiQk51ClpadVFLUVRvSUlqK3VTWEUzTUttMkZTS3NDZ0QyOTF4bXE0ZXQyZk52a2xWM2REN0JpeVZYVjl5bmJ5YTVLWGsKbmZvWnpSUVZHRWl3ZkdPWUEvdk4xTU5RR1RETDZJVTlDRmEyenlhNnV2Y0R0dGZZcHpLQ0tyMisrcCsyYnlOQQoxN0xTUUZvU3RQSi9NeXowZ0NRVE9GdVBPcUxMdFlJek9ybkplWFVORjZGemZaM1FZZlJOcmpRalJtR2FJMjdPCitlNUhSUWNNU2dmaWxxbnBXb1Qrc3piYVc4Mkptc1JJNnllbGxYM2syTHhTQmQwVnN4cGpIb3FpTnZES1FEYnoKaWtXYnJhVFVzVXBZWVhFd0E1a2hyWkZyTzdUbGV0ZFlFck5XS3NJRVRHK0srcHEwdUpXZWFHSWFFUjlBMGhHVwpYSVRJSEVjaStMU1MvQXBsN2pCWlRnVDczZmFUT1BJTkJsdGV5QmhWMCt5bHFBSUpEME5PUWkzV29iczdkVkxrCm85Qnd0TEhCMXRHZzUwYUE4M0tvZjFPamd5S1pRUXhvTU5GL0gya210RXpXUE5CcVdDQU5xSVIyUUpSTHg5L0sKZGlDMCs2Yz0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=, user.key=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, user.p12=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, user.password=YnpzTVpIRGpqYlZZ}, immutable=null, kind=Secret, metadata=ObjectMeta(annotations=null, clusterName=null, creationTimestamp=2022-04-02T22:30:13Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[], generateName=null, generation=null, labels={app.kubernetes.io/instance=my-user-747685068-1146249779, app.kubernetes.io/managed-by=strimzi-user-operator, app.kubernetes.io/name=strimzi-user-operator, app.kubernetes.io/part-of=strimzi-my-user-747685068-1146249779, strimzi.io/cluster=my-cluster, strimzi.io/kind=KafkaUser, test.case=testUserInDifferentNamespace}, managedFields=[], name=my-user-747685068-1146249779, namespace=second-namespace-test, ownerReferences=[OwnerReference(apiVersion=kafka.strimzi.io/v1beta2, blockOwnerDeletion=false, controller=false, kind=KafkaUser, name=my-user-747685068-1146249779, uid=0ad57afd-09a6-46a9-90ba-e430695fcebc, additionalProperties={})], resourceVersion=445168, selfLink=/api/v1/namespaces/second-namespace-test/secrets/my-user-747685068-1146249779, uid=aa3e1033-551c-41e6-974e-b730b9997b62, additionalProperties={}), stringData=null, type=Opaque, additionalProperties={}) from namespace second-namespace-test to namespace third-namespace-test
2022-04-02 22:30:14 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-kafka-clients in namespace third-namespace-test
2022-04-02 22:30:14 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-kafka-clients will be ready
2022-04-02 22:30:15 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-kafka-clients is ready
2022-04-02 22:30:15 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-02 22:30:15 [main] [32mINFO [m [AllNamespaceIsolatedST:168] Checking produced and consumed messages to pod:my-cluster-kafka-clients-75fdd99c5c-9pf7t
2022-04-02 22:30:15 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@5f5b121b, messages=[], arguments=[USER=my_user_747685068_1146249779, --max-messages, 100, --topic, my-topic-467311057-683530871, --bootstrap-server, my-cluster-kafka-bootstrap.third-namespace-test.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-kafka-clients-75fdd99c5c-9pf7t', podNamespace='third-namespace-test', bootstrapServer='my-cluster-kafka-bootstrap.third-namespace-test.svc:9093', topicName='my-topic-467311057-683530871', maxMessages=100, kafkaUsername='my-user-747685068-1146249779', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1ff524ff}
2022-04-02 22:30:15 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-kafka-bootstrap.third-namespace-test.svc:9093:my-topic-467311057-683530871 from pod my-cluster-kafka-clients-75fdd99c5c-9pf7t
2022-04-02 22:30:15 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-kafka-clients-75fdd99c5c-9pf7t -n third-namespace-test -- /opt/kafka/producer.sh USER=my_user_747685068_1146249779 --max-messages 100 --topic my-topic-467311057-683530871 --bootstrap-server my-cluster-kafka-bootstrap.third-namespace-test.svc:9093
2022-04-02 22:30:19 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-02 22:30:19 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-02 22:30:19 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@8451c8f, messages=[], arguments=[USER=my_user_747685068_1146249779, --max-messages, 100, --group-instance-id, instance331504828, --group-id, my-consumer-group-1473170976, --topic, my-topic-467311057-683530871, --bootstrap-server, my-cluster-kafka-bootstrap.third-namespace-test.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-kafka-clients-75fdd99c5c-9pf7t', podNamespace='third-namespace-test', bootstrapServer='my-cluster-kafka-bootstrap.third-namespace-test.svc:9093', topicName='my-topic-467311057-683530871', maxMessages=100, kafkaUsername='my-user-747685068-1146249779', consumerGroupName='my-consumer-group-1473170976', consumerInstanceId='instance331504828', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@530b4f9c}
2022-04-02 22:30:19 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-kafka-bootstrap.third-namespace-test.svc:9093:my-topic-467311057-683530871 from pod my-cluster-kafka-clients-75fdd99c5c-9pf7t
2022-04-02 22:30:19 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-kafka-clients-75fdd99c5c-9pf7t -n third-namespace-test -- /opt/kafka/consumer.sh USER=my_user_747685068_1146249779 --max-messages 100 --group-instance-id instance331504828 --group-id my-consumer-group-1473170976 --topic my-topic-467311057-683530871 --bootstrap-server my-cluster-kafka-bootstrap.third-namespace-test.svc:9093
2022-04-02 22:30:25 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-02 22:30:25 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-02 22:30:25 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-02 22:30:25 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 22:30:25 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testUserInDifferentNamespace
2022-04-02 22:30:25 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-kafka-clients in namespace third-namespace-test
2022-04-02 22:30:25 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-747685068-1146249779 in namespace second-namespace-test
2022-04-02 22:31:06 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 22:31:06 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.watcher.AllNamespaceIsolatedST.testUserInDifferentNamespace-FINISHED
2022-04-02 22:31:06 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 22:31:06 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 22:31:06 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.watcher.AllNamespaceIsolatedST.testDeployMirrorMakerAcrossMultipleNamespace-STARTED
2022-04-02 22:31:06 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 22:31:06 [main] [32mINFO [m [AllNamespaceIsolatedST:92] Deploying KafkaMirrorMaker in different namespace than CO when CO watches all namespaces
2022-04-02 22:31:06 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-namespace-test
2022-04-02 22:31:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-target in namespace second-namespace-test
2022-04-02 22:31:06 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-target will have desired state: Ready
2022-04-02 22:32:13 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-target is in desired state: Ready
2022-04-02 22:32:13 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster in namespace second-namespace-test
2022-04-02 22:32:13 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster will have desired state: Ready
2022-04-02 22:33:24 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster is in desired state: Ready
2022-04-02 22:33:24 [main] [32mINFO [m [AbstractNamespaceST:71] Waiting for creation my-cluster-mirror-maker in namespace second-namespace-test
2022-04-02 22:33:24 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster will have desired state: Ready
2022-04-02 22:33:24 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster is in desired state: Ready
2022-04-02 22:33:24 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-02 22:33:24 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 22:33:24 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDeployMirrorMakerAcrossMultipleNamespace
2022-04-02 22:33:24 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster in namespace second-namespace-test
2022-04-02 22:33:24 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-target in namespace second-namespace-test
2022-04-02 22:33:34 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 22:33:34 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.watcher.AllNamespaceIsolatedST.testDeployMirrorMakerAcrossMultipleNamespace-FINISHED
2022-04-02 22:33:34 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 22:33:34 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 22:33:34 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.watcher.AllNamespaceIsolatedST.testDeployKafkaConnectAndKafkaConnectorInOtherNamespaceThanCO-STARTED
2022-04-02 22:33:34 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 22:33:34 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-namespace-test
2022-04-02 22:33:34 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-a1e68bb2-kafka-clients in namespace second-namespace-test
2022-04-02 22:33:34 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-a1e68bb2-kafka-clients will be ready
2022-04-02 22:33:36 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-a1e68bb2-kafka-clients is ready
2022-04-02 22:33:36 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-a1e68bb2kafka-connect-scraper in namespace second-namespace-test
2022-04-02 22:33:36 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-a1e68bb2kafka-connect-scraper will be ready
2022-04-02 22:33:38 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-a1e68bb2kafka-connect-scraper is ready
2022-04-02 22:33:38 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-a1e68bb2kafka-connect-scraper to be ready
2022-04-02 22:33:48 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-a1e68bb2kafka-connect-scraper is ready
2022-04-02 22:33:48 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-a1e68bb2kafka-connect-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-02 22:33:48 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-a1e68bb2kafka-connect-allow in namespace second-namespace-test
2022-04-02 22:33:48 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-02 22:33:48 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-a1e68bb2kafka-connect in namespace second-namespace-test
2022-04-02 22:33:48 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-a1e68bb2kafka-connect will have desired state: Ready
2022-04-02 22:34:50 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-a1e68bb2kafka-connect is in desired state: Ready
2022-04-02 22:34:50 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-a1e68bb2kafka-connect in namespace second-namespace-test
2022-04-02 22:34:50 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-a1e68bb2kafka-connect will have desired state: Ready
2022-04-02 22:34:51 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-a1e68bb2kafka-connect is in desired state: Ready
2022-04-02 22:34:51 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-a1e68bb2kafka-connect will have desired state: Ready
2022-04-02 22:34:51 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-a1e68bb2kafka-connect is in desired state: Ready
2022-04-02 22:34:51 [main] [32mINFO [m [KafkaConnectUtils:63] Waiting until KafkaConnect API is available
2022-04-02 22:34:51 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace second-namespace-test exec my-cluster-a1e68bb2kafka-connect-connect-6c878f85dc-8jmtp -- /bin/bash -c curl -I http://localhost:8083/connectors
2022-04-02 22:34:51 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 22:34:51 [main] [32mINFO [m [KafkaConnectUtils:66] KafkaConnect API is available
2022-04-02 22:34:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-a1e68bb2kafka-connect-kafka-clients in namespace second-namespace-test
2022-04-02 22:34:52 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-a1e68bb2kafka-connect-kafka-clients will be ready
2022-04-02 22:34:54 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-a1e68bb2kafka-connect-kafka-clients is ready
2022-04-02 22:34:54 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-02 22:34:54 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@7187aa4f, messages=[], arguments=[--max-messages, 100, --topic, my-topic-467311057-683530871, --bootstrap-server, my-cluster-second-kafka-bootstrap.second-namespace-test.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-a1e68bb2-kafka-clients-6d546c9bf4-sdwsj', podNamespace='second-namespace-test', bootstrapServer='my-cluster-second-kafka-bootstrap.second-namespace-test.svc:9092', topicName='my-topic-467311057-683530871', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@41755cb6}
2022-04-02 22:34:54 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-second-kafka-bootstrap.second-namespace-test.svc:9092:my-topic-467311057-683530871 from pod my-cluster-a1e68bb2-kafka-clients-6d546c9bf4-sdwsj
2022-04-02 22:34:54 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-a1e68bb2-kafka-clients-6d546c9bf4-sdwsj -n second-namespace-test -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-467311057-683530871 --bootstrap-server my-cluster-second-kafka-bootstrap.second-namespace-test.svc:9092
2022-04-02 22:34:56 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-02 22:34:56 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-02 22:34:56 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-a1e68bb2kafka-connect-connect-6c878f85dc-8jmtp
2022-04-02 22:34:57 [main] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-a1e68bb2kafka-connect-connect-6c878f85dc-8jmtp
2022-04-02 22:34:57 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-02 22:34:57 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 22:34:57 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDeployKafkaConnectAndKafkaConnectorInOtherNamespaceThanCO
2022-04-02 22:34:57 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-a1e68bb2kafka-connect in namespace second-namespace-test
2022-04-02 22:34:57 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-a1e68bb2-kafka-clients in namespace second-namespace-test
2022-04-02 22:34:57 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-a1e68bb2kafka-connect-allow in namespace second-namespace-test
2022-04-02 22:34:57 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-a1e68bb2kafka-connect-kafka-clients in namespace second-namespace-test
2022-04-02 22:34:57 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-a1e68bb2kafka-connect in namespace second-namespace-test
2022-04-02 22:34:57 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-a1e68bb2kafka-connect-scraper in namespace second-namespace-test
2022-04-02 22:35:47 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 22:35:47 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.watcher.AllNamespaceIsolatedST.testDeployKafkaConnectAndKafkaConnectorInOtherNamespaceThanCO-FINISHED
2022-04-02 22:35:47 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 22:35:47 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 22:35:47 [main] [32mINFO [m [ResourceManager:348] Delete all resources for AllNamespaceIsolatedST
2022-04-02 22:35:47 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-second in namespace second-namespace-test
2022-04-02 22:35:47 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster in namespace third-namespace-test
2022-04-02 22:35:57 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 593.686 s - in io.strimzi.systemtest.watcher.AllNamespaceIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST
2022-04-02 22:35:57 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-02 22:36:22 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-02 22:36:22 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-02 22:36:22 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-02 22:36:22 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 22:36:22 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-02 22:36:22 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 22:36:22 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 22:36:22 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 22:36:22 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 22:36:22 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace second-namespace-test
2022-04-02 22:36:22 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace third-namespace-test
2022-04-02 22:36:22 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 22:36:22 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-02 22:36:22 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace third-namespace-test
2022-04-02 22:36:22 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 22:36:22 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 22:36:22 [main] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 22:36:22 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 22:36:22 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 22:36:22 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 22:36:23 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace second-namespace-test
2022-04-02 22:36:23 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 22:36:23 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 22:36:23 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 22:36:23 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 22:36:23 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 22:36:23 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 22:36:23 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 22:36:23 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 22:36:23 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 22:36:23 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 22:36:23 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 22:36:23 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 22:36:23 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 22:36:23 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 22:36:32 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 22:36:33 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 22:36:33 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 22:36:33 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 22:36:33 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 22:36:43 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 22:36:53 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7e2e5e3d
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-02 22:36:53 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-02 22:36:53 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-02 22:36:53 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-02 22:36:53 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 22:36:53 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 22:36:53 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 22:36:53 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 22:36:53 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 22:36:53 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 22:36:53 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 22:36:54 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 22:36:54 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 22:36:54 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 22:36:54 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 22:36:54 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 22:36:54 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 22:36:54 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 22:36:54 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 22:36:54 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 22:36:54 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 22:36:54 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-02 22:36:54 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 22:36:54 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 22:36:54 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-02 22:36:54 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 22:36:54 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-02 22:36:54 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 22:36:54 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 22:36:54 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 22:36:54 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-02 22:36:54 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 22:36:54 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-02 22:36:54 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-02 22:36:54 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 22:36:54 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-02 22:36:54 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 22:36:54 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-02 22:37:29 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-02 22:37:29 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-02 22:37:39 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-02 22:37:39 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy global-network-policy in namespace infra-namespace
2022-04-02 22:37:39 [main] [32mINFO [m [OauthAbstractST:125] Deploying keycloak...
2022-04-02 22:37:39 [main] [32mINFO [m [KeycloakUtils:35] Prepare Keycloak Operator in namespace: infra-namespace with watching namespace: infra-namespace
2022-04-02 22:40:06 [main] [32mINFO [m [Exec:417] Command: /bin/bash ../systemtest/src/test/resources/oauth2/prepare_keycloak_operator.sh infra-namespace 11.0.1 infra-namespace
2022-04-02 22:40:06 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 22:40:06 [main] [32mINFO [m [KeycloakUtils:48] Keycloak in namespace infra-namespace is ready
2022-04-02 22:40:06 [main] [32mINFO [m [SecretUtils:46] Waiting for Secret credential-example-keycloak
2022-04-02 22:40:06 [main] [32mINFO [m [SecretUtils:50] Secret credential-example-keycloak created
2022-04-02 22:40:06 [main] [32mINFO [m [SecretUtils:70] Creating secret hello-world-producer-secret
2022-04-02 22:40:06 [main] [32mINFO [m [SecretUtils:70] Creating secret hello-world-consumer-secret
2022-04-02 22:40:06 [main] [32mINFO [m [SecretUtils:70] Creating secret team-a-client-secret
2022-04-02 22:40:06 [main] [32mINFO [m [SecretUtils:70] Creating secret team-b-client-secret
2022-04-02 22:40:06 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-broker-secret
2022-04-02 22:40:06 [main] [32mINFO [m [SecretUtils:70] Creating secret my-connect-oauth
2022-04-02 22:40:06 [main] [32mINFO [m [SecretUtils:70] Creating secret my-mirror-maker-oauth
2022-04-02 22:40:06 [main] [32mINFO [m [SecretUtils:70] Creating secret my-mirror-maker-2-oauth
2022-04-02 22:40:06 [main] [32mINFO [m [SecretUtils:70] Creating secret my-bridge-oauth
2022-04-02 22:40:06 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-audience-secret
2022-04-02 22:40:06 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-client-secret
2022-04-02 22:40:06 [main] [32mINFO [m [KeycloakInstance:50] Replacing validIssuerUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal to pointing to internal realm
2022-04-02 22:40:06 [main] [32mINFO [m [KeycloakInstance:51] Replacing jwksEndpointUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/certs to pointing to internal realm
2022-04-02 22:40:06 [main] [32mINFO [m [KeycloakInstance:52] Replacing oauthTokenEndpointUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/token to pointing to internal realm
2022-04-02 22:40:06 [main] [32mINFO [m [KeycloakInstance:60] Using HTTP endpoints
2022-04-02 22:40:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka oauth-cluster-plain-name in namespace infra-namespace
2022-04-02 22:40:06 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: oauth-cluster-plain-name will have desired state: Ready
2022-04-02 22:41:27 [main] [32mINFO [m [ResourceManager:444] Kafka: oauth-cluster-plain-name is in desired state: Ready
2022-04-02 22:41:27 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 22:41:27 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testSaslPlainProducerConsumer-STARTED
2022-04-02 22:41:27 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 22:41:27 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-02 22:41:27 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-02 22:41:27 [main] [32mINFO [m [ResourceManager:155] Create/Update Job kafka-audience-producer-my-cluster-ad20644c in namespace infra-namespace
2022-04-02 22:41:27 [main] [32mINFO [m [JobUtils:81] Waiting for job: kafka-audience-producer-my-cluster-ad20644c will be in active state
2022-04-02 22:41:28 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:kafka-audience-producer-my-cluster-ad20644c to finished
2022-04-02 22:41:36 [main] [32mINFO [m [ResourceManager:155] Create/Update Job kafka-audience-consumer-my-cluster-ad20644c in namespace infra-namespace
2022-04-02 22:41:36 [main] [32mINFO [m [JobUtils:81] Waiting for job: kafka-audience-consumer-my-cluster-ad20644c will be in active state
2022-04-02 22:41:37 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:kafka-audience-consumer-my-cluster-ad20644c to finished
2022-04-02 22:41:47 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 22:41:47 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSaslPlainProducerConsumer
2022-04-02 22:41:47 [main] [32mINFO [m [ResourceManager:241] Delete of Job kafka-audience-consumer-my-cluster-ad20644c in namespace infra-namespace
2022-04-02 22:41:47 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job kafka-audience-producer-my-cluster-ad20644c in namespace infra-namespace
2022-04-02 22:41:47 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 22:41:47 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testSaslPlainProducerConsumer-FINISHED
2022-04-02 22:41:47 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 22:41:47 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 22:41:47 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testSaslPlainAuthenticationKafkaConnectIsAbleToConnectToKafkaOAuth-STARTED
2022-04-02 22:41:47 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 22:41:47 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-3d643545-kafka-clients in namespace infra-namespace
2022-04-02 22:41:47 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-3d643545-kafka-clients will be ready
2022-04-02 22:41:48 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-3d643545-kafka-clients is ready
2022-04-02 22:41:48 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-3d643545-scraper in namespace infra-namespace
2022-04-02 22:41:48 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-3d643545-scraper will be ready
2022-04-02 22:41:49 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-3d643545-scraper is ready
2022-04-02 22:41:49 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-3d643545-scraper to be ready
2022-04-02 22:41:59 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-3d643545-scraper is ready
2022-04-02 22:41:59 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-3d643545-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-02 22:41:59 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-3d643545-allow in namespace infra-namespace
2022-04-02 22:41:59 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-02 22:41:59 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-3d643545 in namespace infra-namespace
2022-04-02 22:41:59 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-3d643545 will have desired state: Ready
2022-04-02 22:43:07 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-3d643545 is in desired state: Ready
2022-04-02 22:43:07 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 22:43:07 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSaslPlainAuthenticationKafkaConnectIsAbleToConnectToKafkaOAuth
2022-04-02 22:43:07 [main] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-3d643545-allow in namespace infra-namespace
2022-04-02 22:43:07 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-3d643545 in namespace infra-namespace
2022-04-02 22:43:07 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-3d643545-scraper in namespace infra-namespace
2022-04-02 22:43:07 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-3d643545-kafka-clients in namespace infra-namespace
2022-04-02 22:43:57 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 22:43:57 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testSaslPlainAuthenticationKafkaConnectIsAbleToConnectToKafkaOAuth-FINISHED
2022-04-02 22:43:57 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 22:43:57 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 22:43:57 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerMirrorMaker-STARTED
2022-04-02 22:43:57 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 22:43:57 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-02 22:43:57 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1731459312-758597149 in namespace infra-namespace
2022-04-02 22:43:57 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1731459312-758597149 will have desired state: Ready
2022-04-02 22:43:58 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1731459312-758597149 is in desired state: Ready
2022-04-02 22:43:58 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-6e64ce3d in namespace infra-namespace
2022-04-02 22:43:58 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-6e64ce3d will be in active state
2022-04-02 22:43:59 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-6e64ce3d to finished
2022-04-02 22:44:07 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-6e64ce3d in namespace infra-namespace
2022-04-02 22:44:07 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-6e64ce3d will be in active state
2022-04-02 22:44:08 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-6e64ce3d to finished
2022-04-02 22:44:18 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-6e64ce3d-target in namespace infra-namespace
2022-04-02 22:44:18 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-6e64ce3d-target will have desired state: Ready
2022-04-02 22:45:39 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-6e64ce3d-target is in desired state: Ready
2022-04-02 22:45:39 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker oauth-cluster-plain-name in namespace infra-namespace
2022-04-02 22:45:39 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: oauth-cluster-plain-name will have desired state: Ready
2022-04-02 22:46:45 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: oauth-cluster-plain-name is in desired state: Ready
2022-04-02 22:46:46 [main] [32mINFO [m [OauthPlainIsolatedST:443] Deleting the Job
2022-04-02 22:46:46 [main] [32mINFO [m [OauthPlainIsolatedST:446] Creating new client with new consumer-group and also to point on my-cluster-6e64ce3d-target cluster
2022-04-02 22:46:46 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-02 22:46:46 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer in namespace infra-namespace
2022-04-02 22:46:46 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer will be in active state
2022-04-02 22:46:47 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer to finished
2022-04-02 22:46:58 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 22:46:58 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumerMirrorMaker
2022-04-02 22:46:58 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-6e64ce3d-target in namespace infra-namespace
2022-04-02 22:46:58 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer in namespace infra-namespace
2022-04-02 22:46:58 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1731459312-758597149 in namespace infra-namespace
2022-04-02 22:46:58 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-6e64ce3d in namespace infra-namespace
2022-04-02 22:46:58 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-6e64ce3d in namespace infra-namespace
2022-04-02 22:46:58 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker oauth-cluster-plain-name in namespace infra-namespace
2022-04-02 22:47:08 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 22:47:08 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerMirrorMaker-FINISHED
2022-04-02 22:47:08 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 22:47:08 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 22:47:08 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerBridge-STARTED
2022-04-02 22:47:08 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 22:47:08 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-02 22:47:08 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1686022798-1574563242 in namespace infra-namespace
2022-04-02 22:47:08 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1686022798-1574563242 will have desired state: Ready
2022-04-02 22:47:09 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1686022798-1574563242 is in desired state: Ready
2022-04-02 22:47:09 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-514e157d in namespace infra-namespace
2022-04-02 22:47:09 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-514e157d will be in active state
2022-04-02 22:47:10 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-514e157d to finished
2022-04-02 22:47:19 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-514e157d in namespace infra-namespace
2022-04-02 22:47:19 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-514e157d will be in active state
2022-04-02 22:47:20 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-514e157d to finished
2022-04-02 22:47:31 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-514e157d-kafka-clients in namespace infra-namespace
2022-04-02 22:47:31 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-514e157d-kafka-clients will be ready
2022-04-02 22:47:33 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-514e157d-kafka-clients is ready
2022-04-02 22:47:33 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge oauth-cluster-plain-name in namespace infra-namespace
2022-04-02 22:47:33 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: oauth-cluster-plain-name will have desired state: Ready
2022-04-02 22:47:57 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: oauth-cluster-plain-name is in desired state: Ready
2022-04-02 22:47:57 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-02 22:47:57 [main] [32mINFO [m [ResourceManager:155] Create/Update Job bridge-producer-my-cluster-514e157d in namespace infra-namespace
2022-04-02 22:47:57 [main] [32mINFO [m [JobUtils:81] Waiting for job: bridge-producer-my-cluster-514e157d will be in active state
2022-04-02 22:47:58 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:bridge-producer-my-cluster-514e157d to finished
2022-04-02 22:49:47 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 22:49:47 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumerBridge
2022-04-02 22:49:47 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-514e157d-kafka-clients in namespace infra-namespace
2022-04-02 22:49:47 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job bridge-producer-my-cluster-514e157d in namespace infra-namespace
2022-04-02 22:49:47 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge oauth-cluster-plain-name in namespace infra-namespace
2022-04-02 22:49:47 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1686022798-1574563242 in namespace infra-namespace
2022-04-02 22:49:47 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-514e157d in namespace infra-namespace
2022-04-02 22:49:47 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-514e157d in namespace infra-namespace
2022-04-02 22:50:27 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 22:50:27 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerBridge-FINISHED
2022-04-02 22:50:27 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 22:50:27 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 22:50:27 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumer-STARTED
2022-04-02 22:50:27 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 22:50:27 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1919010267-933853648 in namespace infra-namespace
2022-04-02 22:50:27 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1919010267-933853648 will have desired state: Ready
2022-04-02 22:50:28 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1919010267-933853648 is in desired state: Ready
2022-04-02 22:50:28 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-02 22:50:28 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-89fc0b48 in namespace infra-namespace
2022-04-02 22:50:28 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-89fc0b48 will be in active state
2022-04-02 22:50:29 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-89fc0b48 to finished
2022-04-02 22:50:37 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-89fc0b48 in namespace infra-namespace
2022-04-02 22:50:37 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-89fc0b48 will be in active state
2022-04-02 22:50:38 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-89fc0b48 to finished
2022-04-02 22:50:44 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 22:50:44 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumer
2022-04-02 22:50:44 [main] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-89fc0b48 in namespace infra-namespace
2022-04-02 22:50:44 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1919010267-933853648 in namespace infra-namespace
2022-04-02 22:50:44 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-89fc0b48 in namespace infra-namespace
2022-04-02 22:50:54 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 22:50:54 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumer-FINISHED
2022-04-02 22:50:54 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 22:50:54 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 22:50:54 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerMirrorMaker2-STARTED
2022-04-02 22:50:54 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 22:50:54 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-02 22:50:54 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-808287176-1477722744 in namespace infra-namespace
2022-04-02 22:50:54 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-808287176-1477722744 will have desired state: Ready
2022-04-02 22:50:55 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-808287176-1477722744 is in desired state: Ready
2022-04-02 22:50:55 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-f53cbe36 in namespace infra-namespace
2022-04-02 22:50:55 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-f53cbe36 will be in active state
2022-04-02 22:50:56 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-f53cbe36 to finished
2022-04-02 22:51:04 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-f53cbe36 in namespace infra-namespace
2022-04-02 22:51:04 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-f53cbe36 will be in active state
2022-04-02 22:51:05 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-f53cbe36 to finished
2022-04-02 22:51:16 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-f53cbe36-target in namespace infra-namespace
2022-04-02 22:51:16 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-f53cbe36-target will have desired state: Ready
2022-04-02 22:52:23 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-f53cbe36-target is in desired state: Ready
2022-04-02 22:52:23 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 oauth-cluster-plain-name in namespace infra-namespace
2022-04-02 22:52:23 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: oauth-cluster-plain-name will have desired state: Ready
2022-04-02 22:53:30 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: oauth-cluster-plain-name is in desired state: Ready
2022-04-02 22:53:31 [main] [32mINFO [m [OauthPlainIsolatedST:593] Deleting the Job oauth-consumer-my-cluster-f53cbe36
2022-04-02 22:53:31 [main] [32mINFO [m [OauthPlainIsolatedST:596] Creating new client with new consumer-group and also to point on my-cluster-f53cbe36-target cluster
2022-04-02 22:53:31 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-02 22:53:31 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-f53cbe36 in namespace infra-namespace
2022-04-02 22:53:31 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-f53cbe36 will be in active state
2022-04-02 22:53:32 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-f53cbe36 to finished
2022-04-02 22:53:43 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 22:53:43 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumerMirrorMaker2
2022-04-02 22:53:43 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-f53cbe36-target in namespace infra-namespace
2022-04-02 22:53:43 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-808287176-1477722744 in namespace infra-namespace
2022-04-02 22:53:43 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-f53cbe36 in namespace infra-namespace
2022-04-02 22:53:43 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-f53cbe36 in namespace infra-namespace
2022-04-02 22:53:43 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-f53cbe36 in namespace infra-namespace
2022-04-02 22:53:43 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 oauth-cluster-plain-name in namespace infra-namespace
2022-04-02 22:54:03 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 22:54:03 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerMirrorMaker2-FINISHED
2022-04-02 22:54:03 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 22:54:03 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 22:54:03 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerAudienceTokenChecks-STARTED
2022-04-02 22:54:03 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 22:54:03 [main] [32mINFO [m [OauthPlainIsolatedST:161] Setting producer and consumer properties
2022-04-02 22:54:03 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-02 22:54:03 [main] [32mINFO [m [OauthPlainIsolatedST:174] Use clients without access token containing audience token
2022-04-02 22:54:03 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-23fa104e in namespace infra-namespace
2022-04-02 22:54:03 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-23fa104e will be in active state
2022-04-02 22:54:04 [main] [32mINFO [m [ClientUtils:89] Waiting for producer/consumer:oauth-producer-my-cluster-23fa104e to finish with failure.
2022-04-02 22:57:44 [main] [1;31mERROR[m [TestUtils:162] Exception waiting for Job did not finish within time limit (as expected)., null
2022-04-02 22:57:44 [main] [32mINFO [m [ClientUtils:100] Client job 'oauth-producer-my-cluster-23fa104e' finished with expected timeout.
2022-04-02 22:57:44 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-23fa104e in namespace infra-namespace
2022-04-02 22:57:44 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-23fa104e will be in active state
2022-04-02 22:57:45 [main] [32mINFO [m [ClientUtils:89] Waiting for producer/consumer:oauth-consumer-my-cluster-23fa104e to finish with failure.
2022-04-02 23:01:25 [main] [1;31mERROR[m [TestUtils:162] Exception waiting for Job did not finish within time limit (as expected)., null
2022-04-02 23:01:25 [main] [32mINFO [m [ClientUtils:100] Client job 'oauth-consumer-my-cluster-23fa104e' finished with expected timeout.
2022-04-02 23:01:35 [main] [32mINFO [m [OauthPlainIsolatedST:183] Use clients with Access token containing audience token
2022-04-02 23:01:35 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-02 23:01:35 [main] [32mINFO [m [ResourceManager:155] Create/Update Job kafka-audience-producer-my-cluster-23fa104e in namespace infra-namespace
2022-04-02 23:01:35 [main] [32mINFO [m [JobUtils:81] Waiting for job: kafka-audience-producer-my-cluster-23fa104e will be in active state
2022-04-02 23:01:36 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:kafka-audience-producer-my-cluster-23fa104e to finished
2022-04-02 23:01:44 [main] [32mINFO [m [ResourceManager:155] Create/Update Job kafka-audience-consumer-my-cluster-23fa104e in namespace infra-namespace
2022-04-02 23:01:44 [main] [32mINFO [m [JobUtils:81] Waiting for job: kafka-audience-consumer-my-cluster-23fa104e will be in active state
2022-04-02 23:01:45 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:kafka-audience-consumer-my-cluster-23fa104e to finished
2022-04-02 23:01:57 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 23:01:57 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumerAudienceTokenChecks
2022-04-02 23:01:57 [main] [32mINFO [m [ResourceManager:241] Delete of Job kafka-audience-producer-my-cluster-23fa104e in namespace infra-namespace
2022-04-02 23:01:57 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Job kafka-audience-consumer-my-cluster-23fa104e in namespace infra-namespace
2022-04-02 23:01:57 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-23fa104e in namespace infra-namespace
2022-04-02 23:01:57 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-23fa104e in namespace infra-namespace
2022-04-02 23:01:57 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 23:01:57 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerAudienceTokenChecks-FINISHED
2022-04-02 23:01:57 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 23:01:57 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 23:01:57 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerConnect-STARTED
2022-04-02 23:01:57 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 23:01:57 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-02 23:01:57 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-212852208-1403118522 in namespace infra-namespace
2022-04-02 23:01:57 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-212852208-1403118522 will have desired state: Ready
2022-04-02 23:01:58 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-212852208-1403118522 is in desired state: Ready
2022-04-02 23:01:58 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-11c10e0c in namespace infra-namespace
2022-04-02 23:01:58 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-11c10e0c will be in active state
2022-04-02 23:01:59 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-11c10e0c to finished
2022-04-02 23:02:07 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-11c10e0c in namespace infra-namespace
2022-04-02 23:02:07 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-11c10e0c will be in active state
2022-04-02 23:02:08 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-11c10e0c to finished
2022-04-02 23:02:19 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-11c10e0c-kafka-clients in namespace infra-namespace
2022-04-02 23:02:19 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-11c10e0c-kafka-clients will be ready
2022-04-02 23:02:21 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-11c10e0c-kafka-clients is ready
2022-04-02 23:02:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-11c10e0c-scraper in namespace infra-namespace
2022-04-02 23:02:21 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-11c10e0c-scraper will be ready
2022-04-02 23:02:22 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-11c10e0c-scraper is ready
2022-04-02 23:02:22 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-11c10e0c-scraper to be ready
2022-04-02 23:02:32 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-11c10e0c-scraper is ready
2022-04-02 23:02:32 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-11c10e0c-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-02 23:02:32 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-11c10e0c-allow in namespace infra-namespace
2022-04-02 23:02:32 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-02 23:02:32 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-11c10e0c in namespace infra-namespace
2022-04-02 23:02:32 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-11c10e0c will have desired state: Ready
2022-04-02 23:12:32 [main] [1;31mERROR[m [TestUtils:162] Exception waiting for KafkaConnect: my-cluster-11c10e0c will have desired state: Ready, null
2022-04-02 23:12:32 [main] [32mINFO [m [ResourceManager:414] KafkaConnect status:

Conditions:
	Type: NotReady
	Message: Exceeded timeout of 300000ms while waiting for Deployment resource my-cluster-11c10e0c-connect in namespace infra-namespace to be ready

Pods with conditions and messages:

my-cluster-11c10e0c-connect-767f6674cb-4pkwl:
	Type: <EMPTY>
	Message: <EMPTY>

	Type: Ready
	Message: containers with unready status: [my-cluster-11c10e0c-connect]

	Type: ContainersReady
	Message: containers with unready status: [my-cluster-11c10e0c-connect]

	Type: <EMPTY>
	Message: <EMPTY>


my-cluster-11c10e0c-kafka-clients-c4656cfbd-wtq6s:
	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>


my-cluster-11c10e0c-scraper-56949544ff-h6hwz:
	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>
2022-04-02 23:12:32 [main] [1;31mERROR[m [TestExecutionWatcher:28] OauthPlainIsolatedST - Exception Timeout after 600000 ms waiting for Resource condition: readiness is fulfilled for resource KafkaConnect:my-cluster-11c10e0c has been thrown in @Test. Going to collect logs from components.
2022-04-02 23:12:32 [main] [32mINFO [m [LogCollector:252] Collecting events in Namespace infra-namespace
2022-04-02 23:12:32 [main] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace infra-namespace
2022-04-02 23:12:32 [main] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace infra-namespace
2022-04-02 23:12:32 [main] [33mWARN [m [LogCollector:247] Searching for logs in all pods failed! Some of the logs will not be stored. Exception messagenull
2022-04-02 23:12:32 [main] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace infra-namespace
2022-04-02 23:12:32 [main] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace infra-namespace
2022-04-02 23:12:32 [main] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace infra-namespace
2022-04-02 23:12:32 [main] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace infra-namespace
2022-04-02 23:12:33 [main] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-04-02 23:12:33 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 23:12:33 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumerConnect
2022-04-02 23:12:33 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-11c10e0c-scraper in namespace infra-namespace
2022-04-02 23:12:33 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-212852208-1403118522 in namespace infra-namespace
2022-04-02 23:12:33 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-11c10e0c-kafka-clients in namespace infra-namespace
2022-04-02 23:12:33 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-11c10e0c in namespace infra-namespace
2022-04-02 23:12:33 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-11c10e0c-allow in namespace infra-namespace
2022-04-02 23:12:33 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-11c10e0c in namespace infra-namespace
2022-04-02 23:12:33 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-11c10e0c in namespace infra-namespace
2022-04-02 23:13:13 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 23:13:13 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerConnect-FINISHED
2022-04-02 23:13:13 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 23:13:13 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 23:13:13 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testAccessTokenClaimCheck-STARTED
2022-04-02 23:13:13 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 23:13:13 [main] [32mINFO [m [OauthPlainIsolatedST:213] Use clients with clientId not containing 'hello-world' in access token.
2022-04-02 23:13:13 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-02 23:13:13 [main] [32mINFO [m [ResourceManager:155] Create/Update Job kafka-audience-producer-my-cluster-3a888507 in namespace infra-namespace
2022-04-02 23:13:13 [main] [32mINFO [m [JobUtils:81] Waiting for job: kafka-audience-producer-my-cluster-3a888507 will be in active state
2022-04-02 23:13:14 [main] [32mINFO [m [ClientUtils:89] Waiting for producer/consumer:kafka-audience-producer-my-cluster-3a888507 to finish with failure.
2022-04-02 23:16:54 [main] [1;31mERROR[m [TestUtils:162] Exception waiting for Job did not finish within time limit (as expected)., null
2022-04-02 23:16:54 [main] [32mINFO [m [ClientUtils:100] Client job 'kafka-audience-producer-my-cluster-3a888507' finished with expected timeout.
2022-04-02 23:16:54 [main] [32mINFO [m [ResourceManager:155] Create/Update Job kafka-audience-consumer-my-cluster-3a888507 in namespace infra-namespace
2022-04-02 23:16:54 [main] [32mINFO [m [JobUtils:81] Waiting for job: kafka-audience-consumer-my-cluster-3a888507 will be in active state
2022-04-02 23:16:55 [main] [32mINFO [m [ClientUtils:89] Waiting for producer/consumer:kafka-audience-consumer-my-cluster-3a888507 to finish with failure.
2022-04-02 23:20:35 [main] [1;31mERROR[m [TestUtils:162] Exception waiting for Job did not finish within time limit (as expected)., null
2022-04-02 23:20:35 [main] [32mINFO [m [ClientUtils:100] Client job 'kafka-audience-consumer-my-cluster-3a888507' finished with expected timeout.
2022-04-02 23:20:45 [main] [32mINFO [m [OauthPlainIsolatedST:236] Use clients with clientId containing 'hello-world' in access token.
2022-04-02 23:20:45 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-02 23:20:45 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-3a888507 in namespace infra-namespace
2022-04-02 23:20:45 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-3a888507 will be in active state
2022-04-02 23:20:46 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-3a888507 to finished
2022-04-02 23:20:54 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-3a888507 in namespace infra-namespace
2022-04-02 23:20:54 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-3a888507 will be in active state
2022-04-02 23:20:55 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-3a888507 to finished
2022-04-02 23:21:06 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 23:21:06 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAccessTokenClaimCheck
2022-04-02 23:21:06 [main] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-3a888507 in namespace infra-namespace
2022-04-02 23:21:06 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-3a888507 in namespace infra-namespace
2022-04-02 23:21:06 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Job kafka-audience-consumer-my-cluster-3a888507 in namespace infra-namespace
2022-04-02 23:21:06 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Job kafka-audience-producer-my-cluster-3a888507 in namespace infra-namespace
2022-04-02 23:21:06 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 23:21:06 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testAccessTokenClaimCheck-FINISHED
2022-04-02 23:21:06 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 23:21:06 [main] [32mINFO [m [KeycloakUtils:52] Teardown Keycloak Operator in namespace: infra-namespace with watching namespace: infra-namespace
2022-04-02 23:21:10 [main] [32mINFO [m [Exec:417] Command: /bin/bash ../systemtest/src/test/resources/oauth2/teardown_keycloak_operator.sh infra-namespace 11.0.1 infra-namespace
2022-04-02 23:21:10 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 23:21:10 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 23:21:10 [main] [32mINFO [m [ResourceManager:348] Delete all resources for OauthPlainIsolatedST
2022-04-02 23:21:10 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka oauth-cluster-plain-name in namespace infra-namespace
2022-04-02 23:21:10 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy global-network-policy in namespace infra-namespace
2022-04-02 23:21:20 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 23:21:20 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 23:21:20 [main] [32mINFO [m [ResourceManager:346] In context OauthPlainIsolatedST is everything deleted.
2022-04-02 23:21:20 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;31mERROR[m] Tests run: 9, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 2,722.551 s <<< FAILURE! - in io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST
[[1;31mERROR[m] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerConnect(ExtensionContext)  Time elapsed: 676.2 s  <<< ERROR!
io.strimzi.test.WaitException: Timeout after 600000 ms waiting for Resource condition: readiness is fulfilled for resource KafkaConnect:my-cluster-11c10e0c
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.resources.ResourceManager.waitResourceCondition(ResourceManager.java:264)
	at io.strimzi.systemtest.resources.ResourceManager.createResource(ResourceManager.java:226)
	at io.strimzi.systemtest.resources.ResourceManager.createResource(ResourceManager.java:148)
	at io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerConnect(OauthPlainIsolatedST.java:287)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)

[[1;34mINFO[m] Running io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST
2022-04-02 23:21:20 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-02 23:21:45 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-02 23:21:45 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-02 23:21:45 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-02 23:21:45 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 23:21:45 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-02 23:21:45 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 23:21:45 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 23:21:45 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 23:21:45 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 23:21:45 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 23:21:45 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 23:21:45 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 23:21:45 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 23:21:45 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 23:21:45 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 23:21:45 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 23:21:45 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 23:21:45 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 23:21:45 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 23:21:45 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 23:21:45 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 23:21:45 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 23:21:45 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 23:21:45 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 23:21:45 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 23:21:45 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 23:21:55 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 23:21:55 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 23:21:55 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 23:21:55 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-02 23:22:05 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 23:22:11 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7e2e5e3d
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-02 23:22:11 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-02 23:22:11 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-02 23:22:11 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-02 23:22:11 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 23:22:11 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 23:22:11 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 23:22:11 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 23:22:11 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 23:22:11 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 23:22:11 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 23:22:11 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 23:22:11 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 23:22:11 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 23:22:11 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 23:22:11 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 23:22:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 23:22:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 23:22:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 23:22:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 23:22:12 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 23:22:12 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-02 23:22:12 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 23:22:12 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 23:22:12 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-02 23:22:12 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 23:22:12 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-02 23:22:12 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 23:22:12 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 23:22:12 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 23:22:12 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-02 23:22:12 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 23:22:12 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-02 23:22:12 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-02 23:22:12 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 23:22:12 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-02 23:22:12 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 23:22:12 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-02 23:22:51 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-02 23:22:51 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-02 23:23:01 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-02 23:23:01 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy global-network-policy in namespace infra-namespace
2022-04-02 23:23:01 [main] [32mINFO [m [OauthAbstractST:125] Deploying keycloak...
2022-04-02 23:23:01 [main] [32mINFO [m [KeycloakUtils:35] Prepare Keycloak Operator in namespace: infra-namespace with watching namespace: infra-namespace
2022-04-02 23:24:30 [main] [32mINFO [m [Exec:417] Command: /bin/bash ../systemtest/src/test/resources/oauth2/prepare_keycloak_operator.sh infra-namespace 11.0.1 infra-namespace
2022-04-02 23:24:30 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 23:24:30 [main] [32mINFO [m [KeycloakUtils:48] Keycloak in namespace infra-namespace is ready
2022-04-02 23:24:30 [main] [32mINFO [m [SecretUtils:46] Waiting for Secret credential-example-keycloak
2022-04-02 23:24:30 [main] [32mINFO [m [SecretUtils:50] Secret credential-example-keycloak created
2022-04-02 23:24:30 [main] [32mINFO [m [SecretUtils:70] Creating secret hello-world-producer-secret
2022-04-02 23:24:30 [main] [32mINFO [m [SecretUtils:70] Creating secret hello-world-consumer-secret
2022-04-02 23:24:30 [main] [32mINFO [m [SecretUtils:70] Creating secret team-a-client-secret
2022-04-02 23:24:30 [main] [32mINFO [m [SecretUtils:70] Creating secret team-b-client-secret
2022-04-02 23:24:30 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-broker-secret
2022-04-02 23:24:30 [main] [32mINFO [m [SecretUtils:70] Creating secret my-connect-oauth
2022-04-02 23:24:30 [main] [32mINFO [m [SecretUtils:70] Creating secret my-mirror-maker-oauth
2022-04-02 23:24:30 [main] [32mINFO [m [SecretUtils:70] Creating secret my-mirror-maker-2-oauth
2022-04-02 23:24:30 [main] [32mINFO [m [SecretUtils:70] Creating secret my-bridge-oauth
2022-04-02 23:24:30 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-audience-secret
2022-04-02 23:24:30 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-client-secret
2022-04-02 23:24:30 [main] [32mINFO [m [KeycloakInstance:50] Replacing validIssuerUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal to pointing to kafka-authz realm
2022-04-02 23:24:30 [main] [32mINFO [m [KeycloakInstance:51] Replacing jwksEndpointUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/certs to pointing to kafka-authz realm
2022-04-02 23:24:30 [main] [32mINFO [m [KeycloakInstance:52] Replacing oauthTokenEndpointUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/token to pointing to kafka-authz realm
2022-04-02 23:24:30 [main] [32mINFO [m [KeycloakInstance:55] Using HTTPS endpoints
2022-04-02 23:24:30 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka oauth-cluster-authz-name in namespace infra-namespace
2022-04-02 23:24:30 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: oauth-cluster-authz-name will have desired state: Ready
2022-04-02 23:25:47 [main] [32mINFO [m [ResourceManager:444] Kafka: oauth-cluster-authz-name is in desired state: Ready
2022-04-02 23:25:47 [main] [32mINFO [m [OauthAuthorizationIsolatedST:680] Setting producer and consumer properties
2022-04-02 23:25:47 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser team-a-client in namespace infra-namespace
2022-04-02 23:25:47 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: team-a-client will have desired state: Ready
2022-04-02 23:25:48 [main] [32mINFO [m [ResourceManager:444] KafkaUser: team-a-client is in desired state: Ready
2022-04-02 23:25:48 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser team-b-client in namespace infra-namespace
2022-04-02 23:25:48 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: team-b-client will have desired state: Ready
2022-04-02 23:25:49 [main] [32mINFO [m [ResourceManager:444] KafkaUser: team-b-client is in desired state: Ready
2022-04-02 23:25:49 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 23:25:49 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.smokeTestForClients-STARTED
2022-04-02 23:25:49 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 23:25:49 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic a-topic-my-topic-150511583-876795190 in namespace infra-namespace
2022-04-02 23:25:49 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: a-topic-my-topic-150511583-876795190 will have desired state: Ready
2022-04-02 23:25:50 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: a-topic-my-topic-150511583-876795190 is in desired state: Ready
2022-04-02 23:25:50 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-producer-my-cluster-4eff523a in namespace infra-namespace
2022-04-02 23:25:50 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-producer-my-cluster-4eff523a will be in active state
2022-04-02 23:25:51 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-producer-my-cluster-4eff523a to finished
2022-04-02 23:25:59 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-consumer-my-cluster-4eff523a in namespace infra-namespace
2022-04-02 23:25:59 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-consumer-my-cluster-4eff523a will be in active state
2022-04-02 23:26:00 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-consumer-my-cluster-4eff523a to finished
2022-04-02 23:26:12 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 23:26:12 [main] [32mINFO [m [ResourceManager:348] Delete all resources for smokeTestForClients
2022-04-02 23:26:12 [main] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-producer-my-cluster-4eff523a in namespace infra-namespace
2022-04-02 23:26:12 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic a-topic-my-topic-150511583-876795190 in namespace infra-namespace
2022-04-02 23:26:12 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-consumer-my-cluster-4eff523a in namespace infra-namespace
2022-04-02 23:26:22 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 23:26:22 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.smokeTestForClients-FINISHED
2022-04-02 23:26:22 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 23:26:22 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 23:26:22 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testTeamAWriteToTopic-STARTED
2022-04-02 23:26:22 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 23:26:22 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1312648716-1540678561 in namespace infra-namespace
2022-04-02 23:26:22 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1312648716-1540678561 will have desired state: Ready
2022-04-02 23:26:23 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1312648716-1540678561 is in desired state: Ready
2022-04-02 23:26:23 [main] [32mINFO [m [OauthAuthorizationIsolatedST:146] Sending 100 messages to broker with topic name my-topic-1312648716-1540678561
2022-04-02 23:26:23 [main] [32mINFO [m [OauthAuthorizationIsolatedST:147] Producer will not produce messages because authorization topic will failed. Team A can write only to topic starting with 'x-'
2022-04-02 23:26:23 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-producer-my-cluster-f0041583 in namespace infra-namespace
2022-04-02 23:26:23 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-producer-my-cluster-f0041583 will be in active state
2022-04-02 23:26:24 [main] [32mINFO [m [JobUtils:70] Waiting for job: team-a-client-producer-my-cluster-f0041583 will be in error state
2022-04-02 23:26:42 [main] [32mINFO [m [OauthAuthorizationIsolatedST:154] Sending 100 messages to broker with topic name x-topic-my-cluster-f0041583
2022-04-02 23:26:42 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-producer-my-cluster-f0041583 in namespace infra-namespace
2022-04-02 23:26:42 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-producer-my-cluster-f0041583 will be in active state
2022-04-02 23:26:42 [main] [32mINFO [m [JobUtils:70] Waiting for job: team-a-client-producer-my-cluster-f0041583 will be in error state
2022-04-02 23:26:56 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic x-topic-my-cluster-f0041583 in namespace infra-namespace
2022-04-02 23:26:56 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: x-topic-my-cluster-f0041583 will have desired state: Ready
2022-04-02 23:26:57 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: x-topic-my-cluster-f0041583 is in desired state: Ready
2022-04-02 23:26:57 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-producer-my-cluster-f0041583 in namespace infra-namespace
2022-04-02 23:26:57 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-producer-my-cluster-f0041583 will be in active state
2022-04-02 23:26:58 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-producer-my-cluster-f0041583 to finished
2022-04-02 23:27:07 [main] [32mINFO [m [OauthAuthorizationIsolatedST:172] Sending 100 messages to broker with topic name a-topic-my-cluster-f0041583
2022-04-02 23:27:07 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-producer-my-cluster-f0041583 in namespace infra-namespace
2022-04-02 23:27:07 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-producer-my-cluster-f0041583 will be in active state
2022-04-02 23:27:08 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-producer-my-cluster-f0041583 to finished
2022-04-02 23:27:17 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 23:27:17 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTeamAWriteToTopic
2022-04-02 23:27:17 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic x-topic-my-cluster-f0041583 in namespace infra-namespace
2022-04-02 23:27:17 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-producer-my-cluster-f0041583 in namespace infra-namespace
2022-04-02 23:27:17 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-producer-my-cluster-f0041583 in namespace infra-namespace
2022-04-02 23:27:17 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-producer-my-cluster-f0041583 in namespace infra-namespace
2022-04-02 23:27:17 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-producer-my-cluster-f0041583 in namespace infra-namespace
2022-04-02 23:27:17 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1312648716-1540678561 in namespace infra-namespace
2022-04-02 23:27:27 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 23:27:27 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testTeamAWriteToTopic-FINISHED
2022-04-02 23:27:27 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 23:27:27 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 23:27:27 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testTeamAReadFromTopic-STARTED
2022-04-02 23:27:27 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 23:27:27 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic a-topic-my-topic-523623520-1175740410 in namespace infra-namespace
2022-04-02 23:27:27 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: a-topic-my-topic-523623520-1175740410 will have desired state: Ready
2022-04-02 23:27:28 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: a-topic-my-topic-523623520-1175740410 is in desired state: Ready
2022-04-02 23:27:28 [main] [32mINFO [m [OauthAuthorizationIsolatedST:208] Sending 100 messages to broker with topic name a-topic-my-topic-523623520-1175740410
2022-04-02 23:27:28 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-producer-my-cluster-58a2e762 in namespace infra-namespace
2022-04-02 23:27:28 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-producer-my-cluster-58a2e762 will be in active state
2022-04-02 23:27:29 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-producer-my-cluster-58a2e762 to finished
2022-04-02 23:27:38 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-consumer-my-cluster-58a2e762 in namespace infra-namespace
2022-04-02 23:27:38 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-consumer-my-cluster-58a2e762 will be in active state
2022-04-02 23:27:39 [main] [32mINFO [m [JobUtils:70] Waiting for job: team-a-client-consumer-my-cluster-58a2e762 will be in error state
2022-04-02 23:27:42 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-producer-my-cluster-58a2e762 in namespace infra-namespace
2022-04-02 23:27:42 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-producer-my-cluster-58a2e762 will be in active state
2022-04-02 23:27:43 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-producer-my-cluster-58a2e762 to finished
2022-04-02 23:27:51 [main] [32mINFO [m [OauthAbstractST:153] Deleting team-a-client-consumer-my-cluster-58a2e762 job
2022-04-02 23:27:56 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 23:27:56 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTeamAReadFromTopic
2022-04-02 23:27:56 [main] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-consumer-my-cluster-58a2e762 in namespace infra-namespace
2022-04-02 23:27:56 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-producer-my-cluster-58a2e762 in namespace infra-namespace
2022-04-02 23:27:56 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-producer-my-cluster-58a2e762 in namespace infra-namespace
2022-04-02 23:27:56 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic a-topic-my-topic-523623520-1175740410 in namespace infra-namespace
2022-04-02 23:28:06 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 23:28:06 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testTeamAReadFromTopic-FINISHED
2022-04-02 23:28:06 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 23:28:06 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 23:28:06 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testTeamBWriteToTopic-STARTED
2022-04-02 23:28:06 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 23:28:06 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1248127217-1592540159 in namespace infra-namespace
2022-04-02 23:28:06 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1248127217-1592540159 will have desired state: Ready
2022-04-02 23:28:07 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1248127217-1592540159 is in desired state: Ready
2022-04-02 23:28:07 [main] [32mINFO [m [OauthAuthorizationIsolatedST:259] Sending 100 messages to broker with topic name my-topic-467311057-683530871
2022-04-02 23:28:07 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-b-client-producer-my-cluster-25a723c8 in namespace infra-namespace
2022-04-02 23:28:07 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-b-client-producer-my-cluster-25a723c8 will be in active state
2022-04-02 23:28:08 [main] [32mINFO [m [JobUtils:70] Waiting for job: team-b-client-producer-my-cluster-25a723c8 will be in error state
2022-04-02 23:28:27 [main] [32mINFO [m [OauthAuthorizationIsolatedST:265] Sending 100 messages to broker with topic name b-topic
2022-04-02 23:28:27 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-b-client-producer-my-cluster-25a723c8 in namespace infra-namespace
2022-04-02 23:28:27 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-b-client-producer-my-cluster-25a723c8 will be in active state
2022-04-02 23:28:28 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-b-client-consumer-my-cluster-25a723c8 in namespace infra-namespace
2022-04-02 23:28:28 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-b-client-consumer-my-cluster-25a723c8 will be in active state
2022-04-02 23:28:29 [main] [32mINFO [m [ClientUtils:61] Waiting till producer team-b-client-producer-my-cluster-25a723c8 and consumer team-b-client-consumer-my-cluster-25a723c8 finish
2022-04-02 23:28:45 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 23:28:45 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTeamBWriteToTopic
2022-04-02 23:28:45 [main] [32mINFO [m [ResourceManager:241] Delete of Job team-b-client-producer-my-cluster-25a723c8 in namespace infra-namespace
2022-04-02 23:28:45 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1248127217-1592540159 in namespace infra-namespace
2022-04-02 23:28:45 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Job team-b-client-producer-my-cluster-25a723c8 in namespace infra-namespace
2022-04-02 23:28:45 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job team-b-client-consumer-my-cluster-25a723c8 in namespace infra-namespace
2022-04-02 23:28:55 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 23:28:55 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testTeamBWriteToTopic-FINISHED
2022-04-02 23:28:55 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 23:28:55 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 23:28:55 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testTeamAWriteToTopicStartingWithXAndTeamBReadFromTopicStartingWithX-STARTED
2022-04-02 23:28:55 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 23:28:55 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic x-topicmy-topic-1532916291-239427070 in namespace infra-namespace
2022-04-02 23:28:55 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: x-topicmy-topic-1532916291-239427070 will have desired state: Ready
2022-04-02 23:28:56 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: x-topicmy-topic-1532916291-239427070 is in desired state: Ready
2022-04-02 23:28:56 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-producer-my-cluster-017b90d6 in namespace infra-namespace
2022-04-02 23:28:56 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-producer-my-cluster-017b90d6 will be in active state
2022-04-02 23:28:57 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-producer-my-cluster-017b90d6 to finished
2022-04-02 23:29:05 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-b-client-consumer-my-cluster-017b90d6 in namespace infra-namespace
2022-04-02 23:29:05 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-b-client-consumer-my-cluster-017b90d6 will be in active state
2022-04-02 23:29:06 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-b-client-consumer-my-cluster-017b90d6 to finished
2022-04-02 23:29:13 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 23:29:13 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTeamAWriteToTopicStartingWithXAndTeamBReadFromTopicStartingWithX
2022-04-02 23:29:13 [main] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-producer-my-cluster-017b90d6 in namespace infra-namespace
2022-04-02 23:29:13 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic x-topicmy-topic-1532916291-239427070 in namespace infra-namespace
2022-04-02 23:29:13 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Job team-b-client-consumer-my-cluster-017b90d6 in namespace infra-namespace
2022-04-02 23:29:23 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 23:29:23 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testTeamAWriteToTopicStartingWithXAndTeamBReadFromTopicStartingWithX-FINISHED
2022-04-02 23:29:23 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 23:29:23 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 23:29:23 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testSuperUserWithOauthAuthorization-STARTED
2022-04-02 23:29:23 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 23:29:23 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic x-topicmy-topic-1505841861-1826840151 in namespace infra-namespace
2022-04-02 23:29:23 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: x-topicmy-topic-1505841861-1826840151 will have desired state: Ready
2022-04-02 23:29:24 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: x-topicmy-topic-1505841861-1826840151 is in desired state: Ready
2022-04-02 23:29:24 [main] [32mINFO [m [OauthAuthorizationIsolatedST:347] Verifying that team B is not able write to topic starting with 'x-' because in kafka clusterdoes not have super-users to break authorization rules
2022-04-02 23:29:24 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1314843055-2087358829 in namespace infra-namespace
2022-04-02 23:29:24 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1314843055-2087358829 will have desired state: Ready
2022-04-02 23:29:25 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1314843055-2087358829 is in desired state: Ready
2022-04-02 23:29:25 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-b-client-producer-my-cluster-291542d8 in namespace infra-namespace
2022-04-02 23:29:25 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-b-client-producer-my-cluster-291542d8 will be in active state
2022-04-02 23:29:26 [main] [32mINFO [m [JobUtils:70] Waiting for job: team-b-client-producer-my-cluster-291542d8 will be in error state
2022-04-02 23:29:35 [main] [32mINFO [m [OauthAuthorizationIsolatedST:370] Verifying that team A is not able read to topic starting with 'x-' because in kafka clusterdoes not have super-users to break authorization rules
2022-04-02 23:29:35 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-consumer-my-cluster-291542d8 in namespace infra-namespace
2022-04-02 23:29:35 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-consumer-my-cluster-291542d8 will be in active state
2022-04-02 23:29:36 [main] [32mINFO [m [JobUtils:70] Waiting for job: team-a-client-consumer-my-cluster-291542d8 will be in error state
2022-04-02 23:29:44 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: oauth-cluster-authz-name-kafka rolling update
2022-04-02 23:30:04 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: oauth-cluster-authz-name-kafka has been successfully rolled
2022-04-02 23:30:04 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 1 Pod(s) of oauth-cluster-authz-name-kafka to be ready
2022-04-02 23:30:31 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: oauth-cluster-authz-name will have desired state: Ready
2022-04-02 23:30:31 [main] [32mINFO [m [ResourceManager:444] Kafka: oauth-cluster-authz-name is in desired state: Ready
2022-04-02 23:30:31 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: oauth-cluster-authz-name is ready
2022-04-02 23:30:31 [main] [32mINFO [m [OauthAuthorizationIsolatedST:404] Verifying that team B is able to write to topic starting with 'x-' and break authorization rule
2022-04-02 23:30:31 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-b-client-producer-my-cluster-291542d8 in namespace infra-namespace
2022-04-02 23:30:31 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-b-client-producer-my-cluster-291542d8 will be in active state
2022-04-02 23:30:32 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-b-client-producer-my-cluster-291542d8 to finished
2022-04-02 23:30:40 [main] [32mINFO [m [OauthAuthorizationIsolatedST:409] Verifying that team A is able to write to topic starting with 'x-' and break authorization rule
2022-04-02 23:30:40 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-consumer-my-cluster-291542d8 in namespace infra-namespace
2022-04-02 23:30:40 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-consumer-my-cluster-291542d8 will be in active state
2022-04-02 23:30:41 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-consumer-my-cluster-291542d8 to finished
2022-04-02 23:30:53 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 23:30:53 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSuperUserWithOauthAuthorization
2022-04-02 23:30:53 [main] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-consumer-my-cluster-291542d8 in namespace infra-namespace
2022-04-02 23:30:53 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job team-b-client-producer-my-cluster-291542d8 in namespace infra-namespace
2022-04-02 23:30:53 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic x-topicmy-topic-1505841861-1826840151 in namespace infra-namespace
2022-04-02 23:30:53 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1314843055-2087358829 in namespace infra-namespace
2022-04-02 23:30:53 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Job team-b-client-producer-my-cluster-291542d8 in namespace infra-namespace
2022-04-02 23:30:53 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-consumer-my-cluster-291542d8 in namespace infra-namespace
2022-04-02 23:31:03 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 23:31:03 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testSuperUserWithOauthAuthorization-FINISHED
2022-04-02 23:31:03 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 23:31:03 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 23:31:03 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testSessionReAuthentication-STARTED
2022-04-02 23:31:03 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 23:31:03 [main] [32mINFO [m [OauthAuthorizationIsolatedST:443] Verifying that team A producer is able to send messages to the x-topic-example-topic topic -> the topic starting with 'x'
2022-04-02 23:31:03 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic x-topic-example-topic in namespace infra-namespace
2022-04-02 23:31:03 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: x-topic-example-topic will have desired state: Ready
2022-04-02 23:31:04 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: x-topic-example-topic is in desired state: Ready
2022-04-02 23:31:04 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic a-topic-example-topic in namespace infra-namespace
2022-04-02 23:31:04 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: a-topic-example-topic will have desired state: Ready
2022-04-02 23:31:05 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: a-topic-example-topic is in desired state: Ready
2022-04-02 23:31:05 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-producer-my-cluster-27f903c8 in namespace infra-namespace
2022-04-02 23:31:05 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-producer-my-cluster-27f903c8 will be in active state
2022-04-02 23:31:06 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-producer-my-cluster-27f903c8 to finished
2022-04-02 23:31:15 [main] [32mINFO [m [OauthAuthorizationIsolatedST:465] Adding the maxSecondsWithoutReauthentication to Kafka listener with OAuth authentication
2022-04-02 23:31:15 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: oauth-cluster-authz-name will have desired state: Ready
2022-04-02 23:31:15 [main] [32mINFO [m [ResourceManager:444] Kafka: oauth-cluster-authz-name is in desired state: Ready
2022-04-02 23:31:15 [main] [32mINFO [m [OauthAuthorizationIsolatedST:493] Setting the master realm token's lifespan to 3600s
2022-04-02 23:31:15 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-6ctsh -- curl -v --insecure -X POST -d client_id=admin-cli&client_secret=aGVsbG8td29ybGQtcHJvZHVjZXItc2VjcmV0&grant_type=password&username=admin&password=BJK6Suad_eg36w== https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/master/protocol/openid-connect/token
2022-04-02 23:31:15 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 23:31:16 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-6ctsh -- curl -v --insecure -X GET https://keycloak.infra-namespace.svc.cluster.local:8443/auth/admin/realms/master -H Authorization: Bearer eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICJCM1ZKeERnQ3dkajZ4OHdWNTNiMGZ3d1JWUUlvSG5vRTFLTnVUODlkcU5BIn0.eyJleHAiOjE2NDg5NDIzMzUsImlhdCI6MTY0ODk0MjI3NSwianRpIjoiMDBmMWZjNTctZjc0MS00OWI0LWIwY2UtODFmMzE0MzJmNWJiIiwiaXNzIjoiaHR0cHM6Ly9rZXljbG9hay5pbmZyYS1uYW1lc3BhY2Uuc3ZjLmNsdXN0ZXIubG9jYWw6ODQ0My9hdXRoL3JlYWxtcy9tYXN0ZXIiLCJzdWIiOiJmZGE0ZDFlNS0xNWIzLTQ5MzYtYTRmOC1jZGE5NzJjNjMwODgiLCJ0eXAiOiJCZWFyZXIiLCJhenAiOiJhZG1pbi1jbGkiLCJzZXNzaW9uX3N0YXRlIjoiNWFjNzFiMzctZWM1Ny00ZGUzLWI1NjQtY2Y0YTQwYWJiNjU1IiwiYWNyIjoiMSIsInNjb3BlIjoiZW1haWwgcHJvZmlsZSIsImVtYWlsX3ZlcmlmaWVkIjpmYWxzZSwicHJlZmVycmVkX3VzZXJuYW1lIjoiYWRtaW4ifQ.SrRKT1QpeSXoK6okoIn079dRqvbvpnr26pPxFOLlhg7uylvcXFfE_ocVA8mnRjtamWy_O7aDgtaULN4h33e_W48wB7F7pz7KAFK-uciIsXNLeuf0sKA1dJjIntH6XRdcvjgaVAisp4WIHPMDWl8ews1BP_AkJkO62I3QyRhHEoC4hCQcb5XJq7b3f3DWkjPqS_bZo-flrnZYFHAocL_d96P579ZVRRcQ4IOQyAMyy0_icxVos8aGueqjiqcdQJ4ZEoPfa8-6F_QJ9WhCYXgwF5gmzWnXdN-yO25CFXCwS1FLwCbi09R4mBa3RahmgB6ISg604GTXGttxy8FCF8ajIA
2022-04-02 23:31:16 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 23:31:16 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-6ctsh -- curl -v --insecure -X PUT https://keycloak.infra-namespace.svc.cluster.local:8443/auth/admin/realms/master -H Authorization: Bearer eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICJCM1ZKeERnQ3dkajZ4OHdWNTNiMGZ3d1JWUUlvSG5vRTFLTnVUODlkcU5BIn0.eyJleHAiOjE2NDg5NDIzMzUsImlhdCI6MTY0ODk0MjI3NSwianRpIjoiMDBmMWZjNTctZjc0MS00OWI0LWIwY2UtODFmMzE0MzJmNWJiIiwiaXNzIjoiaHR0cHM6Ly9rZXljbG9hay5pbmZyYS1uYW1lc3BhY2Uuc3ZjLmNsdXN0ZXIubG9jYWw6ODQ0My9hdXRoL3JlYWxtcy9tYXN0ZXIiLCJzdWIiOiJmZGE0ZDFlNS0xNWIzLTQ5MzYtYTRmOC1jZGE5NzJjNjMwODgiLCJ0eXAiOiJCZWFyZXIiLCJhenAiOiJhZG1pbi1jbGkiLCJzZXNzaW9uX3N0YXRlIjoiNWFjNzFiMzctZWM1Ny00ZGUzLWI1NjQtY2Y0YTQwYWJiNjU1IiwiYWNyIjoiMSIsInNjb3BlIjoiZW1haWwgcHJvZmlsZSIsImVtYWlsX3ZlcmlmaWVkIjpmYWxzZSwicHJlZmVycmVkX3VzZXJuYW1lIjoiYWRtaW4ifQ.SrRKT1QpeSXoK6okoIn079dRqvbvpnr26pPxFOLlhg7uylvcXFfE_ocVA8mnRjtamWy_O7aDgtaULN4h33e_W48wB7F7pz7KAFK-uciIsXNLeuf0sKA1dJjIntH6XRdcvjgaVAisp4WIHPMDWl8ews1BP_AkJkO62I3QyRhHEoC4hCQcb5XJq7b3f3DWkjPqS_bZo-flrnZYFHAocL_d96P579ZVRRcQ4IOQyAMyy0_icxVos8aGueqjiqcdQJ4ZEoPfa8-6F_QJ9WhCYXgwF5gmzWnXdN-yO25CFXCwS1FLwCbi09R4mBa3RahmgB6ISg604GTXGttxy8FCF8ajIA -d {"id":"master","realm":"master","displayName":"Keycloak","displayNameHtml":"<div class=\"kc-logo-text\"><span>Keycloak</span></div>","notBefore":0,"revokeRefreshToken":false,"refreshTokenMaxReuse":0,"accessTokenLifespan":"3600","accessTokenLifespanForImplicitFlow":900,"ssoSessionIdleTimeout":1800,"ssoSessionMaxLifespan":36000,"ssoSessionIdleTimeoutRememberMe":0,"ssoSessionMaxLifespanRememberMe":0,"offlineSessionIdleTimeout":2592000,"offlineSessionMaxLifespanEnabled":false,"offlineSessionMaxLifespan":5184000,"clientSessionIdleTimeout":0,"clientSessionMaxLifespan":0,"clientOfflineSessionIdleTimeout":0,"clientOfflineSessionMaxLifespan":0,"accessCodeLifespan":60,"accessCodeLifespanUserAction":300,"accessCodeLifespanLogin":1800,"actionTokenGeneratedByAdminLifespan":43200,"actionTokenGeneratedByUserLifespan":300,"enabled":true,"sslRequired":"external","registrationAllowed":false,"registrationEmailAsUsername":false,"rememberMe":false,"verifyEmail":false,"loginWithEmailAllowed":true,"duplicateEmailsAllowed":false,"resetPasswordAllowed":false,"editUsernameAllowed":false,"bruteForceProtected":false,"permanentLockout":false,"maxFailureWaitSeconds":900,"minimumQuickLoginWaitSeconds":60,"waitIncrementSeconds":60,"quickLoginCheckMilliSeconds":1000,"maxDeltaTimeSeconds":43200,"failureFactor":30,"defaultRoles":["offline_access","uma_authorization"],"requiredCredentials":["password"],"otpPolicyType":"totp","otpPolicyAlgorithm":"HmacSHA1","otpPolicyInitialCounter":0,"otpPolicyDigits":6,"otpPolicyLookAheadWindow":1,"otpPolicyPeriod":30,"otpSupportedApplications":["FreeOTP","Google Authenticator"],"webAuthnPolicyRpEntityName":"keycloak","webAuthnPolicySignatureAlgorithms":["ES256"],"webAuthnPolicyRpId":"","webAuthnPolicyAttestationConveyancePreference":"not specified","webAuthnPolicyAuthenticatorAttachment":"not specified","webAuthnPolicyRequireResidentKey":"not specified","webAuthnPolicyUserVerificationRequirement":"not specified","webAuthnPolicyCreateTimeout":0,"webAuthnPolicyAvoidSameAuthenticatorRegister":false,"webAuthnPolicyAcceptableAaguids":[],"webAuthnPolicyPasswordlessRpEntityName":"keycloak","webAuthnPolicyPasswordlessSignatureAlgorithms":["ES256"],"webAuthnPolicyPasswordlessRpId":"","webAuthnPolicyPasswordlessAttestationConveyancePreference":"not specified","webAuthnPolicyPasswordlessAuthenticatorAttachment":"not specified","webAuthnPolicyPasswordlessRequireResidentKey":"not specified","webAuthnPolicyPasswordlessUserVerificationRequirement":"not specified","webAuthnPolicyPasswordlessCreateTimeout":0,"webAuthnPolicyPasswordlessAvoidSameAuthenticatorRegister":false,"webAuthnPolicyPasswordlessAcceptableAaguids":[],"browserSecurityHeaders":{"contentSecurityPolicyReportOnly":"","xContentTypeOptions":"nosniff","xRobotsTag":"none","xFrameOptions":"SAMEORIGIN","xXSSProtection":"1; mode=block","contentSecurityPolicy":"frame-src 'self'; frame-ancestors 'self'; object-src 'none';","strictTransportSecurity":"max-age=31536000; includeSubDomains"},"smtpServer":{},"eventsEnabled":false,"eventsListeners":["jboss-logging"],"enabledEventTypes":[],"adminEventsEnabled":false,"adminEventsDetailsEnabled":false,"internationalizationEnabled":false,"supportedLocales":[],"browserFlow":"browser","registrationFlow":"registration","directGrantFlow":"direct grant","resetCredentialsFlow":"reset credentials","clientAuthenticationFlow":"clients","dockerAuthenticationFlow":"docker auth","attributes":{},"userManagedAccessAllowed":false} -H Content-Type: application/json
2022-04-02 23:31:16 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 23:31:16 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-6ctsh -- curl -v --insecure -X POST -d client_id=admin-cli&client_secret=aGVsbG8td29ybGQtcHJvZHVjZXItc2VjcmV0&grant_type=password&username=admin&password=BJK6Suad_eg36w== https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/master/protocol/openid-connect/token
2022-04-02 23:31:16 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 23:31:16 [main] [32mINFO [m [OauthAuthorizationIsolatedST:508] Getting the kafka-authz kafka client for obtaining the Dev A Team policy for the x topics
2022-04-02 23:31:17 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-6ctsh -- curl -v --insecure -X GET https://keycloak.infra-namespace.svc.cluster.local:8443/auth/admin/realms/kafka-authz/clients -H Authorization: Bearer eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICJCM1ZKeERnQ3dkajZ4OHdWNTNiMGZ3d1JWUUlvSG5vRTFLTnVUODlkcU5BIn0.eyJleHAiOjE2NDg5NDU4NzYsImlhdCI6MTY0ODk0MjI3NiwianRpIjoiOTBlNGFlMmItY2M4Ny00MWZkLTg1ZGUtOTMyYTI2MThiOWUzIiwiaXNzIjoiaHR0cHM6Ly9rZXljbG9hay5pbmZyYS1uYW1lc3BhY2Uuc3ZjLmNsdXN0ZXIubG9jYWw6ODQ0My9hdXRoL3JlYWxtcy9tYXN0ZXIiLCJzdWIiOiJmZGE0ZDFlNS0xNWIzLTQ5MzYtYTRmOC1jZGE5NzJjNjMwODgiLCJ0eXAiOiJCZWFyZXIiLCJhenAiOiJhZG1pbi1jbGkiLCJzZXNzaW9uX3N0YXRlIjoiNzIzM2MwOGQtMzY2Zi00MmMzLWEwZjktMTI2YzQ3MGVhZjMyIiwiYWNyIjoiMSIsInNjb3BlIjoiZW1haWwgcHJvZmlsZSIsImVtYWlsX3ZlcmlmaWVkIjpmYWxzZSwicHJlZmVycmVkX3VzZXJuYW1lIjoiYWRtaW4ifQ.HBsrk2SBn6A8Ox1KLRW0llsOhPdQwfY5BlWY-kHUCi-JdpWT2R8g2xujrjc7p8g_VxdlEvtkfMMkLE4N2t1VP1gDBYjUMMdwA4hd8brHnFrI0uwlh2czMtSwZ3Ke5-8hTwJHUNA40Bb7ecK7zW3FyGq-yadEyslZMQ6DSpmB59uKCd32foV-KnUirMmuuUAYc7Q-N-xD6JHxGELzPynRIPN5tiZJbLuYShUfwCBugiPS4ePvtc1UBIAKr71upOVipvtRcKT1JTfT-xLfer91xcNNwvTxhUxXUIlj2VpCwC71gNUdzQiSbOFHkxZmOFFbPCWLSP_2rVlg5tGoX3mrAA
2022-04-02 23:31:17 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 23:31:17 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-6ctsh -- curl -v --insecure -X GET https://keycloak.infra-namespace.svc.cluster.local:8443/auth/admin/realms/kafka-authz/clients/7514b847-7b46-4936-9d9b-59df8fdce294/authz/resource-server/policy -H Authorization: Bearer eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICJCM1ZKeERnQ3dkajZ4OHdWNTNiMGZ3d1JWUUlvSG5vRTFLTnVUODlkcU5BIn0.eyJleHAiOjE2NDg5NDU4NzYsImlhdCI6MTY0ODk0MjI3NiwianRpIjoiOTBlNGFlMmItY2M4Ny00MWZkLTg1ZGUtOTMyYTI2MThiOWUzIiwiaXNzIjoiaHR0cHM6Ly9rZXljbG9hay5pbmZyYS1uYW1lc3BhY2Uuc3ZjLmNsdXN0ZXIubG9jYWw6ODQ0My9hdXRoL3JlYWxtcy9tYXN0ZXIiLCJzdWIiOiJmZGE0ZDFlNS0xNWIzLTQ5MzYtYTRmOC1jZGE5NzJjNjMwODgiLCJ0eXAiOiJCZWFyZXIiLCJhenAiOiJhZG1pbi1jbGkiLCJzZXNzaW9uX3N0YXRlIjoiNzIzM2MwOGQtMzY2Zi00MmMzLWEwZjktMTI2YzQ3MGVhZjMyIiwiYWNyIjoiMSIsInNjb3BlIjoiZW1haWwgcHJvZmlsZSIsImVtYWlsX3ZlcmlmaWVkIjpmYWxzZSwicHJlZmVycmVkX3VzZXJuYW1lIjoiYWRtaW4ifQ.HBsrk2SBn6A8Ox1KLRW0llsOhPdQwfY5BlWY-kHUCi-JdpWT2R8g2xujrjc7p8g_VxdlEvtkfMMkLE4N2t1VP1gDBYjUMMdwA4hd8brHnFrI0uwlh2czMtSwZ3Ke5-8hTwJHUNA40Bb7ecK7zW3FyGq-yadEyslZMQ6DSpmB59uKCd32foV-KnUirMmuuUAYc7Q-N-xD6JHxGELzPynRIPN5tiZJbLuYShUfwCBugiPS4ePvtc1UBIAKr71upOVipvtRcKT1JTfT-xLfer91xcNNwvTxhUxXUIlj2VpCwC71gNUdzQiSbOFHkxZmOFFbPCWLSP_2rVlg5tGoX3mrAA
2022-04-02 23:31:17 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 23:31:17 [main] [32mINFO [m [OauthAuthorizationIsolatedST:539] Changing the Dev Team A policy for topics starting with x- and checking that job will not be successful
2022-04-02 23:31:17 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-6ctsh -- curl -v --insecure -X PUT https://keycloak.infra-namespace.svc.cluster.local:8443/auth/admin/realms/kafka-authz/clients/7514b847-7b46-4936-9d9b-59df8fdce294/authz/resource-server/policy/399491a2-f953-4936-a002-de1f0f98ccf3 -H Authorization: Bearer eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICJCM1ZKeERnQ3dkajZ4OHdWNTNiMGZ3d1JWUUlvSG5vRTFLTnVUODlkcU5BIn0.eyJleHAiOjE2NDg5NDU4NzYsImlhdCI6MTY0ODk0MjI3NiwianRpIjoiOTBlNGFlMmItY2M4Ny00MWZkLTg1ZGUtOTMyYTI2MThiOWUzIiwiaXNzIjoiaHR0cHM6Ly9rZXljbG9hay5pbmZyYS1uYW1lc3BhY2Uuc3ZjLmNsdXN0ZXIubG9jYWw6ODQ0My9hdXRoL3JlYWxtcy9tYXN0ZXIiLCJzdWIiOiJmZGE0ZDFlNS0xNWIzLTQ5MzYtYTRmOC1jZGE5NzJjNjMwODgiLCJ0eXAiOiJCZWFyZXIiLCJhenAiOiJhZG1pbi1jbGkiLCJzZXNzaW9uX3N0YXRlIjoiNzIzM2MwOGQtMzY2Zi00MmMzLWEwZjktMTI2YzQ3MGVhZjMyIiwiYWNyIjoiMSIsInNjb3BlIjoiZW1haWwgcHJvZmlsZSIsImVtYWlsX3ZlcmlmaWVkIjpmYWxzZSwicHJlZmVycmVkX3VzZXJuYW1lIjoiYWRtaW4ifQ.HBsrk2SBn6A8Ox1KLRW0llsOhPdQwfY5BlWY-kHUCi-JdpWT2R8g2xujrjc7p8g_VxdlEvtkfMMkLE4N2t1VP1gDBYjUMMdwA4hd8brHnFrI0uwlh2czMtSwZ3Ke5-8hTwJHUNA40Bb7ecK7zW3FyGq-yadEyslZMQ6DSpmB59uKCd32foV-KnUirMmuuUAYc7Q-N-xD6JHxGELzPynRIPN5tiZJbLuYShUfwCBugiPS4ePvtc1UBIAKr71upOVipvtRcKT1JTfT-xLfer91xcNNwvTxhUxXUIlj2VpCwC71gNUdzQiSbOFHkxZmOFFbPCWLSP_2rVlg5tGoX3mrAA -d {"id":"399491a2-f953-4936-a002-de1f0f98ccf3","name":"Dev Team A can write to topics that start with x- on any cluster","type":"scope","logic":"POSITIVE","decisionStrategy":"UNANIMOUS","config":{"resources":"[\"Topic:x-*\"]","scopes":"[\"Describe\"]","applyPolicies":"[\"Dev Team A\"]"}} -H Content-Type: application/json
2022-04-02 23:31:17 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 23:31:17 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-producer-my-cluster-27f903c8 to finished
2022-04-02 23:34:57 [main] [1;31mERROR[m [TestUtils:162] Exception waiting for job finished, null
2022-04-02 23:34:57 [main] [32mINFO [m [OauthAuthorizationIsolatedST:545] Sending messages to topic starting with a- -> the messages should be successfully sent
2022-04-02 23:34:57 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-producer-my-cluster-27f903c8 in namespace infra-namespace
2022-04-02 23:34:57 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-producer-my-cluster-27f903c8 will be in active state
2022-04-02 23:34:58 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-producer-my-cluster-27f903c8 to finished
2022-04-02 23:35:07 [main] [32mINFO [m [OauthAuthorizationIsolatedST:554] Changing back to the original settings and checking, if the producer will be successful
2022-04-02 23:35:08 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-6ctsh -- curl -v --insecure -X PUT https://keycloak.infra-namespace.svc.cluster.local:8443/auth/admin/realms/kafka-authz/clients/7514b847-7b46-4936-9d9b-59df8fdce294/authz/resource-server/policy/399491a2-f953-4936-a002-de1f0f98ccf3 -H Authorization: Bearer eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICJCM1ZKeERnQ3dkajZ4OHdWNTNiMGZ3d1JWUUlvSG5vRTFLTnVUODlkcU5BIn0.eyJleHAiOjE2NDg5NDU4NzYsImlhdCI6MTY0ODk0MjI3NiwianRpIjoiOTBlNGFlMmItY2M4Ny00MWZkLTg1ZGUtOTMyYTI2MThiOWUzIiwiaXNzIjoiaHR0cHM6Ly9rZXljbG9hay5pbmZyYS1uYW1lc3BhY2Uuc3ZjLmNsdXN0ZXIubG9jYWw6ODQ0My9hdXRoL3JlYWxtcy9tYXN0ZXIiLCJzdWIiOiJmZGE0ZDFlNS0xNWIzLTQ5MzYtYTRmOC1jZGE5NzJjNjMwODgiLCJ0eXAiOiJCZWFyZXIiLCJhenAiOiJhZG1pbi1jbGkiLCJzZXNzaW9uX3N0YXRlIjoiNzIzM2MwOGQtMzY2Zi00MmMzLWEwZjktMTI2YzQ3MGVhZjMyIiwiYWNyIjoiMSIsInNjb3BlIjoiZW1haWwgcHJvZmlsZSIsImVtYWlsX3ZlcmlmaWVkIjpmYWxzZSwicHJlZmVycmVkX3VzZXJuYW1lIjoiYWRtaW4ifQ.HBsrk2SBn6A8Ox1KLRW0llsOhPdQwfY5BlWY-kHUCi-JdpWT2R8g2xujrjc7p8g_VxdlEvtkfMMkLE4N2t1VP1gDBYjUMMdwA4hd8brHnFrI0uwlh2czMtSwZ3Ke5-8hTwJHUNA40Bb7ecK7zW3FyGq-yadEyslZMQ6DSpmB59uKCd32foV-KnUirMmuuUAYc7Q-N-xD6JHxGELzPynRIPN5tiZJbLuYShUfwCBugiPS4ePvtc1UBIAKr71upOVipvtRcKT1JTfT-xLfer91xcNNwvTxhUxXUIlj2VpCwC71gNUdzQiSbOFHkxZmOFFbPCWLSP_2rVlg5tGoX3mrAA -d {"id":"399491a2-f953-4936-a002-de1f0f98ccf3","name":"Dev Team A can write to topics that start with x- on any cluster","type":"scope","logic":"POSITIVE","decisionStrategy":"UNANIMOUS","config":{"resources":"[\"Topic:x-*\"]","scopes":"[\"Describe\",\"Write\"]","applyPolicies":"[\"Dev Team A\"]"}} -H Content-Type: application/json
2022-04-02 23:35:08 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 23:35:08 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-producer-my-cluster-27f903c8 in namespace infra-namespace
2022-04-02 23:35:08 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-producer-my-cluster-27f903c8 will be in active state
2022-04-02 23:35:09 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-producer-my-cluster-27f903c8 to finished
2022-04-02 23:36:57 [main] [32mINFO [m [OauthAuthorizationIsolatedST:568] Changing configuration of Kafka back to it's original form
2022-04-02 23:36:57 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: oauth-cluster-authz-name will have desired state: Ready
2022-04-02 23:36:57 [main] [32mINFO [m [ResourceManager:444] Kafka: oauth-cluster-authz-name is in desired state: Ready
2022-04-02 23:36:57 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 23:36:57 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSessionReAuthentication
2022-04-02 23:36:57 [main] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-producer-my-cluster-27f903c8 in namespace infra-namespace
2022-04-02 23:36:57 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-producer-my-cluster-27f903c8 in namespace infra-namespace
2022-04-02 23:36:57 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-producer-my-cluster-27f903c8 in namespace infra-namespace
2022-04-02 23:36:57 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic x-topic-example-topic in namespace infra-namespace
2022-04-02 23:36:57 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic a-topic-example-topic in namespace infra-namespace
2022-04-02 23:37:07 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 23:37:07 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testSessionReAuthentication-FINISHED
2022-04-02 23:37:07 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 23:37:07 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 23:37:07 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testKeycloakAuthorizerToDelegateToSimpleAuthorizer-STARTED
2022-04-02 23:37:07 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 23:37:07 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-97 for test case:testKeycloakAuthorizerToDelegateToSimpleAuthorizer
2022-04-02 23:37:07 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-97
2022-04-02 23:37:07 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-97
2022-04-02 23:37:07 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-97
2022-04-02 23:37:07 [main] [32mINFO [m [ResourceManager:155] Create/Update Secret sso-x509-https-secret in namespace infra-namespace
2022-04-02 23:37:07 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-97
2022-04-02 23:37:07 [main] [32mINFO [m [ResourceManager:155] Create/Update Secret team-a-client-secret in namespace infra-namespace
2022-04-02 23:37:07 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-97
2022-04-02 23:37:07 [main] [32mINFO [m [ResourceManager:155] Create/Update Secret team-b-client-secret in namespace infra-namespace
2022-04-02 23:37:07 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-97
2022-04-02 23:37:07 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-4d3ba916 in namespace namespace-97
2022-04-02 23:37:07 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-97
2022-04-02 23:37:07 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-4d3ba916 will have desired state: Ready
2022-04-02 23:38:21 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-4d3ba916 is in desired state: Ready
2022-04-02 23:38:21 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser team-a-client in namespace namespace-97
2022-04-02 23:38:21 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-97
2022-04-02 23:38:21 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: team-a-client will have desired state: Ready
2022-04-02 23:38:22 [main] [32mINFO [m [ResourceManager:444] KafkaUser: team-a-client is in desired state: Ready
2022-04-02 23:38:22 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser team-b-client in namespace namespace-97
2022-04-02 23:38:22 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-97
2022-04-02 23:38:22 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: team-b-client will have desired state: Ready
2022-04-02 23:38:23 [main] [32mINFO [m [ResourceManager:444] KafkaUser: team-b-client is in desired state: Ready
2022-04-02 23:38:23 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic a-topic-my-topic-2094851545-1409340599 in namespace namespace-97
2022-04-02 23:38:23 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-97
2022-04-02 23:38:23 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: a-topic-my-topic-2094851545-1409340599 will have desired state: Ready
2022-04-02 23:38:24 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: a-topic-my-topic-2094851545-1409340599 is in desired state: Ready
2022-04-02 23:38:24 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-producer-my-cluster-4d3ba916 in namespace namespace-97
2022-04-02 23:38:24 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-97
2022-04-02 23:38:24 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-producer-my-cluster-4d3ba916 will be in active state
2022-04-02 23:38:25 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-producer-my-cluster-4d3ba916 to finished
2022-04-02 23:38:33 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-consumer-my-cluster-4d3ba916 in namespace namespace-97
2022-04-02 23:38:33 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-97
2022-04-02 23:38:33 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-consumer-my-cluster-4d3ba916 will be in active state
2022-04-02 23:38:34 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-consumer-my-cluster-4d3ba916 to finished
2022-04-02 23:38:46 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 23:38:46 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKeycloakAuthorizerToDelegateToSimpleAuthorizer
2022-04-02 23:38:46 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser team-b-client in namespace namespace-97
2022-04-02 23:38:46 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic a-topic-my-topic-2094851545-1409340599 in namespace namespace-97
2022-04-02 23:38:46 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-producer-my-cluster-4d3ba916 in namespace namespace-97
2022-04-02 23:38:46 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaUser team-a-client in namespace namespace-97
2022-04-02 23:38:46 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Secret team-a-client-secret in namespace namespace-97
2022-04-02 23:38:46 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Secret sso-x509-https-secret in namespace namespace-97
2022-04-02 23:38:46 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Secret team-b-client-secret in namespace namespace-97
2022-04-02 23:38:46 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-consumer-my-cluster-4d3ba916 in namespace namespace-97
2022-04-02 23:38:46 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-4d3ba916 in namespace namespace-97
2022-04-02 23:38:56 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 23:38:56 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-97 for test case:testKeycloakAuthorizerToDelegateToSimpleAuthorizer
2022-04-02 23:39:39 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testKeycloakAuthorizerToDelegateToSimpleAuthorizer-FINISHED
2022-04-02 23:39:39 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 23:39:39 [main] [32mINFO [m [KeycloakUtils:52] Teardown Keycloak Operator in namespace: infra-namespace with watching namespace: infra-namespace
2022-04-02 23:39:42 [main] [32mINFO [m [Exec:417] Command: /bin/bash ../systemtest/src/test/resources/oauth2/teardown_keycloak_operator.sh infra-namespace 11.0.1 infra-namespace
2022-04-02 23:39:42 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 23:39:42 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 23:39:42 [main] [32mINFO [m [ResourceManager:348] Delete all resources for OauthAuthorizationIsolatedST
2022-04-02 23:39:42 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser team-a-client in namespace infra-namespace
2022-04-02 23:39:42 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaUser team-b-client in namespace infra-namespace
2022-04-02 23:39:42 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy global-network-policy in namespace infra-namespace
2022-04-02 23:39:42 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka oauth-cluster-authz-name in namespace infra-namespace
2022-04-02 23:39:52 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 23:39:52 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 23:39:52 [main] [32mINFO [m [ResourceManager:346] In context OauthAuthorizationIsolatedST is everything deleted.
2022-04-02 23:39:52 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;33mWARNING[m] Tests run: 10, Failures: 0, Errors: 0, Skipped: 2, Time elapsed: 1,112.328 s - in io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.security.oauth.OauthScopeIsolatedST
2022-04-02 23:39:52 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-02 23:40:17 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-02 23:40:17 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-02 23:40:17 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-02 23:40:17 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 23:40:17 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-02 23:40:17 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 23:40:17 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 23:40:17 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 23:40:17 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 23:40:17 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 23:40:17 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 23:40:17 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 23:40:17 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 23:40:17 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 23:40:17 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 23:40:17 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 23:40:17 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 23:40:17 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 23:40:17 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 23:40:17 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-02 23:40:17 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 23:40:17 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 23:40:17 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 23:40:18 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 23:40:18 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 23:40:18 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 23:40:18 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 23:40:27 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 23:40:27 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 23:40:27 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 23:40:37 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 23:40:43 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7e2e5e3d
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-02 23:40:43 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-02 23:40:43 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-02 23:40:43 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-02 23:40:43 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 23:40:43 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 23:40:43 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 23:40:43 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 23:40:43 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 23:40:43 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 23:40:43 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 23:40:43 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 23:40:43 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 23:40:43 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 23:40:43 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 23:40:44 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 23:40:44 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 23:40:44 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 23:40:44 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 23:40:44 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 23:40:44 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 23:40:44 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-02 23:40:44 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 23:40:44 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 23:40:44 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-02 23:40:44 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 23:40:44 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-02 23:40:44 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 23:40:44 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 23:40:44 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 23:40:44 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-02 23:40:44 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 23:40:44 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-02 23:40:44 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-02 23:40:44 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 23:40:44 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-02 23:40:44 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 23:40:44 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-02 23:41:04 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-02 23:41:04 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-02 23:41:14 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-02 23:41:14 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy global-network-policy in namespace infra-namespace
2022-04-02 23:41:14 [main] [32mINFO [m [OauthAbstractST:125] Deploying keycloak...
2022-04-02 23:41:14 [main] [32mINFO [m [KeycloakUtils:35] Prepare Keycloak Operator in namespace: infra-namespace with watching namespace: infra-namespace
2022-04-02 23:42:47 [main] [32mINFO [m [Exec:417] Command: /bin/bash ../systemtest/src/test/resources/oauth2/prepare_keycloak_operator.sh infra-namespace 11.0.1 infra-namespace
2022-04-02 23:42:47 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 23:42:47 [main] [32mINFO [m [KeycloakUtils:48] Keycloak in namespace infra-namespace is ready
2022-04-02 23:42:47 [main] [32mINFO [m [SecretUtils:46] Waiting for Secret credential-example-keycloak
2022-04-02 23:42:47 [main] [32mINFO [m [SecretUtils:50] Secret credential-example-keycloak created
2022-04-02 23:42:47 [main] [32mINFO [m [SecretUtils:70] Creating secret hello-world-producer-secret
2022-04-02 23:42:47 [main] [32mINFO [m [SecretUtils:70] Creating secret hello-world-consumer-secret
2022-04-02 23:42:47 [main] [32mINFO [m [SecretUtils:70] Creating secret team-a-client-secret
2022-04-02 23:42:47 [main] [32mINFO [m [SecretUtils:70] Creating secret team-b-client-secret
2022-04-02 23:42:47 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-broker-secret
2022-04-02 23:42:47 [main] [32mINFO [m [SecretUtils:70] Creating secret my-connect-oauth
2022-04-02 23:42:47 [main] [32mINFO [m [SecretUtils:70] Creating secret my-mirror-maker-oauth
2022-04-02 23:42:47 [main] [32mINFO [m [SecretUtils:70] Creating secret my-mirror-maker-2-oauth
2022-04-02 23:42:47 [main] [32mINFO [m [SecretUtils:70] Creating secret my-bridge-oauth
2022-04-02 23:42:47 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-audience-secret
2022-04-02 23:42:47 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-client-secret
2022-04-02 23:42:47 [main] [32mINFO [m [KeycloakInstance:50] Replacing validIssuerUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal to pointing to scope-test realm
2022-04-02 23:42:47 [main] [32mINFO [m [KeycloakInstance:51] Replacing jwksEndpointUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/certs to pointing to scope-test realm
2022-04-02 23:42:47 [main] [32mINFO [m [KeycloakInstance:52] Replacing oauthTokenEndpointUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/token to pointing to scope-test realm
2022-04-02 23:42:47 [main] [32mINFO [m [KeycloakInstance:60] Using HTTP endpoints
2022-04-02 23:42:47 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka oauth-cluster-scope-name in namespace infra-namespace
2022-04-02 23:42:47 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: oauth-cluster-scope-name will have desired state: Ready
2022-04-02 23:43:56 [main] [32mINFO [m [ResourceManager:444] Kafka: oauth-cluster-scope-name is in desired state: Ready
2022-04-02 23:43:56 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 23:43:56 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthScopeIsolatedST.testScopeKafkaConnectSetCorrectly-STARTED
2022-04-02 23:43:56 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 23:43:56 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-01ff52e0-kafka-clients in namespace infra-namespace
2022-04-02 23:43:56 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-01ff52e0-kafka-clients will be ready
2022-04-02 23:43:58 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-01ff52e0-kafka-clients is ready
2022-04-02 23:43:58 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-01ff52e0-scraper in namespace infra-namespace
2022-04-02 23:43:58 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-01ff52e0-scraper will be ready
2022-04-02 23:43:59 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-01ff52e0-scraper is ready
2022-04-02 23:43:59 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-01ff52e0-scraper to be ready
2022-04-02 23:44:09 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-01ff52e0-scraper is ready
2022-04-02 23:44:09 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-01ff52e0-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-02 23:44:09 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-01ff52e0-allow in namespace infra-namespace
2022-04-02 23:44:09 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-02 23:44:09 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-01ff52e0 in namespace infra-namespace
2022-04-02 23:44:09 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-01ff52e0 will have desired state: Ready
2022-04-02 23:45:12 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-01ff52e0 is in desired state: Ready
2022-04-02 23:45:12 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 23:45:12 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testScopeKafkaConnectSetCorrectly
2022-04-02 23:45:12 [main] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-01ff52e0-allow in namespace infra-namespace
2022-04-02 23:45:12 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-01ff52e0-kafka-clients in namespace infra-namespace
2022-04-02 23:45:12 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-01ff52e0-scraper in namespace infra-namespace
2022-04-02 23:45:12 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-01ff52e0 in namespace infra-namespace
2022-04-02 23:45:52 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 23:45:52 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthScopeIsolatedST.testScopeKafkaConnectSetCorrectly-FINISHED
2022-04-02 23:45:52 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 23:45:52 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 23:45:52 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthScopeIsolatedST.testScopeKafkaConnectSetIncorrectly-STARTED
2022-04-02 23:45:52 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 23:45:52 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-19a9354d-kafka-clients in namespace infra-namespace
2022-04-02 23:45:52 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-19a9354d-kafka-clients will be ready
2022-04-02 23:45:53 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-19a9354d-kafka-clients is ready
2022-04-02 23:45:53 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-19a9354d-scraper in namespace infra-namespace
2022-04-02 23:45:53 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-19a9354d-scraper will be ready
2022-04-02 23:45:54 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-19a9354d-scraper is ready
2022-04-02 23:45:54 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-19a9354d-scraper to be ready
2022-04-02 23:46:04 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-19a9354d-scraper is ready
2022-04-02 23:46:04 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-19a9354d-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-02 23:46:04 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-19a9354d-allow in namespace infra-namespace
2022-04-02 23:46:04 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-02 23:46:04 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-19a9354d in namespace infra-namespace
2022-04-02 23:46:18 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 23:46:18 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testScopeKafkaConnectSetIncorrectly
2022-04-02 23:46:18 [main] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-19a9354d-allow in namespace infra-namespace
2022-04-02 23:46:18 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-19a9354d in namespace infra-namespace
2022-04-02 23:46:18 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-19a9354d-kafka-clients in namespace infra-namespace
2022-04-02 23:46:18 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-19a9354d-scraper in namespace infra-namespace
2022-04-02 23:47:08 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 23:47:08 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthScopeIsolatedST.testScopeKafkaConnectSetIncorrectly-FINISHED
2022-04-02 23:47:08 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 23:47:08 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 23:47:08 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthScopeIsolatedST.testClientScopeKafkaSetCorrectly-STARTED
2022-04-02 23:47:08 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 23:47:08 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-02 23:47:08 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-211279640-883112051 in namespace infra-namespace
2022-04-02 23:47:08 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-211279640-883112051 will have desired state: Ready
2022-04-02 23:47:09 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-211279640-883112051 is in desired state: Ready
2022-04-02 23:47:09 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-c71ab00e in namespace infra-namespace
2022-04-02 23:47:09 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-c71ab00e will be in active state
2022-04-02 23:47:10 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-c71ab00e to finished
2022-04-02 23:47:18 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 23:47:18 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testClientScopeKafkaSetCorrectly
2022-04-02 23:47:18 [main] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-c71ab00e in namespace infra-namespace
2022-04-02 23:47:18 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-211279640-883112051 in namespace infra-namespace
2022-04-02 23:47:28 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 23:47:28 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthScopeIsolatedST.testClientScopeKafkaSetCorrectly-FINISHED
2022-04-02 23:47:28 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 23:47:28 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 23:47:28 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthScopeIsolatedST.testClientScopeKafkaSetIncorrectly-STARTED
2022-04-02 23:47:28 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 23:47:28 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-02 23:47:28 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 1 Pod(s) of oauth-cluster-scope-name-kafka to be ready
2022-04-02 23:48:03 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: oauth-cluster-scope-name will have desired state: Ready
2022-04-02 23:48:03 [main] [32mINFO [m [ResourceManager:444] Kafka: oauth-cluster-scope-name is in desired state: Ready
2022-04-02 23:48:03 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: oauth-cluster-scope-name is ready
2022-04-02 23:48:03 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1946468267-1581153779 in namespace infra-namespace
2022-04-02 23:48:03 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1946468267-1581153779 will have desired state: Ready
2022-04-02 23:48:04 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1946468267-1581153779 is in desired state: Ready
2022-04-02 23:48:04 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-a5da0f52 in namespace infra-namespace
2022-04-02 23:48:04 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-a5da0f52 will be in active state
2022-04-02 23:48:05 [main] [32mINFO [m [ClientUtils:89] Waiting for producer/consumer:oauth-producer-my-cluster-a5da0f52 to finish with failure.
2022-04-02 23:51:45 [main] [1;31mERROR[m [TestUtils:162] Exception waiting for Job did not finish within time limit (as expected)., null
2022-04-02 23:51:45 [main] [32mINFO [m [ClientUtils:100] Client job 'oauth-producer-my-cluster-a5da0f52' finished with expected timeout.
2022-04-02 23:51:50 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 1 Pod(s) of oauth-cluster-scope-name-kafka to be ready
2022-04-02 23:52:27 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: oauth-cluster-scope-name will have desired state: Ready
2022-04-02 23:52:27 [main] [32mINFO [m [ResourceManager:444] Kafka: oauth-cluster-scope-name is in desired state: Ready
2022-04-02 23:52:27 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: oauth-cluster-scope-name is ready
2022-04-02 23:52:27 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 23:52:27 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testClientScopeKafkaSetIncorrectly
2022-04-02 23:52:27 [main] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-a5da0f52 in namespace infra-namespace
2022-04-02 23:52:27 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1946468267-1581153779 in namespace infra-namespace
2022-04-02 23:52:37 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 23:52:37 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthScopeIsolatedST.testClientScopeKafkaSetIncorrectly-FINISHED
2022-04-02 23:52:37 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 23:52:37 [main] [32mINFO [m [KeycloakUtils:52] Teardown Keycloak Operator in namespace: infra-namespace with watching namespace: infra-namespace
2022-04-02 23:52:41 [main] [32mINFO [m [Exec:417] Command: /bin/bash ../systemtest/src/test/resources/oauth2/teardown_keycloak_operator.sh infra-namespace 11.0.1 infra-namespace
2022-04-02 23:52:41 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 23:52:41 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 23:52:41 [main] [32mINFO [m [ResourceManager:348] Delete all resources for OauthScopeIsolatedST
2022-04-02 23:52:41 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka oauth-cluster-scope-name in namespace infra-namespace
2022-04-02 23:52:41 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy global-network-policy in namespace infra-namespace
2022-04-02 23:52:51 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 23:52:51 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 23:52:51 [main] [32mINFO [m [ResourceManager:346] In context OauthScopeIsolatedST is everything deleted.
2022-04-02 23:52:51 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 778.746 s - in io.strimzi.systemtest.security.oauth.OauthScopeIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST
2022-04-02 23:52:51 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-02 23:53:16 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-02 23:53:16 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-02 23:53:16 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-02 23:53:16 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 23:53:16 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-02 23:53:16 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 23:53:16 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 23:53:16 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 23:53:16 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 23:53:16 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 23:53:16 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 23:53:16 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 23:53:16 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 23:53:16 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 23:53:16 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 23:53:16 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 23:53:16 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 23:53:16 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 23:53:16 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 23:53:16 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 23:53:16 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 23:53:16 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 23:53:16 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 23:53:16 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 23:53:16 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 23:53:16 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-02 23:53:16 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 23:53:17 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 23:53:26 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 23:53:26 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 23:53:36 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 23:53:42 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7e2e5e3d
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-02 23:53:42 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-02 23:53:42 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-02 23:53:42 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-02 23:53:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-02 23:53:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 23:53:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-02 23:53:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-02 23:53:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-02 23:53:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-02 23:53:42 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-02 23:53:42 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-02 23:53:42 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-02 23:53:42 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-02 23:53:42 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-02 23:53:42 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-02 23:53:42 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-02 23:53:42 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-02 23:53:42 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-02 23:53:42 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-02 23:53:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-02 23:53:42 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-02 23:53:42 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 23:53:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-02 23:53:42 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-02 23:53:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-02 23:53:42 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-02 23:53:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-02 23:53:42 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-02 23:53:42 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-02 23:53:42 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-02 23:53:42 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-02 23:53:42 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-02 23:53:42 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-02 23:53:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-02 23:53:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-02 23:53:42 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-02 23:53:42 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-02 23:54:20 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-02 23:54:20 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-02 23:54:30 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-02 23:54:30 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy global-network-policy in namespace infra-namespace
2022-04-02 23:54:30 [main] [32mINFO [m [OauthAbstractST:125] Deploying keycloak...
2022-04-02 23:54:30 [main] [32mINFO [m [KeycloakUtils:35] Prepare Keycloak Operator in namespace: infra-namespace with watching namespace: infra-namespace
2022-04-02 23:56:16 [main] [32mINFO [m [Exec:417] Command: /bin/bash ../systemtest/src/test/resources/oauth2/prepare_keycloak_operator.sh infra-namespace 11.0.1 infra-namespace
2022-04-02 23:56:16 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-02 23:56:16 [main] [32mINFO [m [KeycloakUtils:48] Keycloak in namespace infra-namespace is ready
2022-04-02 23:56:16 [main] [32mINFO [m [SecretUtils:46] Waiting for Secret credential-example-keycloak
2022-04-02 23:56:16 [main] [32mINFO [m [SecretUtils:50] Secret credential-example-keycloak created
2022-04-02 23:56:16 [main] [32mINFO [m [SecretUtils:70] Creating secret hello-world-producer-secret
2022-04-02 23:56:16 [main] [32mINFO [m [SecretUtils:70] Creating secret hello-world-consumer-secret
2022-04-02 23:56:16 [main] [32mINFO [m [SecretUtils:70] Creating secret team-a-client-secret
2022-04-02 23:56:16 [main] [32mINFO [m [SecretUtils:70] Creating secret team-b-client-secret
2022-04-02 23:56:16 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-broker-secret
2022-04-02 23:56:16 [main] [32mINFO [m [SecretUtils:70] Creating secret my-connect-oauth
2022-04-02 23:56:16 [main] [32mINFO [m [SecretUtils:70] Creating secret my-mirror-maker-oauth
2022-04-02 23:56:16 [main] [32mINFO [m [SecretUtils:70] Creating secret my-mirror-maker-2-oauth
2022-04-02 23:56:16 [main] [32mINFO [m [SecretUtils:70] Creating secret my-bridge-oauth
2022-04-02 23:56:16 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-audience-secret
2022-04-02 23:56:16 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-client-secret
2022-04-02 23:56:16 [main] [32mINFO [m [KeycloakInstance:50] Replacing validIssuerUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal to pointing to internal realm
2022-04-02 23:56:16 [main] [32mINFO [m [KeycloakInstance:51] Replacing jwksEndpointUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/certs to pointing to internal realm
2022-04-02 23:56:16 [main] [32mINFO [m [KeycloakInstance:52] Replacing oauthTokenEndpointUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/token to pointing to internal realm
2022-04-02 23:56:16 [main] [32mINFO [m [KeycloakInstance:55] Using HTTPS endpoints
2022-04-02 23:56:16 [main] [32mINFO [m [OauthTlsIsolatedST:480] Keycloak settings KeycloakInstance{jwksExpireSeconds=500, jwksRefreshSeconds=400, username='admin', password='0pd_SwYwuxj2zw==', httpsUri='keycloak.infra-namespace.svc.cluster.local:8443', httpUri='keycloak-discovery.infra-namespace.svc.cluster.local:8080', validIssuerUri='https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal', jwksEndpointUri='https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/certs', oauthTokenEndpointUri='https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/token', introspectionEndpointUri='https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/token/introspect', userNameClaim='preferred_username', keystorePattern=<tls>\s*<key-stores>\s*<key-store name="kcKeyStore">\s*<credential-reference clear-text=".*"\/>, keystorePasswordPattern=\".*\"}
2022-04-02 23:56:16 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka oauth-cluster-tls-name in namespace infra-namespace
2022-04-02 23:56:16 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: oauth-cluster-tls-name will have desired state: Ready
2022-04-02 23:57:40 [main] [32mINFO [m [ResourceManager:444] Kafka: oauth-cluster-tls-name is in desired state: Ready
2022-04-02 23:57:40 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser hello-world-producer in namespace infra-namespace
2022-04-02 23:57:40 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: hello-world-producer will have desired state: Ready
2022-04-02 23:57:41 [main] [32mINFO [m [ResourceManager:444] KafkaUser: hello-world-producer is in desired state: Ready
2022-04-02 23:57:41 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 23:57:41 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST.testProducerConsumerBridge-STARTED
2022-04-02 23:57:41 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 23:57:41 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1557167488-1208857664 in namespace infra-namespace
2022-04-02 23:57:41 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1557167488-1208857664 will have desired state: Ready
2022-04-02 23:57:42 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1557167488-1208857664 is in desired state: Ready
2022-04-02 23:57:42 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-02 23:57:42 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-feeca1ea in namespace infra-namespace
2022-04-02 23:57:42 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-feeca1ea will be in active state
2022-04-02 23:57:43 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-feeca1ea to finished
2022-04-02 23:57:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-feeca1ea in namespace infra-namespace
2022-04-02 23:57:51 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-feeca1ea will be in active state
2022-04-02 23:57:52 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-feeca1ea to finished
2022-04-02 23:58:04 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-feeca1ea-kafka-clients in namespace infra-namespace
2022-04-02 23:58:04 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-feeca1ea-kafka-clients will be ready
2022-04-02 23:58:06 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-feeca1ea-kafka-clients is ready
2022-04-02 23:58:06 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge oauth-cluster-tls-name in namespace infra-namespace
2022-04-02 23:58:06 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: oauth-cluster-tls-name will have desired state: Ready
2022-04-02 23:58:29 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: oauth-cluster-tls-name is in desired state: Ready
2022-04-02 23:58:29 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-02 23:58:29 [main] [32mINFO [m [ResourceManager:155] Create/Update Job bridge-producer-my-cluster-feeca1ea in namespace infra-namespace
2022-04-02 23:58:29 [main] [32mINFO [m [JobUtils:81] Waiting for job: bridge-producer-my-cluster-feeca1ea will be in active state
2022-04-02 23:58:30 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:bridge-producer-my-cluster-feeca1ea to finished
2022-04-02 23:58:48 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 23:58:48 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumerBridge
2022-04-02 23:58:48 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-feeca1ea-kafka-clients in namespace infra-namespace
2022-04-02 23:58:48 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Job bridge-producer-my-cluster-feeca1ea in namespace infra-namespace
2022-04-02 23:58:48 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1557167488-1208857664 in namespace infra-namespace
2022-04-02 23:58:48 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge oauth-cluster-tls-name in namespace infra-namespace
2022-04-02 23:58:48 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-feeca1ea in namespace infra-namespace
2022-04-02 23:58:48 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-feeca1ea in namespace infra-namespace
2022-04-02 23:59:38 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-02 23:59:38 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST.testProducerConsumerBridge-FINISHED
2022-04-02 23:59:38 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-02 23:59:38 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-02 23:59:38 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST.testProducerConsumer-STARTED
2022-04-02 23:59:38 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-02 23:59:38 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-797455047-1944664274 in namespace infra-namespace
2022-04-02 23:59:38 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-797455047-1944664274 will have desired state: Ready
2022-04-02 23:59:39 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-797455047-1944664274 is in desired state: Ready
2022-04-02 23:59:39 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-02 23:59:39 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-01ff4dfc in namespace infra-namespace
2022-04-02 23:59:39 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-01ff4dfc will be in active state
2022-04-02 23:59:40 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-01ff4dfc to finished
2022-04-02 23:59:43 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-01ff4dfc in namespace infra-namespace
2022-04-02 23:59:43 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-01ff4dfc will be in active state
2022-04-02 23:59:44 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-01ff4dfc to finished
2022-04-02 23:59:56 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-02 23:59:56 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumer
2022-04-02 23:59:56 [main] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-01ff4dfc in namespace infra-namespace
2022-04-02 23:59:56 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-797455047-1944664274 in namespace infra-namespace
2022-04-02 23:59:56 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-01ff4dfc in namespace infra-namespace
2022-04-03 00:00:06 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 00:00:06 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST.testProducerConsumer-FINISHED
2022-04-03 00:00:06 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 00:00:06 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 00:00:06 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST.testIntrospectionEndpoint-STARTED
2022-04-03 00:00:06 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 00:00:06 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1362826314-1145670317 in namespace infra-namespace
2022-04-03 00:00:06 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1362826314-1145670317 will have desired state: Ready
2022-04-03 00:00:07 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1362826314-1145670317 is in desired state: Ready
2022-04-03 00:00:07 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka oauth-cluster-tls-name-intro in namespace infra-namespace
2022-04-03 00:00:07 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: oauth-cluster-tls-name-intro will have desired state: Ready
2022-04-03 00:01:20 [main] [32mINFO [m [ResourceManager:444] Kafka: oauth-cluster-tls-name-intro is in desired state: Ready
2022-04-03 00:01:20 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-03 00:01:20 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-f89de195 in namespace infra-namespace
2022-04-03 00:01:20 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-f89de195 will be in active state
2022-04-03 00:01:21 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-f89de195 to finished
2022-04-03 00:01:30 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-f89de195 in namespace infra-namespace
2022-04-03 00:01:30 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-f89de195 will be in active state
2022-04-03 00:01:31 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-f89de195 to finished
2022-04-03 00:01:42 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 00:01:42 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testIntrospectionEndpoint
2022-04-03 00:01:42 [main] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-f89de195 in namespace infra-namespace
2022-04-03 00:01:42 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka oauth-cluster-tls-name-intro in namespace infra-namespace
2022-04-03 00:01:42 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1362826314-1145670317 in namespace infra-namespace
2022-04-03 00:01:42 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-f89de195 in namespace infra-namespace
2022-04-03 00:01:52 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 00:01:52 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST.testIntrospectionEndpoint-FINISHED
2022-04-03 00:01:52 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 00:01:52 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 00:01:52 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST.testProducerConsumerConnect-STARTED
2022-04-03 00:01:52 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 00:01:52 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-2139242982-267380015 in namespace infra-namespace
2022-04-03 00:01:52 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-2139242982-267380015 will have desired state: Ready
2022-04-03 00:01:53 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-2139242982-267380015 is in desired state: Ready
2022-04-03 00:01:53 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-03 00:01:53 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-0bc97874 in namespace infra-namespace
2022-04-03 00:01:53 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-0bc97874 will be in active state
2022-04-03 00:01:54 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-0bc97874 to finished
2022-04-03 00:02:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-0bc97874 in namespace infra-namespace
2022-04-03 00:02:02 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-0bc97874 will be in active state
2022-04-03 00:02:03 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-0bc97874 to finished
2022-04-03 00:02:09 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment oauth-cluster-tls-name-kafka-clients in namespace infra-namespace
2022-04-03 00:02:09 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: oauth-cluster-tls-name-kafka-clients will be ready
2022-04-03 00:02:10 [main] [32mINFO [m [DeploymentUtils:168] Deployment: oauth-cluster-tls-name-kafka-clients is ready
2022-04-03 00:02:10 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-0bc97874-scraper in namespace infra-namespace
2022-04-03 00:02:10 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-0bc97874-scraper will be ready
2022-04-03 00:02:11 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-0bc97874-scraper is ready
2022-04-03 00:02:11 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-0bc97874-scraper to be ready
2022-04-03 00:02:21 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-0bc97874-scraper is ready
2022-04-03 00:02:21 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-0bc97874-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-03 00:02:21 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-0bc97874-allow in namespace infra-namespace
2022-04-03 00:02:21 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-03 00:02:21 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-0bc97874 in namespace infra-namespace
2022-04-03 00:02:21 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-0bc97874 will have desired state: Ready
2022-04-03 00:03:32 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-0bc97874 is in desired state: Ready
2022-04-03 00:03:32 [main] [32mINFO [m [KafkaConnectUtils:63] Waiting until KafkaConnect API is available
2022-04-03 00:03:33 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-0bc97874-connect-7d94c6955b-hxr6n -- /bin/bash -c curl -I http://localhost:8083/connectors
2022-04-03 00:03:33 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-03 00:03:33 [main] [32mINFO [m [KafkaConnectUtils:66] KafkaConnect API is available
2022-04-03 00:03:33 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec oauth-cluster-tls-name-kafka-clients-8cb45f87d-gzfw2 -- /bin/bash -c curl -X POST -H "Content-Type: application/json" --data '{ "name": "sink-test", "config": { "connector.class": "FileStreamSink", "tasks.max": "1", "topics": "my-topic-2139242982-267380015", "file": "/tmp/test-file-sink.txt" } }' http://my-cluster-0bc97874-connect-api.infra-namespace.svc:8083/connectors
2022-04-03 00:03:33 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-03 00:03:33 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-0bc97874-connect-7d94c6955b-hxr6n
2022-04-03 00:03:37 [main] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-0bc97874-connect-7d94c6955b-hxr6n
2022-04-03 00:03:37 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 00:03:37 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumerConnect
2022-04-03 00:03:37 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-0bc97874-scraper in namespace infra-namespace
2022-04-03 00:03:37 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-2139242982-267380015 in namespace infra-namespace
2022-04-03 00:03:37 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment oauth-cluster-tls-name-kafka-clients in namespace infra-namespace
2022-04-03 00:03:37 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-0bc97874 in namespace infra-namespace
2022-04-03 00:03:37 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-0bc97874 in namespace infra-namespace
2022-04-03 00:03:37 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-0bc97874-allow in namespace infra-namespace
2022-04-03 00:03:37 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-0bc97874 in namespace infra-namespace
2022-04-03 00:04:27 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 00:04:27 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST.testProducerConsumerConnect-FINISHED
2022-04-03 00:04:27 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 00:04:27 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 00:04:27 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST.testMirrorMaker-STARTED
2022-04-03 00:04:27 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 00:04:27 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-393712354-1147155285 in namespace infra-namespace
2022-04-03 00:04:27 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-393712354-1147155285 will have desired state: Ready
2022-04-03 00:04:29 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-393712354-1147155285 is in desired state: Ready
2022-04-03 00:04:29 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-03 00:04:29 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-98f8f699 in namespace infra-namespace
2022-04-03 00:04:29 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-98f8f699 will be in active state
2022-04-03 00:04:30 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-98f8f699 to finished
2022-04-03 00:04:38 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-98f8f699 in namespace infra-namespace
2022-04-03 00:04:38 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-98f8f699 will be in active state
2022-04-03 00:04:39 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-98f8f699 to finished
2022-04-03 00:04:50 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka oauth-cluster-tls-name-target in namespace infra-namespace
2022-04-03 00:04:50 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: oauth-cluster-tls-name-target will have desired state: Ready
2022-04-03 00:06:14 [main] [32mINFO [m [ResourceManager:444] Kafka: oauth-cluster-tls-name-target is in desired state: Ready
2022-04-03 00:06:14 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker oauth-cluster-tls-name in namespace infra-namespace
2022-04-03 00:06:14 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: oauth-cluster-tls-name will have desired state: Ready
2022-04-03 00:07:20 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: oauth-cluster-tls-name is in desired state: Ready
2022-04-03 00:07:21 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-747685068-1146249779 in namespace infra-namespace
2022-04-03 00:07:21 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-747685068-1146249779 will have desired state: Ready
2022-04-03 00:07:22 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-747685068-1146249779 is in desired state: Ready
2022-04-03 00:07:22 [main] [32mINFO [m [SecretUtils:46] Waiting for Secret my-user-747685068-1146249779
2022-04-03 00:07:22 [main] [32mINFO [m [SecretUtils:50] Secret my-user-747685068-1146249779 created
2022-04-03 00:07:22 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-747685068-1146249779 will have desired state: Ready
2022-04-03 00:07:22 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-747685068-1146249779 is in desired state: Ready
2022-04-03 00:07:22 [main] [32mINFO [m [OauthTlsIsolatedST:390] Creating new client with new consumer-group and also to point on oauth-cluster-tls-name-target cluster
2022-04-03 00:07:22 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-03 00:07:22 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-98f8f699 in namespace infra-namespace
2022-04-03 00:07:22 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-98f8f699 will be in active state
2022-04-03 00:07:23 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-98f8f699 to finished
2022-04-03 00:07:34 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 00:07:34 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMirrorMaker
2022-04-03 00:07:34 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker oauth-cluster-tls-name in namespace infra-namespace
2022-04-03 00:07:34 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-393712354-1147155285 in namespace infra-namespace
2022-04-03 00:07:34 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka oauth-cluster-tls-name-target in namespace infra-namespace
2022-04-03 00:07:34 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-98f8f699 in namespace infra-namespace
2022-04-03 00:07:34 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-747685068-1146249779 in namespace infra-namespace
2022-04-03 00:07:34 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-98f8f699 in namespace infra-namespace
2022-04-03 00:07:34 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-98f8f699 in namespace infra-namespace
2022-04-03 00:07:44 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 00:07:44 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST.testMirrorMaker-FINISHED
2022-04-03 00:07:44 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 00:07:44 [main] [32mINFO [m [KeycloakUtils:52] Teardown Keycloak Operator in namespace: infra-namespace with watching namespace: infra-namespace
2022-04-03 00:07:48 [main] [32mINFO [m [Exec:417] Command: /bin/bash ../systemtest/src/test/resources/oauth2/teardown_keycloak_operator.sh infra-namespace 11.0.1 infra-namespace
2022-04-03 00:07:48 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-03 00:07:48 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 00:07:48 [main] [32mINFO [m [ResourceManager:348] Delete all resources for OauthTlsIsolatedST
2022-04-03 00:07:48 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka oauth-cluster-tls-name in namespace infra-namespace
2022-04-03 00:07:48 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaUser hello-world-producer in namespace infra-namespace
2022-04-03 00:07:48 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy global-network-policy in namespace infra-namespace
2022-04-03 00:07:58 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 00:07:58 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 00:07:58 [main] [32mINFO [m [ResourceManager:346] In context OauthTlsIsolatedST is everything deleted.
2022-04-03 00:07:58 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 907.102 s - in io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST
2022-04-03 00:07:58 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-03 00:08:23 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-03 00:08:23 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-03 00:08:23 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-03 00:08:23 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 00:08:23 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-03 00:08:23 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-03 00:08:23 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 00:08:23 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-03 00:08:23 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-03 00:08:23 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-03 00:08:23 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-03 00:08:23 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-03 00:08:23 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-03 00:08:23 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-03 00:08:23 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-03 00:08:23 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-03 00:08:23 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-03 00:08:23 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-03 00:08:23 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-03 00:08:23 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-03 00:08:23 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-03 00:08:23 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 00:08:23 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-03 00:08:23 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-03 00:08:23 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-03 00:08:23 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-03 00:08:33 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-03 00:08:33 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-03 00:08:33 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-03 00:08:33 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-03 00:08:43 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 00:08:49 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7e2e5e3d
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=120000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-03 00:08:49 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-03 00:08:49 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-03 00:08:49 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-03 00:08:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-03 00:08:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 00:08:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-03 00:08:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-03 00:08:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-03 00:08:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-03 00:08:49 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-03 00:08:49 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-03 00:08:49 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-03 00:08:50 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-03 00:08:50 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-03 00:08:50 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-03 00:08:50 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-03 00:08:50 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-03 00:08:50 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-03 00:08:50 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-03 00:08:50 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-03 00:08:50 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-03 00:08:50 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-03 00:08:50 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-03 00:08:50 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-03 00:08:50 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-03 00:08:50 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-03 00:08:50 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-03 00:08:50 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-03 00:08:50 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-03 00:08:50 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-03 00:08:50 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-03 00:08:50 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-03 00:08:50 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-03 00:08:50 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 00:08:50 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-03 00:08:50 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-03 00:08:50 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-03 00:09:29 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-03 00:09:29 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-03 00:09:39 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-03 00:09:39 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 00:09:39 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST.testKafkaRollsWhenTopicIsUnderReplicated-STARTED
2022-04-03 00:09:39 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 00:09:39 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-98 for test case:testKafkaRollsWhenTopicIsUnderReplicated
2022-04-03 00:09:39 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-98
2022-04-03 00:09:39 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-98
2022-04-03 00:09:39 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-98
2022-04-03 00:09:39 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-3bae6085 in namespace namespace-98
2022-04-03 00:09:39 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-98
2022-04-03 00:09:39 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-3bae6085 will have desired state: Ready
2022-04-03 00:11:39 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-3bae6085 is in desired state: Ready
2022-04-03 00:11:39 [main] [32mINFO [m [KafkaRollerIsolatedST:105] Running kafkaScaleUpScaleDown my-cluster-3bae6085
2022-04-03 00:11:39 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-3bae6085-kafka rolling update
2022-04-03 00:12:54 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-3bae6085-kafka has been successfully rolled
2022-04-03 00:12:54 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 4 Pod(s) of my-cluster-3bae6085-kafka to be ready
2022-04-03 00:13:44 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-3bae6085 will have desired state: Ready
2022-04-03 00:13:44 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-3bae6085 is in desired state: Ready
2022-04-03 00:13:44 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-3bae6085 is ready
2022-04-03 00:13:44 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-582556918-35407359 in namespace namespace-98
2022-04-03 00:13:44 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-98
2022-04-03 00:13:44 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-582556918-35407359 will have desired state: Ready
2022-04-03 00:13:45 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-582556918-35407359 is in desired state: Ready
2022-04-03 00:13:45 [main] [32mINFO [m [KafkaRollerIsolatedST:124] Scaling down to 3
2022-04-03 00:13:45 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-3bae6085-kafka rolling update
2022-04-03 00:15:20 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-3bae6085-kafka has been successfully rolled
2022-04-03 00:15:20 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-3bae6085-kafka to be ready
2022-04-03 00:15:52 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-3bae6085 will have desired state: Ready
2022-04-03 00:15:52 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-3bae6085 is in desired state: Ready
2022-04-03 00:15:52 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-3bae6085 is ready
2022-04-03 00:15:52 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-3bae6085 are stable
2022-04-03 00:15:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-entity-operator-66757c97bd-6zztf is in the Running state. Remaining seconds pod to be stable 50
2022-04-03 00:15:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-03 00:15:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-03 00:15:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-03 00:15:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-03 00:15:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-03 00:15:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-03 00:15:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-entity-operator-66757c97bd-6zztf is in the Running state. Remaining seconds pod to be stable 49
2022-04-03 00:15:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-03 00:15:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-03 00:15:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-03 00:15:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-03 00:15:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-03 00:15:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-03 00:15:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-entity-operator-66757c97bd-6zztf is in the Running state. Remaining seconds pod to be stable 48
2022-04-03 00:15:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-03 00:15:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-03 00:15:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-03 00:15:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-03 00:15:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-03 00:15:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-03 00:15:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-entity-operator-66757c97bd-6zztf is in the Running state. Remaining seconds pod to be stable 47
2022-04-03 00:15:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-03 00:15:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-03 00:15:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-03 00:15:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-03 00:15:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-03 00:15:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-03 00:15:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-entity-operator-66757c97bd-6zztf is in the Running state. Remaining seconds pod to be stable 46
2022-04-03 00:15:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-03 00:15:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-03 00:15:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-03 00:15:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-03 00:15:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-03 00:15:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-03 00:15:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-entity-operator-66757c97bd-6zztf is in the Running state. Remaining seconds pod to be stable 45
2022-04-03 00:15:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-03 00:15:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-03 00:15:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-03 00:15:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-03 00:15:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-03 00:15:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-03 00:15:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-entity-operator-66757c97bd-6zztf is in the Running state. Remaining seconds pod to be stable 44
2022-04-03 00:15:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-03 00:15:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-03 00:15:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-03 00:15:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-03 00:15:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-03 00:15:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-03 00:15:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-entity-operator-66757c97bd-6zztf is in the Running state. Remaining seconds pod to be stable 43
2022-04-03 00:15:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-03 00:15:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-03 00:15:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-03 00:15:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-03 00:15:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-03 00:15:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-03 00:16:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-entity-operator-66757c97bd-6zztf is in the Running state. Remaining seconds pod to be stable 42
2022-04-03 00:16:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-03 00:16:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-03 00:16:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-03 00:16:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-03 00:16:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-03 00:16:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-03 00:16:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-entity-operator-66757c97bd-6zztf is in the Running state. Remaining seconds pod to be stable 41
2022-04-03 00:16:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-03 00:16:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-03 00:16:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-03 00:16:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-03 00:16:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-03 00:16:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-03 00:16:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-entity-operator-66757c97bd-6zztf is in the Running state. Remaining seconds pod to be stable 40
2022-04-03 00:16:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-03 00:16:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-03 00:16:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-03 00:16:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-03 00:16:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-03 00:16:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-03 00:16:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-entity-operator-66757c97bd-6zztf is in the Running state. Remaining seconds pod to be stable 39
2022-04-03 00:16:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-03 00:16:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-03 00:16:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-03 00:16:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-03 00:16:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-03 00:16:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-03 00:16:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-entity-operator-66757c97bd-6zztf is in the Running state. Remaining seconds pod to be stable 38
2022-04-03 00:16:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-03 00:16:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-03 00:16:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-03 00:16:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-03 00:16:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-03 00:16:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-03 00:16:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-entity-operator-66757c97bd-6zztf is in the Running state. Remaining seconds pod to be stable 37
2022-04-03 00:16:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-03 00:16:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-03 00:16:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-03 00:16:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-03 00:16:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-03 00:16:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-03 00:16:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-entity-operator-66757c97bd-6zztf is in the Running state. Remaining seconds pod to be stable 36
2022-04-03 00:16:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-03 00:16:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-03 00:16:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-03 00:16:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-03 00:16:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-03 00:16:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-03 00:16:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-entity-operator-66757c97bd-6zztf is in the Running state. Remaining seconds pod to be stable 35
2022-04-03 00:16:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-03 00:16:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-03 00:16:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-03 00:16:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-03 00:16:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-03 00:16:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-03 00:16:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-entity-operator-66757c97bd-6zztf is in the Running state. Remaining seconds pod to be stable 34
2022-04-03 00:16:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-03 00:16:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-03 00:16:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-03 00:16:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-03 00:16:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-03 00:16:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-03 00:16:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-entity-operator-66757c97bd-6zztf is in the Running state. Remaining seconds pod to be stable 33
2022-04-03 00:16:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-03 00:16:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-03 00:16:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-03 00:16:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-03 00:16:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-03 00:16:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-03 00:16:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-entity-operator-66757c97bd-6zztf is in the Running state. Remaining seconds pod to be stable 32
2022-04-03 00:16:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-03 00:16:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-03 00:16:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-03 00:16:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-03 00:16:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-03 00:16:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-03 00:16:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-entity-operator-66757c97bd-6zztf is in the Running state. Remaining seconds pod to be stable 31
2022-04-03 00:16:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-03 00:16:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-03 00:16:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-03 00:16:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-03 00:16:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-03 00:16:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-03 00:16:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-entity-operator-66757c97bd-6zztf is in the Running state. Remaining seconds pod to be stable 30
2022-04-03 00:16:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-03 00:16:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-03 00:16:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-03 00:16:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-03 00:16:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-03 00:16:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-03 00:16:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-entity-operator-66757c97bd-6zztf is in the Running state. Remaining seconds pod to be stable 29
2022-04-03 00:16:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-03 00:16:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-03 00:16:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-03 00:16:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-03 00:16:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-03 00:16:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-03 00:16:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-entity-operator-66757c97bd-6zztf is in the Running state. Remaining seconds pod to be stable 28
2022-04-03 00:16:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-03 00:16:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-03 00:16:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-03 00:16:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-03 00:16:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-03 00:16:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-03 00:16:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-entity-operator-66757c97bd-6zztf is in the Running state. Remaining seconds pod to be stable 27
2022-04-03 00:16:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-03 00:16:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-03 00:16:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-03 00:16:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-03 00:16:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-03 00:16:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-03 00:16:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-entity-operator-66757c97bd-6zztf is in the Running state. Remaining seconds pod to be stable 26
2022-04-03 00:16:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-03 00:16:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-03 00:16:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-03 00:16:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-03 00:16:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-03 00:16:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-03 00:16:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-entity-operator-66757c97bd-6zztf is in the Running state. Remaining seconds pod to be stable 25
2022-04-03 00:16:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-03 00:16:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-03 00:16:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-03 00:16:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-03 00:16:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-03 00:16:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-03 00:16:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-entity-operator-66757c97bd-6zztf is in the Running state. Remaining seconds pod to be stable 24
2022-04-03 00:16:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-03 00:16:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-03 00:16:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-03 00:16:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-03 00:16:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-03 00:16:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-03 00:16:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-entity-operator-66757c97bd-6zztf is in the Running state. Remaining seconds pod to be stable 23
2022-04-03 00:16:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-03 00:16:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-03 00:16:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-03 00:16:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-03 00:16:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-03 00:16:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-03 00:16:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-entity-operator-66757c97bd-6zztf is in the Running state. Remaining seconds pod to be stable 22
2022-04-03 00:16:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-03 00:16:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-03 00:16:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-03 00:16:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-03 00:16:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-03 00:16:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-03 00:16:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-entity-operator-66757c97bd-6zztf is in the Running state. Remaining seconds pod to be stable 21
2022-04-03 00:16:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-03 00:16:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-03 00:16:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-03 00:16:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-03 00:16:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-03 00:16:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-03 00:16:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-entity-operator-66757c97bd-6zztf is in the Running state. Remaining seconds pod to be stable 20
2022-04-03 00:16:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-03 00:16:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-03 00:16:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-03 00:16:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-03 00:16:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-03 00:16:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-03 00:16:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-entity-operator-66757c97bd-6zztf is in the Running state. Remaining seconds pod to be stable 19
2022-04-03 00:16:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-03 00:16:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-03 00:16:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-03 00:16:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-03 00:16:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-03 00:16:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-03 00:16:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-entity-operator-66757c97bd-6zztf is in the Running state. Remaining seconds pod to be stable 18
2022-04-03 00:16:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-03 00:16:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-03 00:16:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-03 00:16:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-03 00:16:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-03 00:16:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-03 00:16:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-entity-operator-66757c97bd-6zztf is in the Running state. Remaining seconds pod to be stable 17
2022-04-03 00:16:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-03 00:16:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-03 00:16:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-03 00:16:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-03 00:16:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-03 00:16:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-03 00:16:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-entity-operator-66757c97bd-6zztf is in the Running state. Remaining seconds pod to be stable 16
2022-04-03 00:16:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-03 00:16:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-03 00:16:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-03 00:16:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-03 00:16:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-03 00:16:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-03 00:16:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-entity-operator-66757c97bd-6zztf is in the Running state. Remaining seconds pod to be stable 15
2022-04-03 00:16:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-03 00:16:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-03 00:16:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-03 00:16:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-03 00:16:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-03 00:16:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-03 00:16:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-entity-operator-66757c97bd-6zztf is in the Running state. Remaining seconds pod to be stable 14
2022-04-03 00:16:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-03 00:16:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-03 00:16:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-03 00:16:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-03 00:16:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-03 00:16:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-03 00:16:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-entity-operator-66757c97bd-6zztf is in the Running state. Remaining seconds pod to be stable 13
2022-04-03 00:16:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-03 00:16:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-03 00:16:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-03 00:16:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-03 00:16:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-03 00:16:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-03 00:16:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-entity-operator-66757c97bd-6zztf is in the Running state. Remaining seconds pod to be stable 12
2022-04-03 00:16:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-03 00:16:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-03 00:16:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-03 00:16:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-03 00:16:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-03 00:16:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-03 00:16:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-entity-operator-66757c97bd-6zztf is in the Running state. Remaining seconds pod to be stable 11
2022-04-03 00:16:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-03 00:16:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-03 00:16:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-03 00:16:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-03 00:16:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-03 00:16:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-03 00:16:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-entity-operator-66757c97bd-6zztf is in the Running state. Remaining seconds pod to be stable 10
2022-04-03 00:16:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-03 00:16:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-03 00:16:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-03 00:16:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-03 00:16:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-03 00:16:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-03 00:16:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-entity-operator-66757c97bd-6zztf is in the Running state. Remaining seconds pod to be stable 9
2022-04-03 00:16:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-03 00:16:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-03 00:16:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-03 00:16:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-03 00:16:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-03 00:16:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-03 00:16:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-entity-operator-66757c97bd-6zztf is in the Running state. Remaining seconds pod to be stable 8
2022-04-03 00:16:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-03 00:16:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-03 00:16:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-03 00:16:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-03 00:16:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-03 00:16:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-03 00:16:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-entity-operator-66757c97bd-6zztf is in the Running state. Remaining seconds pod to be stable 7
2022-04-03 00:16:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-03 00:16:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-03 00:16:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-03 00:16:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-03 00:16:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-03 00:16:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-03 00:16:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-entity-operator-66757c97bd-6zztf is in the Running state. Remaining seconds pod to be stable 6
2022-04-03 00:16:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-03 00:16:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-03 00:16:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-03 00:16:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-03 00:16:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-03 00:16:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-03 00:16:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-entity-operator-66757c97bd-6zztf is in the Running state. Remaining seconds pod to be stable 5
2022-04-03 00:16:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-03 00:16:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-03 00:16:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-03 00:16:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-03 00:16:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-03 00:16:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-03 00:16:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-entity-operator-66757c97bd-6zztf is in the Running state. Remaining seconds pod to be stable 4
2022-04-03 00:16:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-03 00:16:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-03 00:16:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-03 00:16:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-03 00:16:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-03 00:16:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-03 00:16:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-entity-operator-66757c97bd-6zztf is in the Running state. Remaining seconds pod to be stable 3
2022-04-03 00:16:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-03 00:16:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-03 00:16:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-03 00:16:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-03 00:16:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-03 00:16:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-03 00:16:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-entity-operator-66757c97bd-6zztf is in the Running state. Remaining seconds pod to be stable 2
2022-04-03 00:16:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-03 00:16:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-03 00:16:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-03 00:16:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-03 00:16:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-03 00:16:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-03 00:16:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-entity-operator-66757c97bd-6zztf is in the Running state. Remaining seconds pod to be stable 1
2022-04-03 00:16:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-03 00:16:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-03 00:16:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-kafka-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-03 00:16:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-03 00:16:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-03 00:16:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3bae6085-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-03 00:16:42 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-3bae6085-entity-operator-66757c97bd-6zztf ,my-cluster-3bae6085-kafka-0 ,my-cluster-3bae6085-kafka-1 ,my-cluster-3bae6085-kafka-2 ,my-cluster-3bae6085-zookeeper-0 ,my-cluster-3bae6085-zookeeper-1 ,my-cluster-3bae6085-zookeeper-2
2022-04-03 00:16:42 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-3bae6085-kafka rolling update
2022-04-03 00:18:12 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-3bae6085-kafka has been successfully rolled
2022-04-03 00:18:12 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-3bae6085-kafka to be ready
2022-04-03 00:18:38 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-3bae6085 will have desired state: Ready
2022-04-03 00:18:38 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-3bae6085 is in desired state: Ready
2022-04-03 00:18:38 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-3bae6085 is ready
2022-04-03 00:18:38 [main] [32mINFO [m [AbstractST:478] Search in strimzi-cluster-operator log for errors in last 539 seconds
2022-04-03 00:18:38 [main] [32mINFO [m [BaseCmdKubeClient:481] Exception not found
2022-04-03 00:18:38 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 00:18:38 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaRollsWhenTopicIsUnderReplicated
2022-04-03 00:18:38 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-582556918-35407359 in namespace namespace-98
2022-04-03 00:18:38 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-3bae6085 in namespace namespace-98
2022-04-03 00:18:48 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 00:18:48 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-98 for test case:testKafkaRollsWhenTopicIsUnderReplicated
2022-04-03 00:19:31 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST.testKafkaRollsWhenTopicIsUnderReplicated-FINISHED
2022-04-03 00:19:31 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 00:19:31 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 00:19:31 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST.testKafkaPodPendingDueToRack-STARTED
2022-04-03 00:19:31 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 00:19:31 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-99 for test case:testKafkaPodPendingDueToRack
2022-04-03 00:19:31 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-99
2022-04-03 00:19:31 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-99
2022-04-03 00:19:31 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-99
2022-04-03 00:19:31 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-087f9f20 in namespace namespace-99
2022-04-03 00:19:31 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-99
2022-04-03 00:19:32 [main] [32mINFO [m [PodUtils:209] Wait until Pod my-cluster-087f9f20-kafka will have stable 3 replicas
2022-04-03 00:19:32 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-03 00:19:33 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-03 00:19:34 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-03 00:19:35 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-03 00:19:36 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-03 00:19:37 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-03 00:19:38 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-03 00:19:39 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-03 00:19:40 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-03 00:19:41 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-03 00:19:42 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-03 00:19:43 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-03 00:19:44 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-03 00:19:45 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-03 00:19:46 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-03 00:19:47 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-03 00:19:48 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-03 00:19:49 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-03 00:19:50 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-03 00:19:51 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-03 00:19:52 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-03 00:19:53 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-03 00:19:54 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-03 00:19:55 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-03 00:19:56 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-03 00:19:57 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-03 00:19:58 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-03 00:19:59 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-03 00:20:00 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-03 00:20:01 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 19 polls
2022-04-03 00:20:02 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 18 polls
2022-04-03 00:20:03 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 17 polls
2022-04-03 00:20:04 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 16 polls
2022-04-03 00:20:05 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 15 polls
2022-04-03 00:20:06 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 14 polls
2022-04-03 00:20:07 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 13 polls
2022-04-03 00:20:08 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 12 polls
2022-04-03 00:20:09 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 11 polls
2022-04-03 00:20:10 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 10 polls
2022-04-03 00:20:11 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 9 polls
2022-04-03 00:20:12 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 8 polls
2022-04-03 00:20:13 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 7 polls
2022-04-03 00:20:14 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 6 polls
2022-04-03 00:20:15 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 5 polls
2022-04-03 00:20:16 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 4 polls
2022-04-03 00:20:17 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 3 polls
2022-04-03 00:20:18 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 2 polls
2022-04-03 00:20:19 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 1 polls
2022-04-03 00:20:20 [main] [32mINFO [m [PodUtils:217] Pod replicas are stable for 20 polls intervals
2022-04-03 00:20:20 [main] [32mINFO [m [PodUtils:228] Pod my-cluster-087f9f20-kafka has 3 replicas
2022-04-03 00:20:20 [main] [32mINFO [m [KafkaRollerIsolatedST:309] Removing requirement for the affinity
2022-04-03 00:20:20 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-087f9f20 will have desired state: Ready
2022-04-03 00:23:59 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-087f9f20 is in desired state: Ready
2022-04-03 00:23:59 [main] [32mINFO [m [KafkaUtils:399] Waiting for deletion of Kafka:my-cluster-087f9f20
2022-04-03 00:24:05 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 00:24:05 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaPodPendingDueToRack
2022-04-03 00:24:05 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-087f9f20 in namespace namespace-99
2022-04-03 00:24:05 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 00:24:05 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-99 for test case:testKafkaPodPendingDueToRack
2022-04-03 00:24:48 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST.testKafkaPodPendingDueToRack-FINISHED
2022-04-03 00:24:48 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 00:24:48 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 00:24:48 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST.testKafkaPodImagePullBackOff-STARTED
2022-04-03 00:24:48 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 00:24:48 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-100 for test case:testKafkaPodImagePullBackOff
2022-04-03 00:24:48 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-100
2022-04-03 00:24:48 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-100
2022-04-03 00:24:48 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-100
2022-04-03 00:24:48 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-910f346f in namespace namespace-100
2022-04-03 00:24:48 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-100
2022-04-03 00:24:48 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-910f346f will have desired state: Ready
2022-04-03 00:26:14 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-910f346f is in desired state: Ready
2022-04-03 00:26:14 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-910f346f will have desired state: NotReady
2022-04-03 00:28:22 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-910f346f is in desired state: NotReady
2022-04-03 00:28:22 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-910f346f will have desired state: Ready
2022-04-03 00:32:58 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-910f346f is in desired state: Ready
2022-04-03 00:32:58 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 00:32:58 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaPodImagePullBackOff
2022-04-03 00:32:58 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-910f346f in namespace namespace-100
2022-04-03 00:33:08 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 00:33:08 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-100 for test case:testKafkaPodImagePullBackOff
2022-04-03 00:33:51 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST.testKafkaPodImagePullBackOff-FINISHED
2022-04-03 00:33:51 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 00:33:51 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 00:33:51 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST.testKafkaPodPending-STARTED
2022-04-03 00:33:51 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 00:33:51 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-101 for test case:testKafkaPodPending
2022-04-03 00:33:51 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-101
2022-04-03 00:33:51 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-101
2022-04-03 00:33:51 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-101
2022-04-03 00:33:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-66950baa in namespace namespace-101
2022-04-03 00:33:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-101
2022-04-03 00:33:51 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-66950baa will have desired state: Ready
2022-04-03 00:35:42 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-66950baa is in desired state: Ready
2022-04-03 00:35:42 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-66950baa will have desired state: NotReady
2022-04-03 00:38:01 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-66950baa is in desired state: NotReady
2022-04-03 00:38:01 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-66950baa will have desired state: Ready
2022-04-03 00:40:05 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-66950baa is in desired state: Ready
2022-04-03 00:40:05 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 00:40:05 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaPodPending
2022-04-03 00:40:05 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-66950baa in namespace namespace-101
2022-04-03 00:40:15 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 00:40:15 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-101 for test case:testKafkaPodPending
2022-04-03 00:40:58 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST.testKafkaPodPending-FINISHED
2022-04-03 00:40:58 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 00:40:58 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 00:40:58 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST.testKafkaTopicRFLowerThanMinInSyncReplicas-STARTED
2022-04-03 00:40:58 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 00:40:58 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-102 for test case:testKafkaTopicRFLowerThanMinInSyncReplicas
2022-04-03 00:40:58 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-102
2022-04-03 00:40:58 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-102
2022-04-03 00:40:58 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-102
2022-04-03 00:40:58 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-57e82586 in namespace namespace-102
2022-04-03 00:40:58 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-102
2022-04-03 00:40:58 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-57e82586 will have desired state: Ready
2022-04-03 00:43:23 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-57e82586 is in desired state: Ready
2022-04-03 00:43:23 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1823284157-689701455 in namespace namespace-102
2022-04-03 00:43:23 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-102
2022-04-03 00:43:23 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1823284157-689701455 will have desired state: Ready
2022-04-03 00:43:24 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1823284157-689701455 is in desired state: Ready
2022-04-03 00:43:24 [main] [32mINFO [m [KafkaRollerIsolatedST:155] Setting KafkaTopic's min.insync.replicas to be higher than replication factor
2022-04-03 00:43:24 [main] [32mINFO [m [KafkaRollerIsolatedST:159] Annotate Kafka StatefulSet my-cluster-57e82586-kafka with manual rolling update annotation
2022-04-03 00:43:24 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-57e82586-kafka rolling update
2022-04-03 00:44:34 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-57e82586-kafka has been successfully rolled
2022-04-03 00:44:34 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-57e82586-kafka to be ready
2022-04-03 00:44:57 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-57e82586 will have desired state: Ready
2022-04-03 00:44:57 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-57e82586 is in desired state: Ready
2022-04-03 00:44:57 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-57e82586 is ready
2022-04-03 00:44:57 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 00:44:57 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaTopicRFLowerThanMinInSyncReplicas
2022-04-03 00:44:57 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1823284157-689701455 in namespace namespace-102
2022-04-03 00:44:57 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-57e82586 in namespace namespace-102
2022-04-03 00:45:07 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 00:45:07 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-102 for test case:testKafkaTopicRFLowerThanMinInSyncReplicas
2022-04-03 00:45:13 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST.testKafkaTopicRFLowerThanMinInSyncReplicas-FINISHED
2022-04-03 00:45:13 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 00:45:13 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 00:45:13 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST.testKafkaPodCrashLooping-STARTED
2022-04-03 00:45:13 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 00:45:13 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-103 for test case:testKafkaPodCrashLooping
2022-04-03 00:45:13 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-103
2022-04-03 00:45:13 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-103
2022-04-03 00:45:13 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-103
2022-04-03 00:45:13 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-c1e6a4a6 in namespace namespace-103
2022-04-03 00:45:13 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-103
2022-04-03 00:45:13 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-c1e6a4a6 will have desired state: Ready
2022-04-03 00:46:35 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-c1e6a4a6 is in desired state: Ready
2022-04-03 00:46:35 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-c1e6a4a6 will have desired state: NotReady
2022-04-03 00:48:51 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-c1e6a4a6 is in desired state: NotReady
2022-04-03 00:48:51 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-c1e6a4a6 will have desired state: Ready
2022-04-03 00:53:30 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-c1e6a4a6 is in desired state: Ready
2022-04-03 00:53:30 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 00:53:30 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaPodCrashLooping
2022-04-03 00:53:30 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-c1e6a4a6 in namespace namespace-103
2022-04-03 00:53:40 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 00:53:40 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-103 for test case:testKafkaPodCrashLooping
2022-04-03 00:54:23 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST.testKafkaPodCrashLooping-FINISHED
2022-04-03 00:54:23 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 00:54:23 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 00:54:23 [main] [32mINFO [m [ResourceManager:346] In context KafkaRollerIsolatedST is everything deleted.
2022-04-03 00:54:23 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2,785.183 s - in io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.connect.ConnectIsolatedST
2022-04-03 00:54:23 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-03 00:54:48 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-03 00:54:48 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-03 00:54:48 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-03 00:54:48 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 00:54:48 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-03 00:54:48 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 00:54:48 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-03 00:54:48 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-03 00:54:48 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-03 00:54:48 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-03 00:54:48 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-03 00:54:48 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-03 00:54:48 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-03 00:54:48 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-03 00:54:48 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-03 00:54:48 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-03 00:54:48 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-03 00:54:48 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-03 00:54:48 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-03 00:54:48 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-03 00:54:48 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 00:54:48 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-03 00:54:48 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-03 00:54:48 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-03 00:54:49 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-03 00:54:58 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-03 00:54:58 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-03 00:54:58 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-03 00:54:58 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-03 00:54:58 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-03 00:55:09 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 00:55:14 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7e2e5e3d
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-03 00:55:14 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-03 00:55:14 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-03 00:55:14 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-03 00:55:14 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-03 00:55:14 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 00:55:14 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-03 00:55:14 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-03 00:55:14 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-03 00:55:14 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-03 00:55:14 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-03 00:55:14 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-03 00:55:14 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-03 00:55:14 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-03 00:55:14 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-03 00:55:14 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-03 00:55:14 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-03 00:55:14 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-03 00:55:14 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-03 00:55:14 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-03 00:55:14 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-03 00:55:14 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-03 00:55:14 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-03 00:55:14 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-03 00:55:14 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-03 00:55:14 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-03 00:55:14 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-03 00:55:14 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-03 00:55:14 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-03 00:55:14 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-03 00:55:14 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-03 00:55:14 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-03 00:55:14 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-03 00:55:14 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-03 00:55:14 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 00:55:14 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-03 00:55:14 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-03 00:55:14 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-03 00:55:54 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-03 00:55:54 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-03 00:56:04 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-03 00:56:04 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 00:56:04 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testMultiNodeKafkaConnectWithConnectorCreation-STARTED
2022-04-03 00:56:04 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 00:56:04 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-104 for test case:testMultiNodeKafkaConnectWithConnectorCreation
2022-04-03 00:56:04 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-104
2022-04-03 00:56:04 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-104
2022-04-03 00:56:04 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-104
2022-04-03 00:56:04 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-7f64350d in namespace namespace-104
2022-04-03 00:56:04 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-104
2022-04-03 00:56:04 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-7f64350d will have desired state: Ready
2022-04-03 00:57:25 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-7f64350d is in desired state: Ready
2022-04-03 00:57:25 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-7f64350d-scraper in namespace namespace-104
2022-04-03 00:57:25 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-104
2022-04-03 00:57:25 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-7f64350d-scraper will be ready
2022-04-03 00:57:27 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-7f64350d-scraper is ready
2022-04-03 00:57:27 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-7f64350d-scraper to be ready
2022-04-03 00:57:37 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-7f64350d-scraper is ready
2022-04-03 00:57:37 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-7f64350d-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-03 00:57:37 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-7f64350d-allow in namespace namespace-104
2022-04-03 00:57:37 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-104
2022-04-03 00:57:37 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-03 00:57:37 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-7f64350d in namespace namespace-104
2022-04-03 00:57:37 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-104
2022-04-03 00:57:37 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-7f64350d will have desired state: Ready
2022-04-03 00:58:46 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-7f64350d is in desired state: Ready
2022-04-03 00:58:46 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-7f64350d in namespace namespace-104
2022-04-03 00:58:46 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-104
2022-04-03 00:58:46 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-7f64350d will have desired state: Ready
2022-04-03 00:58:47 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-7f64350d is in desired state: Ready
2022-04-03 00:58:47 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-03 00:58:47 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-104 exec my-cluster-7f64350d-connect-9b7f55b86-p2qwm -- curl -X GET http://localhost:8083/connectors/my-cluster-7f64350d/status
2022-04-03 00:58:47 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-03 00:58:47 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-7f64350d-hello-world-producer in namespace namespace-104
2022-04-03 00:58:47 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-104
2022-04-03 00:58:47 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-7f64350d-hello-world-consumer in namespace namespace-104
2022-04-03 00:58:47 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-104
2022-04-03 00:58:47 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-7f64350d-hello-world-producer will be in active state
2022-04-03 00:58:48 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-7f64350d-hello-world-consumer will be in active state
2022-04-03 00:58:48 [main] [32mINFO [m [ClientUtils:61] Waiting till producer my-cluster-7f64350d-hello-world-producer and consumer my-cluster-7f64350d-hello-world-consumer finish
2022-04-03 00:58:59 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-7f64350d-connect-9b7f55b86-tx5cf
2022-04-03 00:58:59 [main] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-7f64350d-connect-9b7f55b86-tx5cf
2022-04-03 00:58:59 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 00:58:59 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMultiNodeKafkaConnectWithConnectorCreation
2022-04-03 00:58:59 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-7f64350d in namespace namespace-104
2022-04-03 00:58:59 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-7f64350d-scraper in namespace namespace-104
2022-04-03 00:58:59 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-7f64350d in namespace namespace-104
2022-04-03 00:58:59 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-7f64350d-hello-world-consumer in namespace namespace-104
2022-04-03 00:58:59 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-7f64350d-hello-world-producer in namespace namespace-104
2022-04-03 00:58:59 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-7f64350d in namespace namespace-104
2022-04-03 00:58:59 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-7f64350d-allow in namespace namespace-104
2022-04-03 00:59:39 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 00:59:39 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-104 for test case:testMultiNodeKafkaConnectWithConnectorCreation
2022-04-03 00:59:44 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testMultiNodeKafkaConnectWithConnectorCreation-FINISHED
2022-04-03 00:59:44 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 00:59:44 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 00:59:44 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testKafkaConnectScaleUpScaleDown-STARTED
2022-04-03 00:59:44 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 00:59:44 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-105 for test case:testKafkaConnectScaleUpScaleDown
2022-04-03 00:59:44 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-105
2022-04-03 00:59:44 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-105
2022-04-03 00:59:44 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-105
2022-04-03 00:59:44 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-f39cc2e5 in namespace namespace-105
2022-04-03 00:59:44 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-105
2022-04-03 00:59:44 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-f39cc2e5 will have desired state: Ready
2022-04-03 01:00:59 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-f39cc2e5 is in desired state: Ready
2022-04-03 01:00:59 [main] [32mINFO [m [ConnectIsolatedST:395] Running kafkaConnectScaleUP namespace-105 in namespace
2022-04-03 01:00:59 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-f39cc2e5 in namespace namespace-105
2022-04-03 01:00:59 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-105
2022-04-03 01:00:59 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-f39cc2e5 will have desired state: Ready
2022-04-03 01:02:11 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-f39cc2e5 is in desired state: Ready
2022-04-03 01:02:11 [main] [32mINFO [m [ConnectIsolatedST:407] Scaling up to 4
2022-04-03 01:02:11 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-f39cc2e5-connect will be ready
2022-04-03 01:02:11 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-f39cc2e5-connect is ready
2022-04-03 01:02:11 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 4 Pod(s) of Deployment my-cluster-f39cc2e5-connect to be ready
2022-04-03 01:03:29 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-f39cc2e5-connect is ready
2022-04-03 01:03:29 [main] [32mINFO [m [ConnectIsolatedST:414] Scaling down to 1
2022-04-03 01:03:29 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-f39cc2e5-connect will be ready
2022-04-03 01:03:29 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-f39cc2e5-connect is ready
2022-04-03 01:03:29 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-f39cc2e5-connect to be ready
2022-04-03 01:03:42 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-f39cc2e5-connect is ready
2022-04-03 01:03:42 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 01:03:42 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaConnectScaleUpScaleDown
2022-04-03 01:03:42 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-f39cc2e5 in namespace namespace-105
2022-04-03 01:03:42 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-f39cc2e5 in namespace namespace-105
2022-04-03 01:03:52 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 01:03:52 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-105 for test case:testKafkaConnectScaleUpScaleDown
2022-04-03 01:04:35 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testKafkaConnectScaleUpScaleDown-FINISHED
2022-04-03 01:04:35 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 01:04:35 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 01:04:35 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testScaleConnectAndConnectorSubresource-STARTED
2022-04-03 01:04:35 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 01:04:35 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-106 for test case:testScaleConnectAndConnectorSubresource
2022-04-03 01:04:35 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-106
2022-04-03 01:04:35 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-106
2022-04-03 01:04:35 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-106
2022-04-03 01:04:35 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-4c15e2a8 in namespace namespace-106
2022-04-03 01:04:35 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-106
2022-04-03 01:04:35 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-4c15e2a8 will have desired state: Ready
2022-04-03 01:05:51 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-4c15e2a8 is in desired state: Ready
2022-04-03 01:05:51 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-4c15e2a8 in namespace namespace-106
2022-04-03 01:05:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-106
2022-04-03 01:05:51 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-4c15e2a8 will have desired state: Ready
2022-04-03 01:07:01 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-4c15e2a8 is in desired state: Ready
2022-04-03 01:07:01 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-4c15e2a8 in namespace namespace-106
2022-04-03 01:07:01 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-106
2022-04-03 01:07:01 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-4c15e2a8 will have desired state: Ready
2022-04-03 01:07:02 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-4c15e2a8 is in desired state: Ready
2022-04-03 01:07:02 [main] [32mINFO [m [ConnectIsolatedST:979] -------> Scaling KafkaConnect subresource <-------
2022-04-03 01:07:02 [main] [32mINFO [m [ConnectIsolatedST:980] Scaling subresource replicas to 4
2022-04-03 01:07:02 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-4c15e2a8-connect will be ready
2022-04-03 01:07:02 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-4c15e2a8-connect is ready
2022-04-03 01:07:02 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 4 Pod(s) of Deployment my-cluster-4c15e2a8-connect to be ready
2022-04-03 01:08:22 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-4c15e2a8-connect is ready
2022-04-03 01:08:22 [main] [32mINFO [m [ConnectIsolatedST:984] Check if replicas is set to 4, observed generation is higher - for spec and status - naming prefix should be same
2022-04-03 01:08:22 [main] [32mINFO [m [ConnectIsolatedST:998] -------> Scaling KafkaConnector subresource <-------
2022-04-03 01:08:22 [main] [32mINFO [m [ConnectIsolatedST:999] Scaling subresource task max to 4
2022-04-03 01:08:24 [main] [32mINFO [m [ConnectIsolatedST:1003] Check if taskMax is set to 4
2022-04-03 01:08:24 [main] [32mINFO [m [ConnectIsolatedST:1007] Check taskMax on Connect pods API
2022-04-03 01:08:24 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-106 exec my-cluster-4c15e2a8-connect-5cb5dccdfd-h69kb -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-4c15e2a8
2022-04-03 01:08:24 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-03 01:08:24 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-106 exec my-cluster-4c15e2a8-connect-5cb5dccdfd-kpxlh -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-4c15e2a8
2022-04-03 01:08:24 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-03 01:08:24 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-106 exec my-cluster-4c15e2a8-connect-5cb5dccdfd-pc2kc -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-4c15e2a8
2022-04-03 01:08:24 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-03 01:08:24 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-106 exec my-cluster-4c15e2a8-connect-5cb5dccdfd-v4zp7 -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-4c15e2a8
2022-04-03 01:08:24 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-03 01:08:24 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 01:08:24 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testScaleConnectAndConnectorSubresource
2022-04-03 01:08:24 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-4c15e2a8 in namespace namespace-106
2022-04-03 01:08:24 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-4c15e2a8 in namespace namespace-106
2022-04-03 01:08:24 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-4c15e2a8 in namespace namespace-106
2022-04-03 01:08:34 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 01:08:34 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-106 for test case:testScaleConnectAndConnectorSubresource
2022-04-03 01:09:17 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testScaleConnectAndConnectorSubresource-FINISHED
2022-04-03 01:09:17 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 01:09:18 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 01:09:18 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testKafkaConnectAndPausedConnectorWithFileSinkPlugin-STARTED
2022-04-03 01:09:18 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 01:09:18 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-107 for test case:testKafkaConnectAndPausedConnectorWithFileSinkPlugin
2022-04-03 01:09:18 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-107
2022-04-03 01:09:18 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-107
2022-04-03 01:09:18 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-107
2022-04-03 01:09:18 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-d70d393e in namespace namespace-107
2022-04-03 01:09:18 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-107
2022-04-03 01:09:18 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d70d393e will have desired state: Ready
2022-04-03 01:10:32 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d70d393e is in desired state: Ready
2022-04-03 01:10:32 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-220517412-974125946 in namespace namespace-107
2022-04-03 01:10:32 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-107
2022-04-03 01:10:32 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-220517412-974125946 will have desired state: Ready
2022-04-03 01:10:33 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-220517412-974125946 is in desired state: Ready
2022-04-03 01:10:33 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-d70d393e-scraper in namespace namespace-107
2022-04-03 01:10:33 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-107
2022-04-03 01:10:33 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-d70d393e-scraper will be ready
2022-04-03 01:10:35 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-d70d393e-scraper is ready
2022-04-03 01:10:35 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-d70d393e-scraper to be ready
2022-04-03 01:10:45 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-d70d393e-scraper is ready
2022-04-03 01:10:45 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-d70d393e-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-03 01:10:45 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-d70d393e-allow in namespace namespace-107
2022-04-03 01:10:45 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-107
2022-04-03 01:10:45 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-03 01:10:45 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-d70d393e in namespace namespace-107
2022-04-03 01:10:45 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-107
2022-04-03 01:10:45 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-d70d393e will have desired state: Ready
2022-04-03 01:11:48 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-d70d393e is in desired state: Ready
2022-04-03 01:11:48 [main] [32mINFO [m [KafkaConnectUtils:63] Waiting until KafkaConnect API is available
2022-04-03 01:11:48 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-107 exec my-cluster-d70d393e-connect-b969c54d-pbmd8 -- /bin/bash -c curl -I http://localhost:8083/connectors
2022-04-03 01:11:48 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-03 01:11:48 [main] [32mINFO [m [KafkaConnectUtils:66] KafkaConnect API is available
2022-04-03 01:11:48 [main] [32mINFO [m [ConnectIsolatedST:181] Creating KafkaConnector with 'pause: true'
2022-04-03 01:11:48 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-d70d393e in namespace namespace-107
2022-04-03 01:11:48 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-107
2022-04-03 01:11:48 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-d70d393e will have desired state: Ready
2022-04-03 01:11:49 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-d70d393e is in desired state: Ready
2022-04-03 01:11:49 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-03 01:11:49 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-d70d393e-hello-world-producer in namespace namespace-107
2022-04-03 01:11:49 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-107
2022-04-03 01:11:49 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-d70d393e-hello-world-consumer in namespace namespace-107
2022-04-03 01:11:49 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-107
2022-04-03 01:11:49 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-d70d393e-hello-world-producer will be in active state
2022-04-03 01:11:50 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-d70d393e-hello-world-consumer will be in active state
2022-04-03 01:11:50 [main] [32mINFO [m [ClientUtils:61] Waiting till producer my-cluster-d70d393e-hello-world-producer and consumer my-cluster-d70d393e-hello-world-consumer finish
2022-04-03 01:12:06 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-d70d393e-connect-b969c54d-pbmd8
2022-04-03 01:12:07 [main] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-d70d393e-connect-b969c54d-pbmd8
2022-04-03 01:12:07 [main] [32mINFO [m [ConnectIsolatedST:207] Pausing KafkaConnector: my-cluster-d70d393e
2022-04-03 01:12:07 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-d70d393e will have desired state: Ready
2022-04-03 01:12:07 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-d70d393e is in desired state: Ready
2022-04-03 01:12:07 [main] [32mINFO [m [ConnectIsolatedST:213] Clearing FileSink file to check if KafkaConnector will be really paused
2022-04-03 01:12:07 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-107 exec my-cluster-d70d393e-connect-b969c54d-pbmd8 -- /bin/bash -c truncate -s 0 /tmp/test-file-sink.txt
2022-04-03 01:12:07 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-03 01:12:07 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-d70d393e-hello-world-producer in namespace namespace-107
2022-04-03 01:12:07 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-107
2022-04-03 01:12:07 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-d70d393e-hello-world-consumer in namespace namespace-107
2022-04-03 01:12:07 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-107
2022-04-03 01:12:07 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-d70d393e-hello-world-producer will be in active state
2022-04-03 01:12:07 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-d70d393e-hello-world-consumer will be in active state
2022-04-03 01:12:07 [main] [32mINFO [m [ClientUtils:61] Waiting till producer my-cluster-d70d393e-hello-world-producer and consumer my-cluster-d70d393e-hello-world-consumer finish
2022-04-03 01:12:52 [main] [32mINFO [m [ConnectIsolatedST:219] Because KafkaConnector is paused, no messages should appear to FileSink file
2022-04-03 01:12:52 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-d70d393e-connect-b969c54d-pbmd8
2022-04-03 01:13:52 [main] [32mINFO [m [ConnectIsolatedST:222] Unpausing KafkaConnector, messages should again appear to FileSink file
2022-04-03 01:13:52 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-d70d393e will have desired state: Ready
2022-04-03 01:13:52 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-d70d393e is in desired state: Ready
2022-04-03 01:13:52 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-d70d393e-connect-b969c54d-pbmd8
2022-04-03 01:13:52 [main] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-d70d393e-connect-b969c54d-pbmd8
2022-04-03 01:13:52 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 01:13:52 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaConnectAndPausedConnectorWithFileSinkPlugin
2022-04-03 01:13:52 [main] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-d70d393e-hello-world-producer in namespace namespace-107
2022-04-03 01:13:52 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-d70d393e in namespace namespace-107
2022-04-03 01:13:52 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-d70d393e-hello-world-producer in namespace namespace-107
2022-04-03 01:13:52 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-d70d393e-hello-world-consumer in namespace namespace-107
2022-04-03 01:13:52 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-220517412-974125946 in namespace namespace-107
2022-04-03 01:13:52 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-d70d393e-scraper in namespace namespace-107
2022-04-03 01:13:52 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-d70d393e in namespace namespace-107
2022-04-03 01:13:52 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-d70d393e-hello-world-consumer in namespace namespace-107
2022-04-03 01:13:52 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-d70d393e-allow in namespace namespace-107
2022-04-03 01:13:52 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-d70d393e in namespace namespace-107
2022-04-03 01:14:32 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 01:14:32 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-107 for test case:testKafkaConnectAndPausedConnectorWithFileSinkPlugin
2022-04-03 01:14:43 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testKafkaConnectAndPausedConnectorWithFileSinkPlugin-FINISHED
2022-04-03 01:14:43 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 01:14:43 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 01:14:43 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testKafkaConnectWithScramShaAuthenticationRolledAfterPasswordChanged-STARTED
2022-04-03 01:14:43 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 01:14:43 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-108 for test case:testKafkaConnectWithScramShaAuthenticationRolledAfterPasswordChanged
2022-04-03 01:14:43 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-108
2022-04-03 01:14:43 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-108
2022-04-03 01:14:43 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-108
2022-04-03 01:14:43 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-1d113595 in namespace namespace-108
2022-04-03 01:14:43 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-108
2022-04-03 01:14:43 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-1d113595 will have desired state: Ready
2022-04-03 01:15:59 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-1d113595 is in desired state: Ready
2022-04-03 01:15:59 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1829604690-271881651 in namespace namespace-108
2022-04-03 01:15:59 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-108
2022-04-03 01:15:59 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1829604690-271881651 will have desired state: Ready
2022-04-03 01:16:00 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1829604690-271881651 is in desired state: Ready
2022-04-03 01:16:00 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1829604690-271881651 in namespace namespace-108
2022-04-03 01:16:00 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-108
2022-04-03 01:16:00 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1829604690-271881651 will have desired state: Ready
2022-04-03 01:16:00 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1829604690-271881651 is in desired state: Ready
2022-04-03 01:16:00 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-2077202813-1126635991 in namespace namespace-108
2022-04-03 01:16:00 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-108
2022-04-03 01:16:00 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-2077202813-1126635991 will have desired state: Ready
2022-04-03 01:16:01 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-2077202813-1126635991 is in desired state: Ready
2022-04-03 01:16:01 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-1d113595 in namespace namespace-108
2022-04-03 01:16:01 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-108
2022-04-03 01:16:01 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-1d113595 will have desired state: Ready
2022-04-03 01:17:13 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-1d113595 is in desired state: Ready
2022-04-03 01:17:13 [main] [32mINFO [m [KafkaConnectUtils:63] Waiting until KafkaConnect API is available
2022-04-03 01:17:13 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-108 exec my-cluster-1d113595-connect-6684c688c8-4w85g -- /bin/bash -c curl -I http://localhost:8083/connectors
2022-04-03 01:17:13 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-03 01:17:13 [main] [32mINFO [m [KafkaConnectUtils:66] KafkaConnect API is available
2022-04-03 01:17:13 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1829604690-271881651 in namespace namespace-108
2022-04-03 01:17:13 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-108
2022-04-03 01:17:13 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1829604690-271881651 will have desired state: Ready
2022-04-03 01:17:13 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1829604690-271881651 is in desired state: Ready
2022-04-03 01:17:13 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-1d113595-connect rolling update
2022-04-03 01:18:33 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-1d113595-connect will be ready
2022-04-03 01:18:33 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-1d113595-connect is ready
2022-04-03 01:18:43 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-1d113595-connect rolling update finished
2022-04-03 01:18:43 [main] [32mINFO [m [KafkaConnectUtils:63] Waiting until KafkaConnect API is available
2022-04-03 01:18:44 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-108 exec my-cluster-1d113595-connect-7fffd84bf9-24j78 -- /bin/bash -c curl -I http://localhost:8083/connectors
2022-04-03 01:18:44 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-03 01:18:44 [main] [32mINFO [m [KafkaConnectUtils:66] KafkaConnect API is available
2022-04-03 01:18:44 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 01:18:44 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaConnectWithScramShaAuthenticationRolledAfterPasswordChanged
2022-04-03 01:18:44 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-2077202813-1126635991 in namespace namespace-108
2022-04-03 01:18:44 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-1d113595 in namespace namespace-108
2022-04-03 01:18:44 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1829604690-271881651 in namespace namespace-108
2022-04-03 01:18:44 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-1d113595 in namespace namespace-108
2022-04-03 01:18:44 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1829604690-271881651 in namespace namespace-108
2022-04-03 01:18:44 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1829604690-271881651 in namespace namespace-108
2022-04-03 01:18:54 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 01:18:54 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-108 for test case:testKafkaConnectWithScramShaAuthenticationRolledAfterPasswordChanged
2022-04-03 01:19:37 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testKafkaConnectWithScramShaAuthenticationRolledAfterPasswordChanged-FINISHED
2022-04-03 01:19:37 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 01:19:37 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 01:19:37 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testSecretsWithKafkaConnectWithTlsAndScramShaAuthentication-STARTED
2022-04-03 01:19:37 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 01:19:37 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-109 for test case:testSecretsWithKafkaConnectWithTlsAndScramShaAuthentication
2022-04-03 01:19:37 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-109
2022-04-03 01:19:37 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-109
2022-04-03 01:19:37 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-109
2022-04-03 01:19:37 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-a42910f2 in namespace namespace-109
2022-04-03 01:19:37 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-109
2022-04-03 01:19:37 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-a42910f2 will have desired state: Ready
2022-04-03 01:21:01 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-a42910f2 is in desired state: Ready
2022-04-03 01:21:01 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-a42910f2-user in namespace namespace-109
2022-04-03 01:21:01 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-109
2022-04-03 01:21:01 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-a42910f2-user will have desired state: Ready
2022-04-03 01:21:02 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-a42910f2-user is in desired state: Ready
2022-04-03 01:21:02 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1910699410-483918406 in namespace namespace-109
2022-04-03 01:21:02 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-109
2022-04-03 01:21:02 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1910699410-483918406 will have desired state: Ready
2022-04-03 01:21:03 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1910699410-483918406 is in desired state: Ready
2022-04-03 01:21:03 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-a42910f2-scraper in namespace namespace-109
2022-04-03 01:21:03 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-109
2022-04-03 01:21:03 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-a42910f2-scraper will be ready
2022-04-03 01:21:05 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-a42910f2-scraper is ready
2022-04-03 01:21:05 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-a42910f2-scraper to be ready
2022-04-03 01:21:15 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-a42910f2-scraper is ready
2022-04-03 01:21:15 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-a42910f2-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-03 01:21:15 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-a42910f2-allow in namespace namespace-109
2022-04-03 01:21:15 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-109
2022-04-03 01:21:15 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-03 01:21:15 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-a42910f2 in namespace namespace-109
2022-04-03 01:21:15 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-109
2022-04-03 01:21:15 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-a42910f2 will have desired state: Ready
2022-04-03 01:22:17 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-a42910f2 is in desired state: Ready
2022-04-03 01:22:18 [main] [32mINFO [m [ConnectIsolatedST:547] Verifying that KafkaConnect pod logs don't contain ERRORs
2022-04-03 01:22:18 [main] [32mINFO [m [ConnectIsolatedST:550] Creating FileStreamSink connector via pod my-cluster-a42910f2-scraper-5c886c9554-qgls7 with topic my-topic-1910699410-483918406
2022-04-03 01:22:18 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-109 exec my-cluster-a42910f2-scraper-5c886c9554-qgls7 -- /bin/bash -c curl -X POST -H "Content-Type: application/json" --data '{ "name": "sink-test", "config": { "connector.class": "FileStreamSink", "tasks.max": "1", "topics": "my-topic-1910699410-483918406", "file": "/tmp/test-file-sink.txt" } }' http://my-cluster-a42910f2-connect-api.namespace-109.svc:8083/connectors
2022-04-03 01:22:18 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-03 01:22:18 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-03 01:22:18 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-a42910f2-hello-world-producer in namespace namespace-109
2022-04-03 01:22:18 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-109
2022-04-03 01:22:18 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-a42910f2-hello-world-consumer in namespace namespace-109
2022-04-03 01:22:18 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-109
2022-04-03 01:22:18 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-a42910f2-hello-world-producer will be in active state
2022-04-03 01:22:19 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-a42910f2-hello-world-consumer will be in active state
2022-04-03 01:22:19 [main] [32mINFO [m [ClientUtils:61] Waiting till producer my-cluster-a42910f2-hello-world-producer and consumer my-cluster-a42910f2-hello-world-consumer finish
2022-04-03 01:22:36 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-a42910f2-connect-b986c6d67-646qb
2022-04-03 01:22:37 [main] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-a42910f2-connect-b986c6d67-646qb
2022-04-03 01:22:37 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 01:22:37 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSecretsWithKafkaConnectWithTlsAndScramShaAuthentication
2022-04-03 01:22:37 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-a42910f2 in namespace namespace-109
2022-04-03 01:22:37 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-a42910f2-scraper in namespace namespace-109
2022-04-03 01:22:37 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-a42910f2-user in namespace namespace-109
2022-04-03 01:22:37 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-a42910f2-allow in namespace namespace-109
2022-04-03 01:22:37 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-a42910f2-hello-world-consumer in namespace namespace-109
2022-04-03 01:22:37 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-a42910f2-hello-world-producer in namespace namespace-109
2022-04-03 01:22:37 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1910699410-483918406 in namespace namespace-109
2022-04-03 01:22:37 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-a42910f2 in namespace namespace-109
2022-04-03 01:23:17 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 01:23:17 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-109 for test case:testSecretsWithKafkaConnectWithTlsAndScramShaAuthentication
2022-04-03 01:23:22 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testSecretsWithKafkaConnectWithTlsAndScramShaAuthentication-FINISHED
2022-04-03 01:23:22 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 01:23:22 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 01:23:22 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testConfigureDeploymentStrategy-STARTED
2022-04-03 01:23:22 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 01:23:22 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-110 for test case:testConfigureDeploymentStrategy
2022-04-03 01:23:22 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-110
2022-04-03 01:23:22 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-110
2022-04-03 01:23:22 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-110
2022-04-03 01:23:22 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-5984f84c in namespace namespace-110
2022-04-03 01:23:22 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-110
2022-04-03 01:23:22 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-5984f84c will have desired state: Ready
2022-04-03 01:24:38 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-5984f84c is in desired state: Ready
2022-04-03 01:24:38 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-5984f84c in namespace namespace-110
2022-04-03 01:24:38 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-110
2022-04-03 01:24:38 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-5984f84c will have desired state: Ready
2022-04-03 01:25:48 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-5984f84c is in desired state: Ready
2022-04-03 01:25:48 [main] [32mINFO [m [ConnectIsolatedST:1191] Adding label to Connect resource, the CR should be recreated
2022-04-03 01:25:48 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-5984f84c-connect will be ready
2022-04-03 01:25:48 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-5984f84c-connect is ready
2022-04-03 01:25:48 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-5984f84c-connect to be ready
2022-04-03 01:27:01 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-5984f84c-connect is ready
2022-04-03 01:27:01 [main] [32mINFO [m [ConnectIsolatedST:1198] Checking that observed gen. is still on 1 (recreation) and new label is present
2022-04-03 01:27:01 [main] [32mINFO [m [ConnectIsolatedST:1203] Changing deployment strategy to ROLLING_UPDATE
2022-04-03 01:27:01 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-5984f84c will have desired state: Ready
2022-04-03 01:27:01 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-5984f84c is in desired state: Ready
2022-04-03 01:27:01 [main] [32mINFO [m [ConnectIsolatedST:1208] Adding another label to Connect resource, pods should be rolled
2022-04-03 01:27:01 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-5984f84c-connect will be ready
2022-04-03 01:27:01 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-5984f84c-connect is ready
2022-04-03 01:27:01 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-5984f84c-connect to be ready
2022-04-03 01:28:20 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-5984f84c-connect is ready
2022-04-03 01:28:20 [main] [32mINFO [m [ConnectIsolatedST:1212] Checking that observed gen. higher (rolling update) and label is changed
2022-04-03 01:28:20 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 01:28:20 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testConfigureDeploymentStrategy
2022-04-03 01:28:20 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-5984f84c in namespace namespace-110
2022-04-03 01:28:20 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-5984f84c in namespace namespace-110
2022-04-03 01:28:30 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 01:28:30 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-110 for test case:testConfigureDeploymentStrategy
2022-04-03 01:28:57 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testConfigureDeploymentStrategy-FINISHED
2022-04-03 01:28:57 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 01:28:57 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 01:28:57 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testKafkaConnectAndConnectorFileSinkPlugin-STARTED
2022-04-03 01:28:57 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 01:28:57 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-111 for test case:testKafkaConnectAndConnectorFileSinkPlugin
2022-04-03 01:28:57 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-111
2022-04-03 01:28:57 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-111
2022-04-03 01:28:57 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-111
2022-04-03 01:28:57 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-fbe86453 in namespace namespace-111
2022-04-03 01:28:57 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-111
2022-04-03 01:28:57 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-fbe86453 will have desired state: Ready
2022-04-03 01:30:21 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-fbe86453 is in desired state: Ready
2022-04-03 01:30:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-fbe86453-scraper in namespace namespace-111
2022-04-03 01:30:21 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-111
2022-04-03 01:30:21 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-fbe86453-scraper will be ready
2022-04-03 01:30:23 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-fbe86453-scraper is ready
2022-04-03 01:30:23 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-fbe86453-scraper to be ready
2022-04-03 01:30:33 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-fbe86453-scraper is ready
2022-04-03 01:30:33 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-fbe86453-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-03 01:30:33 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-fbe86453-allow in namespace namespace-111
2022-04-03 01:30:33 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-111
2022-04-03 01:30:33 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-03 01:30:33 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-fbe86453 in namespace namespace-111
2022-04-03 01:30:33 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-111
2022-04-03 01:30:33 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-fbe86453 will have desired state: Ready
2022-04-03 01:31:44 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-fbe86453 is in desired state: Ready
2022-04-03 01:31:44 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector license-source in namespace namespace-111
2022-04-03 01:31:44 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-111
2022-04-03 01:31:44 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: license-source will have desired state: Ready
2022-04-03 01:31:45 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: license-source is in desired state: Ready
2022-04-03 01:31:45 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-03 01:31:45 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-fbe86453-hello-world-consumer in namespace namespace-111
2022-04-03 01:31:45 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-111
2022-04-03 01:31:45 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-fbe86453-hello-world-consumer will be in active state
2022-04-03 01:31:46 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:my-cluster-fbe86453-hello-world-consumer to finished
2022-04-03 01:31:56 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-111 exec my-cluster-fbe86453-scraper-59555487bc-xzvt6 -- /bin/bash -c curl http://my-cluster-fbe86453-connect-api.namespace-111.svc:8083/connectors/license-source
2022-04-03 01:31:56 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-03 01:31:56 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 01:31:56 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaConnectAndConnectorFileSinkPlugin
2022-04-03 01:31:56 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-fbe86453 in namespace namespace-111
2022-04-03 01:31:56 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector license-source in namespace namespace-111
2022-04-03 01:31:56 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-fbe86453-hello-world-consumer in namespace namespace-111
2022-04-03 01:31:56 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-fbe86453-scraper in namespace namespace-111
2022-04-03 01:31:56 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-fbe86453 in namespace namespace-111
2022-04-03 01:31:56 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-fbe86453-allow in namespace namespace-111
2022-04-03 01:32:46 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 01:32:46 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-111 for test case:testKafkaConnectAndConnectorFileSinkPlugin
2022-04-03 01:32:52 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testKafkaConnectAndConnectorFileSinkPlugin-FINISHED
2022-04-03 01:32:52 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 01:32:52 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 01:32:52 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testDeployUndeploy-STARTED
2022-04-03 01:32:52 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 01:32:52 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-112 for test case:testDeployUndeploy
2022-04-03 01:32:52 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-112
2022-04-03 01:32:52 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-112
2022-04-03 01:32:52 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-112
2022-04-03 01:32:52 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-783c8303 in namespace namespace-112
2022-04-03 01:32:52 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-112
2022-04-03 01:32:52 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-783c8303 will have desired state: Ready
2022-04-03 01:34:05 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-783c8303 is in desired state: Ready
2022-04-03 01:34:05 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-783c8303-scraper in namespace namespace-112
2022-04-03 01:34:05 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-112
2022-04-03 01:34:05 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-783c8303-scraper will be ready
2022-04-03 01:34:07 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-783c8303-scraper is ready
2022-04-03 01:34:07 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-783c8303-scraper to be ready
2022-04-03 01:34:17 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-783c8303-scraper is ready
2022-04-03 01:34:17 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-783c8303-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-03 01:34:17 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-783c8303-allow in namespace namespace-112
2022-04-03 01:34:17 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-112
2022-04-03 01:34:17 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-03 01:34:17 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-783c8303 in namespace namespace-112
2022-04-03 01:34:17 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-112
2022-04-03 01:34:17 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-783c8303 will have desired state: Ready
2022-04-03 01:35:21 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-783c8303 is in desired state: Ready
2022-04-03 01:35:21 [main] [32mINFO [m [ConnectIsolatedST:123] Looks like the connect cluster my-cluster deployed OK
2022-04-03 01:35:21 [main] [32mINFO [m [ConnectIsolatedST:140] Verifying docker image names
2022-04-03 01:35:21 [main] [32mINFO [m [AbstractST:172] strimzi-cluster-operator
2022-04-03 01:35:22 [main] [32mINFO [m [ConnectIsolatedST:152] Docker images verified
2022-04-03 01:35:22 [main] [32mINFO [m [AbstractST:311] Verifying labels on pod type connect
2022-04-03 01:35:22 [main] [32mINFO [m [AbstractST:315] Verifying labels for pod: my-cluster-783c8303-connect-846fd6cd58-8nd7g
2022-04-03 01:35:22 [main] [32mINFO [m [AbstractST:356] Verifying labels for Kafka Connect Services
2022-04-03 01:35:22 [main] [32mINFO [m [AbstractST:362] Verifying labels for service my-cluster-783c8303-connect-api
2022-04-03 01:35:22 [main] [32mINFO [m [AbstractST:384] Verifying labels for Config maps
2022-04-03 01:35:22 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-783c8303-connect-config
2022-04-03 01:35:22 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-783c8303-entity-topic-operator-config
2022-04-03 01:35:22 [main] [32mINFO [m [AbstractST:407] CM my-cluster-783c8303-entity-topic-operator-config is not related to current test
2022-04-03 01:35:22 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-783c8303-entity-user-operator-config
2022-04-03 01:35:22 [main] [32mINFO [m [AbstractST:407] CM my-cluster-783c8303-entity-user-operator-config is not related to current test
2022-04-03 01:35:22 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-783c8303-kafka-config
2022-04-03 01:35:22 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-783c8303-zookeeper-config
2022-04-03 01:35:22 [main] [32mINFO [m [AbstractST:407] CM my-cluster-783c8303-zookeeper-config is not related to current test
2022-04-03 01:35:22 [main] [32mINFO [m [AbstractST:414] Verifying labels for Service Accounts
2022-04-03 01:35:22 [main] [32mINFO [m [AbstractST:427] Verifying labels for service account my-cluster-783c8303-connect
2022-04-03 01:35:22 [main] [32mINFO [m [AbstractST:427] Verifying labels for service account my-cluster-783c8303-entity-operator
2022-04-03 01:35:22 [main] [32mINFO [m [AbstractST:427] Verifying labels for service account my-cluster-783c8303-kafka
2022-04-03 01:35:22 [main] [32mINFO [m [AbstractST:427] Verifying labels for service account my-cluster-783c8303-zookeeper
2022-04-03 01:35:22 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 01:35:22 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDeployUndeploy
2022-04-03 01:35:22 [main] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-783c8303-allow in namespace namespace-112
2022-04-03 01:35:22 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-783c8303-scraper in namespace namespace-112
2022-04-03 01:35:22 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-783c8303 in namespace namespace-112
2022-04-03 01:35:22 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-783c8303 in namespace namespace-112
2022-04-03 01:36:02 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 01:36:02 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-112 for test case:testDeployUndeploy
2022-04-03 01:36:12 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testDeployUndeploy-FINISHED
2022-04-03 01:36:12 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 01:36:12 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 01:36:12 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testMountingSecretAndConfigMapAsVolumesAndEnvVars-STARTED
2022-04-03 01:36:12 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 01:36:12 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-113 for test case:testMountingSecretAndConfigMapAsVolumesAndEnvVars
2022-04-03 01:36:12 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-113
2022-04-03 01:36:12 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-113
2022-04-03 01:36:12 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-113
2022-04-03 01:36:12 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-f9d3bf24 in namespace namespace-113
2022-04-03 01:36:12 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-113
2022-04-03 01:36:12 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-f9d3bf24 will have desired state: Ready
2022-04-03 01:37:26 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-f9d3bf24 is in desired state: Ready
2022-04-03 01:37:26 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-f9d3bf24 in namespace namespace-113
2022-04-03 01:37:26 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-113
2022-04-03 01:37:26 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-f9d3bf24 will have desired state: Ready
2022-04-03 01:38:32 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-f9d3bf24 is in desired state: Ready
2022-04-03 01:38:32 [main] [32mINFO [m [ConnectIsolatedST:1148] Check if the ENVs contains desired values
2022-04-03 01:38:32 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-113 exec my-cluster-f9d3bf24-connect-54c445f895-lmk76 -- /bin/bash -c printenv MY_CONNECT_SECRET
2022-04-03 01:38:32 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-03 01:38:32 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-113 exec my-cluster-f9d3bf24-connect-54c445f895-lmk76 -- /bin/bash -c printenv MY_CONNECT_CONFIG_MAP
2022-04-03 01:38:32 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-03 01:38:33 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-113 exec my-cluster-f9d3bf24-connect-54c445f895-lmk76 -- /bin/bash -c printenv MY_DOTED_CONNECT_SECRET
2022-04-03 01:38:33 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-03 01:38:33 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-113 exec my-cluster-f9d3bf24-connect-54c445f895-lmk76 -- /bin/bash -c printenv MY_DOTED_CONNECT_CONFIG_MAP
2022-04-03 01:38:33 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-03 01:38:33 [main] [32mINFO [m [ConnectIsolatedST:1154] Check if volumes contains desired values
2022-04-03 01:38:33 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-113 exec my-cluster-f9d3bf24-connect-54c445f895-lmk76 -- /bin/bash -c cat external-configuration/connect-config-map/my-key
2022-04-03 01:38:33 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-03 01:38:33 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-113 exec my-cluster-f9d3bf24-connect-54c445f895-lmk76 -- /bin/bash -c cat external-configuration/connect-secret/my-secret-key
2022-04-03 01:38:33 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-03 01:38:33 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-113 exec my-cluster-f9d3bf24-connect-54c445f895-lmk76 -- /bin/bash -c cat external-configuration/connect.config.map/my-key
2022-04-03 01:38:33 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-03 01:38:34 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-113 exec my-cluster-f9d3bf24-connect-54c445f895-lmk76 -- /bin/bash -c cat external-configuration/connect.secret/my-secret-key
2022-04-03 01:38:34 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-03 01:38:34 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 01:38:34 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMountingSecretAndConfigMapAsVolumesAndEnvVars
2022-04-03 01:38:34 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-f9d3bf24 in namespace namespace-113
2022-04-03 01:38:34 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-f9d3bf24 in namespace namespace-113
2022-04-03 01:38:44 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 01:38:44 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-113 for test case:testMountingSecretAndConfigMapAsVolumesAndEnvVars
2022-04-03 01:39:27 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testMountingSecretAndConfigMapAsVolumesAndEnvVars-FINISHED
2022-04-03 01:39:27 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 01:39:27 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 01:39:27 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testJvmAndResources-STARTED
2022-04-03 01:39:27 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 01:39:27 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-114 for test case:testJvmAndResources
2022-04-03 01:39:27 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-114
2022-04-03 01:39:27 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-114
2022-04-03 01:39:27 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-114
2022-04-03 01:39:27 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-bb196dd7 in namespace namespace-114
2022-04-03 01:39:27 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-114
2022-04-03 01:39:27 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-bb196dd7 will have desired state: Ready
2022-04-03 01:40:46 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-bb196dd7 is in desired state: Ready
2022-04-03 01:40:46 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-bb196dd7-kafka-clients in namespace namespace-114
2022-04-03 01:40:46 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-114
2022-04-03 01:40:46 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-bb196dd7-kafka-clients will be ready
2022-04-03 01:40:48 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-bb196dd7-kafka-clients is ready
2022-04-03 01:40:48 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-bb196dd7-scraper in namespace namespace-114
2022-04-03 01:40:48 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-114
2022-04-03 01:40:48 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-bb196dd7-scraper will be ready
2022-04-03 01:40:50 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-bb196dd7-scraper is ready
2022-04-03 01:40:50 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-bb196dd7-scraper to be ready
2022-04-03 01:41:00 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-bb196dd7-scraper is ready
2022-04-03 01:41:00 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-bb196dd7-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-03 01:41:00 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-bb196dd7-allow in namespace namespace-114
2022-04-03 01:41:00 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-114
2022-04-03 01:41:00 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-03 01:41:00 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-bb196dd7 in namespace namespace-114
2022-04-03 01:41:00 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-114
2022-04-03 01:41:00 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-bb196dd7 will have desired state: Ready
2022-04-03 01:42:03 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-bb196dd7 is in desired state: Ready
2022-04-03 01:42:03 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-114 exec my-cluster-bb196dd7-connect-6547f98f98-rxgsm -c my-cluster-bb196dd7-connect -- /bin/bash -c for proc in $(ls -1 /proc/ | grep [0-9]); do if echo "$(ls -lh /proc/$proc/exe 2>/dev/null || true)" | grep -q java; then cat /proc/$proc/cmdline; fi; done
2022-04-03 01:42:03 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-03 01:42:03 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 01:42:03 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testJvmAndResources
2022-04-03 01:42:03 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-bb196dd7-scraper in namespace namespace-114
2022-04-03 01:42:03 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-bb196dd7-allow in namespace namespace-114
2022-04-03 01:42:03 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-bb196dd7 in namespace namespace-114
2022-04-03 01:42:03 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-bb196dd7-kafka-clients in namespace namespace-114
2022-04-03 01:42:03 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-bb196dd7 in namespace namespace-114
2022-04-03 01:42:54 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 01:42:54 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-114 for test case:testJvmAndResources
2022-04-03 01:42:59 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testJvmAndResources-FINISHED
2022-04-03 01:42:59 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 01:42:59 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 01:42:59 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testSecretsWithKafkaConnectWithTlsAndTlsClientAuthentication-STARTED
2022-04-03 01:42:59 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 01:42:59 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-115 for test case:testSecretsWithKafkaConnectWithTlsAndTlsClientAuthentication
2022-04-03 01:42:59 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-115
2022-04-03 01:42:59 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-115
2022-04-03 01:42:59 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-115
2022-04-03 01:42:59 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-64fb8783 in namespace namespace-115
2022-04-03 01:42:59 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-115
2022-04-03 01:42:59 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-64fb8783 will have desired state: Ready
2022-04-03 01:44:15 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-64fb8783 is in desired state: Ready
2022-04-03 01:44:15 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-64fb8783-user in namespace namespace-115
2022-04-03 01:44:15 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-115
2022-04-03 01:44:15 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-64fb8783-user will have desired state: Ready
2022-04-03 01:44:16 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-64fb8783-user is in desired state: Ready
2022-04-03 01:44:16 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-471575122-472701833 in namespace namespace-115
2022-04-03 01:44:16 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-115
2022-04-03 01:44:16 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-471575122-472701833 will have desired state: Ready
2022-04-03 01:44:17 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-471575122-472701833 is in desired state: Ready
2022-04-03 01:44:17 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-64fb8783-scraper in namespace namespace-115
2022-04-03 01:44:17 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-115
2022-04-03 01:44:17 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-64fb8783-scraper will be ready
2022-04-03 01:44:18 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-64fb8783-scraper is ready
2022-04-03 01:44:18 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-64fb8783-scraper to be ready
2022-04-03 01:44:28 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-64fb8783-scraper is ready
2022-04-03 01:44:28 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-64fb8783-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-03 01:44:28 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-64fb8783-allow in namespace namespace-115
2022-04-03 01:44:28 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-115
2022-04-03 01:44:28 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-03 01:44:28 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-64fb8783 in namespace namespace-115
2022-04-03 01:44:28 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-115
2022-04-03 01:44:28 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-64fb8783 will have desired state: Ready
2022-04-03 01:45:37 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-64fb8783 is in desired state: Ready
2022-04-03 01:45:37 [main] [32mINFO [m [KafkaConnectUtils:63] Waiting until KafkaConnect API is available
2022-04-03 01:45:37 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-115 exec my-cluster-64fb8783-connect-f88789dcd-22k8b -- /bin/bash -c curl -I http://localhost:8083/connectors
2022-04-03 01:45:37 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-03 01:45:37 [main] [32mINFO [m [KafkaConnectUtils:66] KafkaConnect API is available
2022-04-03 01:45:37 [main] [32mINFO [m [ConnectIsolatedST:474] Verifying that KafkaConnect pod logs don't contain ERRORs
2022-04-03 01:45:37 [main] [32mINFO [m [ConnectIsolatedST:477] Creating FileStreamSink connector via pod my-cluster-64fb8783-scraper-7fb4685794-29qzj with topic my-topic-471575122-472701833
2022-04-03 01:45:38 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-115 exec my-cluster-64fb8783-scraper-7fb4685794-29qzj -- /bin/bash -c curl -X POST -H "Content-Type: application/json" --data '{ "name": "sink-test", "config": { "connector.class": "FileStreamSink", "tasks.max": "1", "topics": "my-topic-471575122-472701833", "file": "/tmp/test-file-sink.txt" } }' http://my-cluster-64fb8783-connect-api.namespace-115.svc:8083/connectors
2022-04-03 01:45:38 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-03 01:45:38 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-03 01:45:38 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-64fb8783-hello-world-producer in namespace namespace-115
2022-04-03 01:45:38 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-115
2022-04-03 01:45:38 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-64fb8783-hello-world-consumer in namespace namespace-115
2022-04-03 01:45:38 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-115
2022-04-03 01:45:38 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-64fb8783-hello-world-producer will be in active state
2022-04-03 01:45:38 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-64fb8783-hello-world-consumer will be in active state
2022-04-03 01:45:38 [main] [32mINFO [m [ClientUtils:61] Waiting till producer my-cluster-64fb8783-hello-world-producer and consumer my-cluster-64fb8783-hello-world-consumer finish
2022-04-03 01:45:56 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-64fb8783-connect-f88789dcd-22k8b
2022-04-03 01:45:56 [main] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-64fb8783-connect-f88789dcd-22k8b
2022-04-03 01:45:56 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 01:45:56 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSecretsWithKafkaConnectWithTlsAndTlsClientAuthentication
2022-04-03 01:45:56 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-64fb8783 in namespace namespace-115
2022-04-03 01:45:56 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-64fb8783-allow in namespace namespace-115
2022-04-03 01:45:56 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-64fb8783-hello-world-consumer in namespace namespace-115
2022-04-03 01:45:56 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-64fb8783-scraper in namespace namespace-115
2022-04-03 01:45:56 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-64fb8783-user in namespace namespace-115
2022-04-03 01:45:56 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-64fb8783-hello-world-producer in namespace namespace-115
2022-04-03 01:45:56 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-471575122-472701833 in namespace namespace-115
2022-04-03 01:45:56 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-64fb8783 in namespace namespace-115
2022-04-03 01:46:46 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 01:46:46 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-115 for test case:testSecretsWithKafkaConnectWithTlsAndTlsClientAuthentication
2022-04-03 01:46:51 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testSecretsWithKafkaConnectWithTlsAndTlsClientAuthentication-FINISHED
2022-04-03 01:46:51 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 01:46:51 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 01:46:51 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testScaleConnectWithoutConnectorToZero-STARTED
2022-04-03 01:46:51 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 01:46:51 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-116 for test case:testScaleConnectWithoutConnectorToZero
2022-04-03 01:46:51 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-116
2022-04-03 01:46:51 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-116
2022-04-03 01:46:51 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-116
2022-04-03 01:46:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-0fe302e9 in namespace namespace-116
2022-04-03 01:46:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-116
2022-04-03 01:46:51 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-0fe302e9 will have desired state: Ready
2022-04-03 01:48:13 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-0fe302e9 is in desired state: Ready
2022-04-03 01:48:13 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-0fe302e9 in namespace namespace-116
2022-04-03 01:48:13 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-116
2022-04-03 01:48:13 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-0fe302e9 will have desired state: Ready
2022-04-03 01:49:25 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-0fe302e9 is in desired state: Ready
2022-04-03 01:49:25 [main] [32mINFO [m [ConnectIsolatedST:891] Scaling KafkaConnect down to zero
2022-04-03 01:49:25 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-0fe302e9 will have desired state: Ready
2022-04-03 01:49:25 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-0fe302e9 is in desired state: Ready
2022-04-03 01:49:31 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 01:49:31 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testScaleConnectWithoutConnectorToZero
2022-04-03 01:49:31 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-0fe302e9 in namespace namespace-116
2022-04-03 01:49:31 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-0fe302e9 in namespace namespace-116
2022-04-03 01:49:41 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 01:49:41 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-116 for test case:testScaleConnectWithoutConnectorToZero
2022-04-03 01:50:24 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testScaleConnectWithoutConnectorToZero-FINISHED
2022-04-03 01:50:24 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 01:50:24 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 01:50:24 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testScaleConnectWithConnectorToZero-STARTED
2022-04-03 01:50:24 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 01:50:24 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-117 for test case:testScaleConnectWithConnectorToZero
2022-04-03 01:50:24 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-117
2022-04-03 01:50:24 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-117
2022-04-03 01:50:24 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-117
2022-04-03 01:50:24 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-bc3346b7 in namespace namespace-117
2022-04-03 01:50:24 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-117
2022-04-03 01:50:24 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-bc3346b7 will have desired state: Ready
2022-04-03 01:51:39 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-bc3346b7 is in desired state: Ready
2022-04-03 01:51:39 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-bc3346b7 in namespace namespace-117
2022-04-03 01:51:39 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-117
2022-04-03 01:51:39 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-bc3346b7 will have desired state: Ready
2022-04-03 01:52:51 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-bc3346b7 is in desired state: Ready
2022-04-03 01:52:51 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-bc3346b7 in namespace namespace-117
2022-04-03 01:52:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-117
2022-04-03 01:52:51 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-bc3346b7 will have desired state: Ready
2022-04-03 01:52:52 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-bc3346b7 is in desired state: Ready
2022-04-03 01:52:52 [main] [32mINFO [m [ConnectIsolatedST:934] Scaling KafkaConnect down to zero
2022-04-03 01:52:52 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-bc3346b7 will have desired state: Ready
2022-04-03 01:52:52 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-bc3346b7 is in desired state: Ready
2022-04-03 01:52:59 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 01:52:59 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testScaleConnectWithConnectorToZero
2022-04-03 01:52:59 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-bc3346b7 in namespace namespace-117
2022-04-03 01:52:59 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-bc3346b7 in namespace namespace-117
2022-04-03 01:52:59 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-bc3346b7 in namespace namespace-117
2022-04-03 01:53:09 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 01:53:09 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-117 for test case:testScaleConnectWithConnectorToZero
2022-04-03 01:53:52 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testScaleConnectWithConnectorToZero-FINISHED
2022-04-03 01:53:52 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 01:53:52 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 01:53:52 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testKafkaConnectWithPlainAndScramShaAuthentication-STARTED
2022-04-03 01:53:52 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 01:53:52 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-118 for test case:testKafkaConnectWithPlainAndScramShaAuthentication
2022-04-03 01:53:52 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-118
2022-04-03 01:53:52 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-118
2022-04-03 01:53:52 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-118
2022-04-03 01:53:52 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-27e6a0da in namespace namespace-118
2022-04-03 01:53:52 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-118
2022-04-03 01:53:52 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-27e6a0da will have desired state: Ready
2022-04-03 01:55:12 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-27e6a0da is in desired state: Ready
2022-04-03 01:55:12 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-27e6a0da-user in namespace namespace-118
2022-04-03 01:55:12 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-118
2022-04-03 01:55:12 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-27e6a0da-user will have desired state: Ready
2022-04-03 01:55:13 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-27e6a0da-user is in desired state: Ready
2022-04-03 01:55:13 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-2139564162-1969115528 in namespace namespace-118
2022-04-03 01:55:13 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-118
2022-04-03 01:55:13 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-2139564162-1969115528 will have desired state: Ready
2022-04-03 01:55:14 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-2139564162-1969115528 is in desired state: Ready
2022-04-03 01:55:14 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-27e6a0da-scraper in namespace namespace-118
2022-04-03 01:55:14 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-118
2022-04-03 01:55:14 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-27e6a0da-scraper will be ready
2022-04-03 01:55:15 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-27e6a0da-scraper is ready
2022-04-03 01:55:15 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-27e6a0da-scraper to be ready
2022-04-03 01:55:25 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-27e6a0da-scraper is ready
2022-04-03 01:55:25 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-27e6a0da-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-03 01:55:25 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-27e6a0da-allow in namespace namespace-118
2022-04-03 01:55:25 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-118
2022-04-03 01:55:25 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-03 01:55:25 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-27e6a0da in namespace namespace-118
2022-04-03 01:55:25 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-118
2022-04-03 01:55:25 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-27e6a0da will have desired state: Ready
2022-04-03 01:56:27 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-27e6a0da is in desired state: Ready
2022-04-03 01:56:28 [main] [32mINFO [m [KafkaConnectUtils:63] Waiting until KafkaConnect API is available
2022-04-03 01:56:28 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-118 exec my-cluster-27e6a0da-connect-7774844dbf-r7hwh -- /bin/bash -c curl -I http://localhost:8083/connectors
2022-04-03 01:56:28 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-03 01:56:28 [main] [32mINFO [m [KafkaConnectUtils:66] KafkaConnect API is available
2022-04-03 01:56:28 [main] [32mINFO [m [ConnectIsolatedST:280] Verifying that KafkaConnect pod logs don't contain ERRORs
2022-04-03 01:56:28 [main] [32mINFO [m [ConnectIsolatedST:283] Creating FileStreamSink connector via pod my-cluster-27e6a0da-scraper-7df7d99944-q9k2z with topic my-topic-2139564162-1969115528
2022-04-03 01:56:28 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-118 exec my-cluster-27e6a0da-scraper-7df7d99944-q9k2z -- /bin/bash -c curl -X POST -H "Content-Type: application/json" --data '{ "name": "sink-test", "config": { "connector.class": "FileStreamSink", "tasks.max": "1", "topics": "my-topic-2139564162-1969115528", "file": "/tmp/test-file-sink.txt" } }' http://my-cluster-27e6a0da-connect-api.namespace-118.svc:8083/connectors
2022-04-03 01:56:28 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-03 01:56:28 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-03 01:56:28 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-27e6a0da-hello-world-producer in namespace namespace-118
2022-04-03 01:56:28 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-118
2022-04-03 01:56:28 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-27e6a0da-hello-world-consumer in namespace namespace-118
2022-04-03 01:56:28 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-118
2022-04-03 01:56:28 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-27e6a0da-hello-world-producer will be in active state
2022-04-03 01:56:29 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-27e6a0da-hello-world-consumer will be in active state
2022-04-03 01:56:29 [main] [32mINFO [m [ClientUtils:61] Waiting till producer my-cluster-27e6a0da-hello-world-producer and consumer my-cluster-27e6a0da-hello-world-consumer finish
2022-04-03 01:56:45 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-27e6a0da-connect-7774844dbf-r7hwh
2022-04-03 01:56:45 [main] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-27e6a0da-connect-7774844dbf-r7hwh
2022-04-03 01:56:45 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 01:56:45 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaConnectWithPlainAndScramShaAuthentication
2022-04-03 01:56:45 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-27e6a0da-allow in namespace namespace-118
2022-04-03 01:56:45 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-27e6a0da-hello-world-producer in namespace namespace-118
2022-04-03 01:56:45 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-27e6a0da in namespace namespace-118
2022-04-03 01:56:45 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-27e6a0da-hello-world-consumer in namespace namespace-118
2022-04-03 01:56:45 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-27e6a0da-user in namespace namespace-118
2022-04-03 01:56:45 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-2139564162-1969115528 in namespace namespace-118
2022-04-03 01:56:45 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-27e6a0da-scraper in namespace namespace-118
2022-04-03 01:56:45 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-27e6a0da in namespace namespace-118
2022-04-03 01:57:35 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 01:57:35 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-118 for test case:testKafkaConnectWithPlainAndScramShaAuthentication
2022-04-03 01:57:41 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testKafkaConnectWithPlainAndScramShaAuthentication-FINISHED
2022-04-03 01:57:41 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 01:57:41 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 01:57:41 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testCustomAndUpdatedValues-STARTED
2022-04-03 01:57:41 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 01:57:41 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-119 for test case:testCustomAndUpdatedValues
2022-04-03 01:57:41 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-119
2022-04-03 01:57:41 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-119
2022-04-03 01:57:41 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-119
2022-04-03 01:57:41 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-21b792f3 in namespace namespace-119
2022-04-03 01:57:41 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-119
2022-04-03 01:57:41 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-21b792f3 will have desired state: Ready
2022-04-03 01:58:48 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-21b792f3 is in desired state: Ready
2022-04-03 01:58:48 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-21b792f3 in namespace namespace-119
2022-04-03 01:58:48 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-119
2022-04-03 01:58:48 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-21b792f3 will have desired state: Ready
2022-04-03 01:59:26 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-21b792f3 is in desired state: Ready
2022-04-03 01:59:26 [main] [32mINFO [m [ConnectIsolatedST:629] Verify values before update
2022-04-03 01:59:26 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-21b792f3-connect in pod name
2022-04-03 01:59:26 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container my-cluster-21b792f3-connect
2022-04-03 01:59:26 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-21b792f3-connect
2022-04-03 01:59:26 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container my-cluster-21b792f3-connect
2022-04-03 01:59:26 [main] [32mINFO [m [ConnectIsolatedST:634] Check if actual env variable KAFKA_CONNECT_CONFIGURATION has different value than test.value
2022-04-03 01:59:26 [main] [32mINFO [m [ConnectIsolatedST:640] Updating values in MirrorMaker container
2022-04-03 01:59:26 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-21b792f3-connect rolling update
2022-04-03 02:00:06 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-21b792f3-connect will be ready
2022-04-03 02:00:06 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-21b792f3-connect is ready
2022-04-03 02:00:16 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-21b792f3-connect rolling update finished
2022-04-03 02:00:16 [main] [32mINFO [m [ConnectIsolatedST:657] Verify values after update
2022-04-03 02:00:16 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-21b792f3-connect in pod name
2022-04-03 02:00:16 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container my-cluster-21b792f3-connect
2022-04-03 02:00:16 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-21b792f3-connect
2022-04-03 02:00:16 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container my-cluster-21b792f3-connect
2022-04-03 02:00:16 [main] [32mINFO [m [AbstractST:190] Getting pods by prefix in name my-cluster-21b792f3-connect
2022-04-03 02:00:16 [main] [32mINFO [m [AbstractST:194] Testing configuration for container my-cluster-21b792f3-connect
2022-04-03 02:00:16 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 02:00:16 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCustomAndUpdatedValues
2022-04-03 02:00:16 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-21b792f3 in namespace namespace-119
2022-04-03 02:00:16 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-21b792f3 in namespace namespace-119
2022-04-03 02:00:26 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 02:00:26 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-119 for test case:testCustomAndUpdatedValues
2022-04-03 02:00:53 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testCustomAndUpdatedValues-FINISHED
2022-04-03 02:00:53 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 02:00:53 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 02:00:53 [main] [32mINFO [m [ResourceManager:346] In context ConnectIsolatedST is everything deleted.
2022-04-03 02:00:53 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 16, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3,990.11 s - in io.strimzi.systemtest.connect.ConnectIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.connect.ConnectBuilderIsolatedST
2022-04-03 02:00:54 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-03 02:01:19 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-03 02:01:19 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-03 02:01:19 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-03 02:01:19 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 02:01:19 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-03 02:01:19 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-03 02:01:19 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-03 02:01:19 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-03 02:01:19 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-03 02:01:19 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-03 02:01:19 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-03 02:01:19 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 02:01:19 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-03 02:01:19 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-03 02:01:19 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-03 02:01:19 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-03 02:01:19 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-03 02:01:19 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-03 02:01:19 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-03 02:01:19 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 02:01:19 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-03 02:01:19 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-03 02:01:19 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-03 02:01:19 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-03 02:01:19 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-03 02:01:19 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-03 02:01:19 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-03 02:01:29 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-03 02:01:29 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-03 02:01:29 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-03 02:01:39 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 02:01:44 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7e2e5e3d
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=30000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-03 02:01:44 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-03 02:01:44 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-03 02:01:44 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-03 02:01:44 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-03 02:01:44 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 02:01:44 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-03 02:01:44 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-03 02:01:44 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-03 02:01:44 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-03 02:01:44 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-03 02:01:44 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-03 02:01:44 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-03 02:01:44 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-03 02:01:44 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-03 02:01:44 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-03 02:01:44 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-03 02:01:44 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-03 02:01:44 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-03 02:01:44 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-03 02:01:44 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-03 02:01:44 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-03 02:01:44 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-03 02:01:44 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-03 02:01:44 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-03 02:01:44 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-03 02:01:44 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-03 02:01:44 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-03 02:01:44 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-03 02:01:44 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-03 02:01:44 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-03 02:01:44 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-03 02:01:44 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-03 02:01:44 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-03 02:01:44 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 02:01:44 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-03 02:01:44 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-03 02:01:44 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-03 02:02:25 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-03 02:02:25 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-03 02:02:35 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-03 02:02:35 [main] [33mWARN [m [ConnectBuilderIsolatedST:546] For running these tests on K8s you have to have internal registry deployed using `minikube start --insecure-registry '10.0.0.0/24'` and `minikube addons enable registry`
2022-04-03 02:02:35 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka infra-namespace in namespace infra-namespace
2022-04-03 02:02:35 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: infra-namespace will have desired state: Ready
2022-04-03 02:04:00 [main] [32mINFO [m [ResourceManager:444] Kafka: infra-namespace is in desired state: Ready
2022-04-03 02:04:00 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 02:04:00 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectBuilderIsolatedST.testBuildWithJarTgzAndZip-STARTED
2022-04-03 02:04:00 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 02:04:00 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1544786452-1952572712 in namespace infra-namespace
2022-04-03 02:04:00 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1544786452-1952572712 will have desired state: Ready
2022-04-03 02:04:01 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1544786452-1952572712 is in desired state: Ready
2022-04-03 02:04:01 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-91cbdae9 in namespace infra-namespace
2022-04-03 02:04:01 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-91cbdae9 will have desired state: Ready
2022-04-03 02:05:52 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-91cbdae9 is in desired state: Ready
2022-04-03 02:05:52 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-91cbdae9 in namespace infra-namespace
2022-04-03 02:05:52 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-91cbdae9 will have desired state: Ready
2022-04-03 02:05:53 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-91cbdae9 is in desired state: Ready
2022-04-03 02:05:53 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-03 02:05:53 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-91cbdae9-hello-world-producer in namespace infra-namespace
2022-04-03 02:05:53 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-91cbdae9-hello-world-producer will be in active state
2022-04-03 02:05:54 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:my-cluster-91cbdae9-hello-world-producer to finished
2022-04-03 02:06:02 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-03 02:06:02 [main] [32mINFO [m [PodUtils:189] Message Received message with key 'null' and value '"Hello-world - 99"' found in my-cluster-91cbdae9-connect-7d4846b65-595vn log
2022-04-03 02:06:02 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 02:06:02 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testBuildWithJarTgzAndZip
2022-04-03 02:06:02 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-91cbdae9 in namespace infra-namespace
2022-04-03 02:06:02 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1544786452-1952572712 in namespace infra-namespace
2022-04-03 02:06:02 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-91cbdae9-hello-world-producer in namespace infra-namespace
2022-04-03 02:06:02 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-91cbdae9 in namespace infra-namespace
2022-04-03 02:06:12 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 02:06:12 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectBuilderIsolatedST.testBuildWithJarTgzAndZip-FINISHED
2022-04-03 02:06:12 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 02:06:12 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 02:06:12 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectBuilderIsolatedST.testBuildFailsWithWrongChecksumOfArtifact-STARTED
2022-04-03 02:06:12 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 02:06:12 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-1c3542b5-scraper in namespace infra-namespace
2022-04-03 02:06:12 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-1c3542b5-scraper will be ready
2022-04-03 02:06:14 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-1c3542b5-scraper is ready
2022-04-03 02:06:14 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-1c3542b5-scraper to be ready
2022-04-03 02:06:24 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-1c3542b5-scraper is ready
2022-04-03 02:06:24 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-1c3542b5-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-03 02:06:24 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-1c3542b5-allow in namespace infra-namespace
2022-04-03 02:06:24 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-03 02:06:24 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-1c3542b5 in namespace infra-namespace
2022-04-03 02:06:24 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-1c3542b5 will have desired state: NotReady
2022-04-03 02:06:25 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-1c3542b5 is in desired state: NotReady
2022-04-03 02:06:48 [main] [32mINFO [m [ConnectBuilderIsolatedST:186] Checking if KafkaConnect status condition contains message about build failure
2022-04-03 02:06:48 [main] [32mINFO [m [ConnectBuilderIsolatedST:189] Deploying network policies for KafkaConnect
2022-04-03 02:06:48 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-1c3542b5-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-03 02:06:48 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-1c3542b5-allow in namespace infra-namespace
2022-04-03 02:06:48 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-03 02:06:48 [main] [32mINFO [m [ConnectBuilderIsolatedST:197] Replacing plugin's checksum with right one
2022-04-03 02:06:48 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-1c3542b5 will have desired state: Ready
2022-04-03 02:09:59 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-1c3542b5 is in desired state: Ready
2022-04-03 02:09:59 [main] [32mINFO [m [ConnectBuilderIsolatedST:215] Checking if KafkaConnect API contains EchoSink connector
2022-04-03 02:09:59 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-1c3542b5-scraper-f9ff6655f-58x5b -- curl -X GET http://my-cluster-1c3542b5-connect-api:8083/connector-plugins
2022-04-03 02:09:59 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-03 02:09:59 [main] [32mINFO [m [ConnectBuilderIsolatedST:220] Checking if KafkaConnect resource contains EchoSink connector in status
2022-04-03 02:09:59 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 02:09:59 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testBuildFailsWithWrongChecksumOfArtifact
2022-04-03 02:09:59 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-1c3542b5 in namespace infra-namespace
2022-04-03 02:09:59 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-1c3542b5-allow in namespace infra-namespace
2022-04-03 02:09:59 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-1c3542b5-scraper in namespace infra-namespace
2022-04-03 02:09:59 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-1c3542b5-allow in namespace infra-namespace
2022-04-03 02:10:39 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 02:10:39 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectBuilderIsolatedST.testBuildFailsWithWrongChecksumOfArtifact-FINISHED
2022-04-03 02:10:39 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 02:10:39 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 02:10:39 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectBuilderIsolatedST.testBuildOtherPluginTypeWithAndWithoutFileName-STARTED
2022-04-03 02:10:39 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 02:10:39 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1828966152-1971502921 in namespace infra-namespace
2022-04-03 02:10:39 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1828966152-1971502921 will have desired state: Ready
2022-04-03 02:10:40 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1828966152-1971502921 is in desired state: Ready
2022-04-03 02:10:40 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-6fdeec64-scraper in namespace infra-namespace
2022-04-03 02:10:40 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-6fdeec64-scraper will be ready
2022-04-03 02:10:42 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-6fdeec64-scraper is ready
2022-04-03 02:10:42 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-6fdeec64-scraper to be ready
2022-04-03 02:10:53 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-6fdeec64-scraper is ready
2022-04-03 02:10:53 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-6fdeec64-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-03 02:10:53 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-6fdeec64-allow in namespace infra-namespace
2022-04-03 02:10:53 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-03 02:10:53 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-6fdeec64 in namespace infra-namespace
2022-04-03 02:10:53 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-6fdeec64 will have desired state: Ready
2022-04-03 02:12:27 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-6fdeec64 is in desired state: Ready
2022-04-03 02:12:27 [main] [32mINFO [m [ConnectBuilderIsolatedST:448] Checking that plugin has correct file name: echo-sink-test.jar
2022-04-03 02:12:27 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-6fdeec64-connect-5b8cf9b8ff-br862 -- /bin/bash -c ls plugins/plugin-with-other-type/*
2022-04-03 02:12:27 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-03 02:12:27 [main] [32mINFO [m [ConnectBuilderIsolatedST:461] Removing file name from the plugin, hash should be used
2022-04-03 02:12:27 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-6fdeec64-connect rolling update
2022-04-03 02:14:12 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-6fdeec64-connect will be ready
2022-04-03 02:14:12 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-6fdeec64-connect is ready
2022-04-03 02:14:22 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-6fdeec64-connect rolling update finished
2022-04-03 02:14:22 [main] [32mINFO [m [ConnectBuilderIsolatedST:468] Checking that plugin has different name than before
2022-04-03 02:14:23 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-6fdeec64-connect-8f6f6f4b4-6wj9h -- /bin/bash -c ls plugins/plugin-with-other-type/*
2022-04-03 02:14:23 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-03 02:14:23 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 02:14:23 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testBuildOtherPluginTypeWithAndWithoutFileName
2022-04-03 02:14:23 [main] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-6fdeec64-allow in namespace infra-namespace
2022-04-03 02:14:23 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-6fdeec64 in namespace infra-namespace
2022-04-03 02:14:23 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-6fdeec64-scraper in namespace infra-namespace
2022-04-03 02:14:23 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1828966152-1971502921 in namespace infra-namespace
2022-04-03 02:15:03 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 02:15:03 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectBuilderIsolatedST.testBuildOtherPluginTypeWithAndWithoutFileName-FINISHED
2022-04-03 02:15:03 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 02:15:03 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 02:15:03 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectBuilderIsolatedST.testUpdateConnectWithAnotherPlugin-STARTED
2022-04-03 02:15:03 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 02:15:03 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-2029416125-2085493341 in namespace infra-namespace
2022-04-03 02:15:03 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-2029416125-2085493341 will have desired state: Ready
2022-04-03 02:15:04 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-2029416125-2085493341 is in desired state: Ready
2022-04-03 02:15:04 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-3681634a-scraper in namespace infra-namespace
2022-04-03 02:15:04 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-3681634a-scraper will be ready
2022-04-03 02:15:06 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-3681634a-scraper is ready
2022-04-03 02:15:06 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-3681634a-scraper to be ready
2022-04-03 02:15:16 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-3681634a-scraper is ready
2022-04-03 02:15:16 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-3681634a-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-03 02:15:16 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-3681634a-allow in namespace infra-namespace
2022-04-03 02:15:16 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-03 02:15:16 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-3681634a in namespace infra-namespace
2022-04-03 02:15:16 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-3681634a will have desired state: Ready
2022-04-03 02:16:51 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-3681634a is in desired state: Ready
2022-04-03 02:16:51 [main] [32mINFO [m [ConnectBuilderIsolatedST:370] Creating EchoSink connector
2022-04-03 02:16:51 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector echo-sink-connector in namespace infra-namespace
2022-04-03 02:16:51 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: echo-sink-connector will have desired state: Ready
2022-04-03 02:16:52 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: echo-sink-connector is in desired state: Ready
2022-04-03 02:16:52 [main] [32mINFO [m [ConnectBuilderIsolatedST:382] Checking that KafkaConnect API contains EchoSink connector and not Camel-Telegram Connector class name
2022-04-03 02:16:52 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-3681634a-scraper-554f47954b-bnqgk -- curl -X GET http://my-cluster-3681634a-connect-api:8083/connector-plugins
2022-04-03 02:16:52 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-03 02:16:52 [main] [32mINFO [m [ConnectBuilderIsolatedST:388] Adding one more connector to the KafkaConnect
2022-04-03 02:16:52 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-3681634a-connect rolling update
2022-04-03 02:18:32 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-3681634a-connect will be ready
2022-04-03 02:18:32 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-3681634a-connect is ready
2022-04-03 02:18:43 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-3681634a-connect rolling update finished
2022-04-03 02:18:43 [main] [32mINFO [m [ConnectBuilderIsolatedST:399] Creating Camel-HTTP-Sink connector
2022-04-03 02:18:43 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector camel-http-connector in namespace infra-namespace
2022-04-03 02:18:43 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: camel-http-connector will have desired state: Ready
2022-04-03 02:18:44 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: camel-http-connector is in desired state: Ready
2022-04-03 02:18:44 [main] [32mINFO [m [ConnectBuilderIsolatedST:409] Checking if both Connectors were created and Connect contains both plugins
2022-04-03 02:18:44 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 02:18:44 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testUpdateConnectWithAnotherPlugin
2022-04-03 02:18:44 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-3681634a in namespace infra-namespace
2022-04-03 02:18:44 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-2029416125-2085493341 in namespace infra-namespace
2022-04-03 02:18:44 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector camel-http-connector in namespace infra-namespace
2022-04-03 02:18:44 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector echo-sink-connector in namespace infra-namespace
2022-04-03 02:18:44 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-3681634a-allow in namespace infra-namespace
2022-04-03 02:18:44 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-3681634a-scraper in namespace infra-namespace
2022-04-03 02:19:24 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 02:19:24 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectBuilderIsolatedST.testUpdateConnectWithAnotherPlugin-FINISHED
2022-04-03 02:19:24 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 02:19:24 [main] [32mINFO [m [OpenShiftOnlyCondition:25] testPushIntoImageStream is @OpenShiftOnly, but the running cluster is not OpenShift: Ignoring testPushIntoImageStream
2022-04-03 02:19:24 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 02:19:24 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectBuilderIsolatedST.testBuildPluginUsingMavenCoordinatesArtifacts-STARTED
2022-04-03 02:19:24 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 02:19:24 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-356936781-1073449205 in namespace infra-namespace
2022-04-03 02:19:24 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-4bf0770c in namespace infra-namespace
2022-04-03 02:19:24 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-356936781-1073449205 will have desired state: Ready
2022-04-03 02:19:25 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-356936781-1073449205 is in desired state: Ready
2022-04-03 02:19:25 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-4bf0770c will have desired state: Ready
2022-04-03 02:21:36 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-4bf0770c is in desired state: Ready
2022-04-03 02:21:36 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-4bf0770c-camel-connector in namespace infra-namespace
2022-04-03 02:21:36 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-4bf0770c-camel-connector will have desired state: Ready
2022-04-03 02:21:37 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-4bf0770c-camel-connector is in desired state: Ready
2022-04-03 02:21:37 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-03 02:21:37 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-4bf0770c-hello-world-consumer in namespace infra-namespace
2022-04-03 02:21:37 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-4bf0770c-hello-world-consumer will be in active state
2022-04-03 02:21:38 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:my-cluster-4bf0770c-hello-world-consumer to finished
2022-04-03 02:22:32 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 02:22:32 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testBuildPluginUsingMavenCoordinatesArtifacts
2022-04-03 02:22:32 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-4bf0770c-camel-connector in namespace infra-namespace
2022-04-03 02:22:32 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-4bf0770c-hello-world-consumer in namespace infra-namespace
2022-04-03 02:22:32 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-356936781-1073449205 in namespace infra-namespace
2022-04-03 02:22:32 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-4bf0770c in namespace infra-namespace
2022-04-03 02:22:52 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 02:22:52 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectBuilderIsolatedST.testBuildPluginUsingMavenCoordinatesArtifacts-FINISHED
2022-04-03 02:22:52 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 02:22:52 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 02:22:52 [main] [32mINFO [m [ResourceManager:348] Delete all resources for ConnectBuilderIsolatedST
2022-04-03 02:22:52 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka infra-namespace in namespace infra-namespace
2022-04-03 02:23:02 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;33mWARNING[m] Tests run: 6, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 1,328.831 s - in io.strimzi.systemtest.connect.ConnectBuilderIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.backup.ColdBackupScriptIsolatedST
2022-04-03 02:23:02 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-03 02:23:27 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-03 02:23:27 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-03 02:23:27 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-03 02:23:27 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 02:23:27 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-03 02:23:27 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-03 02:23:27 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 02:23:27 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 02:23:27 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-03 02:23:27 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-03 02:23:27 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-03 02:23:27 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-03 02:23:27 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-03 02:23:27 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-03 02:23:27 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-03 02:23:27 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-03 02:23:27 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-03 02:23:27 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-03 02:23:27 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-03 02:23:27 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-03 02:23:27 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-03 02:23:27 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-03 02:23:27 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-03 02:23:27 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-03 02:23:37 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-03 02:23:37 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-03 02:23:37 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-03 02:23:37 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-03 02:23:37 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-03 02:23:37 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-03 02:23:48 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 02:23:53 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7e2e5e3d
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-03 02:23:53 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-03 02:23:53 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-03 02:23:53 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-03 02:23:53 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-03 02:23:53 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 02:23:53 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-03 02:23:53 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-03 02:23:53 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-03 02:23:53 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-03 02:23:54 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-03 02:23:54 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-03 02:23:54 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-03 02:23:54 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-03 02:23:54 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-03 02:23:54 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-03 02:23:54 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-03 02:23:54 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-03 02:23:54 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-03 02:23:54 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-03 02:23:54 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-03 02:23:54 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-03 02:23:54 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-03 02:23:54 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-03 02:23:54 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-03 02:23:54 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-03 02:23:54 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-03 02:23:54 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-03 02:23:54 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-03 02:23:54 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-03 02:23:54 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-03 02:23:54 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-03 02:23:54 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-03 02:23:54 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-03 02:23:54 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 02:23:54 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-03 02:23:54 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-03 02:23:54 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-03 02:24:14 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-03 02:24:14 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-03 02:24:24 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-03 02:24:24 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 02:24:24 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.backup.ColdBackupScriptIsolatedST.backupAndRestore-STARTED
2022-04-03 02:24:24 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 02:24:24 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-5e4d2021 in namespace infra-namespace
2022-04-03 02:24:24 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-5e4d2021 will have desired state: Ready
2022-04-03 02:25:48 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-5e4d2021 is in desired state: Ready
2022-04-03 02:25:48 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-5e4d2021-producer in namespace infra-namespace
2022-04-03 02:25:48 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-5e4d2021-consumer in namespace infra-namespace
2022-04-03 02:25:48 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-5e4d2021-producer will be in active state
2022-04-03 02:25:48 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-5e4d2021-consumer will be in active state
2022-04-03 02:25:48 [main] [32mINFO [m [ClientUtils:61] Waiting till producer my-cluster-5e4d2021-producer and consumer my-cluster-5e4d2021-consumer finish
2022-04-03 02:26:08 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-5e4d2021-kafka-0 -- /opt/kafka/bin/kafka-consumer-groups.sh --describe --bootstrap-server localhost:9092 --group my-group
2022-04-03 02:26:08 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-03 02:26:08 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-5e4d2021-producer in namespace infra-namespace
2022-04-03 02:26:08 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-5e4d2021-producer will be in active state
2022-04-03 02:26:09 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:my-cluster-5e4d2021-producer to finished
2022-04-03 02:26:16 [main] [32mINFO [m [ColdBackupScriptIsolatedST:95] Running backup procedure for infra-namespace/my-cluster-5e4d2021
2022-04-03 02:26:18 [main] [32mINFO [m [Exec:417] Failed to exec command: /home/ec2-user/strimzi-kafka-operator/systemtest/../tools/cold-backup/run.sh backup -n infra-namespace -c my-cluster-5e4d2021 -t /home/ec2-user/strimzi-kafka-operator/systemtest/target/my-cluster-5e4d2021.tgz -y
2022-04-03 02:26:18 [main] [32mINFO [m [Exec:417] Return code: 1
2022-04-03 02:26:18 [main] [32mINFO [m [Exec:417] ======STDOUT START=======
2022-04-03 02:26:18 [main] [32mINFO [m [Exec:417] Exporting environment
Starting cluster my-cluster-5e4d2021
2022-04-03 02:26:18 [main] [32mINFO [m [Exec:417] ======STDOUT END======
2022-04-03 02:26:18 [main] [32mINFO [m [Exec:417] ======STDERR START=======
2022-04-03 02:26:18 [main] [32mINFO [m [Exec:417] /home/ec2-user/strimzi-kafka-operator/systemtest/../tools/cold-backup/run.sh: line 145: yq: command not found
Error: invalid argument "Starting cluster my-cluster-5e4d2021\nstatefulset.apps/my-cluster-5e4d2021-zookeeper scaled\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/name=my-cluster-5e4d2021-zookeeper\" in namespace \"infra-namespace\"\npod/my-cluster-5e4d2021-zookeeper-0 condition met\nstatefulset.apps/my-cluster-5e4d2021-kafka scaled\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/name=my-cluster-5e4d2021-kafka\" in namespace \"infra-namespace\"\npod/my-cluster-5e4d2021-kafka-0 condition met\ndeployment.apps/strimzi-cluster-operator scaled\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/kind=cluster-operator\" in namespace \"infra-namespace\"\npod/strimzi-cluster-operator-78689684d4-82k89 condition met\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/name=my-cluster-5e4d2021-kafka\" in namespace \"infra-namespace\"\npod/my-cluster-5e4d2021-kafka-0 condition met\nbackup failed at 145: yq eval \".spec.zookeeper.replicas\" -" for "--replicas" flag: strconv.ParseInt: parsing "Starting cluster my-cluster-5e4d2021\nstatefulset.apps/my-cluster-5e4d2021-zookeeper scaled\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/name=my-cluster-5e4d2021-zookeeper\" in namespace \"infra-namespace\"\npod/my-cluster-5e4d2021-zookeeper-0 condition met\nstatefulset.apps/my-cluster-5e4d2021-kafka scaled\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/name=my-cluster-5e4d2021-kafka\" in namespace \"infra-namespace\"\npod/my-cluster-5e4d2021-kafka-0 condition met\ndeployment.apps/strimzi-cluster-operator scaled\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/kind=cluster-operator\" in namespace \"infra-namespace\"\npod/strimzi-cluster-operator-78689684d4-82k89 condition met\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/name=my-cluster-5e4d2021-kafka\" in namespace \"infra-namespace\"\npod/my-cluster-5e4d2021-kafka-0 condition met\nbackup failed at 145: yq eval \".spec.zookeeper.replicas\" -": invalid syntax


Examples:
  # Scale a replicaset named 'foo' to 3.
  kubectl scale --replicas=3 rs/foo
  
  # Scale a resource identified by type and name specified in "foo.yaml" to 3.
  kubectl scale --replicas=3 -f foo.yaml
  
  # If the deployment named mysql's current size is 2, scale mysql to 3.
  kubectl scale --current-replicas=2 --replicas=3 deployment/mysql
  
  # Scale multiple replication controllers.
  kubectl scale --replicas=5 rc/foo rc/bar rc/baz
  
  # Scale statefulset named 'web' to 3.
  kubectl scale --replicas=3 statefulset/web

Options:
      --all=false: Select all resources in the namespace of the specified resource types
      --allow-missing-template-keys=true: If true, ignore any errors in templates when a field or map key is missing in the template. Only applies to golang and jsonpath output formats.
      --current-replicas=-1: Precondition for current size. Requires that the current size of the resource match this value in order to scale.
  -f, --filename=[]: Filename, directory, or URL to files identifying the resource to set a new size
  -k, --kustomize='': Process the kustomization directory. This flag can't be used together with -f or -R.
  -o, --output='': Output format. One of: json|yaml|name|go-template|go-template-file|template|templatefile|jsonpath|jsonpath-file.
      --record=false: Record current kubectl command in the resource annotation. If set to false, do not record the command. If set to true, record the command. If not set, default to updating the existing annotation value only if one already exists.
  -R, --recursive=false: Process the directory used in -f, --filename recursively. Useful when you want to manage related manifests organized within the same directory.
      --replicas=0: The new desired number of replicas. Required.
      --resource-version='': Precondition for resource version. Requires that the current resource version match this value in order to scale.
  -l, --selector='': Selector (label query) to filter on, supports '=', '==', and '!='.(e.g. -l key1=value1,key2=value2)
      --template='': Template string or path to template file to use when -o=go-template, -o=go-template-file. The template format is golang templates [http://golang.org/pkg/text/template/#pkg-overview].
      --timeout=0s: The length of time to wait before giving up on a scale operation, zero means don't wait. Any other values should contain a corresponding time unit (e.g. 1s, 2m, 3h).

Usage:
  kubectl scale [--resource-version=version] [--current-replicas=count] --replicas=COUNT (-f FILENAME | TYPE NAME) [options]

Use "kubectl options" for a list of global command-line options (applies to all commands).
2022-04-03 02:26:18 [main] [32mINFO [m [Exec:417] ======STDERR END======
2022-04-03 02:26:18 [main] [1;31mERROR[m [TestExecutionWatcher:28] ColdBackupScriptIsolatedST - Exception `/home/ec2-user/strimzi-kafka-operator/systemtest/../tools/cold-backup/run.sh backup -n infra-namespace -c my-cluster-5e4d2021 -t /home/ec2-user/strimzi-kafka-operator/systemtest/target/my-cluster-5e4d2021.tgz -y` got status code 1 and stderr:
------
/home/ec2-user/strimzi-kafka-operator/systemtest/../tools/cold-backup/run.sh: line 145: yq: command not found
Error: invalid argument "Starting cluster my-cluster-5e4d2021\nstatefulset.apps/my-cluster-5e4d2021-zookeeper scaled\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/name=my-cluster-5e4d2021-zookeeper\" in namespace \"infra-namespace\"\npod/my-cluster-5e4d2021-zookeeper-0 condition met\nstatefulset.apps/my-cluster-5e4d2021-kafka scaled\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/name=my-cluster-5e4d2021-kafka\" in namespace \"infra-namespace\"\npod/my-cluster-5e4d2021-kafka-0 condition met\ndeployment.apps/strimzi-cluster-operator scaled\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/kind=cluster-operator\" in namespace \"infra-namespace\"\npod/strimzi-cluster-operator-78689684d4-82k89 condition met\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/name=my-cluster-5e4d2021-kafka\" in namespace \"infra-namespace\"\npod/my-cluster-5e4d2021-kafka-0 condition met\nbackup failed at 145: yq eval \".spec.zookeeper.replicas\" -" for "--replicas" flag: strconv.ParseInt: parsing "Starting cluster my-cluster-5e4d2021\nstatefulset.apps/my-cluster-5e4d2021-zookeeper scaled\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/name=my-cluster-5e4d2021-zookeeper\" in namespace \"infra-namespace\"\npod/my-cluster-5e4d2021-zookeeper-0 condition met\nstatefulset.apps/my-cluster-5e4d2021-kafka scaled\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/name=my-cluster-5e4d2021-kafka\" in namespace \"infra-namespace\"\npod/my-cluster-5e4d2021-kafka-0 condition met\ndeployment.apps/strimzi-cluster-operator scaled\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/kind=cluster-operator\" in namespace \"infra-namespace\"\npod/strimzi-cluster-operator-78689684d4-82k89 condition met\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/name=my-cluster-5e4d2021-kafka\" in namespace \"infra-namespace\"\npod/my-cluster-5e4d2021-kafka-0 condition met\nbackup failed at 145: yq eval \".spec.zookeeper.replicas\" -": invalid syntax


Examples:
  # Scale a replicaset named 'foo' to 3.
  kubectl scale --replicas=3 rs/foo
  
  # Scale a resource identified by type and name specified in "foo.yaml" to 3.
  kubectl scale --replicas=3 -f foo.yaml
  
  # If the deployment named mysql's current size is 2, scale mysql to 3.
  kubectl scale --current-replicas=2 --replicas=3 deployment/mysql
  
  # Scale multiple replication controllers.
  kubectl scale --replicas=5 rc/foo rc/bar rc/baz
  
  # Scale statefulset named 'web' to 3.
  kubectl scale --replicas=3 statefulset/web

Options:
      --all=false: Select all resources in the namespace of the specified resource types
      --allow-missing-template-keys=true: If true, ignore any errors in templates when a field or map key is missing in the template. Only applies to golang and jsonpath output formats.
      --current-replicas=-1: Precondition for current size. Requires that the current size of the resource match this value in order to scale.
  -f, --filename=[]: Filename, directory, or URL to files identifying the resource to set a new size
  -k, --kustomize='': Process the kustomization directory. This flag can't be used together with -f or -R.
  -o, --output='': Output format. One of: json|yaml|name|go-template|go-template-file|template|templatefile|jsonpath|jsonpath-file.
      --record=false: Record current kubectl command in the resource annotation. If set to false, do not record the command. If set to true, record the command. If not set, default to updating the existing annotation value only if one already exists.
  -R, --recursive=false: Process the directory used in -f, --filename recursively. Useful when you want to manage related manifests organized within the same directory.
      --replicas=0: The new desired number of replicas. Required.
      --resource-version='': Precondition for resource version. Requires that the current resource version match this value in order to scale.
  -l, --selector='': Selector (label query) to filter on, supports '=', '==', and '!='.(e.g. -l key1=value1,key2=value2)
      --template='': Template string or path to template file to use when -o=go-template, -o=go-template-file. The template format is golang templates [http://golang.org/pkg/text/template/#pkg-overview].
      --timeout=0s: The length of time to wait before giving up on a scale operation, zero means don't wait. Any other values should contain a corresponding time unit (e.g. 1s, 2m, 3h).

Usage:
  kubectl scale [--resource-version=version] [--current-replicas=count] --replicas=COUNT (-f FILENAME | TYPE NAME) [options]

Use "kubectl options" for a list of global command-line options (applies to all commands).


------
and stdout:
------
Exporting environment
Starting cluster my-cluster-5e4d2021

------ has been thrown in @Test. Going to collect logs from components.
2022-04-03 02:26:18 [main] [32mINFO [m [LogCollector:252] Collecting events in Namespace infra-namespace
2022-04-03 02:26:18 [main] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace infra-namespace
2022-04-03 02:26:18 [main] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace infra-namespace
2022-04-03 02:26:18 [main] [33mWARN [m [LogCollector:298] Unable to collect log from pod: my-cluster-5e4d2021-zookeeper-0 and container: zookeeper - pod container is not initialized
2022-04-03 02:26:18 [main] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace infra-namespace
2022-04-03 02:26:19 [main] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace infra-namespace
2022-04-03 02:26:19 [main] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace infra-namespace
2022-04-03 02:26:19 [main] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace infra-namespace
2022-04-03 02:26:19 [main] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-04-03 02:26:19 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 02:26:19 [main] [32mINFO [m [ResourceManager:348] Delete all resources for backupAndRestore
2022-04-03 02:26:19 [main] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-5e4d2021-consumer in namespace infra-namespace
2022-04-03 02:26:19 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-5e4d2021-producer in namespace infra-namespace
2022-04-03 02:26:19 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-5e4d2021-producer in namespace infra-namespace
2022-04-03 02:26:19 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-5e4d2021 in namespace infra-namespace
2022-04-03 02:26:29 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 02:26:29 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.backup.ColdBackupScriptIsolatedST.backupAndRestore-FINISHED
2022-04-03 02:26:29 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 02:26:29 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 02:26:29 [main] [32mINFO [m [ResourceManager:346] In context ColdBackupScriptIsolatedST is everything deleted.
2022-04-03 02:26:29 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;31mERROR[m] Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 206.83 s <<< FAILURE! - in io.strimzi.systemtest.backup.ColdBackupScriptIsolatedST
[[1;31mERROR[m] io.strimzi.systemtest.backup.ColdBackupScriptIsolatedST.backupAndRestore(ExtensionContext)  Time elapsed: 125.1 s  <<< ERROR!
io.strimzi.test.k8s.exceptions.KubeClusterException: 
`/home/ec2-user/strimzi-kafka-operator/systemtest/../tools/cold-backup/run.sh backup -n infra-namespace -c my-cluster-5e4d2021 -t /home/ec2-user/strimzi-kafka-operator/systemtest/target/my-cluster-5e4d2021.tgz -y` got status code 1 and stderr:
------
/home/ec2-user/strimzi-kafka-operator/systemtest/../tools/cold-backup/run.sh: line 145: yq: command not found
Error: invalid argument "Starting cluster my-cluster-5e4d2021\nstatefulset.apps/my-cluster-5e4d2021-zookeeper scaled\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/name=my-cluster-5e4d2021-zookeeper\" in namespace \"infra-namespace\"\npod/my-cluster-5e4d2021-zookeeper-0 condition met\nstatefulset.apps/my-cluster-5e4d2021-kafka scaled\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/name=my-cluster-5e4d2021-kafka\" in namespace \"infra-namespace\"\npod/my-cluster-5e4d2021-kafka-0 condition met\ndeployment.apps/strimzi-cluster-operator scaled\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/kind=cluster-operator\" in namespace \"infra-namespace\"\npod/strimzi-cluster-operator-78689684d4-82k89 condition met\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/name=my-cluster-5e4d2021-kafka\" in namespace \"infra-namespace\"\npod/my-cluster-5e4d2021-kafka-0 condition met\nbackup failed at 145: yq eval \".spec.zookeeper.replicas\" -" for "--replicas" flag: strconv.ParseInt: parsing "Starting cluster my-cluster-5e4d2021\nstatefulset.apps/my-cluster-5e4d2021-zookeeper scaled\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/name=my-cluster-5e4d2021-zookeeper\" in namespace \"infra-namespace\"\npod/my-cluster-5e4d2021-zookeeper-0 condition met\nstatefulset.apps/my-cluster-5e4d2021-kafka scaled\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/name=my-cluster-5e4d2021-kafka\" in namespace \"infra-namespace\"\npod/my-cluster-5e4d2021-kafka-0 condition met\ndeployment.apps/strimzi-cluster-operator scaled\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/kind=cluster-operator\" in namespace \"infra-namespace\"\npod/strimzi-cluster-operator-78689684d4-82k89 condition met\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/name=my-cluster-5e4d2021-kafka\" in namespace \"infra-namespace\"\npod/my-cluster-5e4d2021-kafka-0 condition met\nbackup failed at 145: yq eval \".spec.zookeeper.replicas\" -": invalid syntax


Examples:
  # Scale a replicaset named 'foo' to 3.
  kubectl scale --replicas=3 rs/foo
  
  # Scale a resource identified by type and name specified in "foo.yaml" to 3.
  kubectl scale --replicas=3 -f foo.yaml
  
  # If the deployment named mysql's current size is 2, scale mysql to 3.
  kubectl scale --current-replicas=2 --replicas=3 deployment/mysql
  
  # Scale multiple replication controllers.
  kubectl scale --replicas=5 rc/foo rc/bar rc/baz
  
  # Scale statefulset named 'web' to 3.
  kubectl scale --replicas=3 statefulset/web

Options:
      --all=false: Select all resources in the namespace of the specified resource types
      --allow-missing-template-keys=true: If true, ignore any errors in templates when a field or map key is missing in the template. Only applies to golang and jsonpath output formats.
      --current-replicas=-1: Precondition for current size. Requires that the current size of the resource match this value in order to scale.
  -f, --filename=[]: Filename, directory, or URL to files identifying the resource to set a new size
  -k, --kustomize='': Process the kustomization directory. This flag can't be used together with -f or -R.
  -o, --output='': Output format. One of: json|yaml|name|go-template|go-template-file|template|templatefile|jsonpath|jsonpath-file.
      --record=false: Record current kubectl command in the resource annotation. If set to false, do not record the command. If set to true, record the command. If not set, default to updating the existing annotation value only if one already exists.
  -R, --recursive=false: Process the directory used in -f, --filename recursively. Useful when you want to manage related manifests organized within the same directory.
      --replicas=0: The new desired number of replicas. Required.
      --resource-version='': Precondition for resource version. Requires that the current resource version match this value in order to scale.
  -l, --selector='': Selector (label query) to filter on, supports '=', '==', and '!='.(e.g. -l key1=value1,key2=value2)
      --template='': Template string or path to template file to use when -o=go-template, -o=go-template-file. The template format is golang templates [http://golang.org/pkg/text/template/#pkg-overview].
      --timeout=0s: The length of time to wait before giving up on a scale operation, zero means don't wait. Any other values should contain a corresponding time unit (e.g. 1s, 2m, 3h).

Usage:
  kubectl scale [--resource-version=version] [--current-replicas=count] --replicas=COUNT (-f FILENAME | TYPE NAME) [options]

Use "kubectl options" for a list of global command-line options (applies to all commands).


------
and stdout:
------
Exporting environment
Starting cluster my-cluster-5e4d2021

------
	at io.strimzi.test.executor.Exec.exec(Exec.java:223)
	at io.strimzi.test.executor.Exec.exec(Exec.java:149)
	at io.strimzi.test.executor.Exec.exec(Exec.java:118)
	at io.strimzi.systemtest.backup.ColdBackupScriptIsolatedST.backupAndRestore(ColdBackupScriptIsolatedST.java:99)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)

[[1;34mINFO[m] Running io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST
2022-04-03 02:26:29 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-03 02:26:54 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-03 02:26:54 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-03 02:26:54 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-03 02:26:54 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 02:26:54 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-03 02:26:54 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-03 02:26:54 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 02:26:54 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-03 02:26:54 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-03 02:26:54 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-03 02:26:54 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-03 02:26:54 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-03 02:26:54 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 02:26:54 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-03 02:26:54 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-03 02:26:54 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-03 02:26:54 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-03 02:26:54 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-03 02:26:54 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-03 02:26:54 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-03 02:26:54 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-03 02:26:54 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-03 02:26:54 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-03 02:27:04 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-03 02:27:04 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-03 02:27:04 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-03 02:27:04 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-03 02:27:04 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-03 02:27:04 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-03 02:27:04 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-03 02:27:14 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 02:27:20 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7e2e5e3d
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=30000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-03 02:27:20 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-03 02:27:20 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-03 02:27:20 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-03 02:27:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-03 02:27:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 02:27:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-03 02:27:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-03 02:27:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-03 02:27:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-03 02:27:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-03 02:27:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-03 02:27:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-03 02:27:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-03 02:27:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-03 02:27:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-03 02:27:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-03 02:27:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-03 02:27:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-03 02:27:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-03 02:27:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-03 02:27:20 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-03 02:27:20 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-03 02:27:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-03 02:27:20 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-03 02:27:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-03 02:27:20 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-03 02:27:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-03 02:27:20 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-03 02:27:20 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-03 02:27:20 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-03 02:27:20 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-03 02:27:20 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-03 02:27:20 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-03 02:27:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 02:27:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-03 02:27:20 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-03 02:27:20 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-03 02:27:55 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-03 02:27:55 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-03 02:28:05 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-03 02:28:05 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 02:28:05 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testRestoreOffsetsInConsumerGroup-STARTED
2022-04-03 02:28:05 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 02:28:05 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-120 for test case:testRestoreOffsetsInConsumerGroup
2022-04-03 02:28:05 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-120
2022-04-03 02:28:05 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-120
2022-04-03 02:28:05 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-120
2022-04-03 02:28:05 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-5cc5bf68-source in namespace namespace-120
2022-04-03 02:28:05 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-03 02:28:05 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-5cc5bf68-target in namespace namespace-120
2022-04-03 02:28:05 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-03 02:28:05 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-5cc5bf68-source will have desired state: Ready
2022-04-03 02:29:24 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-5cc5bf68-source is in desired state: Ready
2022-04-03 02:29:24 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-5cc5bf68-target will have desired state: Ready
2022-04-03 02:29:24 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-5cc5bf68-target is in desired state: Ready
2022-04-03 02:29:24 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-5cc5bf68-trg-src in namespace namespace-120
2022-04-03 02:29:24 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-03 02:29:24 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-5cc5bf68-src-trg in namespace namespace-120
2022-04-03 02:29:24 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-03 02:29:24 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic test-sync-offset-1294641364 in namespace namespace-120
2022-04-03 02:29:24 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-03 02:29:24 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-5cc5bf68-trg-src will have desired state: Ready
2022-04-03 02:30:31 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-5cc5bf68-trg-src is in desired state: Ready
2022-04-03 02:30:31 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-5cc5bf68-src-trg will have desired state: Ready
2022-04-03 02:30:34 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-5cc5bf68-src-trg is in desired state: Ready
2022-04-03 02:30:34 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: test-sync-offset-1294641364 will have desired state: Ready
2022-04-03 02:30:34 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: test-sync-offset-1294641364 is in desired state: Ready
2022-04-03 02:30:34 [main] [32mINFO [m [MirrorMaker2IsolatedST:1090] Send & receive 100 messages to/from Source cluster.
2022-04-03 02:30:34 [main] [32mINFO [m [ResourceManager:155] Create/Update Job mm2-producer-source-my-consumer-group-882892323 in namespace namespace-120
2022-04-03 02:30:34 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-03 02:30:34 [main] [32mINFO [m [ResourceManager:155] Create/Update Job mm2-consumer-source-my-consumer-group-521940760 in namespace namespace-120
2022-04-03 02:30:34 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-03 02:30:34 [main] [32mINFO [m [JobUtils:81] Waiting for job: mm2-producer-source-my-consumer-group-882892323 will be in active state
2022-04-03 02:30:35 [main] [32mINFO [m [JobUtils:81] Waiting for job: mm2-consumer-source-my-consumer-group-521940760 will be in active state
2022-04-03 02:30:35 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:mm2-producer-source-my-consumer-group-882892323 to finished
2022-04-03 02:30:43 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:mm2-consumer-source-my-consumer-group-521940760 to finished
2022-04-03 02:30:48 [main] [32mINFO [m [MirrorMaker2IsolatedST:1098] Send 100 messages to Source cluster.
2022-04-03 02:30:48 [main] [32mINFO [m [ResourceManager:155] Create/Update Job mm2-producer-source-my-consumer-group-882892323 in namespace namespace-120
2022-04-03 02:30:48 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-03 02:30:48 [main] [32mINFO [m [JobUtils:81] Waiting for job: mm2-producer-source-my-consumer-group-882892323 will be in active state
2022-04-03 02:30:49 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:mm2-producer-source-my-consumer-group-882892323 to finished
2022-04-03 02:30:52 [main] [32mINFO [m [MirrorMaker2IsolatedST:1105] Wait 1 second as 'sync.group.offsets.interval.seconds=1'. As this is insignificant wait, we're skipping it
2022-04-03 02:30:52 [main] [32mINFO [m [MirrorMaker2IsolatedST:1107] Receive 100 messages from mirrored topic on Target cluster.
2022-04-03 02:30:52 [main] [32mINFO [m [ResourceManager:155] Create/Update Job mm2-consumer-target-my-consumer-group-1087244715 in namespace namespace-120
2022-04-03 02:30:52 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-03 02:30:52 [main] [32mINFO [m [JobUtils:81] Waiting for job: mm2-consumer-target-my-consumer-group-1087244715 will be in active state
2022-04-03 02:30:53 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:mm2-consumer-target-my-consumer-group-1087244715 to finished
2022-04-03 02:31:04 [main] [32mINFO [m [MirrorMaker2IsolatedST:1112] Send 50 messages to Source cluster
2022-04-03 02:31:04 [main] [32mINFO [m [ResourceManager:155] Create/Update Job mm2-producer-source-my-consumer-group-882892323 in namespace namespace-120
2022-04-03 02:31:04 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-03 02:31:04 [main] [32mINFO [m [JobUtils:81] Waiting for job: mm2-producer-source-my-consumer-group-882892323 will be in active state
2022-04-03 02:31:05 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:mm2-producer-source-my-consumer-group-882892323 to finished
2022-04-03 02:31:13 [main] [32mINFO [m [MirrorMaker2IsolatedST:1118] Wait 1 second as 'sync.group.offsets.interval.seconds=1'. As this is insignificant wait, we're skipping it
2022-04-03 02:31:13 [main] [32mINFO [m [MirrorMaker2IsolatedST:1119] Receive 10 msgs from source cluster
2022-04-03 02:31:13 [main] [32mINFO [m [ResourceManager:155] Create/Update Job mm2-consumer-source-my-consumer-group-521940760 in namespace namespace-120
2022-04-03 02:31:13 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-03 02:31:13 [main] [32mINFO [m [JobUtils:81] Waiting for job: mm2-consumer-source-my-consumer-group-521940760 will be in active state
2022-04-03 02:31:14 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:mm2-consumer-source-my-consumer-group-521940760 to finished
2022-04-03 02:31:26 [main] [32mINFO [m [MirrorMaker2IsolatedST:1125] Wait 1 second as 'sync.group.offsets.interval.seconds=1'. As this is insignificant wait, we're skipping it
2022-04-03 02:31:26 [main] [32mINFO [m [MirrorMaker2IsolatedST:1127] Receive 40 msgs from mirrored topic on Target cluster
2022-04-03 02:31:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Job mm2-consumer-target-my-consumer-group-1087244715 in namespace namespace-120
2022-04-03 02:31:26 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-03 02:31:26 [main] [32mINFO [m [JobUtils:81] Waiting for job: mm2-consumer-target-my-consumer-group-1087244715 will be in active state
2022-04-03 02:31:27 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:mm2-consumer-target-my-consumer-group-1087244715 to finished
2022-04-03 02:31:48 [main] [32mINFO [m [MirrorMaker2IsolatedST:1133] There should be no more messages to read. Try to consume at least 1 message. This client job should fail on timeout.
2022-04-03 02:31:48 [main] [32mINFO [m [ResourceManager:155] Create/Update Job mm2-consumer-target-my-consumer-group-1087244715 in namespace namespace-120
2022-04-03 02:31:48 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-03 02:31:48 [main] [32mINFO [m [JobUtils:81] Waiting for job: mm2-consumer-target-my-consumer-group-1087244715 will be in active state
2022-04-03 02:31:49 [main] [32mINFO [m [ClientUtils:89] Waiting for producer/consumer:mm2-consumer-target-my-consumer-group-1087244715 to finish with failure.
2022-04-03 02:33:50 [main] [1;31mERROR[m [TestUtils:162] Exception waiting for Job did not finish within time limit (as expected)., null
2022-04-03 02:33:50 [main] [32mINFO [m [ClientUtils:100] Client job 'mm2-consumer-target-my-consumer-group-1087244715' finished with expected timeout.
2022-04-03 02:33:50 [main] [32mINFO [m [MirrorMaker2IsolatedST:1139] As it's Active-Active MM2 mode, there should be no more messages to read from Source cluster topic. This client job should fail on timeout.
2022-04-03 02:33:50 [main] [32mINFO [m [ResourceManager:155] Create/Update Job mm2-consumer-source-my-consumer-group-521940760 in namespace namespace-120
2022-04-03 02:33:50 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-03 02:33:50 [main] [32mINFO [m [JobUtils:81] Waiting for job: mm2-consumer-source-my-consumer-group-521940760 will be in active state
2022-04-03 02:33:51 [main] [32mINFO [m [ClientUtils:89] Waiting for producer/consumer:mm2-consumer-source-my-consumer-group-521940760 to finish with failure.
2022-04-03 02:35:52 [main] [1;31mERROR[m [TestUtils:162] Exception waiting for Job did not finish within time limit (as expected)., null
2022-04-03 02:35:52 [main] [32mINFO [m [ClientUtils:100] Client job 'mm2-consumer-source-my-consumer-group-521940760' finished with expected timeout.
2022-04-03 02:35:52 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 02:35:52 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRestoreOffsetsInConsumerGroup
2022-04-03 02:35:52 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job mm2-producer-source-my-consumer-group-882892323 in namespace namespace-120
2022-04-03 02:35:52 [main] [32mINFO [m [ResourceManager:241] Delete of Job mm2-consumer-target-my-consumer-group-1087244715 in namespace namespace-120
2022-04-03 02:35:52 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Job mm2-consumer-target-my-consumer-group-1087244715 in namespace namespace-120
2022-04-03 02:35:52 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Job mm2-producer-source-my-consumer-group-882892323 in namespace namespace-120
2022-04-03 02:35:52 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job mm2-consumer-target-my-consumer-group-1087244715 in namespace namespace-120
2022-04-03 02:35:52 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic test-sync-offset-1294641364 in namespace namespace-120
2022-04-03 02:35:52 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job mm2-consumer-source-my-consumer-group-521940760 in namespace namespace-120
2022-04-03 02:35:52 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Job mm2-consumer-source-my-consumer-group-521940760 in namespace namespace-120
2022-04-03 02:35:53 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-5cc5bf68-target in namespace namespace-120
2022-04-03 02:35:53 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-5cc5bf68-source in namespace namespace-120
2022-04-03 02:35:53 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-5cc5bf68-trg-src in namespace namespace-120
2022-04-03 02:35:53 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job mm2-consumer-source-my-consumer-group-521940760 in namespace namespace-120
2022-04-03 02:35:53 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Job mm2-producer-source-my-consumer-group-882892323 in namespace namespace-120
2022-04-03 02:35:53 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-5cc5bf68-src-trg in namespace namespace-120
2022-04-03 02:36:13 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 02:36:13 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-120 for test case:testRestoreOffsetsInConsumerGroup
2022-04-03 02:36:24 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testRestoreOffsetsInConsumerGroup-FINISHED
2022-04-03 02:36:24 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 02:36:24 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 02:36:24 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testMirrorMaker2-STARTED
2022-04-03 02:36:24 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 02:36:24 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-121 for test case:testMirrorMaker2
2022-04-03 02:36:24 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-121
2022-04-03 02:36:24 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-121
2022-04-03 02:36:24 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-121
2022-04-03 02:36:24 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-b11bd693-source in namespace namespace-121
2022-04-03 02:36:24 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-121
2022-04-03 02:36:24 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-b11bd693-source will have desired state: Ready
2022-04-03 02:37:33 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-b11bd693-source is in desired state: Ready
2022-04-03 02:37:33 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-b11bd693-target in namespace namespace-121
2022-04-03 02:37:33 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-121
2022-04-03 02:37:33 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-b11bd693-target will have desired state: Ready
2022-04-03 02:38:52 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-b11bd693-target is in desired state: Ready
2022-04-03 02:38:52 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic mirrormaker2-topic-example-550186906 in namespace namespace-121
2022-04-03 02:38:52 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-121
2022-04-03 02:38:52 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: mirrormaker2-topic-example-550186906 will have desired state: Ready
2022-04-03 02:38:53 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: mirrormaker2-topic-example-550186906 is in desired state: Ready
2022-04-03 02:38:53 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-b11bd693-kafka-clients in namespace namespace-121
2022-04-03 02:38:53 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-121
2022-04-03 02:39:03 [main] [32mINFO [m [MirrorMaker2IsolatedST:155] Sending messages to - topic availability-topic-source-my-topic-1802241396-711765821, cluster my-cluster-b11bd693-source and message count of 100
2022-04-03 02:39:03 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@4ec62c12, messages=[], arguments=[--max-messages, 100, --topic, availability-topic-source-my-topic-1802241396-711765821, --bootstrap-server, my-cluster-b11bd693-source-kafka-bootstrap.namespace-121.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-b11bd693-kafka-clients-6897ddcd8c-h9mvf', podNamespace='namespace-121', bootstrapServer='my-cluster-b11bd693-source-kafka-bootstrap.namespace-121.svc:9092', topicName='availability-topic-source-my-topic-1802241396-711765821', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@4438d9f5}
2022-04-03 02:39:03 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-b11bd693-source-kafka-bootstrap.namespace-121.svc:9092:availability-topic-source-my-topic-1802241396-711765821 from pod my-cluster-b11bd693-kafka-clients-6897ddcd8c-h9mvf
2022-04-03 02:39:03 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b11bd693-kafka-clients-6897ddcd8c-h9mvf -n namespace-121 -- /opt/kafka/producer.sh --max-messages 100 --topic availability-topic-source-my-topic-1802241396-711765821 --bootstrap-server my-cluster-b11bd693-source-kafka-bootstrap.namespace-121.svc:9092
2022-04-03 02:39:06 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-03 02:39:06 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-03 02:39:06 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@7b447e04, messages=[], arguments=[--max-messages, 100, --group-instance-id, instance896664632, --group-id, my-consumer-group-1906149714, --topic, availability-topic-source-my-topic-1802241396-711765821, --bootstrap-server, my-cluster-b11bd693-source-kafka-bootstrap.namespace-121.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-b11bd693-kafka-clients-6897ddcd8c-h9mvf', podNamespace='namespace-121', bootstrapServer='my-cluster-b11bd693-source-kafka-bootstrap.namespace-121.svc:9092', topicName='availability-topic-source-my-topic-1802241396-711765821', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1906149714', consumerInstanceId='instance896664632', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7931f7a6}
2022-04-03 02:39:06 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-b11bd693-source-kafka-bootstrap.namespace-121.svc:9092#availability-topic-source-my-topic-1802241396-711765821 from pod my-cluster-b11bd693-kafka-clients-6897ddcd8c-h9mvf
2022-04-03 02:39:06 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b11bd693-kafka-clients-6897ddcd8c-h9mvf -n namespace-121 -- /opt/kafka/consumer.sh --max-messages 100 --group-instance-id instance896664632 --group-id my-consumer-group-1906149714 --topic availability-topic-source-my-topic-1802241396-711765821 --bootstrap-server my-cluster-b11bd693-source-kafka-bootstrap.namespace-121.svc:9092
2022-04-03 02:39:11 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-03 02:39:11 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-03 02:39:11 [main] [32mINFO [m [MirrorMaker2IsolatedST:160] Setting topic to availability-topic-target-my-topic-1802241396-711765821, cluster to my-cluster-b11bd693-target and changing consumer group
2022-04-03 02:39:11 [main] [32mINFO [m [MirrorMaker2IsolatedST:168] Sending messages to - topic availability-topic-target-my-topic-1802241396-711765821, cluster my-cluster-b11bd693-target and message count of 100
2022-04-03 02:39:11 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@61185746, messages=[], arguments=[--max-messages, 100, --topic, availability-topic-target-my-topic-1802241396-711765821, --bootstrap-server, my-cluster-b11bd693-target-kafka-bootstrap.namespace-121.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-b11bd693-kafka-clients-6897ddcd8c-h9mvf', podNamespace='namespace-121', bootstrapServer='my-cluster-b11bd693-target-kafka-bootstrap.namespace-121.svc:9092', topicName='availability-topic-target-my-topic-1802241396-711765821', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@49d7bc2}
2022-04-03 02:39:11 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-b11bd693-target-kafka-bootstrap.namespace-121.svc:9092:availability-topic-target-my-topic-1802241396-711765821 from pod my-cluster-b11bd693-kafka-clients-6897ddcd8c-h9mvf
2022-04-03 02:39:11 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b11bd693-kafka-clients-6897ddcd8c-h9mvf -n namespace-121 -- /opt/kafka/producer.sh --max-messages 100 --topic availability-topic-target-my-topic-1802241396-711765821 --bootstrap-server my-cluster-b11bd693-target-kafka-bootstrap.namespace-121.svc:9092
2022-04-03 02:39:14 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-03 02:39:14 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-03 02:39:14 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@4f0ee8b2, messages=[], arguments=[--max-messages, 100, --group-instance-id, instance975393720, --group-id, my-consumer-group-1700298353, --topic, availability-topic-target-my-topic-1802241396-711765821, --bootstrap-server, my-cluster-b11bd693-target-kafka-bootstrap.namespace-121.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-b11bd693-kafka-clients-6897ddcd8c-h9mvf', podNamespace='namespace-121', bootstrapServer='my-cluster-b11bd693-target-kafka-bootstrap.namespace-121.svc:9092', topicName='availability-topic-target-my-topic-1802241396-711765821', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1700298353', consumerInstanceId='instance975393720', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@17620004}
2022-04-03 02:39:14 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-b11bd693-target-kafka-bootstrap.namespace-121.svc:9092#availability-topic-target-my-topic-1802241396-711765821 from pod my-cluster-b11bd693-kafka-clients-6897ddcd8c-h9mvf
2022-04-03 02:39:14 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b11bd693-kafka-clients-6897ddcd8c-h9mvf -n namespace-121 -- /opt/kafka/consumer.sh --max-messages 100 --group-instance-id instance975393720 --group-id my-consumer-group-1700298353 --topic availability-topic-target-my-topic-1802241396-711765821 --bootstrap-server my-cluster-b11bd693-target-kafka-bootstrap.namespace-121.svc:9092
2022-04-03 02:39:19 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-03 02:39:19 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-03 02:39:19 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-b11bd693 in namespace namespace-121
2022-04-03 02:39:19 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-121
2022-04-03 02:39:19 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-b11bd693 will have desired state: Ready
2022-04-03 02:40:29 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-b11bd693 is in desired state: Ready
2022-04-03 02:40:29 [main] [32mINFO [m [MirrorMaker2IsolatedST:183] Looks like the mirrormaker2 cluster my-cluster deployed OK
2022-04-03 02:40:29 [main] [32mINFO [m [MirrorMaker2IsolatedST:640] Verifying docker image names
2022-04-03 02:40:29 [main] [32mINFO [m [AbstractST:172] strimzi-cluster-operator
2022-04-03 02:40:29 [main] [32mINFO [m [MirrorMaker2IsolatedST:653] Docker images verified
2022-04-03 02:40:29 [main] [32mINFO [m [AbstractST:311] Verifying labels on pod type mirrormaker2
2022-04-03 02:40:29 [main] [32mINFO [m [AbstractST:315] Verifying labels for pod: my-cluster-b11bd693-mirrormaker2-67dbbb58b8-4k6hr
2022-04-03 02:40:29 [main] [32mINFO [m [AbstractST:356] Verifying labels for Kafka Connect Services
2022-04-03 02:40:29 [main] [32mINFO [m [AbstractST:362] Verifying labels for service my-cluster-b11bd693-mirrormaker2-api
2022-04-03 02:40:29 [main] [32mINFO [m [AbstractST:384] Verifying labels for Config maps
2022-04-03 02:40:29 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-b11bd693-mirrormaker2-config
2022-04-03 02:40:29 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-b11bd693-source-entity-topic-operator-config
2022-04-03 02:40:29 [main] [32mINFO [m [AbstractST:407] CM my-cluster-b11bd693-source-entity-topic-operator-config is not related to current test
2022-04-03 02:40:29 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-b11bd693-source-entity-user-operator-config
2022-04-03 02:40:29 [main] [32mINFO [m [AbstractST:407] CM my-cluster-b11bd693-source-entity-user-operator-config is not related to current test
2022-04-03 02:40:29 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-b11bd693-source-kafka-config
2022-04-03 02:40:29 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-b11bd693-source-zookeeper-config
2022-04-03 02:40:29 [main] [32mINFO [m [AbstractST:407] CM my-cluster-b11bd693-source-zookeeper-config is not related to current test
2022-04-03 02:40:29 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-b11bd693-target-entity-topic-operator-config
2022-04-03 02:40:29 [main] [32mINFO [m [AbstractST:407] CM my-cluster-b11bd693-target-entity-topic-operator-config is not related to current test
2022-04-03 02:40:29 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-b11bd693-target-entity-user-operator-config
2022-04-03 02:40:29 [main] [32mINFO [m [AbstractST:407] CM my-cluster-b11bd693-target-entity-user-operator-config is not related to current test
2022-04-03 02:40:29 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-b11bd693-target-kafka-config
2022-04-03 02:40:29 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-b11bd693-target-zookeeper-config
2022-04-03 02:40:29 [main] [32mINFO [m [AbstractST:407] CM my-cluster-b11bd693-target-zookeeper-config is not related to current test
2022-04-03 02:40:29 [main] [32mINFO [m [AbstractST:414] Verifying labels for Service Accounts
2022-04-03 02:40:29 [main] [32mINFO [m [AbstractST:427] Verifying labels for service account my-cluster-b11bd693-source-entity-operator
2022-04-03 02:40:29 [main] [32mINFO [m [AbstractST:427] Verifying labels for service account my-cluster-b11bd693-source-kafka
2022-04-03 02:40:29 [main] [32mINFO [m [AbstractST:427] Verifying labels for service account my-cluster-b11bd693-source-zookeeper
2022-04-03 02:40:29 [main] [32mINFO [m [MirrorMaker2IsolatedST:198] Setting topic to mirrormaker2-topic-example-550186906, cluster to my-cluster-b11bd693-source and changing consumer group
2022-04-03 02:40:29 [main] [32mINFO [m [MirrorMaker2IsolatedST:206] Sending messages to - topic mirrormaker2-topic-example-550186906, cluster my-cluster-b11bd693-source and message count of 100
2022-04-03 02:40:29 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@e3e0803, messages=[], arguments=[--max-messages, 100, --topic, mirrormaker2-topic-example-550186906, --bootstrap-server, my-cluster-b11bd693-source-kafka-bootstrap.namespace-121.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-b11bd693-kafka-clients-6897ddcd8c-h9mvf', podNamespace='namespace-121', bootstrapServer='my-cluster-b11bd693-source-kafka-bootstrap.namespace-121.svc:9092', topicName='mirrormaker2-topic-example-550186906', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@485a7771}
2022-04-03 02:40:29 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-b11bd693-source-kafka-bootstrap.namespace-121.svc:9092:mirrormaker2-topic-example-550186906 from pod my-cluster-b11bd693-kafka-clients-6897ddcd8c-h9mvf
2022-04-03 02:40:29 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b11bd693-kafka-clients-6897ddcd8c-h9mvf -n namespace-121 -- /opt/kafka/producer.sh --max-messages 100 --topic mirrormaker2-topic-example-550186906 --bootstrap-server my-cluster-b11bd693-source-kafka-bootstrap.namespace-121.svc:9092
2022-04-03 02:40:31 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-03 02:40:31 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-03 02:40:31 [main] [32mINFO [m [MirrorMaker2IsolatedST:210] Consumer in source cluster and topic should receive 100 messages
2022-04-03 02:40:31 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@16e8bf8f, messages=[], arguments=[--max-messages, 100, --group-instance-id, instance2008782160, --group-id, my-consumer-group-45336329, --topic, mirrormaker2-topic-example-550186906, --bootstrap-server, my-cluster-b11bd693-source-kafka-bootstrap.namespace-121.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-b11bd693-kafka-clients-6897ddcd8c-h9mvf', podNamespace='namespace-121', bootstrapServer='my-cluster-b11bd693-source-kafka-bootstrap.namespace-121.svc:9092', topicName='mirrormaker2-topic-example-550186906', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-45336329', consumerInstanceId='instance2008782160', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@68e8cc81}
2022-04-03 02:40:31 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-b11bd693-source-kafka-bootstrap.namespace-121.svc:9092#mirrormaker2-topic-example-550186906 from pod my-cluster-b11bd693-kafka-clients-6897ddcd8c-h9mvf
2022-04-03 02:40:31 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b11bd693-kafka-clients-6897ddcd8c-h9mvf -n namespace-121 -- /opt/kafka/consumer.sh --max-messages 100 --group-instance-id instance2008782160 --group-id my-consumer-group-45336329 --topic mirrormaker2-topic-example-550186906 --bootstrap-server my-cluster-b11bd693-source-kafka-bootstrap.namespace-121.svc:9092
2022-04-03 02:40:37 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-03 02:40:37 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-03 02:40:37 [main] [32mINFO [m [MirrorMaker2IsolatedST:214] Now setting topic to my-cluster-b11bd693-source.mirrormaker2-topic-example-550186906 and cluster to my-cluster-b11bd693-target - the messages should be mirrored
2022-04-03 02:40:37 [main] [32mINFO [m [MirrorMaker2IsolatedST:222] Consumer in target cluster and topic should receive 100 messages
2022-04-03 02:40:37 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@180f4923, messages=[], arguments=[--max-messages, 100, --group-instance-id, instance1238401846, --group-id, my-consumer-group-1552110551, --topic, my-cluster-b11bd693-source.mirrormaker2-topic-example-550186906, --bootstrap-server, my-cluster-b11bd693-target-kafka-bootstrap.namespace-121.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-b11bd693-kafka-clients-6897ddcd8c-h9mvf', podNamespace='namespace-121', bootstrapServer='my-cluster-b11bd693-target-kafka-bootstrap.namespace-121.svc:9092', topicName='my-cluster-b11bd693-source.mirrormaker2-topic-example-550186906', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1552110551', consumerInstanceId='instance1238401846', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7d1b8349}
2022-04-03 02:40:37 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-b11bd693-target-kafka-bootstrap.namespace-121.svc:9092#my-cluster-b11bd693-source.mirrormaker2-topic-example-550186906 from pod my-cluster-b11bd693-kafka-clients-6897ddcd8c-h9mvf
2022-04-03 02:40:37 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b11bd693-kafka-clients-6897ddcd8c-h9mvf -n namespace-121 -- /opt/kafka/consumer.sh --max-messages 100 --group-instance-id instance1238401846 --group-id my-consumer-group-1552110551 --topic my-cluster-b11bd693-source.mirrormaker2-topic-example-550186906 --bootstrap-server my-cluster-b11bd693-target-kafka-bootstrap.namespace-121.svc:9092
2022-04-03 02:40:42 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-03 02:40:42 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-03 02:40:42 [main] [32mINFO [m [MirrorMaker2IsolatedST:227] Changing topic to my-cluster-b11bd693-source.availability-topic-source-my-topic-1802241396-711765821
2022-04-03 02:40:42 [main] [32mINFO [m [MirrorMaker2IsolatedST:233] Check if mm2 mirror automatically created topic
2022-04-03 02:40:42 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@65eac7ea, messages=[], arguments=[--max-messages, 100, --group-instance-id, instance670493142, --group-id, my-consumer-group-250439913, --topic, my-cluster-b11bd693-source.availability-topic-source-my-topic-1802241396-711765821, --bootstrap-server, my-cluster-b11bd693-target-kafka-bootstrap.namespace-121.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-b11bd693-kafka-clients-6897ddcd8c-h9mvf', podNamespace='namespace-121', bootstrapServer='my-cluster-b11bd693-target-kafka-bootstrap.namespace-121.svc:9092', topicName='my-cluster-b11bd693-source.availability-topic-source-my-topic-1802241396-711765821', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-250439913', consumerInstanceId='instance670493142', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@362d1267}
2022-04-03 02:40:42 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-b11bd693-target-kafka-bootstrap.namespace-121.svc:9092#my-cluster-b11bd693-source.availability-topic-source-my-topic-1802241396-711765821 from pod my-cluster-b11bd693-kafka-clients-6897ddcd8c-h9mvf
2022-04-03 02:40:42 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b11bd693-kafka-clients-6897ddcd8c-h9mvf -n namespace-121 -- /opt/kafka/consumer.sh --max-messages 100 --group-instance-id instance670493142 --group-id my-consumer-group-250439913 --topic my-cluster-b11bd693-source.availability-topic-source-my-topic-1802241396-711765821 --bootstrap-server my-cluster-b11bd693-target-kafka-bootstrap.namespace-121.svc:9092
2022-04-03 02:40:48 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-03 02:40:48 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-03 02:40:48 [main] [32mINFO [m [MirrorMaker2IsolatedST:236] Mirrored successful
2022-04-03 02:40:48 [main] [32mINFO [m [KafkaTopicUtils:124] Waiting for KafkaTopic change my-cluster-b11bd693-source.mirrormaker2-topic-example-550186906
2022-04-03 02:41:28 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 02:41:28 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMirrorMaker2
2022-04-03 02:41:28 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic mirrormaker2-topic-example-550186906 in namespace namespace-121
2022-04-03 02:41:28 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-b11bd693-source in namespace namespace-121
2022-04-03 02:41:28 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-b11bd693-target in namespace namespace-121
2022-04-03 02:41:28 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-b11bd693-kafka-clients in namespace namespace-121
2022-04-03 02:41:28 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-b11bd693 in namespace namespace-121
2022-04-03 02:42:18 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 02:42:18 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-121 for test case:testMirrorMaker2
2022-04-03 02:42:24 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testMirrorMaker2-FINISHED
2022-04-03 02:42:24 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 02:42:24 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 02:42:24 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testKafkaMirrorMaker2ReflectsConnectorsState-STARTED
2022-04-03 02:42:24 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 02:42:24 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-122 for test case:testKafkaMirrorMaker2ReflectsConnectorsState
2022-04-03 02:42:24 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-122
2022-04-03 02:42:24 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-122
2022-04-03 02:42:24 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-122
2022-04-03 02:42:24 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-0c33d406-source in namespace namespace-122
2022-04-03 02:42:24 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-122
2022-04-03 02:42:24 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-0c33d406-target in namespace namespace-122
2022-04-03 02:42:24 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-122
2022-04-03 02:42:24 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-0c33d406-source will have desired state: Ready
2022-04-03 02:43:40 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-0c33d406-source is in desired state: Ready
2022-04-03 02:43:40 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-0c33d406-target will have desired state: Ready
2022-04-03 02:43:40 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-0c33d406-target is in desired state: Ready
2022-04-03 02:43:40 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-0c33d406 in namespace namespace-122
2022-04-03 02:43:40 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-122
2022-04-03 02:43:40 [main] [32mINFO [m [ResourceManager:481] Wait for KafkaMirrorMaker2: my-cluster-0c33d406 will contain desired status message: One or more connectors are in FAILED state
2022-04-03 02:44:57 [main] [32mINFO [m [ResourceManager:492] KafkaMirrorMaker2: my-cluster-0c33d406 contains desired message in status: One or more connectors are in FAILED state
2022-04-03 02:44:57 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-0c33d406 will have desired state: Ready
2022-04-03 02:44:58 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-0c33d406 is in desired state: Ready
2022-04-03 02:44:58 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 02:44:58 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaMirrorMaker2ReflectsConnectorsState
2022-04-03 02:44:58 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-0c33d406-target in namespace namespace-122
2022-04-03 02:44:58 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-0c33d406-source in namespace namespace-122
2022-04-03 02:44:58 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-0c33d406 in namespace namespace-122
2022-04-03 02:45:18 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 02:45:18 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-122 for test case:testKafkaMirrorMaker2ReflectsConnectorsState
2022-04-03 02:45:24 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testKafkaMirrorMaker2ReflectsConnectorsState-FINISHED
2022-04-03 02:45:24 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 02:45:24 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 02:45:24 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testKMM2RollAfterSecretsCertsUpdateTLS-STARTED
2022-04-03 02:45:24 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 02:45:24 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-123 for test case:testKMM2RollAfterSecretsCertsUpdateTLS
2022-04-03 02:45:24 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-123
2022-04-03 02:45:24 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-123
2022-04-03 02:45:24 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-123
2022-04-03 02:45:24 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-68341c87-source in namespace namespace-123
2022-04-03 02:45:24 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-123
2022-04-03 02:45:24 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-68341c87-source will have desired state: Ready
2022-04-03 02:46:40 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-68341c87-source is in desired state: Ready
2022-04-03 02:46:40 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-68341c87-target in namespace namespace-123
2022-04-03 02:46:40 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-123
2022-04-03 02:46:40 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-68341c87-target will have desired state: Ready
2022-04-03 02:47:49 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-68341c87-target is in desired state: Ready
2022-04-03 02:47:49 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic mirrormaker2-topic-example-a-1770134866 in namespace namespace-123
2022-04-03 02:47:49 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-123
2022-04-03 02:47:49 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: mirrormaker2-topic-example-a-1770134866 will have desired state: Ready
2022-04-03 02:47:50 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: mirrormaker2-topic-example-a-1770134866 is in desired state: Ready
2022-04-03 02:47:50 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic mirrormaker2-topic-example-b-922858390 in namespace namespace-123
2022-04-03 02:47:50 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-123
2022-04-03 02:47:50 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: mirrormaker2-topic-example-b-922858390 will have desired state: Ready
2022-04-03 02:47:51 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: mirrormaker2-topic-example-b-922858390 is in desired state: Ready
2022-04-03 02:47:51 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-68341c87-my-user-source in namespace namespace-123
2022-04-03 02:47:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-123
2022-04-03 02:47:52 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-68341c87-my-user-source will have desired state: Ready
2022-04-03 02:47:53 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-68341c87-my-user-source is in desired state: Ready
2022-04-03 02:47:53 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-68341c87-my-user-target in namespace namespace-123
2022-04-03 02:47:53 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-123
2022-04-03 02:47:53 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-68341c87-my-user-target will have desired state: Ready
2022-04-03 02:47:54 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-68341c87-my-user-target is in desired state: Ready
2022-04-03 02:47:54 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-22c34230-kafka-clients in namespace namespace-123
2022-04-03 02:47:54 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-123
2022-04-03 02:48:04 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-998415096-794653296-test-1 in namespace namespace-123
2022-04-03 02:48:04 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-123
2022-04-03 02:48:04 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-998415096-794653296-test-1 will have desired state: Ready
2022-04-03 02:48:05 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-998415096-794653296-test-1 is in desired state: Ready
2022-04-03 02:48:05 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-998415096-794653296-test-2 in namespace namespace-123
2022-04-03 02:48:05 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-123
2022-04-03 02:48:05 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-998415096-794653296-test-2 will have desired state: Ready
2022-04-03 02:48:06 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-998415096-794653296-test-2 is in desired state: Ready
2022-04-03 02:48:06 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-03 02:48:06 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@29cbcfcd, messages=[], arguments=[USER=my_cluster_68341c87_my_user_target, --max-messages, 200, --topic, my-topic-998415096-794653296-test-2, --bootstrap-server, my-cluster-68341c87-target-kafka-bootstrap.namespace-123.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-22c34230-kafka-clients-58b8c84cb5-76l87', podNamespace='namespace-123', bootstrapServer='my-cluster-68341c87-target-kafka-bootstrap.namespace-123.svc:9093', topicName='my-topic-998415096-794653296-test-2', maxMessages=200, kafkaUsername='my-cluster-68341c87-my-user-target', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5ba2ce41}
2022-04-03 02:48:06 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-68341c87-target-kafka-bootstrap.namespace-123.svc:9093:my-topic-998415096-794653296-test-2 from pod my-cluster-22c34230-kafka-clients-58b8c84cb5-76l87
2022-04-03 02:48:06 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-22c34230-kafka-clients-58b8c84cb5-76l87 -n namespace-123 -- /opt/kafka/producer.sh USER=my_cluster_68341c87_my_user_target --max-messages 200 --topic my-topic-998415096-794653296-test-2 --bootstrap-server my-cluster-68341c87-target-kafka-bootstrap.namespace-123.svc:9093
2022-04-03 02:48:09 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-03 02:48:09 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-03 02:48:09 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@308465cc, messages=[], arguments=[USER=my_cluster_68341c87_my_user_target, --max-messages, 200, --group-instance-id, instance121052838, --group-id, my-consumer-group-1193241010, --topic, my-topic-998415096-794653296-test-2, --bootstrap-server, my-cluster-68341c87-target-kafka-bootstrap.namespace-123.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-22c34230-kafka-clients-58b8c84cb5-76l87', podNamespace='namespace-123', bootstrapServer='my-cluster-68341c87-target-kafka-bootstrap.namespace-123.svc:9093', topicName='my-topic-998415096-794653296-test-2', maxMessages=200, kafkaUsername='my-cluster-68341c87-my-user-target', consumerGroupName='my-consumer-group-1193241010', consumerInstanceId='instance121052838', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7d196ce8}
2022-04-03 02:48:09 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-68341c87-target-kafka-bootstrap.namespace-123.svc:9093:my-topic-998415096-794653296-test-2 from pod my-cluster-22c34230-kafka-clients-58b8c84cb5-76l87
2022-04-03 02:48:09 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-22c34230-kafka-clients-58b8c84cb5-76l87 -n namespace-123 -- /opt/kafka/consumer.sh USER=my_cluster_68341c87_my_user_target --max-messages 200 --group-instance-id instance121052838 --group-id my-consumer-group-1193241010 --topic my-topic-998415096-794653296-test-2 --bootstrap-server my-cluster-68341c87-target-kafka-bootstrap.namespace-123.svc:9093
2022-04-03 02:48:16 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-03 02:48:16 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-03 02:48:16 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-68341c87 in namespace namespace-123
2022-04-03 02:48:16 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-123
2022-04-03 02:48:16 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-68341c87 will have desired state: Ready
2022-04-03 02:49:28 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-68341c87 is in desired state: Ready
2022-04-03 02:49:29 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@33e6ac17, messages=[], arguments=[USER=my_cluster_68341c87_my_user_source, --max-messages, 200, --topic, mirrormaker2-topic-example-a-1770134866, --bootstrap-server, my-cluster-68341c87-source-kafka-bootstrap.namespace-123.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-22c34230-kafka-clients-58b8c84cb5-76l87', podNamespace='namespace-123', bootstrapServer='my-cluster-68341c87-source-kafka-bootstrap.namespace-123.svc:9093', topicName='mirrormaker2-topic-example-a-1770134866', maxMessages=200, kafkaUsername='my-cluster-68341c87-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@37d3b328}
2022-04-03 02:49:29 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-68341c87-source-kafka-bootstrap.namespace-123.svc:9093:mirrormaker2-topic-example-a-1770134866 from pod my-cluster-22c34230-kafka-clients-58b8c84cb5-76l87
2022-04-03 02:49:29 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-22c34230-kafka-clients-58b8c84cb5-76l87 -n namespace-123 -- /opt/kafka/producer.sh USER=my_cluster_68341c87_my_user_source --max-messages 200 --topic mirrormaker2-topic-example-a-1770134866 --bootstrap-server my-cluster-68341c87-source-kafka-bootstrap.namespace-123.svc:9093
2022-04-03 02:49:32 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-03 02:49:32 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-03 02:49:32 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@f8e71c0, messages=[], arguments=[USER=my_cluster_68341c87_my_user_source, --max-messages, 200, --group-instance-id, instance1969159936, --group-id, my-consumer-group-1193241010, --topic, mirrormaker2-topic-example-a-1770134866, --bootstrap-server, my-cluster-68341c87-source-kafka-bootstrap.namespace-123.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-22c34230-kafka-clients-58b8c84cb5-76l87', podNamespace='namespace-123', bootstrapServer='my-cluster-68341c87-source-kafka-bootstrap.namespace-123.svc:9093', topicName='mirrormaker2-topic-example-a-1770134866', maxMessages=200, kafkaUsername='my-cluster-68341c87-my-user-source', consumerGroupName='my-consumer-group-1193241010', consumerInstanceId='instance1969159936', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@25eecca6}
2022-04-03 02:49:32 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-68341c87-source-kafka-bootstrap.namespace-123.svc:9093:mirrormaker2-topic-example-a-1770134866 from pod my-cluster-22c34230-kafka-clients-58b8c84cb5-76l87
2022-04-03 02:49:32 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-22c34230-kafka-clients-58b8c84cb5-76l87 -n namespace-123 -- /opt/kafka/consumer.sh USER=my_cluster_68341c87_my_user_source --max-messages 200 --group-instance-id instance1969159936 --group-id my-consumer-group-1193241010 --topic mirrormaker2-topic-example-a-1770134866 --bootstrap-server my-cluster-68341c87-source-kafka-bootstrap.namespace-123.svc:9093
2022-04-03 02:49:39 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-03 02:49:39 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-03 02:49:39 [main] [32mINFO [m [MirrorMaker2IsolatedST:1551] Consumer in target cluster and topic should receive 200 messages
2022-04-03 02:49:39 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@6eb676c4, messages=[], arguments=[USER=my_cluster_68341c87_my_user_target, --max-messages, 200, --group-instance-id, instance1162549164, --group-id, my-consumer-group-1193241010, --topic, my-cluster-68341c87-source.mirrormaker2-topic-example-a-1770134866, --bootstrap-server, my-cluster-68341c87-target-kafka-bootstrap.namespace-123.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-22c34230-kafka-clients-58b8c84cb5-76l87', podNamespace='namespace-123', bootstrapServer='my-cluster-68341c87-target-kafka-bootstrap.namespace-123.svc:9093', topicName='my-cluster-68341c87-source.mirrormaker2-topic-example-a-1770134866', maxMessages=200, kafkaUsername='my-cluster-68341c87-my-user-target', consumerGroupName='my-consumer-group-1193241010', consumerInstanceId='instance1162549164', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@98ee232}
2022-04-03 02:49:39 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-68341c87-target-kafka-bootstrap.namespace-123.svc:9093:my-cluster-68341c87-source.mirrormaker2-topic-example-a-1770134866 from pod my-cluster-22c34230-kafka-clients-58b8c84cb5-76l87
2022-04-03 02:49:39 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-22c34230-kafka-clients-58b8c84cb5-76l87 -n namespace-123 -- /opt/kafka/consumer.sh USER=my_cluster_68341c87_my_user_target --max-messages 200 --group-instance-id instance1162549164 --group-id my-consumer-group-1193241010 --topic my-cluster-68341c87-source.mirrormaker2-topic-example-a-1770134866 --bootstrap-server my-cluster-68341c87-target-kafka-bootstrap.namespace-123.svc:9093
2022-04-03 02:49:46 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-03 02:49:46 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-03 02:49:46 [main] [32mINFO [m [MirrorMaker2IsolatedST:1553] Messages successfully mirrored
2022-04-03 02:49:46 [main] [32mINFO [m [MirrorMaker2IsolatedST:1567] Renew Clients CA secret for Source cluster via annotation
2022-04-03 02:49:46 [main] [32mINFO [m [SecretUtils:178] Annotating Secret:my-cluster-68341c87-source-clients-ca-cert with annotation strimzi.io/force-renew=true
2022-04-03 02:49:46 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-68341c87-source-kafka rolling update
2022-04-03 02:51:21 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-68341c87-source-kafka has been successfully rolled
2022-04-03 02:51:21 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-68341c87-source-kafka to be ready
2022-04-03 02:51:50 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-68341c87-mirrormaker2 rolling update
2022-04-03 02:51:50 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-68341c87-mirrormaker2 will be ready
2022-04-03 02:51:50 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-68341c87-mirrormaker2 is ready
2022-04-03 02:52:00 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-68341c87-mirrormaker2 rolling update finished
2022-04-03 02:52:00 [main] [32mINFO [m [MirrorMaker2IsolatedST:1573] Renew Clients CA secret for Target cluster via annotation
2022-04-03 02:52:00 [main] [32mINFO [m [SecretUtils:178] Annotating Secret:my-cluster-68341c87-target-clients-ca-cert with annotation strimzi.io/force-renew=true
2022-04-03 02:52:01 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-68341c87-target-kafka rolling update
2022-04-03 02:53:26 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-68341c87-target-kafka has been successfully rolled
2022-04-03 02:53:26 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-68341c87-target-kafka to be ready
2022-04-03 02:53:55 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-68341c87-mirrormaker2 rolling update
2022-04-03 02:55:10 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-68341c87-mirrormaker2 will be ready
2022-04-03 02:55:10 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-68341c87-mirrormaker2 is ready
2022-04-03 02:55:20 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-68341c87-mirrormaker2 rolling update finished
2022-04-03 02:55:20 [main] [32mINFO [m [MirrorMaker2IsolatedST:1579] Send and receive messages after clients certs were removed
2022-04-03 02:55:20 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@3e7ab84f, messages=[], arguments=[USER=my_cluster_68341c87_my_user_source, --max-messages, 200, --topic, mirrormaker2-topic-example-a-1770134866, --bootstrap-server, my-cluster-68341c87-source-kafka-bootstrap.namespace-123.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-22c34230-kafka-clients-58b8c84cb5-76l87', podNamespace='namespace-123', bootstrapServer='my-cluster-68341c87-source-kafka-bootstrap.namespace-123.svc:9093', topicName='mirrormaker2-topic-example-a-1770134866', maxMessages=200, kafkaUsername='my-cluster-68341c87-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@41f97b38}
2022-04-03 02:55:20 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-68341c87-source-kafka-bootstrap.namespace-123.svc:9093:mirrormaker2-topic-example-a-1770134866 from pod my-cluster-22c34230-kafka-clients-58b8c84cb5-76l87
2022-04-03 02:55:20 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-22c34230-kafka-clients-58b8c84cb5-76l87 -n namespace-123 -- /opt/kafka/producer.sh USER=my_cluster_68341c87_my_user_source --max-messages 200 --topic mirrormaker2-topic-example-a-1770134866 --bootstrap-server my-cluster-68341c87-source-kafka-bootstrap.namespace-123.svc:9093
2022-04-03 02:55:24 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-03 02:55:24 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-03 02:55:24 [main] [32mINFO [m [MirrorMaker2IsolatedST:1595] Consumer in target cluster and topic should receive 200 messages
2022-04-03 02:55:24 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@69ca9469, messages=[], arguments=[USER=my_cluster_68341c87_my_user_target, --max-messages, 200, --group-instance-id, instance1504177344, --group-id, my-consumer-group-777314841, --topic, my-cluster-68341c87-source.mirrormaker2-topic-example-a-1770134866, --bootstrap-server, my-cluster-68341c87-target-kafka-bootstrap.namespace-123.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-22c34230-kafka-clients-58b8c84cb5-76l87', podNamespace='namespace-123', bootstrapServer='my-cluster-68341c87-target-kafka-bootstrap.namespace-123.svc:9093', topicName='my-cluster-68341c87-source.mirrormaker2-topic-example-a-1770134866', maxMessages=200, kafkaUsername='my-cluster-68341c87-my-user-target', consumerGroupName='my-consumer-group-777314841', consumerInstanceId='instance1504177344', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@63600386}
2022-04-03 02:55:24 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-68341c87-target-kafka-bootstrap.namespace-123.svc:9093:my-cluster-68341c87-source.mirrormaker2-topic-example-a-1770134866 from pod my-cluster-22c34230-kafka-clients-58b8c84cb5-76l87
2022-04-03 02:55:24 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-22c34230-kafka-clients-58b8c84cb5-76l87 -n namespace-123 -- /opt/kafka/consumer.sh USER=my_cluster_68341c87_my_user_target --max-messages 200 --group-instance-id instance1504177344 --group-id my-consumer-group-777314841 --topic my-cluster-68341c87-source.mirrormaker2-topic-example-a-1770134866 --bootstrap-server my-cluster-68341c87-target-kafka-bootstrap.namespace-123.svc:9093
2022-04-03 02:55:31 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-03 02:55:31 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-03 02:55:31 [main] [32mINFO [m [MirrorMaker2IsolatedST:1597] Messages successfully mirrored
2022-04-03 02:55:31 [main] [32mINFO [m [MirrorMaker2IsolatedST:1599] Renew Cluster CA secret for Source clusters via annotation
2022-04-03 02:55:31 [main] [32mINFO [m [SecretUtils:178] Annotating Secret:my-cluster-68341c87-source-cluster-ca-cert with annotation strimzi.io/force-renew=true
2022-04-03 02:55:31 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-68341c87-source-zookeeper rolling update
2022-04-03 02:57:11 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-68341c87-source-zookeeper has been successfully rolled
2022-04-03 02:57:11 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-68341c87-source-zookeeper to be ready
2022-04-03 02:57:38 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-68341c87-source-kafka rolling update
2022-04-03 02:58:53 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-68341c87-source-kafka has been successfully rolled
2022-04-03 02:58:53 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-68341c87-source-kafka to be ready
2022-04-03 02:59:22 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-68341c87-source-entity-operator rolling update
2022-04-03 02:59:22 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-68341c87-source-entity-operator will be ready
2022-04-03 03:04:48 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-68341c87-source-entity-operator is ready
2022-04-03 03:04:58 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-68341c87-source-entity-operator rolling update finished
2022-04-03 03:04:58 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-68341c87-mirrormaker2 rolling update
2022-04-03 03:04:58 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-68341c87-mirrormaker2 will be ready
2022-04-03 03:04:58 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-68341c87-mirrormaker2 is ready
2022-04-03 03:05:08 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-68341c87-mirrormaker2 rolling update finished
2022-04-03 03:05:08 [main] [32mINFO [m [MirrorMaker2IsolatedST:1607] Renew Cluster CA secret for Target clusters via annotation
2022-04-03 03:05:08 [main] [32mINFO [m [SecretUtils:178] Annotating Secret:my-cluster-68341c87-target-cluster-ca-cert with annotation strimzi.io/force-renew=true
2022-04-03 03:05:09 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-68341c87-target-zookeeper rolling update
2022-04-03 03:06:44 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-68341c87-target-zookeeper has been successfully rolled
2022-04-03 03:06:44 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-68341c87-target-zookeeper to be ready
2022-04-03 03:07:09 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-68341c87-target-kafka rolling update
2022-04-03 03:08:14 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-68341c87-target-kafka has been successfully rolled
2022-04-03 03:08:14 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-68341c87-target-kafka to be ready
2022-04-03 03:08:45 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-68341c87-target-entity-operator rolling update
2022-04-03 03:08:45 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-68341c87-target-entity-operator will be ready
2022-04-03 03:12:30 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-68341c87-target-entity-operator is ready
2022-04-03 03:12:40 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-68341c87-target-entity-operator rolling update finished
2022-04-03 03:12:40 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-68341c87-mirrormaker2 rolling update
2022-04-03 03:12:40 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-68341c87-mirrormaker2 will be ready
2022-04-03 03:12:40 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-68341c87-mirrormaker2 is ready
2022-04-03 03:12:50 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-68341c87-mirrormaker2 rolling update finished
2022-04-03 03:12:50 [main] [32mINFO [m [MirrorMaker2IsolatedST:1615] Send and receive messages after clients certs were removed
2022-04-03 03:12:50 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@5b7bb99d, messages=[], arguments=[USER=my_cluster_68341c87_my_user_source, --max-messages, 200, --topic, mirrormaker2-topic-example-b-922858390, --bootstrap-server, my-cluster-68341c87-source-kafka-bootstrap.namespace-123.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-22c34230-kafka-clients-58b8c84cb5-76l87', podNamespace='namespace-123', bootstrapServer='my-cluster-68341c87-source-kafka-bootstrap.namespace-123.svc:9093', topicName='mirrormaker2-topic-example-b-922858390', maxMessages=200, kafkaUsername='my-cluster-68341c87-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@48c99cfe}
2022-04-03 03:12:50 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-68341c87-source-kafka-bootstrap.namespace-123.svc:9093:mirrormaker2-topic-example-b-922858390 from pod my-cluster-22c34230-kafka-clients-58b8c84cb5-76l87
2022-04-03 03:12:50 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-22c34230-kafka-clients-58b8c84cb5-76l87 -n namespace-123 -- /opt/kafka/producer.sh USER=my_cluster_68341c87_my_user_source --max-messages 200 --topic mirrormaker2-topic-example-b-922858390 --bootstrap-server my-cluster-68341c87-source-kafka-bootstrap.namespace-123.svc:9093
2022-04-03 03:12:54 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-03 03:12:54 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-03 03:12:54 [main] [32mINFO [m [MirrorMaker2IsolatedST:1631] Consumer in target cluster and topic should receive 200 messages
2022-04-03 03:12:54 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@6270b758, messages=[], arguments=[USER=my_cluster_68341c87_my_user_target, --max-messages, 200, --group-instance-id, instance1516971551, --group-id, my-consumer-group-1254196039, --topic, my-cluster-68341c87-source.mirrormaker2-topic-example-b-922858390, --bootstrap-server, my-cluster-68341c87-target-kafka-bootstrap.namespace-123.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-22c34230-kafka-clients-58b8c84cb5-76l87', podNamespace='namespace-123', bootstrapServer='my-cluster-68341c87-target-kafka-bootstrap.namespace-123.svc:9093', topicName='my-cluster-68341c87-source.mirrormaker2-topic-example-b-922858390', maxMessages=200, kafkaUsername='my-cluster-68341c87-my-user-target', consumerGroupName='my-consumer-group-1254196039', consumerInstanceId='instance1516971551', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@66dae911}
2022-04-03 03:12:54 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-68341c87-target-kafka-bootstrap.namespace-123.svc:9093:my-cluster-68341c87-source.mirrormaker2-topic-example-b-922858390 from pod my-cluster-22c34230-kafka-clients-58b8c84cb5-76l87
2022-04-03 03:12:54 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-22c34230-kafka-clients-58b8c84cb5-76l87 -n namespace-123 -- /opt/kafka/consumer.sh USER=my_cluster_68341c87_my_user_target --max-messages 200 --group-instance-id instance1516971551 --group-id my-consumer-group-1254196039 --topic my-cluster-68341c87-source.mirrormaker2-topic-example-b-922858390 --bootstrap-server my-cluster-68341c87-target-kafka-bootstrap.namespace-123.svc:9093
2022-04-03 03:13:01 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-03 03:13:01 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-03 03:13:01 [main] [32mINFO [m [MirrorMaker2IsolatedST:1633] Messages successfully mirrored
2022-04-03 03:13:01 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 03:13:01 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKMM2RollAfterSecretsCertsUpdateTLS
2022-04-03 03:13:01 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-998415096-794653296-test-2 in namespace namespace-123
2022-04-03 03:13:01 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-22c34230-kafka-clients in namespace namespace-123
2022-04-03 03:13:01 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-68341c87-my-user-target in namespace namespace-123
2022-04-03 03:13:01 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-68341c87-target in namespace namespace-123
2022-04-03 03:13:01 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-998415096-794653296-test-1 in namespace namespace-123
2022-04-03 03:13:01 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic mirrormaker2-topic-example-a-1770134866 in namespace namespace-123
2022-04-03 03:13:01 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-68341c87-my-user-source in namespace namespace-123
2022-04-03 03:13:01 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic mirrormaker2-topic-example-b-922858390 in namespace namespace-123
2022-04-03 03:13:11 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-68341c87-source in namespace namespace-123
2022-04-03 03:13:11 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-68341c87 in namespace namespace-123
2022-04-03 03:13:51 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 03:13:51 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-123 for test case:testKMM2RollAfterSecretsCertsUpdateTLS
2022-04-03 03:13:57 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testKMM2RollAfterSecretsCertsUpdateTLS-FINISHED
2022-04-03 03:13:57 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 03:13:57 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 03:13:57 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testStrimziIdentityReplicationPolicy-STARTED
2022-04-03 03:13:57 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 03:13:57 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-124 for test case:testStrimziIdentityReplicationPolicy
2022-04-03 03:13:57 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-124
2022-04-03 03:13:57 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-124
2022-04-03 03:13:57 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-124
2022-04-03 03:13:57 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-4cd320e1-source in namespace namespace-124
2022-04-03 03:13:57 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-124
2022-04-03 03:13:57 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-4cd320e1-source will have desired state: Ready
2022-04-03 03:15:00 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-4cd320e1-source is in desired state: Ready
2022-04-03 03:15:01 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-4cd320e1-target in namespace namespace-124
2022-04-03 03:15:01 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-124
2022-04-03 03:15:01 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-4cd320e1-target will have desired state: Ready
2022-04-03 03:16:21 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-4cd320e1-target is in desired state: Ready
2022-04-03 03:16:21 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-cluster-4cd320e1 in namespace namespace-124
2022-04-03 03:16:21 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-124
2022-04-03 03:16:21 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-cluster-4cd320e1 will have desired state: Ready
2022-04-03 03:16:22 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-cluster-4cd320e1 is in desired state: Ready
2022-04-03 03:16:22 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-4cd320e1-kafka-clients in namespace namespace-124
2022-04-03 03:16:22 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-124
2022-04-03 03:16:32 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-4cd320e1 in namespace namespace-124
2022-04-03 03:16:32 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-124
2022-04-03 03:16:32 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-4cd320e1 will have desired state: Ready
2022-04-03 03:17:38 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-4cd320e1 is in desired state: Ready
2022-04-03 03:17:38 [main] [32mINFO [m [MirrorMaker2IsolatedST:902] Sending and receiving messages via my-cluster-4cd320e1-source
2022-04-03 03:17:38 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-03 03:17:38 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@43c9f117, messages=[], arguments=[--max-messages, 100, --topic, my-cluster-4cd320e1, --bootstrap-server, my-cluster-4cd320e1-source-kafka-bootstrap.namespace-124.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-4cd320e1-kafka-clients-5785d5647d-twbb9', podNamespace='namespace-124', bootstrapServer='my-cluster-4cd320e1-source-kafka-bootstrap.namespace-124.svc:9092', topicName='my-cluster-4cd320e1', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@4e252580}
2022-04-03 03:17:38 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-4cd320e1-source-kafka-bootstrap.namespace-124.svc:9092:my-cluster-4cd320e1 from pod my-cluster-4cd320e1-kafka-clients-5785d5647d-twbb9
2022-04-03 03:17:38 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-4cd320e1-kafka-clients-5785d5647d-twbb9 -n namespace-124 -- /opt/kafka/producer.sh --max-messages 100 --topic my-cluster-4cd320e1 --bootstrap-server my-cluster-4cd320e1-source-kafka-bootstrap.namespace-124.svc:9092
2022-04-03 03:17:41 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-03 03:17:41 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-03 03:17:41 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@5bc22c1e, messages=[], arguments=[--max-messages, 100, --group-instance-id, instance1650903290, --group-id, my-consumer-group-765205638, --topic, my-cluster-4cd320e1, --bootstrap-server, my-cluster-4cd320e1-source-kafka-bootstrap.namespace-124.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-4cd320e1-kafka-clients-5785d5647d-twbb9', podNamespace='namespace-124', bootstrapServer='my-cluster-4cd320e1-source-kafka-bootstrap.namespace-124.svc:9092', topicName='my-cluster-4cd320e1', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-765205638', consumerInstanceId='instance1650903290', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3c2c173e}
2022-04-03 03:17:41 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-4cd320e1-source-kafka-bootstrap.namespace-124.svc:9092#my-cluster-4cd320e1 from pod my-cluster-4cd320e1-kafka-clients-5785d5647d-twbb9
2022-04-03 03:17:41 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-4cd320e1-kafka-clients-5785d5647d-twbb9 -n namespace-124 -- /opt/kafka/consumer.sh --max-messages 100 --group-instance-id instance1650903290 --group-id my-consumer-group-765205638 --topic my-cluster-4cd320e1 --bootstrap-server my-cluster-4cd320e1-source-kafka-bootstrap.namespace-124.svc:9092
2022-04-03 03:17:46 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-03 03:17:46 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-03 03:17:46 [main] [32mINFO [m [MirrorMaker2IsolatedST:917] Changing to my-cluster-4cd320e1-target and will try to receive messages
2022-04-03 03:17:46 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@553823d1, messages=[], arguments=[--max-messages, 100, --group-instance-id, instance214308993, --group-id, my-consumer-group-765205638, --topic, my-cluster-4cd320e1, --bootstrap-server, my-cluster-4cd320e1-target-kafka-bootstrap.namespace-124.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-4cd320e1-kafka-clients-5785d5647d-twbb9', podNamespace='namespace-124', bootstrapServer='my-cluster-4cd320e1-target-kafka-bootstrap.namespace-124.svc:9092', topicName='my-cluster-4cd320e1', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-765205638', consumerInstanceId='instance214308993', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@570f2f38}
2022-04-03 03:17:46 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-4cd320e1-target-kafka-bootstrap.namespace-124.svc:9092#my-cluster-4cd320e1 from pod my-cluster-4cd320e1-kafka-clients-5785d5647d-twbb9
2022-04-03 03:17:46 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-4cd320e1-kafka-clients-5785d5647d-twbb9 -n namespace-124 -- /opt/kafka/consumer.sh --max-messages 100 --group-instance-id instance214308993 --group-id my-consumer-group-765205638 --topic my-cluster-4cd320e1 --bootstrap-server my-cluster-4cd320e1-target-kafka-bootstrap.namespace-124.svc:9092
2022-04-03 03:17:52 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-03 03:17:52 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-03 03:17:52 [main] [32mINFO [m [MirrorMaker2IsolatedST:925] Checking if the mirrored topic name is same as the original one
2022-04-03 03:17:55 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-124 exec my-cluster-4cd320e1-target-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-03 03:17:55 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-03 03:17:57 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-124 exec my-cluster-4cd320e1-target-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic my-cluster-4cd320e1
2022-04-03 03:17:57 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-03 03:17:57 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 03:17:57 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testStrimziIdentityReplicationPolicy
2022-04-03 03:17:57 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-cluster-4cd320e1 in namespace namespace-124
2022-04-03 03:17:57 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-4cd320e1-kafka-clients in namespace namespace-124
2022-04-03 03:17:57 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-4cd320e1-target in namespace namespace-124
2022-04-03 03:17:57 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-4cd320e1 in namespace namespace-124
2022-04-03 03:17:57 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-4cd320e1-source in namespace namespace-124
2022-04-03 03:18:57 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 03:18:57 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-124 for test case:testStrimziIdentityReplicationPolicy
2022-04-03 03:19:03 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testStrimziIdentityReplicationPolicy-FINISHED
2022-04-03 03:19:03 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 03:19:03 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 03:19:03 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testScaleMirrorMaker2Subresource-STARTED
2022-04-03 03:19:03 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 03:19:03 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-125 for test case:testScaleMirrorMaker2Subresource
2022-04-03 03:19:03 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-125
2022-04-03 03:19:03 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-125
2022-04-03 03:19:03 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-125
2022-04-03 03:19:03 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-9cd73fbc-source in namespace namespace-125
2022-04-03 03:19:03 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-125
2022-04-03 03:19:03 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-9cd73fbc-source will have desired state: Ready
2022-04-03 03:20:17 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-9cd73fbc-source is in desired state: Ready
2022-04-03 03:20:17 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-9cd73fbc-target in namespace namespace-125
2022-04-03 03:20:17 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-125
2022-04-03 03:20:17 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-9cd73fbc-target will have desired state: Ready
2022-04-03 03:21:30 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-9cd73fbc-target is in desired state: Ready
2022-04-03 03:21:30 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-9cd73fbc in namespace namespace-125
2022-04-03 03:21:30 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-125
2022-04-03 03:21:30 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-9cd73fbc will have desired state: Ready
2022-04-03 03:22:40 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-9cd73fbc is in desired state: Ready
2022-04-03 03:22:40 [main] [32mINFO [m [MirrorMaker2IsolatedST:675] -------> Scaling KafkaMirrorMaker2 subresource <-------
2022-04-03 03:22:40 [main] [32mINFO [m [MirrorMaker2IsolatedST:676] Scaling subresource replicas to 4
2022-04-03 03:22:40 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-9cd73fbc-mirrormaker2 will be ready
2022-04-03 03:22:40 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-9cd73fbc-mirrormaker2 is ready
2022-04-03 03:22:40 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 4 Pod(s) of Deployment my-cluster-9cd73fbc-mirrormaker2 to be ready
2022-04-03 03:23:55 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-9cd73fbc-mirrormaker2 is ready
2022-04-03 03:23:55 [main] [32mINFO [m [MirrorMaker2IsolatedST:680] Check if replicas is set to 4, naming prefix should be same and observed generation higher
2022-04-03 03:23:55 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 03:23:55 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testScaleMirrorMaker2Subresource
2022-04-03 03:23:55 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-9cd73fbc-target in namespace namespace-125
2022-04-03 03:23:55 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-9cd73fbc in namespace namespace-125
2022-04-03 03:23:55 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-9cd73fbc-source in namespace namespace-125
2022-04-03 03:24:15 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 03:24:15 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-125 for test case:testScaleMirrorMaker2Subresource
2022-04-03 03:24:26 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testScaleMirrorMaker2Subresource-FINISHED
2022-04-03 03:24:26 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 03:24:26 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 03:24:26 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testIdentityReplicationPolicy-STARTED
2022-04-03 03:24:26 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 03:24:26 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-126 for test case:testIdentityReplicationPolicy
2022-04-03 03:24:26 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-126
2022-04-03 03:24:26 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-126
2022-04-03 03:24:26 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-126
2022-04-03 03:24:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-28a7b11e-source in namespace namespace-126
2022-04-03 03:24:26 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-126
2022-04-03 03:24:26 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-28a7b11e-source will have desired state: Ready
2022-04-03 03:25:29 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-28a7b11e-source is in desired state: Ready
2022-04-03 03:25:29 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-28a7b11e-target in namespace namespace-126
2022-04-03 03:25:29 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-126
2022-04-03 03:25:29 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-28a7b11e-target will have desired state: Ready
2022-04-03 03:26:42 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-28a7b11e-target is in desired state: Ready
2022-04-03 03:26:42 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-cluster-28a7b11e in namespace namespace-126
2022-04-03 03:26:42 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-126
2022-04-03 03:26:42 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-cluster-28a7b11e will have desired state: Ready
2022-04-03 03:26:43 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-cluster-28a7b11e is in desired state: Ready
2022-04-03 03:26:43 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-28a7b11e-kafka-clients in namespace namespace-126
2022-04-03 03:26:43 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-126
2022-04-03 03:26:53 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-28a7b11e in namespace namespace-126
2022-04-03 03:26:53 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-126
2022-04-03 03:26:53 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-28a7b11e will have desired state: Ready
2022-04-03 03:27:55 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-28a7b11e is in desired state: Ready
2022-04-03 03:27:55 [main] [32mINFO [m [MirrorMaker2IsolatedST:833] Sending and receiving messages via my-cluster-28a7b11e-source
2022-04-03 03:27:55 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-03 03:27:55 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@ab7c6a3, messages=[], arguments=[--max-messages, 100, --topic, my-cluster-28a7b11e, --bootstrap-server, my-cluster-28a7b11e-source-kafka-bootstrap.namespace-126.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-28a7b11e-kafka-clients-7f747b87fd-rkxk9', podNamespace='namespace-126', bootstrapServer='my-cluster-28a7b11e-source-kafka-bootstrap.namespace-126.svc:9092', topicName='my-cluster-28a7b11e', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@21914acf}
2022-04-03 03:27:55 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-28a7b11e-source-kafka-bootstrap.namespace-126.svc:9092:my-cluster-28a7b11e from pod my-cluster-28a7b11e-kafka-clients-7f747b87fd-rkxk9
2022-04-03 03:27:55 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-28a7b11e-kafka-clients-7f747b87fd-rkxk9 -n namespace-126 -- /opt/kafka/producer.sh --max-messages 100 --topic my-cluster-28a7b11e --bootstrap-server my-cluster-28a7b11e-source-kafka-bootstrap.namespace-126.svc:9092
2022-04-03 03:27:57 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-03 03:27:57 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-03 03:27:57 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@71b13e3f, messages=[], arguments=[--max-messages, 100, --group-instance-id, instance1443106649, --group-id, my-consumer-group-182299010, --topic, my-cluster-28a7b11e, --bootstrap-server, my-cluster-28a7b11e-source-kafka-bootstrap.namespace-126.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-28a7b11e-kafka-clients-7f747b87fd-rkxk9', podNamespace='namespace-126', bootstrapServer='my-cluster-28a7b11e-source-kafka-bootstrap.namespace-126.svc:9092', topicName='my-cluster-28a7b11e', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-182299010', consumerInstanceId='instance1443106649', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5addd099}
2022-04-03 03:27:57 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-28a7b11e-source-kafka-bootstrap.namespace-126.svc:9092#my-cluster-28a7b11e from pod my-cluster-28a7b11e-kafka-clients-7f747b87fd-rkxk9
2022-04-03 03:27:57 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-28a7b11e-kafka-clients-7f747b87fd-rkxk9 -n namespace-126 -- /opt/kafka/consumer.sh --max-messages 100 --group-instance-id instance1443106649 --group-id my-consumer-group-182299010 --topic my-cluster-28a7b11e --bootstrap-server my-cluster-28a7b11e-source-kafka-bootstrap.namespace-126.svc:9092
2022-04-03 03:28:03 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-03 03:28:03 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-03 03:28:03 [main] [32mINFO [m [MirrorMaker2IsolatedST:848] Changing to my-cluster-28a7b11e-target and will try to receive messages
2022-04-03 03:28:03 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@9241395, messages=[], arguments=[--max-messages, 100, --group-instance-id, instance625699131, --group-id, my-consumer-group-182299010, --topic, my-cluster-28a7b11e, --bootstrap-server, my-cluster-28a7b11e-target-kafka-bootstrap.namespace-126.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-28a7b11e-kafka-clients-7f747b87fd-rkxk9', podNamespace='namespace-126', bootstrapServer='my-cluster-28a7b11e-target-kafka-bootstrap.namespace-126.svc:9092', topicName='my-cluster-28a7b11e', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-182299010', consumerInstanceId='instance625699131', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@45076c74}
2022-04-03 03:28:03 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-28a7b11e-target-kafka-bootstrap.namespace-126.svc:9092#my-cluster-28a7b11e from pod my-cluster-28a7b11e-kafka-clients-7f747b87fd-rkxk9
2022-04-03 03:28:03 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-28a7b11e-kafka-clients-7f747b87fd-rkxk9 -n namespace-126 -- /opt/kafka/consumer.sh --max-messages 100 --group-instance-id instance625699131 --group-id my-consumer-group-182299010 --topic my-cluster-28a7b11e --bootstrap-server my-cluster-28a7b11e-target-kafka-bootstrap.namespace-126.svc:9092
2022-04-03 03:28:09 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-03 03:28:09 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-03 03:28:09 [main] [32mINFO [m [MirrorMaker2IsolatedST:856] Checking if the mirrored topic name is same as the original one
2022-04-03 03:28:12 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-126 exec my-cluster-28a7b11e-target-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-03 03:28:12 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-03 03:28:14 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-126 exec my-cluster-28a7b11e-target-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic my-cluster-28a7b11e
2022-04-03 03:28:14 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-03 03:28:14 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 03:28:14 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testIdentityReplicationPolicy
2022-04-03 03:28:14 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-cluster-28a7b11e in namespace namespace-126
2022-04-03 03:28:14 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-28a7b11e in namespace namespace-126
2022-04-03 03:28:14 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-28a7b11e-kafka-clients in namespace namespace-126
2022-04-03 03:28:14 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-28a7b11e-source in namespace namespace-126
2022-04-03 03:28:14 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-28a7b11e-target in namespace namespace-126
2022-04-03 03:29:04 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 03:29:04 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-126 for test case:testIdentityReplicationPolicy
2022-04-03 03:29:10 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testIdentityReplicationPolicy-FINISHED
2022-04-03 03:29:10 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 03:29:10 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 03:29:10 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testKMM2RollAfterSecretsCertsUpdateScramsha-STARTED
2022-04-03 03:29:10 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 03:29:10 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-127 for test case:testKMM2RollAfterSecretsCertsUpdateScramsha
2022-04-03 03:29:10 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-127
2022-04-03 03:29:10 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-127
2022-04-03 03:29:10 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-127
2022-04-03 03:29:10 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-fcdea3fe-source in namespace namespace-127
2022-04-03 03:29:10 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-127
2022-04-03 03:29:10 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-fcdea3fe-source will have desired state: Ready
2022-04-03 03:30:17 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-fcdea3fe-source is in desired state: Ready
2022-04-03 03:30:17 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-fcdea3fe-target in namespace namespace-127
2022-04-03 03:30:17 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-127
2022-04-03 03:30:17 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-fcdea3fe-target will have desired state: Ready
2022-04-03 03:31:19 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-fcdea3fe-target is in desired state: Ready
2022-04-03 03:31:19 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic mirrormaker2-topic-example-a-1009984158 in namespace namespace-127
2022-04-03 03:31:19 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-127
2022-04-03 03:31:19 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic mirrormaker2-topic-example-b-2124003847 in namespace namespace-127
2022-04-03 03:31:19 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-127
2022-04-03 03:31:19 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: mirrormaker2-topic-example-a-1009984158 will have desired state: Ready
2022-04-03 03:31:20 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: mirrormaker2-topic-example-a-1009984158 is in desired state: Ready
2022-04-03 03:31:20 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: mirrormaker2-topic-example-b-2124003847 will have desired state: Ready
2022-04-03 03:31:20 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: mirrormaker2-topic-example-b-2124003847 is in desired state: Ready
2022-04-03 03:31:20 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-fcdea3fe-my-user-source in namespace namespace-127
2022-04-03 03:31:20 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-127
2022-04-03 03:31:20 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-fcdea3fe-my-user-target in namespace namespace-127
2022-04-03 03:31:20 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-127
2022-04-03 03:31:20 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-fcdea3fe-my-user-source will have desired state: Ready
2022-04-03 03:31:21 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-fcdea3fe-my-user-source is in desired state: Ready
2022-04-03 03:31:21 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-fcdea3fe-my-user-target will have desired state: Ready
2022-04-03 03:31:21 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-fcdea3fe-my-user-target is in desired state: Ready
2022-04-03 03:31:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-fcdea3fe-kafka-clients in namespace namespace-127
2022-04-03 03:31:21 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-127
2022-04-03 03:31:21 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-fcdea3fe-kafka-clients will be ready
2022-04-03 03:31:23 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-fcdea3fe-kafka-clients is ready
2022-04-03 03:31:23 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-fcdea3fe in namespace namespace-127
2022-04-03 03:31:23 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-127
2022-04-03 03:31:23 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-fcdea3fe will have desired state: Ready
2022-04-03 03:32:30 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-fcdea3fe is in desired state: Ready
2022-04-03 03:32:30 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-03 03:32:30 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@42816db7, messages=[], arguments=[USER=my_cluster_fcdea3fe_my_user_source, --max-messages, 200, --topic, mirrormaker2-topic-example-a-1009984158, --bootstrap-server, my-cluster-fcdea3fe-source-kafka-bootstrap.namespace-127.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-fcdea3fe-kafka-clients-7bdc86db8d-qs5h2', podNamespace='namespace-127', bootstrapServer='my-cluster-fcdea3fe-source-kafka-bootstrap.namespace-127.svc:9093', topicName='mirrormaker2-topic-example-a-1009984158', maxMessages=200, kafkaUsername='my-cluster-fcdea3fe-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@74bf207d}
2022-04-03 03:32:30 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-fcdea3fe-source-kafka-bootstrap.namespace-127.svc:9093:mirrormaker2-topic-example-a-1009984158 from pod my-cluster-fcdea3fe-kafka-clients-7bdc86db8d-qs5h2
2022-04-03 03:32:30 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-fcdea3fe-kafka-clients-7bdc86db8d-qs5h2 -n namespace-127 -- /opt/kafka/producer.sh USER=my_cluster_fcdea3fe_my_user_source --max-messages 200 --topic mirrormaker2-topic-example-a-1009984158 --bootstrap-server my-cluster-fcdea3fe-source-kafka-bootstrap.namespace-127.svc:9093
2022-04-03 03:32:33 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-03 03:32:33 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-03 03:32:33 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@65fd30d, messages=[], arguments=[USER=my_cluster_fcdea3fe_my_user_source, --max-messages, 200, --group-instance-id, instance698119548, --group-id, my-consumer-group-1315576923, --topic, mirrormaker2-topic-example-a-1009984158, --bootstrap-server, my-cluster-fcdea3fe-source-kafka-bootstrap.namespace-127.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-fcdea3fe-kafka-clients-7bdc86db8d-qs5h2', podNamespace='namespace-127', bootstrapServer='my-cluster-fcdea3fe-source-kafka-bootstrap.namespace-127.svc:9093', topicName='mirrormaker2-topic-example-a-1009984158', maxMessages=200, kafkaUsername='my-cluster-fcdea3fe-my-user-source', consumerGroupName='my-consumer-group-1315576923', consumerInstanceId='instance698119548', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@beeb6c5}
2022-04-03 03:32:33 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-fcdea3fe-source-kafka-bootstrap.namespace-127.svc:9093:mirrormaker2-topic-example-a-1009984158 from pod my-cluster-fcdea3fe-kafka-clients-7bdc86db8d-qs5h2
2022-04-03 03:32:33 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-fcdea3fe-kafka-clients-7bdc86db8d-qs5h2 -n namespace-127 -- /opt/kafka/consumer.sh USER=my_cluster_fcdea3fe_my_user_source --max-messages 200 --group-instance-id instance698119548 --group-id my-consumer-group-1315576923 --topic mirrormaker2-topic-example-a-1009984158 --bootstrap-server my-cluster-fcdea3fe-source-kafka-bootstrap.namespace-127.svc:9093
2022-04-03 03:32:40 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-03 03:32:40 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-03 03:32:40 [main] [32mINFO [m [MirrorMaker2IsolatedST:1338] Now messages should be mirrored to target topic and cluster
2022-04-03 03:32:40 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@518e62b9, messages=[], arguments=[USER=my_cluster_fcdea3fe_my_user_target, --max-messages, 200, --group-instance-id, instance127590168, --group-id, my-consumer-group-412263295, --topic, my-cluster-fcdea3fe-source.mirrormaker2-topic-example-a-1009984158, --bootstrap-server, my-cluster-fcdea3fe-target-kafka-bootstrap.namespace-127.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-fcdea3fe-kafka-clients-7bdc86db8d-qs5h2', podNamespace='namespace-127', bootstrapServer='my-cluster-fcdea3fe-target-kafka-bootstrap.namespace-127.svc:9093', topicName='my-cluster-fcdea3fe-source.mirrormaker2-topic-example-a-1009984158', maxMessages=200, kafkaUsername='my-cluster-fcdea3fe-my-user-target', consumerGroupName='my-consumer-group-412263295', consumerInstanceId='instance127590168', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@4f7afaa4}
2022-04-03 03:32:40 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-fcdea3fe-target-kafka-bootstrap.namespace-127.svc:9093:my-cluster-fcdea3fe-source.mirrormaker2-topic-example-a-1009984158 from pod my-cluster-fcdea3fe-kafka-clients-7bdc86db8d-qs5h2
2022-04-03 03:32:40 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-fcdea3fe-kafka-clients-7bdc86db8d-qs5h2 -n namespace-127 -- /opt/kafka/consumer.sh USER=my_cluster_fcdea3fe_my_user_target --max-messages 200 --group-instance-id instance127590168 --group-id my-consumer-group-412263295 --topic my-cluster-fcdea3fe-source.mirrormaker2-topic-example-a-1009984158 --bootstrap-server my-cluster-fcdea3fe-target-kafka-bootstrap.namespace-127.svc:9093
2022-04-03 03:32:47 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-03 03:32:47 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-03 03:32:47 [main] [32mINFO [m [MirrorMaker2IsolatedST:1340] Messages successfully mirrored
2022-04-03 03:32:47 [main] [32mINFO [m [MirrorMaker2IsolatedST:1344] Changing KafkaUser sha-password on KMM2 Source and make sure it rolled
2022-04-03 03:32:47 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-fcdea3fe-mirrormaker2 rolling update
2022-04-03 03:34:07 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-fcdea3fe-mirrormaker2 will be ready
2022-04-03 03:34:07 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-fcdea3fe-mirrormaker2 is ready
2022-04-03 03:34:17 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-fcdea3fe-mirrormaker2 rolling update finished
2022-04-03 03:34:17 [main] [32mINFO [m [MirrorMaker2IsolatedST:1354] Changing KafkaUser sha-password on KMM2 Target
2022-04-03 03:34:17 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-fcdea3fe-mirrormaker2 rolling update
2022-04-03 03:36:23 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-fcdea3fe-mirrormaker2 will be ready
2022-04-03 03:36:23 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-fcdea3fe-mirrormaker2 is ready
2022-04-03 03:36:33 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-fcdea3fe-mirrormaker2 rolling update finished
2022-04-03 03:36:33 [main] [32mINFO [m [MirrorMaker2IsolatedST:1364] Recreate kafkaClients pod with new passwords.
2022-04-03 03:36:33 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-fcdea3fe-kafka-clients in namespace namespace-127
2022-04-03 03:37:13 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-fcdea3fe-kafka-clients in namespace namespace-127
2022-04-03 03:37:13 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-127
2022-04-03 03:37:13 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-fcdea3fe-kafka-clients will be ready
2022-04-03 03:37:15 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-fcdea3fe-kafka-clients is ready
2022-04-03 03:37:15 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@6754f7a5, messages=[], arguments=[USER=my_cluster_fcdea3fe_my_user_source, --max-messages, 200, --topic, mirrormaker2-topic-example-b-2124003847, --bootstrap-server, my-cluster-fcdea3fe-source-kafka-bootstrap.namespace-127.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-fcdea3fe-kafka-clients-64d8f854d6-czx84', podNamespace='namespace-127', bootstrapServer='my-cluster-fcdea3fe-source-kafka-bootstrap.namespace-127.svc:9093', topicName='mirrormaker2-topic-example-b-2124003847', maxMessages=200, kafkaUsername='my-cluster-fcdea3fe-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@756d135a}
2022-04-03 03:37:15 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-fcdea3fe-source-kafka-bootstrap.namespace-127.svc:9093:mirrormaker2-topic-example-b-2124003847 from pod my-cluster-fcdea3fe-kafka-clients-64d8f854d6-czx84
2022-04-03 03:37:15 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-fcdea3fe-kafka-clients-64d8f854d6-czx84 -n namespace-127 -- /opt/kafka/producer.sh USER=my_cluster_fcdea3fe_my_user_source --max-messages 200 --topic mirrormaker2-topic-example-b-2124003847 --bootstrap-server my-cluster-fcdea3fe-source-kafka-bootstrap.namespace-127.svc:9093
2022-04-03 03:37:19 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-03 03:37:19 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-03 03:37:19 [main] [32mINFO [m [MirrorMaker2IsolatedST:1385] Now messages should be mirrored to target topic and cluster
2022-04-03 03:37:19 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@64199dc, messages=[], arguments=[USER=my_cluster_fcdea3fe_my_user_target, --max-messages, 200, --group-instance-id, instance240640755, --group-id, my-consumer-group-970064506, --topic, my-cluster-fcdea3fe-source.mirrormaker2-topic-example-b-2124003847, --bootstrap-server, my-cluster-fcdea3fe-target-kafka-bootstrap.namespace-127.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-fcdea3fe-kafka-clients-64d8f854d6-czx84', podNamespace='namespace-127', bootstrapServer='my-cluster-fcdea3fe-target-kafka-bootstrap.namespace-127.svc:9093', topicName='my-cluster-fcdea3fe-source.mirrormaker2-topic-example-b-2124003847', maxMessages=200, kafkaUsername='my-cluster-fcdea3fe-my-user-target', consumerGroupName='my-consumer-group-970064506', consumerInstanceId='instance240640755', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1b2bae20}
2022-04-03 03:37:19 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-fcdea3fe-target-kafka-bootstrap.namespace-127.svc:9093:my-cluster-fcdea3fe-source.mirrormaker2-topic-example-b-2124003847 from pod my-cluster-fcdea3fe-kafka-clients-64d8f854d6-czx84
2022-04-03 03:37:19 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-fcdea3fe-kafka-clients-64d8f854d6-czx84 -n namespace-127 -- /opt/kafka/consumer.sh USER=my_cluster_fcdea3fe_my_user_target --max-messages 200 --group-instance-id instance240640755 --group-id my-consumer-group-970064506 --topic my-cluster-fcdea3fe-source.mirrormaker2-topic-example-b-2124003847 --bootstrap-server my-cluster-fcdea3fe-target-kafka-bootstrap.namespace-127.svc:9093
2022-04-03 03:37:26 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-03 03:37:26 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-03 03:37:26 [main] [32mINFO [m [MirrorMaker2IsolatedST:1387] Messages successfully mirrored
2022-04-03 03:37:26 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 03:37:26 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKMM2RollAfterSecretsCertsUpdateScramsha
2022-04-03 03:37:26 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-fcdea3fe in namespace namespace-127
2022-04-03 03:37:26 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-fcdea3fe-kafka-clients in namespace namespace-127
2022-04-03 03:37:26 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-fcdea3fe-my-user-target in namespace namespace-127
2022-04-03 03:37:26 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-fcdea3fe-target in namespace namespace-127
2022-04-03 03:37:26 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-fcdea3fe-source in namespace namespace-127
2022-04-03 03:37:26 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-fcdea3fe-kafka-clients in namespace namespace-127
2022-04-03 03:37:26 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic mirrormaker2-topic-example-a-1009984158 in namespace namespace-127
2022-04-03 03:37:26 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic mirrormaker2-topic-example-b-2124003847 in namespace namespace-127
2022-04-03 03:37:36 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-fcdea3fe-my-user-source in namespace namespace-127
2022-04-03 03:38:16 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 03:38:16 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-127 for test case:testKMM2RollAfterSecretsCertsUpdateScramsha
2022-04-03 03:38:21 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testKMM2RollAfterSecretsCertsUpdateScramsha-FINISHED
2022-04-03 03:38:21 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 03:38:21 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 03:38:21 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testMirrorMaker2TlsAndTlsClientAuth-STARTED
2022-04-03 03:38:21 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 03:38:21 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-128 for test case:testMirrorMaker2TlsAndTlsClientAuth
2022-04-03 03:38:21 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-128
2022-04-03 03:38:21 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-128
2022-04-03 03:38:21 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-128
2022-04-03 03:38:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-0590f1f7-source in namespace namespace-128
2022-04-03 03:38:21 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-128
2022-04-03 03:38:21 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-0590f1f7-source will have desired state: Ready
2022-04-03 03:39:35 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-0590f1f7-source is in desired state: Ready
2022-04-03 03:39:35 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-0590f1f7-target in namespace namespace-128
2022-04-03 03:39:35 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-128
2022-04-03 03:39:35 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-0590f1f7-target will have desired state: Ready
2022-04-03 03:40:40 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-0590f1f7-target is in desired state: Ready
2022-04-03 03:40:40 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic mirrormaker2-topic-example-600911110 in namespace namespace-128
2022-04-03 03:40:40 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-128
2022-04-03 03:40:40 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: mirrormaker2-topic-example-600911110 will have desired state: Ready
2022-04-03 03:40:41 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: mirrormaker2-topic-example-600911110 is in desired state: Ready
2022-04-03 03:40:41 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-0590f1f7-my-user-source in namespace namespace-128
2022-04-03 03:40:41 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-128
2022-04-03 03:40:41 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-0590f1f7-my-user-source will have desired state: Ready
2022-04-03 03:40:42 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-0590f1f7-my-user-source is in desired state: Ready
2022-04-03 03:40:42 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-0590f1f7-my-user-target in namespace namespace-128
2022-04-03 03:40:42 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-128
2022-04-03 03:40:42 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-0590f1f7-my-user-target will have desired state: Ready
2022-04-03 03:40:43 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-0590f1f7-my-user-target is in desired state: Ready
2022-04-03 03:40:43 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-0590f1f7-kafka-clients in namespace namespace-128
2022-04-03 03:40:43 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-128
2022-04-03 03:40:53 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-188326166-286933457-test-1 in namespace namespace-128
2022-04-03 03:40:53 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-128
2022-04-03 03:40:53 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-188326166-286933457-test-1 will have desired state: Ready
2022-04-03 03:40:54 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-188326166-286933457-test-1 is in desired state: Ready
2022-04-03 03:40:54 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-188326166-286933457-test-2 in namespace namespace-128
2022-04-03 03:40:54 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-128
2022-04-03 03:40:54 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-188326166-286933457-test-2 will have desired state: Ready
2022-04-03 03:40:55 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-188326166-286933457-test-2 is in desired state: Ready
2022-04-03 03:40:55 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-03 03:40:55 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-88892582-501167887 in namespace namespace-128
2022-04-03 03:40:55 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-128
2022-04-03 03:40:55 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-88892582-501167887 will have desired state: Ready
2022-04-03 03:40:56 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-88892582-501167887 is in desired state: Ready
2022-04-03 03:40:56 [main] [32mINFO [m [ClientUtils:127] Sending messages to - topic my-topic-188326166-286933457-test-1, cluster my-cluster-0590f1f7-source and message count of 200
2022-04-03 03:40:56 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@53803053, messages=[], arguments=[USER=my_cluster_0590f1f7_my_user_source, --max-messages, 200, --topic, my-topic-88892582-501167887, --bootstrap-server, my-cluster-0590f1f7-source-kafka-bootstrap.namespace-128.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-0590f1f7-kafka-clients-7f49c94674-km5tn', podNamespace='namespace-128', bootstrapServer='my-cluster-0590f1f7-source-kafka-bootstrap.namespace-128.svc:9093', topicName='my-topic-88892582-501167887', maxMessages=200, kafkaUsername='my-cluster-0590f1f7-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6b88645d}
2022-04-03 03:40:56 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-0590f1f7-source-kafka-bootstrap.namespace-128.svc:9093:my-topic-88892582-501167887 from pod my-cluster-0590f1f7-kafka-clients-7f49c94674-km5tn
2022-04-03 03:40:56 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-0590f1f7-kafka-clients-7f49c94674-km5tn -n namespace-128 -- /opt/kafka/producer.sh USER=my_cluster_0590f1f7_my_user_source --max-messages 200 --topic my-topic-88892582-501167887 --bootstrap-server my-cluster-0590f1f7-source-kafka-bootstrap.namespace-128.svc:9093
2022-04-03 03:40:59 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-03 03:40:59 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-03 03:40:59 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@7d6ffd55, messages=[], arguments=[USER=my_cluster_0590f1f7_my_user_source, --max-messages, 200, --group-instance-id, instance229648015, --group-id, my-consumer-group-510792187, --topic, my-topic-88892582-501167887, --bootstrap-server, my-cluster-0590f1f7-source-kafka-bootstrap.namespace-128.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-0590f1f7-kafka-clients-7f49c94674-km5tn', podNamespace='namespace-128', bootstrapServer='my-cluster-0590f1f7-source-kafka-bootstrap.namespace-128.svc:9093', topicName='my-topic-88892582-501167887', maxMessages=200, kafkaUsername='my-cluster-0590f1f7-my-user-source', consumerGroupName='my-consumer-group-510792187', consumerInstanceId='instance229648015', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@556dd129}
2022-04-03 03:40:59 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-0590f1f7-source-kafka-bootstrap.namespace-128.svc:9093:my-topic-88892582-501167887 from pod my-cluster-0590f1f7-kafka-clients-7f49c94674-km5tn
2022-04-03 03:40:59 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-0590f1f7-kafka-clients-7f49c94674-km5tn -n namespace-128 -- /opt/kafka/consumer.sh USER=my_cluster_0590f1f7_my_user_source --max-messages 200 --group-instance-id instance229648015 --group-id my-consumer-group-510792187 --topic my-topic-88892582-501167887 --bootstrap-server my-cluster-0590f1f7-source-kafka-bootstrap.namespace-128.svc:9093
2022-04-03 03:41:06 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-03 03:41:06 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-03 03:41:06 [main] [32mINFO [m [ClientUtils:133] Sent 200 and received 200
2022-04-03 03:41:06 [main] [32mINFO [m [MirrorMaker2IsolatedST:328] Setting topic to my-topic-188326166-286933457-test-2, cluster to my-cluster-0590f1f7-target and changing user to my-cluster-0590f1f7-my-user-target
2022-04-03 03:41:06 [main] [32mINFO [m [MirrorMaker2IsolatedST:337] Sending messages to - topic my-topic-188326166-286933457-test-2, cluster my-cluster-0590f1f7-target and message count of 200
2022-04-03 03:41:06 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@6b4cc41, messages=[], arguments=[USER=my_cluster_0590f1f7_my_user_target, --max-messages, 200, --topic, my-topic-188326166-286933457-test-2, --bootstrap-server, my-cluster-0590f1f7-target-kafka-bootstrap.namespace-128.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-0590f1f7-kafka-clients-7f49c94674-km5tn', podNamespace='namespace-128', bootstrapServer='my-cluster-0590f1f7-target-kafka-bootstrap.namespace-128.svc:9093', topicName='my-topic-188326166-286933457-test-2', maxMessages=200, kafkaUsername='my-cluster-0590f1f7-my-user-target', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@2f3f4803}
2022-04-03 03:41:06 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-0590f1f7-target-kafka-bootstrap.namespace-128.svc:9093:my-topic-188326166-286933457-test-2 from pod my-cluster-0590f1f7-kafka-clients-7f49c94674-km5tn
2022-04-03 03:41:06 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-0590f1f7-kafka-clients-7f49c94674-km5tn -n namespace-128 -- /opt/kafka/producer.sh USER=my_cluster_0590f1f7_my_user_target --max-messages 200 --topic my-topic-188326166-286933457-test-2 --bootstrap-server my-cluster-0590f1f7-target-kafka-bootstrap.namespace-128.svc:9093
2022-04-03 03:41:10 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-03 03:41:10 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-03 03:41:10 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@3f6c668a, messages=[], arguments=[USER=my_cluster_0590f1f7_my_user_target, --max-messages, 200, --group-instance-id, instance1720364272, --group-id, my-consumer-group-201804074, --topic, my-topic-188326166-286933457-test-2, --bootstrap-server, my-cluster-0590f1f7-target-kafka-bootstrap.namespace-128.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-0590f1f7-kafka-clients-7f49c94674-km5tn', podNamespace='namespace-128', bootstrapServer='my-cluster-0590f1f7-target-kafka-bootstrap.namespace-128.svc:9093', topicName='my-topic-188326166-286933457-test-2', maxMessages=200, kafkaUsername='my-cluster-0590f1f7-my-user-target', consumerGroupName='my-consumer-group-201804074', consumerInstanceId='instance1720364272', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3d6ba127}
2022-04-03 03:41:10 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-0590f1f7-target-kafka-bootstrap.namespace-128.svc:9093:my-topic-188326166-286933457-test-2 from pod my-cluster-0590f1f7-kafka-clients-7f49c94674-km5tn
2022-04-03 03:41:10 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-0590f1f7-kafka-clients-7f49c94674-km5tn -n namespace-128 -- /opt/kafka/consumer.sh USER=my_cluster_0590f1f7_my_user_target --max-messages 200 --group-instance-id instance1720364272 --group-id my-consumer-group-201804074 --topic my-topic-188326166-286933457-test-2 --bootstrap-server my-cluster-0590f1f7-target-kafka-bootstrap.namespace-128.svc:9093
2022-04-03 03:41:17 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-03 03:41:17 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-03 03:41:17 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-0590f1f7 in namespace namespace-128
2022-04-03 03:41:17 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-128
2022-04-03 03:41:17 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-0590f1f7 will have desired state: Ready
2022-04-03 03:42:28 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-0590f1f7 is in desired state: Ready
2022-04-03 03:42:28 [main] [32mINFO [m [MirrorMaker2IsolatedST:397] Setting topic to mirrormaker2-topic-example-600911110, cluster to my-cluster-0590f1f7-source and changing user to my-cluster-0590f1f7-my-user-source
2022-04-03 03:42:28 [main] [32mINFO [m [MirrorMaker2IsolatedST:407] Sending messages to - topic mirrormaker2-topic-example-600911110, cluster my-cluster-0590f1f7-source and message count of 200
2022-04-03 03:42:28 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@7ce836c6, messages=[], arguments=[USER=my_cluster_0590f1f7_my_user_source, --max-messages, 200, --topic, mirrormaker2-topic-example-600911110, --bootstrap-server, my-cluster-0590f1f7-source-kafka-bootstrap.namespace-128.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-0590f1f7-kafka-clients-7f49c94674-km5tn', podNamespace='namespace-128', bootstrapServer='my-cluster-0590f1f7-source-kafka-bootstrap.namespace-128.svc:9093', topicName='mirrormaker2-topic-example-600911110', maxMessages=200, kafkaUsername='my-cluster-0590f1f7-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@9c3a976}
2022-04-03 03:42:28 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-0590f1f7-source-kafka-bootstrap.namespace-128.svc:9093:mirrormaker2-topic-example-600911110 from pod my-cluster-0590f1f7-kafka-clients-7f49c94674-km5tn
2022-04-03 03:42:28 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-0590f1f7-kafka-clients-7f49c94674-km5tn -n namespace-128 -- /opt/kafka/producer.sh USER=my_cluster_0590f1f7_my_user_source --max-messages 200 --topic mirrormaker2-topic-example-600911110 --bootstrap-server my-cluster-0590f1f7-source-kafka-bootstrap.namespace-128.svc:9093
2022-04-03 03:42:32 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-03 03:42:32 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-03 03:42:32 [main] [32mINFO [m [MirrorMaker2IsolatedST:411] Receiving messages from - topic mirrormaker2-topic-example-600911110, cluster my-cluster-0590f1f7-source and message count of 200
2022-04-03 03:42:32 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@51856ccc, messages=[], arguments=[USER=my_cluster_0590f1f7_my_user_source, --max-messages, 200, --group-instance-id, instance1804574099, --group-id, my-consumer-group-201804074, --topic, mirrormaker2-topic-example-600911110, --bootstrap-server, my-cluster-0590f1f7-source-kafka-bootstrap.namespace-128.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-0590f1f7-kafka-clients-7f49c94674-km5tn', podNamespace='namespace-128', bootstrapServer='my-cluster-0590f1f7-source-kafka-bootstrap.namespace-128.svc:9093', topicName='mirrormaker2-topic-example-600911110', maxMessages=200, kafkaUsername='my-cluster-0590f1f7-my-user-source', consumerGroupName='my-consumer-group-201804074', consumerInstanceId='instance1804574099', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@4599e510}
2022-04-03 03:42:32 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-0590f1f7-source-kafka-bootstrap.namespace-128.svc:9093:mirrormaker2-topic-example-600911110 from pod my-cluster-0590f1f7-kafka-clients-7f49c94674-km5tn
2022-04-03 03:42:32 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-0590f1f7-kafka-clients-7f49c94674-km5tn -n namespace-128 -- /opt/kafka/consumer.sh USER=my_cluster_0590f1f7_my_user_source --max-messages 200 --group-instance-id instance1804574099 --group-id my-consumer-group-201804074 --topic mirrormaker2-topic-example-600911110 --bootstrap-server my-cluster-0590f1f7-source-kafka-bootstrap.namespace-128.svc:9093
2022-04-03 03:42:39 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-03 03:42:39 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-03 03:42:39 [main] [32mINFO [m [MirrorMaker2IsolatedST:418] Now setting topic to my-cluster-0590f1f7-source.mirrormaker2-topic-example-600911110, cluster to my-cluster-0590f1f7-target and user to my-cluster-0590f1f7-my-user-target - the messages should be mirrored
2022-04-03 03:42:39 [main] [32mINFO [m [MirrorMaker2IsolatedST:427] Consumer in target cluster and topic should receive 200 messages
2022-04-03 03:42:39 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@3817a216, messages=[], arguments=[USER=my_cluster_0590f1f7_my_user_target, --max-messages, 200, --group-instance-id, instance803364721, --group-id, my-consumer-group-201804074, --topic, my-cluster-0590f1f7-source.mirrormaker2-topic-example-600911110, --bootstrap-server, my-cluster-0590f1f7-target-kafka-bootstrap.namespace-128.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-0590f1f7-kafka-clients-7f49c94674-km5tn', podNamespace='namespace-128', bootstrapServer='my-cluster-0590f1f7-target-kafka-bootstrap.namespace-128.svc:9093', topicName='my-cluster-0590f1f7-source.mirrormaker2-topic-example-600911110', maxMessages=200, kafkaUsername='my-cluster-0590f1f7-my-user-target', consumerGroupName='my-consumer-group-201804074', consumerInstanceId='instance803364721', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6c663e3c}
2022-04-03 03:42:39 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-0590f1f7-target-kafka-bootstrap.namespace-128.svc:9093:my-cluster-0590f1f7-source.mirrormaker2-topic-example-600911110 from pod my-cluster-0590f1f7-kafka-clients-7f49c94674-km5tn
2022-04-03 03:42:39 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-0590f1f7-kafka-clients-7f49c94674-km5tn -n namespace-128 -- /opt/kafka/consumer.sh USER=my_cluster_0590f1f7_my_user_target --max-messages 200 --group-instance-id instance803364721 --group-id my-consumer-group-201804074 --topic my-cluster-0590f1f7-source.mirrormaker2-topic-example-600911110 --bootstrap-server my-cluster-0590f1f7-target-kafka-bootstrap.namespace-128.svc:9093
2022-04-03 03:42:45 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-03 03:42:45 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-03 03:42:45 [main] [32mINFO [m [MirrorMaker2IsolatedST:432] Messages successfully mirrored
2022-04-03 03:42:45 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 03:42:45 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMirrorMaker2TlsAndTlsClientAuth
2022-04-03 03:42:45 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-188326166-286933457-test-1 in namespace namespace-128
2022-04-03 03:42:45 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-0590f1f7-source in namespace namespace-128
2022-04-03 03:42:45 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-0590f1f7-target in namespace namespace-128
2022-04-03 03:42:45 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-0590f1f7-kafka-clients in namespace namespace-128
2022-04-03 03:42:45 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-88892582-501167887 in namespace namespace-128
2022-04-03 03:42:45 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic mirrormaker2-topic-example-600911110 in namespace namespace-128
2022-04-03 03:42:45 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-188326166-286933457-test-2 in namespace namespace-128
2022-04-03 03:42:45 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-0590f1f7 in namespace namespace-128
2022-04-03 03:42:55 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-0590f1f7-my-user-target in namespace namespace-128
2022-04-03 03:42:55 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-0590f1f7-my-user-source in namespace namespace-128
2022-04-03 03:43:36 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 03:43:36 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-128 for test case:testMirrorMaker2TlsAndTlsClientAuth
2022-04-03 03:43:41 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testMirrorMaker2TlsAndTlsClientAuth-FINISHED
2022-04-03 03:43:41 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 03:43:41 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 03:43:41 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testConfigureDeploymentStrategy-STARTED
2022-04-03 03:43:41 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 03:43:41 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-129 for test case:testConfigureDeploymentStrategy
2022-04-03 03:43:41 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-129
2022-04-03 03:43:41 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-129
2022-04-03 03:43:41 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-129
2022-04-03 03:43:41 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-e87a4da8-source in namespace namespace-129
2022-04-03 03:43:41 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-129
2022-04-03 03:43:41 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-e87a4da8-source will have desired state: Ready
2022-04-03 03:44:46 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-e87a4da8-source is in desired state: Ready
2022-04-03 03:44:46 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-e87a4da8-target in namespace namespace-129
2022-04-03 03:44:46 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-129
2022-04-03 03:44:46 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-e87a4da8-target will have desired state: Ready
2022-04-03 03:45:55 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-e87a4da8-target is in desired state: Ready
2022-04-03 03:45:55 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-e87a4da8 in namespace namespace-129
2022-04-03 03:45:55 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-129
2022-04-03 03:45:56 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-e87a4da8 will have desired state: Ready
2022-04-03 03:47:05 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-e87a4da8 is in desired state: Ready
2022-04-03 03:47:05 [main] [32mINFO [m [MirrorMaker2IsolatedST:959] Adding label to MirrorMaker2 resource, the CR should be recreated
2022-04-03 03:47:05 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-e87a4da8-mirrormaker2 will be ready
2022-04-03 03:47:05 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-e87a4da8-mirrormaker2 is ready
2022-04-03 03:47:05 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-e87a4da8-mirrormaker2 to be ready
2022-04-03 03:48:29 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-e87a4da8-mirrormaker2 is ready
2022-04-03 03:48:29 [main] [32mINFO [m [MirrorMaker2IsolatedST:966] Checking that observed gen. is still on 1 (recreation) and new label is present
2022-04-03 03:48:29 [main] [32mINFO [m [MirrorMaker2IsolatedST:971] Changing deployment strategy to ROLLING_UPDATE
2022-04-03 03:48:29 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-e87a4da8 will have desired state: Ready
2022-04-03 03:48:29 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-e87a4da8 is in desired state: Ready
2022-04-03 03:48:29 [main] [32mINFO [m [MirrorMaker2IsolatedST:976] Adding another label to MirrorMaker2 resource, pods should be rolled
2022-04-03 03:48:29 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-e87a4da8-mirrormaker2 will be ready
2022-04-03 03:48:29 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-e87a4da8-mirrormaker2 is ready
2022-04-03 03:48:29 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-e87a4da8-mirrormaker2 to be ready
2022-04-03 03:50:00 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-e87a4da8-mirrormaker2 is ready
2022-04-03 03:50:00 [main] [32mINFO [m [MirrorMaker2IsolatedST:980] Checking that observed gen. higher (rolling update) and label is changed
2022-04-03 03:50:00 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 03:50:00 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testConfigureDeploymentStrategy
2022-04-03 03:50:00 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-e87a4da8-source in namespace namespace-129
2022-04-03 03:50:00 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-e87a4da8 in namespace namespace-129
2022-04-03 03:50:00 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-e87a4da8-target in namespace namespace-129
2022-04-03 03:50:20 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 03:50:20 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-129 for test case:testConfigureDeploymentStrategy
2022-04-03 03:50:31 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testConfigureDeploymentStrategy-FINISHED
2022-04-03 03:50:31 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 03:50:31 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 03:50:31 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testMirrorMaker2CorrectlyMirrorsHeaders-STARTED
2022-04-03 03:50:31 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 03:50:31 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-130 for test case:testMirrorMaker2CorrectlyMirrorsHeaders
2022-04-03 03:50:31 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-130
2022-04-03 03:50:32 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-130
2022-04-03 03:50:32 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-130
2022-04-03 03:50:32 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-185378bb-source in namespace namespace-130
2022-04-03 03:50:32 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-130
2022-04-03 03:50:32 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-185378bb-source will have desired state: Ready
2022-04-03 03:51:30 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-185378bb-source is in desired state: Ready
2022-04-03 03:51:30 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-185378bb-target in namespace namespace-130
2022-04-03 03:51:30 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-130
2022-04-03 03:51:30 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-185378bb-target will have desired state: Ready
2022-04-03 03:52:34 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-185378bb-target is in desired state: Ready
2022-04-03 03:52:34 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-cluster-185378bb-source-example-topic in namespace namespace-130
2022-04-03 03:52:34 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-130
2022-04-03 03:52:34 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-cluster-185378bb-source-example-topic will have desired state: Ready
2022-04-03 03:52:35 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-cluster-185378bb-source-example-topic is in desired state: Ready
2022-04-03 03:52:35 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-185378bb in namespace namespace-130
2022-04-03 03:52:35 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-130
2022-04-03 03:52:35 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-185378bb will have desired state: Ready
2022-04-03 03:53:45 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-185378bb is in desired state: Ready
2022-04-03 03:53:45 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-03 03:53:45 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-185378bb-target-consumer in namespace namespace-130
2022-04-03 03:53:45 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-130
2022-04-03 03:53:45 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-185378bb-target-consumer will be in active state
2022-04-03 03:53:46 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-03 03:53:46 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-185378bb-source-producer in namespace namespace-130
2022-04-03 03:53:46 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-130
2022-04-03 03:53:46 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-185378bb-source-producer will be in active state
2022-04-03 03:53:47 [main] [32mINFO [m [ClientUtils:61] Waiting till producer my-cluster-185378bb-source-producer and consumer my-cluster-185378bb-target-consumer finish
2022-04-03 03:55:30 [main] [32mINFO [m [MirrorMaker2IsolatedST:753] Checking log of my-cluster-185378bb-target-consumer job if the headers are correct
2022-04-03 03:55:31 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 03:55:31 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMirrorMaker2CorrectlyMirrorsHeaders
2022-04-03 03:55:31 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-185378bb in namespace namespace-130
2022-04-03 03:55:31 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-185378bb-source in namespace namespace-130
2022-04-03 03:55:31 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-185378bb-source-producer in namespace namespace-130
2022-04-03 03:55:31 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-cluster-185378bb-source-example-topic in namespace namespace-130
2022-04-03 03:55:31 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-185378bb-target-consumer in namespace namespace-130
2022-04-03 03:55:31 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-185378bb-target in namespace namespace-130
2022-04-03 03:55:51 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 03:55:51 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-130 for test case:testMirrorMaker2CorrectlyMirrorsHeaders
2022-04-03 03:56:02 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testMirrorMaker2CorrectlyMirrorsHeaders-FINISHED
2022-04-03 03:56:02 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 03:56:02 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 03:56:02 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testMirrorMaker2TlsAndScramSha512Auth-STARTED
2022-04-03 03:56:02 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 03:56:02 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-131 for test case:testMirrorMaker2TlsAndScramSha512Auth
2022-04-03 03:56:02 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-131
2022-04-03 03:56:02 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-131
2022-04-03 03:56:02 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-131
2022-04-03 03:56:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-820374da-source in namespace namespace-131
2022-04-03 03:56:02 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-131
2022-04-03 03:56:02 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-820374da-source will have desired state: Ready
2022-04-03 03:57:16 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-820374da-source is in desired state: Ready
2022-04-03 03:57:16 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-820374da-target in namespace namespace-131
2022-04-03 03:57:16 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-131
2022-04-03 03:57:16 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-820374da-target will have desired state: Ready
2022-04-03 03:58:15 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-820374da-target is in desired state: Ready
2022-04-03 03:58:15 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic mirrormaker2-topic-example-1255801930 in namespace namespace-131
2022-04-03 03:58:15 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-131
2022-04-03 03:58:15 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: mirrormaker2-topic-example-1255801930 will have desired state: Ready
2022-04-03 03:58:16 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: mirrormaker2-topic-example-1255801930 is in desired state: Ready
2022-04-03 03:58:16 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-820374da-my-user-source in namespace namespace-131
2022-04-03 03:58:16 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-131
2022-04-03 03:58:16 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-820374da-my-user-source will have desired state: Ready
2022-04-03 03:58:17 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-820374da-my-user-source is in desired state: Ready
2022-04-03 03:58:17 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-820374da-my-user-target in namespace namespace-131
2022-04-03 03:58:17 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-131
2022-04-03 03:58:17 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-820374da-my-user-target will have desired state: Ready
2022-04-03 03:58:18 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-820374da-my-user-target is in desired state: Ready
2022-04-03 03:58:18 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-820374da-kafka-clients in namespace namespace-131
2022-04-03 03:58:18 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-131
2022-04-03 03:58:18 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-820374da-kafka-clients will be ready
2022-04-03 03:58:19 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-820374da-kafka-clients is ready
2022-04-03 03:58:19 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-03 03:58:19 [main] [32mINFO [m [MirrorMaker2IsolatedST:536] Sending messages to - topic availability-topic-source-my-topic-1414941987-1136987228, cluster my-cluster-820374da-source and message count of 200
2022-04-03 03:58:19 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@40ec23bf, messages=[], arguments=[USER=my_cluster_820374da_my_user_source, --max-messages, 200, --topic, availability-topic-source-my-topic-1414941987-1136987228, --bootstrap-server, my-cluster-820374da-source-kafka-bootstrap.namespace-131.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-820374da-kafka-clients-679f4c9dc8-q8bmz', podNamespace='namespace-131', bootstrapServer='my-cluster-820374da-source-kafka-bootstrap.namespace-131.svc:9093', topicName='availability-topic-source-my-topic-1414941987-1136987228', maxMessages=200, kafkaUsername='my-cluster-820374da-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@269cc541}
2022-04-03 03:58:19 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-820374da-source-kafka-bootstrap.namespace-131.svc:9093:availability-topic-source-my-topic-1414941987-1136987228 from pod my-cluster-820374da-kafka-clients-679f4c9dc8-q8bmz
2022-04-03 03:58:19 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-820374da-kafka-clients-679f4c9dc8-q8bmz -n namespace-131 -- /opt/kafka/producer.sh USER=my_cluster_820374da_my_user_source --max-messages 200 --topic availability-topic-source-my-topic-1414941987-1136987228 --bootstrap-server my-cluster-820374da-source-kafka-bootstrap.namespace-131.svc:9093
2022-04-03 03:58:23 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-03 03:58:23 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-03 03:58:23 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@2e501add, messages=[], arguments=[USER=my_cluster_820374da_my_user_source, --max-messages, 200, --group-instance-id, instance52036795, --group-id, my-consumer-group-355373181, --topic, availability-topic-source-my-topic-1414941987-1136987228, --bootstrap-server, my-cluster-820374da-source-kafka-bootstrap.namespace-131.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-820374da-kafka-clients-679f4c9dc8-q8bmz', podNamespace='namespace-131', bootstrapServer='my-cluster-820374da-source-kafka-bootstrap.namespace-131.svc:9093', topicName='availability-topic-source-my-topic-1414941987-1136987228', maxMessages=200, kafkaUsername='my-cluster-820374da-my-user-source', consumerGroupName='my-consumer-group-355373181', consumerInstanceId='instance52036795', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6ea67c85}
2022-04-03 03:58:23 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-820374da-source-kafka-bootstrap.namespace-131.svc:9093:availability-topic-source-my-topic-1414941987-1136987228 from pod my-cluster-820374da-kafka-clients-679f4c9dc8-q8bmz
2022-04-03 03:58:23 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-820374da-kafka-clients-679f4c9dc8-q8bmz -n namespace-131 -- /opt/kafka/consumer.sh USER=my_cluster_820374da_my_user_source --max-messages 200 --group-instance-id instance52036795 --group-id my-consumer-group-355373181 --topic availability-topic-source-my-topic-1414941987-1136987228 --bootstrap-server my-cluster-820374da-source-kafka-bootstrap.namespace-131.svc:9093
2022-04-03 03:58:30 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-03 03:58:30 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-03 03:58:30 [main] [32mINFO [m [MirrorMaker2IsolatedST:544] Setting topic to availability-topic-target-my-topic-1414941987-1136987228, cluster to my-cluster-820374da-target and changing user to my-cluster-820374da-my-user-target
2022-04-03 03:58:30 [main] [32mINFO [m [MirrorMaker2IsolatedST:553] Sending messages to - topic availability-topic-target-my-topic-1414941987-1136987228, cluster my-cluster-820374da-target and message count of 200
2022-04-03 03:58:30 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@1a97aef8, messages=[], arguments=[USER=my_cluster_820374da_my_user_target, --max-messages, 200, --topic, availability-topic-target-my-topic-1414941987-1136987228, --bootstrap-server, my-cluster-820374da-target-kafka-bootstrap.namespace-131.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-820374da-kafka-clients-679f4c9dc8-q8bmz', podNamespace='namespace-131', bootstrapServer='my-cluster-820374da-target-kafka-bootstrap.namespace-131.svc:9093', topicName='availability-topic-target-my-topic-1414941987-1136987228', maxMessages=200, kafkaUsername='my-cluster-820374da-my-user-target', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@f002573}
2022-04-03 03:58:30 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-820374da-target-kafka-bootstrap.namespace-131.svc:9093:availability-topic-target-my-topic-1414941987-1136987228 from pod my-cluster-820374da-kafka-clients-679f4c9dc8-q8bmz
2022-04-03 03:58:30 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-820374da-kafka-clients-679f4c9dc8-q8bmz -n namespace-131 -- /opt/kafka/producer.sh USER=my_cluster_820374da_my_user_target --max-messages 200 --topic availability-topic-target-my-topic-1414941987-1136987228 --bootstrap-server my-cluster-820374da-target-kafka-bootstrap.namespace-131.svc:9093
2022-04-03 03:58:34 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-03 03:58:34 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-03 03:58:34 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@69a0d7b5, messages=[], arguments=[USER=my_cluster_820374da_my_user_target, --max-messages, 200, --group-instance-id, instance1288024085, --group-id, my-consumer-group-355373181, --topic, availability-topic-target-my-topic-1414941987-1136987228, --bootstrap-server, my-cluster-820374da-target-kafka-bootstrap.namespace-131.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-820374da-kafka-clients-679f4c9dc8-q8bmz', podNamespace='namespace-131', bootstrapServer='my-cluster-820374da-target-kafka-bootstrap.namespace-131.svc:9093', topicName='availability-topic-target-my-topic-1414941987-1136987228', maxMessages=200, kafkaUsername='my-cluster-820374da-my-user-target', consumerGroupName='my-consumer-group-355373181', consumerInstanceId='instance1288024085', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@4708ab7b}
2022-04-03 03:58:34 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-820374da-target-kafka-bootstrap.namespace-131.svc:9093:availability-topic-target-my-topic-1414941987-1136987228 from pod my-cluster-820374da-kafka-clients-679f4c9dc8-q8bmz
2022-04-03 03:58:34 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-820374da-kafka-clients-679f4c9dc8-q8bmz -n namespace-131 -- /opt/kafka/consumer.sh USER=my_cluster_820374da_my_user_target --max-messages 200 --group-instance-id instance1288024085 --group-id my-consumer-group-355373181 --topic availability-topic-target-my-topic-1414941987-1136987228 --bootstrap-server my-cluster-820374da-target-kafka-bootstrap.namespace-131.svc:9093
2022-04-03 03:58:41 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-03 03:58:41 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-03 03:58:41 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-820374da in namespace namespace-131
2022-04-03 03:58:41 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-131
2022-04-03 03:58:41 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-820374da will have desired state: Ready
2022-04-03 03:59:59 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-820374da is in desired state: Ready
2022-04-03 03:59:59 [main] [32mINFO [m [MirrorMaker2IsolatedST:597] Setting topic to mirrormaker2-topic-example-1255801930, cluster to my-cluster-820374da-source and changing user to my-cluster-820374da-my-user-source
2022-04-03 03:59:59 [main] [32mINFO [m [MirrorMaker2IsolatedST:606] Sending messages to - topic mirrormaker2-topic-example-1255801930, cluster my-cluster-820374da-source and message count of 200
2022-04-03 03:59:59 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@7736e1b2, messages=[], arguments=[USER=my_cluster_820374da_my_user_source, --max-messages, 200, --topic, mirrormaker2-topic-example-1255801930, --bootstrap-server, my-cluster-820374da-source-kafka-bootstrap.namespace-131.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-820374da-kafka-clients-679f4c9dc8-q8bmz', podNamespace='namespace-131', bootstrapServer='my-cluster-820374da-source-kafka-bootstrap.namespace-131.svc:9093', topicName='mirrormaker2-topic-example-1255801930', maxMessages=200, kafkaUsername='my-cluster-820374da-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7c8baa67}
2022-04-03 03:59:59 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-820374da-source-kafka-bootstrap.namespace-131.svc:9093:mirrormaker2-topic-example-1255801930 from pod my-cluster-820374da-kafka-clients-679f4c9dc8-q8bmz
2022-04-03 03:59:59 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-820374da-kafka-clients-679f4c9dc8-q8bmz -n namespace-131 -- /opt/kafka/producer.sh USER=my_cluster_820374da_my_user_source --max-messages 200 --topic mirrormaker2-topic-example-1255801930 --bootstrap-server my-cluster-820374da-source-kafka-bootstrap.namespace-131.svc:9093
2022-04-03 04:00:03 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-03 04:00:03 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-03 04:00:03 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@45c4abb5, messages=[], arguments=[USER=my_cluster_820374da_my_user_source, --max-messages, 200, --group-instance-id, instance2012853942, --group-id, my-consumer-group-355373181, --topic, mirrormaker2-topic-example-1255801930, --bootstrap-server, my-cluster-820374da-source-kafka-bootstrap.namespace-131.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-820374da-kafka-clients-679f4c9dc8-q8bmz', podNamespace='namespace-131', bootstrapServer='my-cluster-820374da-source-kafka-bootstrap.namespace-131.svc:9093', topicName='mirrormaker2-topic-example-1255801930', maxMessages=200, kafkaUsername='my-cluster-820374da-my-user-source', consumerGroupName='my-consumer-group-355373181', consumerInstanceId='instance2012853942', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@64bdfdd7}
2022-04-03 04:00:03 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-820374da-source-kafka-bootstrap.namespace-131.svc:9093:mirrormaker2-topic-example-1255801930 from pod my-cluster-820374da-kafka-clients-679f4c9dc8-q8bmz
2022-04-03 04:00:03 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-820374da-kafka-clients-679f4c9dc8-q8bmz -n namespace-131 -- /opt/kafka/consumer.sh USER=my_cluster_820374da_my_user_source --max-messages 200 --group-instance-id instance2012853942 --group-id my-consumer-group-355373181 --topic mirrormaker2-topic-example-1255801930 --bootstrap-server my-cluster-820374da-source-kafka-bootstrap.namespace-131.svc:9093
2022-04-03 04:00:10 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-03 04:00:10 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-03 04:00:10 [main] [32mINFO [m [MirrorMaker2IsolatedST:615] Changing to target - topic my-cluster-820374da-source.mirrormaker2-topic-example-1255801930, cluster my-cluster-820374da-target, user my-cluster-820374da-my-user-target
2022-04-03 04:00:10 [main] [32mINFO [m [MirrorMaker2IsolatedST:623] Now messages should be mirrored to target topic and cluster
2022-04-03 04:00:10 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@2c0f965a, messages=[], arguments=[USER=my_cluster_820374da_my_user_target, --max-messages, 200, --group-instance-id, instance750869118, --group-id, my-consumer-group-355373181, --topic, my-cluster-820374da-source.mirrormaker2-topic-example-1255801930, --bootstrap-server, my-cluster-820374da-target-kafka-bootstrap.namespace-131.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-820374da-kafka-clients-679f4c9dc8-q8bmz', podNamespace='namespace-131', bootstrapServer='my-cluster-820374da-target-kafka-bootstrap.namespace-131.svc:9093', topicName='my-cluster-820374da-source.mirrormaker2-topic-example-1255801930', maxMessages=200, kafkaUsername='my-cluster-820374da-my-user-target', consumerGroupName='my-consumer-group-355373181', consumerInstanceId='instance750869118', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@53fe9ce}
2022-04-03 04:00:10 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-820374da-target-kafka-bootstrap.namespace-131.svc:9093:my-cluster-820374da-source.mirrormaker2-topic-example-1255801930 from pod my-cluster-820374da-kafka-clients-679f4c9dc8-q8bmz
2022-04-03 04:00:10 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-820374da-kafka-clients-679f4c9dc8-q8bmz -n namespace-131 -- /opt/kafka/consumer.sh USER=my_cluster_820374da_my_user_target --max-messages 200 --group-instance-id instance750869118 --group-id my-consumer-group-355373181 --topic my-cluster-820374da-source.mirrormaker2-topic-example-1255801930 --bootstrap-server my-cluster-820374da-target-kafka-bootstrap.namespace-131.svc:9093
2022-04-03 04:00:17 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-03 04:00:17 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-03 04:00:17 [main] [32mINFO [m [MirrorMaker2IsolatedST:628] Messages successfully mirrored
2022-04-03 04:00:17 [main] [32mINFO [m [KafkaTopicUtils:78] Waiting for KafkaTopic my-cluster-820374da-source.mirrormaker2-topic-example-1255801930 creation 
2022-04-03 04:00:17 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 04:00:17 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMirrorMaker2TlsAndScramSha512Auth
2022-04-03 04:00:17 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-820374da-my-user-target in namespace namespace-131
2022-04-03 04:00:17 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-820374da-my-user-source in namespace namespace-131
2022-04-03 04:00:17 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-820374da-kafka-clients in namespace namespace-131
2022-04-03 04:00:17 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-820374da-source in namespace namespace-131
2022-04-03 04:00:17 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-820374da in namespace namespace-131
2022-04-03 04:00:17 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-820374da-target in namespace namespace-131
2022-04-03 04:00:17 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic mirrormaker2-topic-example-1255801930 in namespace namespace-131
2022-04-03 04:01:17 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 04:01:17 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-131 for test case:testMirrorMaker2TlsAndScramSha512Auth
2022-04-03 04:01:23 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testMirrorMaker2TlsAndScramSha512Auth-FINISHED
2022-04-03 04:01:23 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 04:01:23 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 04:01:23 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testScaleMirrorMaker2ToZero-STARTED
2022-04-03 04:01:23 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 04:01:23 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-132 for test case:testScaleMirrorMaker2ToZero
2022-04-03 04:01:23 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-132
2022-04-03 04:01:23 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-132
2022-04-03 04:01:23 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-132
2022-04-03 04:01:23 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-553ec50a-source in namespace namespace-132
2022-04-03 04:01:23 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-132
2022-04-03 04:01:23 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-553ec50a-source will have desired state: Ready
2022-04-03 04:02:33 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-553ec50a-source is in desired state: Ready
2022-04-03 04:02:33 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-553ec50a-target in namespace namespace-132
2022-04-03 04:02:33 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-132
2022-04-03 04:02:33 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-553ec50a-target will have desired state: Ready
2022-04-03 04:03:42 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-553ec50a-target is in desired state: Ready
2022-04-03 04:03:42 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-553ec50a in namespace namespace-132
2022-04-03 04:03:42 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-132
2022-04-03 04:03:42 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-553ec50a will have desired state: Ready
2022-04-03 04:04:58 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-553ec50a is in desired state: Ready
2022-04-03 04:04:58 [main] [32mINFO [m [MirrorMaker2IsolatedST:781] Scaling MirrorMaker2 to zero
2022-04-03 04:05:11 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 04:05:11 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testScaleMirrorMaker2ToZero
2022-04-03 04:05:11 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-553ec50a-target in namespace namespace-132
2022-04-03 04:05:11 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-553ec50a-source in namespace namespace-132
2022-04-03 04:05:11 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-553ec50a in namespace namespace-132
2022-04-03 04:05:31 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 04:05:31 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-132 for test case:testScaleMirrorMaker2ToZero
2022-04-03 04:05:37 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testScaleMirrorMaker2ToZero-FINISHED
2022-04-03 04:05:37 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 04:05:37 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 04:05:37 [main] [32mINFO [m [ResourceManager:346] In context MirrorMaker2IsolatedST is everything deleted.
2022-04-03 04:05:37 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 13, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5,947.678 s - in io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST
2022-04-03 04:05:37 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-03 04:06:02 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-03 04:06:02 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-03 04:06:02 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-03 04:06:02 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 04:06:02 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-03 04:06:02 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-03 04:06:02 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-03 04:06:02 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-03 04:06:02 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-03 04:06:02 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-03 04:06:02 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-03 04:06:02 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 04:06:02 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-03 04:06:02 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-03 04:06:02 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-03 04:06:02 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-03 04:06:02 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-03 04:06:02 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-03 04:06:02 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-03 04:06:02 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 04:06:02 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-03 04:06:02 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-03 04:06:02 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-03 04:06:02 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-03 04:06:02 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-03 04:06:02 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-03 04:06:02 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-03 04:06:12 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-03 04:06:12 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-03 04:06:12 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-03 04:06:22 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 04:06:27 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7e2e5e3d
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=120000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-03 04:06:27 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-03 04:06:27 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-03 04:06:27 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-03 04:06:27 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-03 04:06:27 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 04:06:27 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-03 04:06:27 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-03 04:06:27 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-03 04:06:27 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-03 04:06:27 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-03 04:06:27 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-03 04:06:27 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-03 04:06:27 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-03 04:06:27 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-03 04:06:27 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-03 04:06:27 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-03 04:06:27 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-03 04:06:27 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-03 04:06:28 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-03 04:06:28 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-03 04:06:28 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-03 04:06:28 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-03 04:06:28 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-03 04:06:28 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-03 04:06:28 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-03 04:06:28 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-03 04:06:28 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-03 04:06:28 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-03 04:06:28 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-03 04:06:28 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-03 04:06:28 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-03 04:06:28 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-03 04:06:28 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-03 04:06:28 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 04:06:28 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-03 04:06:28 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-03 04:06:28 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-03 04:06:40 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-03 04:06:40 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-03 04:06:50 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-03 04:06:50 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 04:06:50 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testMirrorMakerTlsAuthenticated-STARTED
2022-04-03 04:06:50 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 04:06:50 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-133 for test case:testMirrorMakerTlsAuthenticated
2022-04-03 04:06:50 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-133
2022-04-03 04:06:50 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-133
2022-04-03 04:06:50 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-133
2022-04-03 04:06:50 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-fc3b17fa-source in namespace namespace-133
2022-04-03 04:06:50 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-133
2022-04-03 04:06:50 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-fc3b17fa-source will have desired state: Ready
2022-04-03 04:08:03 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-fc3b17fa-source is in desired state: Ready
2022-04-03 04:08:03 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-fc3b17fa-target in namespace namespace-133
2022-04-03 04:08:03 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-133
2022-04-03 04:08:03 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-fc3b17fa-target will have desired state: Ready
2022-04-03 04:09:08 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-fc3b17fa-target is in desired state: Ready
2022-04-03 04:09:08 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-467311057-683530871-source-357216060 in namespace namespace-133
2022-04-03 04:09:08 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-133
2022-04-03 04:09:08 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-467311057-683530871-source-357216060 will have desired state: Ready
2022-04-03 04:09:09 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-467311057-683530871-source-357216060 is in desired state: Ready
2022-04-03 04:09:09 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-fc3b17fa-my-user-source in namespace namespace-133
2022-04-03 04:09:09 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-133
2022-04-03 04:09:09 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-fc3b17fa-my-user-source will have desired state: Ready
2022-04-03 04:09:10 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-fc3b17fa-my-user-source is in desired state: Ready
2022-04-03 04:09:10 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-fc3b17fa-my-user-target in namespace namespace-133
2022-04-03 04:09:10 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-133
2022-04-03 04:09:10 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-fc3b17fa-my-user-target will have desired state: Ready
2022-04-03 04:09:11 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-fc3b17fa-my-user-target is in desired state: Ready
2022-04-03 04:09:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-fc3b17fa-kafka-clients in namespace namespace-133
2022-04-03 04:09:11 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-133
2022-04-03 04:09:11 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-fc3b17fa-kafka-clients will be ready
2022-04-03 04:09:12 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-fc3b17fa-kafka-clients is ready
2022-04-03 04:09:12 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-2048382318-595971412-test-1 in namespace namespace-133
2022-04-03 04:09:12 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-133
2022-04-03 04:09:12 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-2048382318-595971412-test-1 will have desired state: Ready
2022-04-03 04:09:13 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-2048382318-595971412-test-1 is in desired state: Ready
2022-04-03 04:09:13 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-2048382318-595971412-test-2 in namespace namespace-133
2022-04-03 04:09:13 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-133
2022-04-03 04:09:13 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-2048382318-595971412-test-2 will have desired state: Ready
2022-04-03 04:09:14 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-2048382318-595971412-test-2 is in desired state: Ready
2022-04-03 04:09:14 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-03 04:09:14 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@5d075818, messages=[], arguments=[USER=my_cluster_fc3b17fa_my_user_source, --max-messages, 200, --topic, my-topic-2048382318-595971412-test-1, --bootstrap-server, my-cluster-fc3b17fa-source-kafka-bootstrap.namespace-133.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-fc3b17fa-kafka-clients-6dd6884458-695s6', podNamespace='namespace-133', bootstrapServer='my-cluster-fc3b17fa-source-kafka-bootstrap.namespace-133.svc:9093', topicName='my-topic-2048382318-595971412-test-1', maxMessages=200, kafkaUsername='my-cluster-fc3b17fa-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@62835a23}
2022-04-03 04:09:14 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-fc3b17fa-source-kafka-bootstrap.namespace-133.svc:9093:my-topic-2048382318-595971412-test-1 from pod my-cluster-fc3b17fa-kafka-clients-6dd6884458-695s6
2022-04-03 04:09:14 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-fc3b17fa-kafka-clients-6dd6884458-695s6 -n namespace-133 -- /opt/kafka/producer.sh USER=my_cluster_fc3b17fa_my_user_source --max-messages 200 --topic my-topic-2048382318-595971412-test-1 --bootstrap-server my-cluster-fc3b17fa-source-kafka-bootstrap.namespace-133.svc:9093
2022-04-03 04:09:18 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-03 04:09:18 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-03 04:09:18 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@7be22acd, messages=[], arguments=[USER=my_cluster_fc3b17fa_my_user_source, --max-messages, 200, --group-instance-id, instance871821856, --group-id, my-consumer-group-589624338, --topic, my-topic-2048382318-595971412-test-1, --bootstrap-server, my-cluster-fc3b17fa-source-kafka-bootstrap.namespace-133.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-fc3b17fa-kafka-clients-6dd6884458-695s6', podNamespace='namespace-133', bootstrapServer='my-cluster-fc3b17fa-source-kafka-bootstrap.namespace-133.svc:9093', topicName='my-topic-2048382318-595971412-test-1', maxMessages=200, kafkaUsername='my-cluster-fc3b17fa-my-user-source', consumerGroupName='my-consumer-group-589624338', consumerInstanceId='instance871821856', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3482ac5}
2022-04-03 04:09:18 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-fc3b17fa-source-kafka-bootstrap.namespace-133.svc:9093:my-topic-2048382318-595971412-test-1 from pod my-cluster-fc3b17fa-kafka-clients-6dd6884458-695s6
2022-04-03 04:09:18 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-fc3b17fa-kafka-clients-6dd6884458-695s6 -n namespace-133 -- /opt/kafka/consumer.sh USER=my_cluster_fc3b17fa_my_user_source --max-messages 200 --group-instance-id instance871821856 --group-id my-consumer-group-589624338 --topic my-topic-2048382318-595971412-test-1 --bootstrap-server my-cluster-fc3b17fa-source-kafka-bootstrap.namespace-133.svc:9093
2022-04-03 04:09:25 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-03 04:09:25 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-03 04:09:25 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@2c607d1c, messages=[], arguments=[USER=my_cluster_fc3b17fa_my_user_target, --max-messages, 200, --topic, my-topic-2048382318-595971412-test-2, --bootstrap-server, my-cluster-fc3b17fa-target-kafka-bootstrap.namespace-133.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-fc3b17fa-kafka-clients-6dd6884458-695s6', podNamespace='namespace-133', bootstrapServer='my-cluster-fc3b17fa-target-kafka-bootstrap.namespace-133.svc:9093', topicName='my-topic-2048382318-595971412-test-2', maxMessages=200, kafkaUsername='my-cluster-fc3b17fa-my-user-target', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1cc27a31}
2022-04-03 04:09:25 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-fc3b17fa-target-kafka-bootstrap.namespace-133.svc:9093:my-topic-2048382318-595971412-test-2 from pod my-cluster-fc3b17fa-kafka-clients-6dd6884458-695s6
2022-04-03 04:09:25 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-fc3b17fa-kafka-clients-6dd6884458-695s6 -n namespace-133 -- /opt/kafka/producer.sh USER=my_cluster_fc3b17fa_my_user_target --max-messages 200 --topic my-topic-2048382318-595971412-test-2 --bootstrap-server my-cluster-fc3b17fa-target-kafka-bootstrap.namespace-133.svc:9093
2022-04-03 04:09:29 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-03 04:09:29 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-03 04:09:29 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@4628f0f, messages=[], arguments=[USER=my_cluster_fc3b17fa_my_user_target, --max-messages, 200, --group-instance-id, instance189825743, --group-id, my-consumer-group-843308884, --topic, my-topic-2048382318-595971412-test-2, --bootstrap-server, my-cluster-fc3b17fa-target-kafka-bootstrap.namespace-133.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-fc3b17fa-kafka-clients-6dd6884458-695s6', podNamespace='namespace-133', bootstrapServer='my-cluster-fc3b17fa-target-kafka-bootstrap.namespace-133.svc:9093', topicName='my-topic-2048382318-595971412-test-2', maxMessages=200, kafkaUsername='my-cluster-fc3b17fa-my-user-target', consumerGroupName='my-consumer-group-843308884', consumerInstanceId='instance189825743', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6ebc7457}
2022-04-03 04:09:29 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-fc3b17fa-target-kafka-bootstrap.namespace-133.svc:9093:my-topic-2048382318-595971412-test-2 from pod my-cluster-fc3b17fa-kafka-clients-6dd6884458-695s6
2022-04-03 04:09:29 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-fc3b17fa-kafka-clients-6dd6884458-695s6 -n namespace-133 -- /opt/kafka/consumer.sh USER=my_cluster_fc3b17fa_my_user_target --max-messages 200 --group-instance-id instance189825743 --group-id my-consumer-group-843308884 --topic my-topic-2048382318-595971412-test-2 --bootstrap-server my-cluster-fc3b17fa-target-kafka-bootstrap.namespace-133.svc:9093
2022-04-03 04:09:35 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-03 04:09:35 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-03 04:09:35 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-fc3b17fa in namespace namespace-133
2022-04-03 04:09:35 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-133
2022-04-03 04:09:35 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-fc3b17fa will have desired state: Ready
2022-04-03 04:10:41 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-fc3b17fa is in desired state: Ready
2022-04-03 04:10:41 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@67312e1e, messages=[], arguments=[USER=my_cluster_fc3b17fa_my_user_source, --max-messages, 200, --topic, my-topic-467311057-683530871-source-357216060, --bootstrap-server, my-cluster-fc3b17fa-source-kafka-bootstrap.namespace-133.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-fc3b17fa-kafka-clients-6dd6884458-695s6', podNamespace='namespace-133', bootstrapServer='my-cluster-fc3b17fa-source-kafka-bootstrap.namespace-133.svc:9093', topicName='my-topic-467311057-683530871-source-357216060', maxMessages=200, kafkaUsername='my-cluster-fc3b17fa-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6e060112}
2022-04-03 04:10:41 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-fc3b17fa-source-kafka-bootstrap.namespace-133.svc:9093:my-topic-467311057-683530871-source-357216060 from pod my-cluster-fc3b17fa-kafka-clients-6dd6884458-695s6
2022-04-03 04:10:41 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-fc3b17fa-kafka-clients-6dd6884458-695s6 -n namespace-133 -- /opt/kafka/producer.sh USER=my_cluster_fc3b17fa_my_user_source --max-messages 200 --topic my-topic-467311057-683530871-source-357216060 --bootstrap-server my-cluster-fc3b17fa-source-kafka-bootstrap.namespace-133.svc:9093
2022-04-03 04:10:44 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-03 04:10:44 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-03 04:10:44 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@50e2e62c, messages=[], arguments=[USER=my_cluster_fc3b17fa_my_user_source, --max-messages, 200, --group-instance-id, instance1249538538, --group-id, my-consumer-group-798945927, --topic, my-topic-467311057-683530871-source-357216060, --bootstrap-server, my-cluster-fc3b17fa-source-kafka-bootstrap.namespace-133.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-fc3b17fa-kafka-clients-6dd6884458-695s6', podNamespace='namespace-133', bootstrapServer='my-cluster-fc3b17fa-source-kafka-bootstrap.namespace-133.svc:9093', topicName='my-topic-467311057-683530871-source-357216060', maxMessages=200, kafkaUsername='my-cluster-fc3b17fa-my-user-source', consumerGroupName='my-consumer-group-798945927', consumerInstanceId='instance1249538538', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@eb26879}
2022-04-03 04:10:44 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-fc3b17fa-source-kafka-bootstrap.namespace-133.svc:9093:my-topic-467311057-683530871-source-357216060 from pod my-cluster-fc3b17fa-kafka-clients-6dd6884458-695s6
2022-04-03 04:10:44 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-fc3b17fa-kafka-clients-6dd6884458-695s6 -n namespace-133 -- /opt/kafka/consumer.sh USER=my_cluster_fc3b17fa_my_user_source --max-messages 200 --group-instance-id instance1249538538 --group-id my-consumer-group-798945927 --topic my-topic-467311057-683530871-source-357216060 --bootstrap-server my-cluster-fc3b17fa-source-kafka-bootstrap.namespace-133.svc:9093
2022-04-03 04:10:51 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-03 04:10:51 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-03 04:10:51 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@3a5f0750, messages=[], arguments=[USER=my_cluster_fc3b17fa_my_user_target, --max-messages, 200, --group-instance-id, instance131856484, --group-id, my-consumer-group-1533858753, --topic, my-topic-467311057-683530871-source-357216060, --bootstrap-server, my-cluster-fc3b17fa-target-kafka-bootstrap.namespace-133.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-fc3b17fa-kafka-clients-6dd6884458-695s6', podNamespace='namespace-133', bootstrapServer='my-cluster-fc3b17fa-target-kafka-bootstrap.namespace-133.svc:9093', topicName='my-topic-467311057-683530871-source-357216060', maxMessages=200, kafkaUsername='my-cluster-fc3b17fa-my-user-target', consumerGroupName='my-consumer-group-1533858753', consumerInstanceId='instance131856484', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3ecd63f0}
2022-04-03 04:10:51 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-fc3b17fa-target-kafka-bootstrap.namespace-133.svc:9093:my-topic-467311057-683530871-source-357216060 from pod my-cluster-fc3b17fa-kafka-clients-6dd6884458-695s6
2022-04-03 04:10:51 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-fc3b17fa-kafka-clients-6dd6884458-695s6 -n namespace-133 -- /opt/kafka/consumer.sh USER=my_cluster_fc3b17fa_my_user_target --max-messages 200 --group-instance-id instance131856484 --group-id my-consumer-group-1533858753 --topic my-topic-467311057-683530871-source-357216060 --bootstrap-server my-cluster-fc3b17fa-target-kafka-bootstrap.namespace-133.svc:9093
2022-04-03 04:10:58 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-03 04:10:58 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-03 04:10:58 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 04:10:58 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMirrorMakerTlsAuthenticated
2022-04-03 04:10:58 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-fc3b17fa-kafka-clients in namespace namespace-133
2022-04-03 04:10:58 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-fc3b17fa-target in namespace namespace-133
2022-04-03 04:10:58 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-fc3b17fa-source in namespace namespace-133
2022-04-03 04:10:58 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-fc3b17fa-my-user-source in namespace namespace-133
2022-04-03 04:10:58 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-2048382318-595971412-test-2 in namespace namespace-133
2022-04-03 04:10:58 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-467311057-683530871-source-357216060 in namespace namespace-133
2022-04-03 04:10:58 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-2048382318-595971412-test-1 in namespace namespace-133
2022-04-03 04:10:58 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-fc3b17fa in namespace namespace-133
2022-04-03 04:11:08 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-fc3b17fa-my-user-target in namespace namespace-133
2022-04-03 04:11:48 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 04:11:48 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-133 for test case:testMirrorMakerTlsAuthenticated
2022-04-03 04:11:54 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testMirrorMakerTlsAuthenticated-FINISHED
2022-04-03 04:11:54 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 04:11:54 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 04:11:54 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testMirrorMakerTlsScramSha-STARTED
2022-04-03 04:11:54 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 04:11:54 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-134 for test case:testMirrorMakerTlsScramSha
2022-04-03 04:11:54 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-134
2022-04-03 04:11:54 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-134
2022-04-03 04:11:54 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-134
2022-04-03 04:11:54 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-105e97a5-source in namespace namespace-134
2022-04-03 04:11:54 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-134
2022-04-03 04:11:54 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-105e97a5-source will have desired state: Ready
2022-04-03 04:13:04 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-105e97a5-source is in desired state: Ready
2022-04-03 04:13:04 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-105e97a5-target in namespace namespace-134
2022-04-03 04:13:04 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-134
2022-04-03 04:13:04 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-105e97a5-target will have desired state: Ready
2022-04-03 04:14:17 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-105e97a5-target is in desired state: Ready
2022-04-03 04:14:17 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1620565035-1516543607 in namespace namespace-134
2022-04-03 04:14:17 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-134
2022-04-03 04:14:17 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1620565035-1516543607 will have desired state: Ready
2022-04-03 04:14:18 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1620565035-1516543607 is in desired state: Ready
2022-04-03 04:14:18 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-105e97a5-my-user-source in namespace namespace-134
2022-04-03 04:14:18 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-134
2022-04-03 04:14:18 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-105e97a5-my-user-source will have desired state: Ready
2022-04-03 04:14:19 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-105e97a5-my-user-source is in desired state: Ready
2022-04-03 04:14:19 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-105e97a5-my-user-target in namespace namespace-134
2022-04-03 04:14:19 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-134
2022-04-03 04:14:19 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-105e97a5-my-user-target will have desired state: Ready
2022-04-03 04:14:20 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-105e97a5-my-user-target is in desired state: Ready
2022-04-03 04:14:20 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-105e97a5-kafka-clients in namespace namespace-134
2022-04-03 04:14:20 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-134
2022-04-03 04:14:20 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-105e97a5-kafka-clients will be ready
2022-04-03 04:14:22 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-105e97a5-kafka-clients is ready
2022-04-03 04:14:22 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1620565035-1516543607-test-1 in namespace namespace-134
2022-04-03 04:14:22 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-134
2022-04-03 04:14:22 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1620565035-1516543607-test-1 will have desired state: Ready
2022-04-03 04:14:23 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1620565035-1516543607-test-1 is in desired state: Ready
2022-04-03 04:14:23 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1620565035-1516543607-test-2 in namespace namespace-134
2022-04-03 04:14:23 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-134
2022-04-03 04:14:23 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1620565035-1516543607-test-2 will have desired state: Ready
2022-04-03 04:14:24 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1620565035-1516543607-test-2 is in desired state: Ready
2022-04-03 04:14:24 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-03 04:14:24 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@459b44e9, messages=[], arguments=[USER=my_cluster_105e97a5_my_user_source, --max-messages, 200, --topic, my-topic-1620565035-1516543607-test-1, --bootstrap-server, my-cluster-105e97a5-source-kafka-bootstrap.namespace-134.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-105e97a5-kafka-clients-865db6c4f5-j2nh9', podNamespace='namespace-134', bootstrapServer='my-cluster-105e97a5-source-kafka-bootstrap.namespace-134.svc:9093', topicName='my-topic-1620565035-1516543607-test-1', maxMessages=200, kafkaUsername='my-cluster-105e97a5-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3de8b973}
2022-04-03 04:14:24 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-105e97a5-source-kafka-bootstrap.namespace-134.svc:9093:my-topic-1620565035-1516543607-test-1 from pod my-cluster-105e97a5-kafka-clients-865db6c4f5-j2nh9
2022-04-03 04:14:24 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-105e97a5-kafka-clients-865db6c4f5-j2nh9 -n namespace-134 -- /opt/kafka/producer.sh USER=my_cluster_105e97a5_my_user_source --max-messages 200 --topic my-topic-1620565035-1516543607-test-1 --bootstrap-server my-cluster-105e97a5-source-kafka-bootstrap.namespace-134.svc:9093
2022-04-03 04:14:28 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-03 04:14:28 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-03 04:14:28 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@74dbccf2, messages=[], arguments=[USER=my_cluster_105e97a5_my_user_source, --max-messages, 200, --group-instance-id, instance382733743, --group-id, my-consumer-group-1457439447, --topic, my-topic-1620565035-1516543607-test-1, --bootstrap-server, my-cluster-105e97a5-source-kafka-bootstrap.namespace-134.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-105e97a5-kafka-clients-865db6c4f5-j2nh9', podNamespace='namespace-134', bootstrapServer='my-cluster-105e97a5-source-kafka-bootstrap.namespace-134.svc:9093', topicName='my-topic-1620565035-1516543607-test-1', maxMessages=200, kafkaUsername='my-cluster-105e97a5-my-user-source', consumerGroupName='my-consumer-group-1457439447', consumerInstanceId='instance382733743', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@c00df20}
2022-04-03 04:14:28 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-105e97a5-source-kafka-bootstrap.namespace-134.svc:9093:my-topic-1620565035-1516543607-test-1 from pod my-cluster-105e97a5-kafka-clients-865db6c4f5-j2nh9
2022-04-03 04:14:28 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-105e97a5-kafka-clients-865db6c4f5-j2nh9 -n namespace-134 -- /opt/kafka/consumer.sh USER=my_cluster_105e97a5_my_user_source --max-messages 200 --group-instance-id instance382733743 --group-id my-consumer-group-1457439447 --topic my-topic-1620565035-1516543607-test-1 --bootstrap-server my-cluster-105e97a5-source-kafka-bootstrap.namespace-134.svc:9093
2022-04-03 04:14:35 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-03 04:14:35 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-03 04:14:35 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@2d5d8386, messages=[], arguments=[USER=my_cluster_105e97a5_my_user_target, --max-messages, 200, --topic, my-topic-1620565035-1516543607-test-2, --bootstrap-server, my-cluster-105e97a5-target-kafka-bootstrap.namespace-134.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-105e97a5-kafka-clients-865db6c4f5-j2nh9', podNamespace='namespace-134', bootstrapServer='my-cluster-105e97a5-target-kafka-bootstrap.namespace-134.svc:9093', topicName='my-topic-1620565035-1516543607-test-2', maxMessages=200, kafkaUsername='my-cluster-105e97a5-my-user-target', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6bf8728c}
2022-04-03 04:14:35 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-105e97a5-target-kafka-bootstrap.namespace-134.svc:9093:my-topic-1620565035-1516543607-test-2 from pod my-cluster-105e97a5-kafka-clients-865db6c4f5-j2nh9
2022-04-03 04:14:35 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-105e97a5-kafka-clients-865db6c4f5-j2nh9 -n namespace-134 -- /opt/kafka/producer.sh USER=my_cluster_105e97a5_my_user_target --max-messages 200 --topic my-topic-1620565035-1516543607-test-2 --bootstrap-server my-cluster-105e97a5-target-kafka-bootstrap.namespace-134.svc:9093
2022-04-03 04:14:39 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-03 04:14:39 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-03 04:14:39 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@d385499, messages=[], arguments=[USER=my_cluster_105e97a5_my_user_target, --max-messages, 200, --group-instance-id, instance837663111, --group-id, my-consumer-group-569589997, --topic, my-topic-1620565035-1516543607-test-2, --bootstrap-server, my-cluster-105e97a5-target-kafka-bootstrap.namespace-134.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-105e97a5-kafka-clients-865db6c4f5-j2nh9', podNamespace='namespace-134', bootstrapServer='my-cluster-105e97a5-target-kafka-bootstrap.namespace-134.svc:9093', topicName='my-topic-1620565035-1516543607-test-2', maxMessages=200, kafkaUsername='my-cluster-105e97a5-my-user-target', consumerGroupName='my-consumer-group-569589997', consumerInstanceId='instance837663111', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@272eb0d2}
2022-04-03 04:14:39 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-105e97a5-target-kafka-bootstrap.namespace-134.svc:9093:my-topic-1620565035-1516543607-test-2 from pod my-cluster-105e97a5-kafka-clients-865db6c4f5-j2nh9
2022-04-03 04:14:39 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-105e97a5-kafka-clients-865db6c4f5-j2nh9 -n namespace-134 -- /opt/kafka/consumer.sh USER=my_cluster_105e97a5_my_user_target --max-messages 200 --group-instance-id instance837663111 --group-id my-consumer-group-569589997 --topic my-topic-1620565035-1516543607-test-2 --bootstrap-server my-cluster-105e97a5-target-kafka-bootstrap.namespace-134.svc:9093
2022-04-03 04:14:46 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-03 04:14:46 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-03 04:14:46 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-105e97a5 in namespace namespace-134
2022-04-03 04:14:46 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-134
2022-04-03 04:14:46 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-105e97a5 will have desired state: Ready
2022-04-03 04:15:57 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-105e97a5 is in desired state: Ready
2022-04-03 04:15:57 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@3f2755a2, messages=[], arguments=[USER=my_cluster_105e97a5_my_user_source, --max-messages, 200, --topic, my-topic-1620565035-1516543607, --bootstrap-server, my-cluster-105e97a5-source-kafka-bootstrap.namespace-134.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-105e97a5-kafka-clients-865db6c4f5-j2nh9', podNamespace='namespace-134', bootstrapServer='my-cluster-105e97a5-source-kafka-bootstrap.namespace-134.svc:9093', topicName='my-topic-1620565035-1516543607', maxMessages=200, kafkaUsername='my-cluster-105e97a5-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3db0da23}
2022-04-03 04:15:57 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-105e97a5-source-kafka-bootstrap.namespace-134.svc:9093:my-topic-1620565035-1516543607 from pod my-cluster-105e97a5-kafka-clients-865db6c4f5-j2nh9
2022-04-03 04:15:57 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-105e97a5-kafka-clients-865db6c4f5-j2nh9 -n namespace-134 -- /opt/kafka/producer.sh USER=my_cluster_105e97a5_my_user_source --max-messages 200 --topic my-topic-1620565035-1516543607 --bootstrap-server my-cluster-105e97a5-source-kafka-bootstrap.namespace-134.svc:9093
2022-04-03 04:16:01 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-03 04:16:01 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-03 04:16:01 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@53cf30b3, messages=[], arguments=[USER=my_cluster_105e97a5_my_user_source, --max-messages, 200, --group-instance-id, instance1688972638, --group-id, my-consumer-group-1641747612, --topic, my-topic-1620565035-1516543607, --bootstrap-server, my-cluster-105e97a5-source-kafka-bootstrap.namespace-134.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-105e97a5-kafka-clients-865db6c4f5-j2nh9', podNamespace='namespace-134', bootstrapServer='my-cluster-105e97a5-source-kafka-bootstrap.namespace-134.svc:9093', topicName='my-topic-1620565035-1516543607', maxMessages=200, kafkaUsername='my-cluster-105e97a5-my-user-source', consumerGroupName='my-consumer-group-1641747612', consumerInstanceId='instance1688972638', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@68959e40}
2022-04-03 04:16:01 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-105e97a5-source-kafka-bootstrap.namespace-134.svc:9093:my-topic-1620565035-1516543607 from pod my-cluster-105e97a5-kafka-clients-865db6c4f5-j2nh9
2022-04-03 04:16:01 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-105e97a5-kafka-clients-865db6c4f5-j2nh9 -n namespace-134 -- /opt/kafka/consumer.sh USER=my_cluster_105e97a5_my_user_source --max-messages 200 --group-instance-id instance1688972638 --group-id my-consumer-group-1641747612 --topic my-topic-1620565035-1516543607 --bootstrap-server my-cluster-105e97a5-source-kafka-bootstrap.namespace-134.svc:9093
2022-04-03 04:16:08 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-03 04:16:08 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-03 04:16:08 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@121004fa, messages=[], arguments=[USER=my_cluster_105e97a5_my_user_target, --max-messages, 200, --group-instance-id, instance449646730, --group-id, my-consumer-group-773635789, --topic, my-topic-1620565035-1516543607, --bootstrap-server, my-cluster-105e97a5-target-kafka-bootstrap.namespace-134.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-105e97a5-kafka-clients-865db6c4f5-j2nh9', podNamespace='namespace-134', bootstrapServer='my-cluster-105e97a5-target-kafka-bootstrap.namespace-134.svc:9093', topicName='my-topic-1620565035-1516543607', maxMessages=200, kafkaUsername='my-cluster-105e97a5-my-user-target', consumerGroupName='my-consumer-group-773635789', consumerInstanceId='instance449646730', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@56c0f52d}
2022-04-03 04:16:08 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-105e97a5-target-kafka-bootstrap.namespace-134.svc:9093:my-topic-1620565035-1516543607 from pod my-cluster-105e97a5-kafka-clients-865db6c4f5-j2nh9
2022-04-03 04:16:08 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-105e97a5-kafka-clients-865db6c4f5-j2nh9 -n namespace-134 -- /opt/kafka/consumer.sh USER=my_cluster_105e97a5_my_user_target --max-messages 200 --group-instance-id instance449646730 --group-id my-consumer-group-773635789 --topic my-topic-1620565035-1516543607 --bootstrap-server my-cluster-105e97a5-target-kafka-bootstrap.namespace-134.svc:9093
2022-04-03 04:16:15 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-03 04:16:15 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-03 04:16:15 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 04:16:15 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMirrorMakerTlsScramSha
2022-04-03 04:16:15 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-105e97a5-my-user-target in namespace namespace-134
2022-04-03 04:16:15 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-105e97a5-kafka-clients in namespace namespace-134
2022-04-03 04:16:15 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-105e97a5-target in namespace namespace-134
2022-04-03 04:16:15 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1620565035-1516543607-test-2 in namespace namespace-134
2022-04-03 04:16:15 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-105e97a5-source in namespace namespace-134
2022-04-03 04:16:15 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1620565035-1516543607 in namespace namespace-134
2022-04-03 04:16:15 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-105e97a5-my-user-source in namespace namespace-134
2022-04-03 04:16:15 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1620565035-1516543607-test-1 in namespace namespace-134
2022-04-03 04:16:25 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-105e97a5 in namespace namespace-134
2022-04-03 04:17:05 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 04:17:05 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-134 for test case:testMirrorMakerTlsScramSha
2022-04-03 04:17:10 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testMirrorMakerTlsScramSha-FINISHED
2022-04-03 04:17:10 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 04:17:10 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 04:17:10 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testIncludeList-STARTED
2022-04-03 04:17:10 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 04:17:10 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-135 for test case:testIncludeList
2022-04-03 04:17:10 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-135
2022-04-03 04:17:10 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-135
2022-04-03 04:17:10 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-135
2022-04-03 04:17:10 [main] [32mINFO [m [MirrorMakerIsolatedST:471] Creating kafka source cluster my-cluster-d884152f-source
2022-04-03 04:17:10 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-d884152f-source in namespace namespace-135
2022-04-03 04:17:10 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-135
2022-04-03 04:17:10 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d884152f-source will have desired state: Ready
2022-04-03 04:18:13 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d884152f-source is in desired state: Ready
2022-04-03 04:18:13 [main] [32mINFO [m [MirrorMakerIsolatedST:473] Creating kafka target cluster my-cluster-d884152f-target
2022-04-03 04:18:13 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-d884152f-target in namespace namespace-135
2022-04-03 04:18:13 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-135
2022-04-03 04:18:13 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d884152f-target will have desired state: Ready
2022-04-03 04:19:21 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d884152f-target is in desired state: Ready
2022-04-03 04:19:21 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic included-topic in namespace namespace-135
2022-04-03 04:19:21 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-135
2022-04-03 04:19:21 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: included-topic will have desired state: Ready
2022-04-03 04:19:22 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: included-topic is in desired state: Ready
2022-04-03 04:19:22 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic not-included-topic in namespace namespace-135
2022-04-03 04:19:22 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-135
2022-04-03 04:19:22 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: not-included-topic will have desired state: Ready
2022-04-03 04:19:23 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: not-included-topic is in desired state: Ready
2022-04-03 04:19:23 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-d884152f-kafka-clients in namespace namespace-135
2022-04-03 04:19:23 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-135
2022-04-03 04:19:23 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-d884152f-kafka-clients will be ready
2022-04-03 04:19:25 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-d884152f-kafka-clients is ready
2022-04-03 04:19:25 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@5516539f, messages=[], arguments=[--max-messages, 200, --topic, topic-example-10, --bootstrap-server, my-cluster-d884152f-source-kafka-bootstrap.namespace-135.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-d884152f-kafka-clients-79f47546f6-wssq2', podNamespace='namespace-135', bootstrapServer='my-cluster-d884152f-source-kafka-bootstrap.namespace-135.svc:9092', topicName='topic-example-10', maxMessages=200, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6cf59df3}
2022-04-03 04:19:25 [main] [32mINFO [m [InternalKafkaClient:94] Producing 200 messages to my-cluster-d884152f-source-kafka-bootstrap.namespace-135.svc:9092:topic-example-10 from pod my-cluster-d884152f-kafka-clients-79f47546f6-wssq2
2022-04-03 04:19:25 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-d884152f-kafka-clients-79f47546f6-wssq2 -n namespace-135 -- /opt/kafka/producer.sh --max-messages 200 --topic topic-example-10 --bootstrap-server my-cluster-d884152f-source-kafka-bootstrap.namespace-135.svc:9092
2022-04-03 04:19:27 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-03 04:19:27 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 200 messages
2022-04-03 04:19:27 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@1d72d66d, messages=[], arguments=[--max-messages, 200, --group-instance-id, instance835979997, --group-id, my-consumer-group-1594677844, --topic, topic-example-10, --bootstrap-server, my-cluster-d884152f-source-kafka-bootstrap.namespace-135.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-d884152f-kafka-clients-79f47546f6-wssq2', podNamespace='namespace-135', bootstrapServer='my-cluster-d884152f-source-kafka-bootstrap.namespace-135.svc:9092', topicName='topic-example-10', maxMessages=200, kafkaUsername='null', consumerGroupName='my-consumer-group-1594677844', consumerInstanceId='instance835979997', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5d28d23e}
2022-04-03 04:19:27 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 200 messages from my-cluster-d884152f-source-kafka-bootstrap.namespace-135.svc:9092#topic-example-10 from pod my-cluster-d884152f-kafka-clients-79f47546f6-wssq2
2022-04-03 04:19:27 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-d884152f-kafka-clients-79f47546f6-wssq2 -n namespace-135 -- /opt/kafka/consumer.sh --max-messages 200 --group-instance-id instance835979997 --group-id my-consumer-group-1594677844 --topic topic-example-10 --bootstrap-server my-cluster-d884152f-source-kafka-bootstrap.namespace-135.svc:9092
2022-04-03 04:19:33 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-03 04:19:33 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 200 messages
2022-04-03 04:19:33 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@12824c1d, messages=[], arguments=[--max-messages, 200, --topic, topic-example-11, --bootstrap-server, my-cluster-d884152f-target-kafka-bootstrap.namespace-135.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-d884152f-kafka-clients-79f47546f6-wssq2', podNamespace='namespace-135', bootstrapServer='my-cluster-d884152f-target-kafka-bootstrap.namespace-135.svc:9092', topicName='topic-example-11', maxMessages=200, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7a9fe4f7}
2022-04-03 04:19:33 [main] [32mINFO [m [InternalKafkaClient:94] Producing 200 messages to my-cluster-d884152f-target-kafka-bootstrap.namespace-135.svc:9092:topic-example-11 from pod my-cluster-d884152f-kafka-clients-79f47546f6-wssq2
2022-04-03 04:19:33 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-d884152f-kafka-clients-79f47546f6-wssq2 -n namespace-135 -- /opt/kafka/producer.sh --max-messages 200 --topic topic-example-11 --bootstrap-server my-cluster-d884152f-target-kafka-bootstrap.namespace-135.svc:9092
2022-04-03 04:19:35 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-03 04:19:35 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 200 messages
2022-04-03 04:19:35 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@26abbb6, messages=[], arguments=[--max-messages, 200, --group-instance-id, instance2079290176, --group-id, my-consumer-group-1798658636, --topic, topic-example-11, --bootstrap-server, my-cluster-d884152f-target-kafka-bootstrap.namespace-135.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-d884152f-kafka-clients-79f47546f6-wssq2', podNamespace='namespace-135', bootstrapServer='my-cluster-d884152f-target-kafka-bootstrap.namespace-135.svc:9092', topicName='topic-example-11', maxMessages=200, kafkaUsername='null', consumerGroupName='my-consumer-group-1798658636', consumerInstanceId='instance2079290176', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@9a0d551}
2022-04-03 04:19:35 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 200 messages from my-cluster-d884152f-target-kafka-bootstrap.namespace-135.svc:9092#topic-example-11 from pod my-cluster-d884152f-kafka-clients-79f47546f6-wssq2
2022-04-03 04:19:35 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-d884152f-kafka-clients-79f47546f6-wssq2 -n namespace-135 -- /opt/kafka/consumer.sh --max-messages 200 --group-instance-id instance2079290176 --group-id my-consumer-group-1798658636 --topic topic-example-11 --bootstrap-server my-cluster-d884152f-target-kafka-bootstrap.namespace-135.svc:9092
2022-04-03 04:19:41 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-03 04:19:41 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 200 messages
2022-04-03 04:19:41 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-d884152f in namespace namespace-135
2022-04-03 04:19:41 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-135
2022-04-03 04:19:41 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-d884152f will have desired state: Ready
2022-04-03 04:20:49 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-d884152f is in desired state: Ready
2022-04-03 04:20:49 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@7351913, messages=[], arguments=[--max-messages, 200, --topic, included-topic, --bootstrap-server, my-cluster-d884152f-source-kafka-bootstrap.namespace-135.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-d884152f-kafka-clients-79f47546f6-wssq2', podNamespace='namespace-135', bootstrapServer='my-cluster-d884152f-source-kafka-bootstrap.namespace-135.svc:9092', topicName='included-topic', maxMessages=200, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7d74f50}
2022-04-03 04:20:49 [main] [32mINFO [m [InternalKafkaClient:94] Producing 200 messages to my-cluster-d884152f-source-kafka-bootstrap.namespace-135.svc:9092:included-topic from pod my-cluster-d884152f-kafka-clients-79f47546f6-wssq2
2022-04-03 04:20:49 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-d884152f-kafka-clients-79f47546f6-wssq2 -n namespace-135 -- /opt/kafka/producer.sh --max-messages 200 --topic included-topic --bootstrap-server my-cluster-d884152f-source-kafka-bootstrap.namespace-135.svc:9092
2022-04-03 04:20:52 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-03 04:20:52 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 200 messages
2022-04-03 04:20:52 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@62409a37, messages=[], arguments=[--max-messages, 200, --group-instance-id, instance243945544, --group-id, my-consumer-group-1490165044, --topic, included-topic, --bootstrap-server, my-cluster-d884152f-source-kafka-bootstrap.namespace-135.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-d884152f-kafka-clients-79f47546f6-wssq2', podNamespace='namespace-135', bootstrapServer='my-cluster-d884152f-source-kafka-bootstrap.namespace-135.svc:9092', topicName='included-topic', maxMessages=200, kafkaUsername='null', consumerGroupName='my-consumer-group-1490165044', consumerInstanceId='instance243945544', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5fd0e352}
2022-04-03 04:20:52 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 200 messages from my-cluster-d884152f-source-kafka-bootstrap.namespace-135.svc:9092#included-topic from pod my-cluster-d884152f-kafka-clients-79f47546f6-wssq2
2022-04-03 04:20:52 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-d884152f-kafka-clients-79f47546f6-wssq2 -n namespace-135 -- /opt/kafka/consumer.sh --max-messages 200 --group-instance-id instance243945544 --group-id my-consumer-group-1490165044 --topic included-topic --bootstrap-server my-cluster-d884152f-source-kafka-bootstrap.namespace-135.svc:9092
2022-04-03 04:20:57 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-03 04:20:57 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 200 messages
2022-04-03 04:20:58 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@475f3230, messages=[], arguments=[--max-messages, 200, --group-instance-id, instance817176461, --group-id, my-consumer-group-647310536, --topic, included-topic, --bootstrap-server, my-cluster-d884152f-target-kafka-bootstrap.namespace-135.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-d884152f-kafka-clients-79f47546f6-wssq2', podNamespace='namespace-135', bootstrapServer='my-cluster-d884152f-target-kafka-bootstrap.namespace-135.svc:9092', topicName='included-topic', maxMessages=200, kafkaUsername='null', consumerGroupName='my-consumer-group-647310536', consumerInstanceId='instance817176461', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@4d92faed}
2022-04-03 04:20:58 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 200 messages from my-cluster-d884152f-target-kafka-bootstrap.namespace-135.svc:9092#included-topic from pod my-cluster-d884152f-kafka-clients-79f47546f6-wssq2
2022-04-03 04:20:58 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-d884152f-kafka-clients-79f47546f6-wssq2 -n namespace-135 -- /opt/kafka/consumer.sh --max-messages 200 --group-instance-id instance817176461 --group-id my-consumer-group-647310536 --topic included-topic --bootstrap-server my-cluster-d884152f-target-kafka-bootstrap.namespace-135.svc:9092
2022-04-03 04:21:03 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-03 04:21:03 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 200 messages
2022-04-03 04:21:03 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@79ba3316, messages=[], arguments=[--max-messages, 200, --topic, not-included-topic, --bootstrap-server, my-cluster-d884152f-source-kafka-bootstrap.namespace-135.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-d884152f-kafka-clients-79f47546f6-wssq2', podNamespace='namespace-135', bootstrapServer='my-cluster-d884152f-source-kafka-bootstrap.namespace-135.svc:9092', topicName='not-included-topic', maxMessages=200, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1fcd83fa}
2022-04-03 04:21:03 [main] [32mINFO [m [InternalKafkaClient:94] Producing 200 messages to my-cluster-d884152f-source-kafka-bootstrap.namespace-135.svc:9092:not-included-topic from pod my-cluster-d884152f-kafka-clients-79f47546f6-wssq2
2022-04-03 04:21:03 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-d884152f-kafka-clients-79f47546f6-wssq2 -n namespace-135 -- /opt/kafka/producer.sh --max-messages 200 --topic not-included-topic --bootstrap-server my-cluster-d884152f-source-kafka-bootstrap.namespace-135.svc:9092
2022-04-03 04:21:06 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-03 04:21:06 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 200 messages
2022-04-03 04:21:06 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@1dd593a8, messages=[], arguments=[--max-messages, 200, --group-instance-id, instance1639359154, --group-id, my-consumer-group-226369791, --topic, not-included-topic, --bootstrap-server, my-cluster-d884152f-source-kafka-bootstrap.namespace-135.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-d884152f-kafka-clients-79f47546f6-wssq2', podNamespace='namespace-135', bootstrapServer='my-cluster-d884152f-source-kafka-bootstrap.namespace-135.svc:9092', topicName='not-included-topic', maxMessages=200, kafkaUsername='null', consumerGroupName='my-consumer-group-226369791', consumerInstanceId='instance1639359154', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@23a5fb5e}
2022-04-03 04:21:06 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 200 messages from my-cluster-d884152f-source-kafka-bootstrap.namespace-135.svc:9092#not-included-topic from pod my-cluster-d884152f-kafka-clients-79f47546f6-wssq2
2022-04-03 04:21:06 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-d884152f-kafka-clients-79f47546f6-wssq2 -n namespace-135 -- /opt/kafka/consumer.sh --max-messages 200 --group-instance-id instance1639359154 --group-id my-consumer-group-226369791 --topic not-included-topic --bootstrap-server my-cluster-d884152f-source-kafka-bootstrap.namespace-135.svc:9092
2022-04-03 04:21:11 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-03 04:21:11 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 200 messages
2022-04-03 04:21:11 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@467ebde0, messages=[], arguments=[--max-messages, 200, --group-instance-id, instance361278008, --group-id, my-consumer-group-226369791, --topic, not-included-topic, --bootstrap-server, my-cluster-d884152f-target-kafka-bootstrap.namespace-135.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-d884152f-kafka-clients-79f47546f6-wssq2', podNamespace='namespace-135', bootstrapServer='my-cluster-d884152f-target-kafka-bootstrap.namespace-135.svc:9092', topicName='not-included-topic', maxMessages=200, kafkaUsername='null', consumerGroupName='my-consumer-group-226369791', consumerInstanceId='instance361278008', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6e7411bb}
2022-04-03 04:21:11 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 200 messages from my-cluster-d884152f-target-kafka-bootstrap.namespace-135.svc:9092#not-included-topic from pod my-cluster-d884152f-kafka-clients-79f47546f6-wssq2
2022-04-03 04:21:11 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-d884152f-kafka-clients-79f47546f6-wssq2 -n namespace-135 -- /opt/kafka/consumer.sh --max-messages 200 --group-instance-id instance361278008 --group-id my-consumer-group-226369791 --topic not-included-topic --bootstrap-server my-cluster-d884152f-target-kafka-bootstrap.namespace-135.svc:9092
2022-04-03 04:23:11 [main] [32mINFO [m [VerifiableClient:199] CLI_KAFKA_VERIFIABLE_CONSUMER RETURN code: 1
2022-04-03 04:23:11 [main] [32mINFO [m [VerifiableClient:201] ======STDOUT START=======
2022-04-03 04:23:11 [main] [33mWARN [m [Exec:358] Executor log is too long. Going to strip it and print only first 20000 characters
2022-04-03 04:23:11 [main] [32mINFO [m [VerifiableClient:202] /tmp/.properties
Starting Consumer with configuration:

[2022-04-03 04:21:13,324] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [my-cluster-d884152f-target-kafka-bootstrap.namespace-135.svc:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-my-consumer-group-226369791-instance361278008
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = my-consumer-group-226369791
	group.instance.id = instance361278008
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
 (ConsumerConfig:376)
[2022-04-03 04:21:13,329] DEBUG [Consumer instanceId=instance361278008, clientId=consumer-my-consumer-group-226369791-instance361278008, groupId=my-consumer-group-226369791] Initializing the Kafka consumer (KafkaConsumer:695)
[2022-04-03 04:21:13,456] INFO Kafka version: 3.1.0 (AppInfoParser:119)
[2022-04-03 04:21:13,457] INFO Kafka commitId: 37edeed0777bacb3 (AppInfoParser:120)
[2022-04-03 04:21:13,457] INFO Kafka startTimeMs: 1648959673453 (AppInfoParser:121)
[2022-04-03 04:21:13,459] DEBUG [Consumer instanceId=instance361278008, clientId=consumer-my-consumer-group-226369791-instance361278008, groupId=my-consumer-group-226369791] Kafka consumer initialized (KafkaConsumer:815)
{"timestamp":1648959673592,"name":"startup_complete"}
[2022-04-03 04:21:13,631] INFO [Consumer instanceId=instance361278008, clientId=consumer-my-consumer-group-226369791-instance361278008, groupId=my-consumer-group-226369791] Subscribed to topic(s): not-included-topic (KafkaConsumer:966)
[2022-04-03 04:21:13,632] DEBUG [Consumer instanceId=instance361278008, clientId=consumer-my-consumer-group-226369791-instance361278008, groupId=my-consumer-group-226369791] Sending FindCoordinator request to broker my-cluster-d884152f-target-kafka-bootstrap.namespace-135.svc:9092 (id: -1 rack: null) (ConsumerCoordinator:821)
[2022-04-03 04:21:13,870] DEBUG Resolved host my-cluster-d884152f-target-kafka-bootstrap.namespace-135.svc as 10.101.185.53 (ClientUtils:113)
[2022-04-03 04:21:13,871] DEBUG [Consumer instanceId=instance361278008, clientId=consumer-my-consumer-group-226369791-instance361278008, groupId=my-consumer-group-226369791] Initiating connection to node my-cluster-d884152f-target-kafka-bootstrap.namespace-135.svc:9092 (id: -1 rack: null) using address my-cluster-d884152f-target-kafka-bootstrap.namespace-135.svc/10.101.185.53 (NetworkClient:985)
[2022-04-03 04:21:13,883] DEBUG [Consumer instanceId=instance361278008, clientId=consumer-my-consumer-group-226369791-instance361278008, groupId=my-consumer-group-226369791] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1 (Selector:531)
[2022-04-03 04:21:13,884] DEBUG [Consumer instanceId=instance361278008, clientId=consumer-my-consumer-group-226369791-instance361278008, groupId=my-consumer-group-226369791] Completed connection to node -1. Fetching API versions. (NetworkClient:952)
[2022-04-03 04:21:13,885] DEBUG [Consumer instanceId=instance361278008, clientId=consumer-my-consumer-group-226369791-instance361278008, groupId=my-consumer-group-226369791] Initiating API versions fetch from node -1. (NetworkClient:966)
[2022-04-03 04:21:13,887] DEBUG [Consumer instanceId=instance361278008, clientId=consumer-my-consumer-group-226369791-instance361278008, groupId=my-consumer-group-226369791] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-my-consumer-group-226369791-instance361278008, correlationId=1) and timeout 30000 to node -1: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='3.1.0') (NetworkClient:521)
[2022-04-03 04:21:13,920] DEBUG [Consumer instanceId=instance361278008, clientId=consumer-my-consumer-group-226369791-instance361278008, groupId=my-consumer-group-226369791] Received API_VERSIONS response from node -1 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-my-consumer-group-226369791-instance361278008, correlationId=1): ApiVersionsResponseData(errorCode=0, apiKeys=[ApiVersion(apiKey=0, minVersion=0, maxVersion=9), ApiVersion(apiKey=1, minVersion=0, maxVersion=13), ApiVersion(apiKey=2, minVersion=0, maxVersion=7), ApiVersion(apiKey=3, minVersion=0, maxVersion=12), ApiVersion(apiKey=4, minVersion=0, maxVersion=5), ApiVersion(apiKey=5, minVersion=0, maxVersion=3), ApiVersion(apiKey=6, minVersion=0, maxVersion=7), ApiVersion(apiKey=7, minVersion=0, maxVersion=3), ApiVersion(apiKey=8, minVersion=0, maxVersion=8), ApiVersion(apiKey=9, minVersion=0, maxVersion=8), ApiVersion(apiKey=10, minVersion=0, maxVersion=4), ApiVersion(apiKey=11, minVersion=0, maxVersion=7), ApiVersion(apiKey=12, minVersion=0, maxVersion=4), ApiVersion(apiKey=13, minVersion=0, maxVersion=4), ApiVersion(apiKey=14, minVersion=0, maxVersion=5), ApiVersion(apiKey=15, minVersion=0, maxVersion=5), ApiVersion(apiKey=16, minVersion=0, maxVersion=4), ApiVersion(apiKey=17, minVersion=0, maxVersion=1), ApiVersion(apiKey=18, minVersion=0, maxVersion=3), ApiVersion(apiKey=19, minVersion=0, maxVersion=7), ApiVersion(apiKey=20, minVersion=0, maxVersion=6), ApiVersion(apiKey=21, minVersion=0, maxVersion=2), ApiVersion(apiKey=22, minVersion=0, maxVersion=4), ApiVersion(apiKey=23, minVersion=0, maxVersion=4), ApiVersion(apiKey=24, minVersion=0, maxVersion=3), ApiVersion(apiKey=25, minVersion=0, maxVersion=3), ApiVersion(apiKey=26, minVersion=0, maxVersion=3), ApiVersion(apiKey=27, minVersion=0, maxVersion=1), ApiVersion(apiKey=28, minVersion=0, maxVersion=3), ApiVersion(apiKey=29, minVersion=0, maxVersion=2), ApiVersion(apiKey=30, minVersion=0, maxVersion=2), ApiVersion(apiKey=31, minVersion=0, maxVersion=2), ApiVersion(apiKey=32, minVersion=0, maxVersion=4), ApiVersion(apiKey=33, minVersion=0, maxVersion=2), ApiVersion(apiKey=34, minVersion=0, maxVersion=2), ApiVersion(apiKey=35, minVersion=0, maxVersion=2), ApiVersion(apiKey=36, minVersion=0, maxVersion=2), ApiVersion(apiKey=37, minVersion=0, maxVersion=3), ApiVersion(apiKey=38, minVersion=0, maxVersion=2), ApiVersion(apiKey=39, minVersion=0, maxVersion=2), ApiVersion(apiKey=40, minVersion=0, maxVersion=2), ApiVersion(apiKey=41, minVersion=0, maxVersion=2), ApiVersion(apiKey=42, minVersion=0, maxVersion=2), ApiVersion(apiKey=43, minVersion=0, maxVersion=2), ApiVersion(apiKey=44, minVersion=0, maxVersion=1), ApiVersion(apiKey=45, minVersion=0, maxVersion=0), ApiVersion(apiKey=46, minVersion=0, maxVersion=0), ApiVersion(apiKey=47, minVersion=0, maxVersion=0), ApiVersion(apiKey=48, minVersion=0, maxVersion=1), ApiVersion(apiKey=49, minVersion=0, maxVersion=1), ApiVersion(apiKey=50, minVersion=0, maxVersion=0), ApiVersion(apiKey=51, minVersion=0, maxVersion=0), ApiVersion(apiKey=56, minVersion=0, maxVersion=0), ApiVersion(apiKey=57, minVersion=0, maxVersion=0), ApiVersion(apiKey=60, minVersion=0, maxVersion=0), ApiVersion(apiKey=61, minVersion=0, maxVersion=0), ApiVersion(apiKey=65, minVersion=0, maxVersion=0), ApiVersion(apiKey=66, minVersion=0, maxVersion=0), ApiVersion(apiKey=67, minVersion=0, maxVersion=0)], throttleTimeMs=0, supportedFeatures=[], finalizedFeaturesEpoch=0, finalizedFeatures=[]) (NetworkClient:879)
[2022-04-03 04:21:13,984] DEBUG [Consumer instanceId=instance361278008, clientId=consumer-my-consumer-group-226369791-instance361278008, groupId=my-consumer-group-226369791] Node -1 has finalized features epoch: 0, finalized features: [], supported features: [], API versions: (Produce(0): 0 to 9 [usable: 9], Fetch(1): 0 to 13 [usable: 13], ListOffsets(2): 0 to 7 [usable: 7], Metadata(3): 0 to 12 [usable: 12], LeaderAndIsr(4): 0 to 5 [usable: 5], StopReplica(5): 0 to 3 [usable: 3], UpdateMetadata(6): 0 to 7 [usable: 7], ControlledShutdown(7): 0 to 3 [usable: 3], OffsetCommit(8): 0 to 8 [usable: 8], OffsetFetch(9): 0 to 8 [usable: 8], FindCoordinator(10): 0 to 4 [usable: 4], JoinGroup(11): 0 to 7 [usable: 7], Heartbeat(12): 0 to 4 [usable: 4], LeaveGroup(13): 0 to 4 [usable: 4], SyncGroup(14): 0 to 5 [usable: 5], DescribeGroups(15): 0 to 5 [usable: 5], ListGroups(16): 0 to 4 [usable: 4], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 3 [usable: 3], CreateTopics(19): 0 to 7 [usable: 7], DeleteTopics(20): 0 to 6 [usable: 6], DeleteRecords(21): 0 to 2 [usable: 2], InitProducerId(22): 0 to 4 [usable: 4], OffsetForLeaderEpoch(23): 0 to 4 [usable: 4], AddPartitionsToTxn(24): 0 to 3 [usable: 3], AddOffsetsToTxn(25): 0 to 3 [usable: 3], EndTxn(26): 0 to 3 [usable: 3], WriteTxnMarkers(27): 0 to 1 [usable: 1], TxnOffsetCommit(28): 0 to 3 [usable: 3], DescribeAcls(29): 0 to 2 [usable: 2], CreateAcls(30): 0 to 2 [usable: 2], DeleteAcls(31): 0 to 2 [usable: 2], DescribeConfigs(32): 0 to 4 [usable: 4], AlterConfigs(33): 0 to 2 [usable: 2], AlterReplicaLogDirs(34): 0 to 2 [usable: 2], DescribeLogDirs(35): 0 to 2 [usable: 2], SaslAuthenticate(36): 0 to 2 [usable: 2], CreatePartitions(37): 0 to 3 [usable: 3], CreateDelegationToken(38): 0 to 2 [usable: 2], RenewDelegationToken(39): 0 to 2 [usable: 2], ExpireDelegationToken(40): 0 to 2 [usable: 2], DescribeDelegationToken(41): 0 to 2 [usable: 2], DeleteGroups(42): 0 to 2 [usable: 2], ElectLeaders(43): 0 to 2 [usable: 2], IncrementalAlterConfigs(44): 0 to 1 [usable: 1], AlterPartitionReassignments(45): 0 [usable: 0], ListPartitionReassignments(46): 0 [usable: 0], OffsetDelete(47): 0 [usable: 0], DescribeClientQuotas(48): 0 to 1 [usable: 1], AlterClientQuotas(49): 0 to 1 [usable: 1], DescribeUserScramCredentials(50): 0 [usable: 0], AlterUserScramCredentials(51): 0 [usable: 0], AlterIsr(56): 0 [usable: 0], UpdateFeatures(57): 0 [usable: 0], DescribeCluster(60): 0 [usable: 0], DescribeProducers(61): 0 [usable: 0], DescribeTransactions(65): 0 [usable: 0], ListTransactions(66): 0 [usable: 0], AllocateProducerIds(67): 0 [usable: 0]). (NetworkClient:921)
[2022-04-03 04:21:13,987] DEBUG [Consumer instanceId=instance361278008, clientId=consumer-my-consumer-group-226369791-instance361278008, groupId=my-consumer-group-226369791] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(topicId=AAAAAAAAAAAAAAAAAAAAAA, name='not-included-topic')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node my-cluster-d884152f-target-kafka-bootstrap.namespace-135.svc:9092 (id: -1 rack: null) (NetworkClient:1139)
[2022-04-03 04:21:13,988] DEBUG [Consumer instanceId=instance361278008, clientId=consumer-my-consumer-group-226369791-instance361278008, groupId=my-consumer-group-226369791] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=12, clientId=consumer-my-consumer-group-226369791-instance361278008, correlationId=2) and timeout 30000 to node -1: MetadataRequestData(topics=[MetadataRequestTopic(topicId=AAAAAAAAAAAAAAAAAAAAAA, name='not-included-topic')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) (NetworkClient:521)
[2022-04-03 04:21:13,989] DEBUG [Consumer instanceId=instance361278008, clientId=consumer-my-consumer-group-226369791-instance361278008, groupId=my-consumer-group-226369791] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=4, clientId=consumer-my-consumer-group-226369791-instance361278008, correlationId=0) and timeout 30000 to node -1: FindCoordinatorRequestData(key='', keyType=0, coordinatorKeys=[my-consumer-group-226369791]) (NetworkClient:521)
[2022-04-03 04:21:14,006] DEBUG [Consumer instanceId=instance361278008, clientId=consumer-my-consumer-group-226369791-instance361278008, groupId=my-consumer-group-226369791] Received METADATA response from node -1 for request with header RequestHeader(apiKey=METADATA, apiVersion=12, clientId=consumer-my-consumer-group-226369791-instance361278008, correlationId=2): MetadataResponseData(throttleTimeMs=0, brokers=[MetadataResponseBroker(nodeId=0, host='my-cluster-d884152f-target-kafka-0.my-cluster-d884152f-target-kafka-brokers.namespace-135.svc', port=9092, rack=null)], clusterId='dlAFjBcRQTqtYrKLgsyvSw', controllerId=0, topics=[MetadataResponseTopic(errorCode=5, name='not-included-topic', topicId=AAAAAAAAAAAAAAAAAAAAAA, isInternal=false, partitions=[], topicAuthorizedOperations=-2147483648)], clusterAuthorizedOperations=-2147483648) (NetworkClient:879)
[2022-04-03 04:21:14,010] WARN [Consumer instanceId=instance361278008, clientId=consumer-my-consumer-group-226369791-instance361278008, groupId=my-consumer-group-226369791] Error while fetching metadata with correlation id 2 : {not-included-topic=LEADER_NOT_AVAILABLE} (NetworkClient:1099)
[2022-04-03 04:21:14,010] DEBUG [Consumer instanceId=instance361278008, clientId=consumer-my-consumer-group-226369791-instance361278008, groupId=my-consumer-group-226369791] Requesting metadata update for topic not-included-topic due to error LEADER_NOT_AVAILABLE (Metadata:363)
[2022-04-03 04:21:14,011] INFO [Consumer instanceId=instance361278008, clientId=consumer-my-consumer-group-226369791-instance361278008, groupId=my-consumer-group-226369791] Cluster ID: dlAFjBcRQTqtYrKLgsyvSw (Metadata:287)
[2022-04-03 04:21:14,011] DEBUG [Consumer instanceId=instance361278008, clientId=consumer-my-consumer-group-226369791-instance361278008, groupId=my-consumer-group-226369791] Updated cluster metadata updateVersion 2 to MetadataCache{clusterId='dlAFjBcRQTqtYrKLgsyvSw', nodes={0=my-cluster-d884152f-target-kafka-0.my-cluster-d884152f-target-kafka-brokers.namespace-135.svc:9092 (id: 0 rack: null)}, partitions=[], controller=my-cluster-d884152f-target-kafka-0.my-cluster-d884152f-target-kafka-brokers.namespace-135.svc:9092 (id: 0 rack: null)} (Metadata:291)
[2022-04-03 04:21:14,012] DEBUG [Consumer instanceId=instance361278008, clientId=consumer-my-consumer-group-226369791-instance361278008, groupId=my-consumer-group-226369791] Received FIND_COORDINATOR response from node -1 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=4, clientId=consumer-my-consumer-group-226369791-instance361278008, correlationId=0): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=0, errorMessage='', nodeId=0, host='', port=0, coordinators=[Coordinator(key='my-consumer-group-226369791', nodeId=0, host='my-cluster-d884152f-target-kafka-0.my-cluster-d884152f-target-kafka-brokers.namespace-135.svc', port=9092, errorCode=0, errorMessage='')]) (NetworkClient:879)
[2022-04-03 04:21:14,013] DEBUG [Consumer instanceId=instance361278008, clientId=consumer-my-consumer-group-226369791-instance361278008, groupId=my-consumer-group-226369791] Received FindCoordinator response ClientResponse(receivedTimeMs=1648959674012, latencyMs=149, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=4, clientId=consumer-my-consumer-group-226369791-instance361278008, correlationId=0), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=0, errorMessage='', nodeId=0, host='', port=0, coordinators=[Coordinator(key='my-consumer-group-226369791', nodeId=0, host='my-cluster-d884152f-target-kafka-0.my-cluster-d884152f-target-kafka-brokers.namespace-135.svc', port=9092, errorCode=0, errorMessage='')])) (ConsumerCoordinator:834)
[2022-04-03 04:21:14,013] INFO [Consumer instanceId=instance361278008, clientId=consumer-my-consumer-group-226369791-instance361278008, groupId=my-consumer-group-226369791] Discovered group coordinator my-cluster-d884152f-target-kafka-0.my-cluster-d884152f-target-kafka-brokers.namespace-135.svc:9092 (id: 2147483647 rack: null) (ConsumerCoordinator:853)
[2022-04-03 04:21:14,015] DEBUG Resolved host my-cluster-d884152f-target-kafka-0.my-cluster-d884152f-target-kafka-brokers.namespace-135.svc as 172.17.0.11 (ClientUtils:113)
[2022-04-03 04:21:14,015] DEBUG [Consumer instanceId=instance361278008, clientId=consumer-my-consumer-group-226369791-instance361278008, groupId=my-consumer-group-226369791] Initiating connection to node my-cluster-d884152f-target-kafka-0.my-cluster-d884152f-target-kafka-brokers.namespace-135.svc:9092 (id: 2147483647 rack: null) using address my-cluster-d884152f-target-kafka-0.my-cluster-d884152f-target-kafka-brokers.namespace-135.svc/172.17.0.11 (NetworkClient:985)
[2022-04-03 04:21:14,017] DEBUG [Consumer instanceId=instance361278008, clientId=consumer-my-consumer-group-226369791-instance361278008, groupId=my-consumer-group-226369791] Executing onJoinPrepare with generation -1 and memberId  (ConsumerCoordinator:700)
[2022-04-03 04:21:14,017] INFO [Consumer instanceId=instance361278008, clientId=consumer-my-consumer-group-226369791-instance361278008, groupId=my-consumer-group-226369791] (Re-)joining group (ConsumerCoordinator:535)
[2022-04-03 04:21:14,018] DEBUG [Consumer instanceId=instance361278008, clientId=consumer-my-consumer-group-226369791-instance361278008, groupId=my-consumer-group-226369791] Joining group with current subscription: [not-included-topic] (ConsumerCoordinator:218)
[2022-04-03 04:21:14,017] DEBUG [Consumer instanceId=instance361278008, clientId=consumer-my-consumer-grou
2022-04-03 04:23:11 [main] [32mINFO [m [VerifiableClient:203] ======STDOUT END======
2022-04-03 04:23:11 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: false
2022-04-03 04:23:11 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 0 messages
2022-04-03 04:23:11 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 04:23:11 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testIncludeList
2022-04-03 04:23:11 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic not-included-topic in namespace namespace-135
2022-04-03 04:23:11 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-d884152f in namespace namespace-135
2022-04-03 04:23:11 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-d884152f-source in namespace namespace-135
2022-04-03 04:23:11 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-d884152f-kafka-clients in namespace namespace-135
2022-04-03 04:23:11 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic included-topic in namespace namespace-135
2022-04-03 04:23:11 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-d884152f-target in namespace namespace-135
2022-04-03 04:24:01 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 04:24:01 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-135 for test case:testIncludeList
2022-04-03 04:24:07 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testIncludeList-FINISHED
2022-04-03 04:24:07 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 04:24:07 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 04:24:07 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testConfigureDeploymentStrategy-STARTED
2022-04-03 04:24:07 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 04:24:07 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-136 for test case:testConfigureDeploymentStrategy
2022-04-03 04:24:07 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-136
2022-04-03 04:24:07 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-136
2022-04-03 04:24:07 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-136
2022-04-03 04:24:07 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-92ccd7d3-source in namespace namespace-136
2022-04-03 04:24:07 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-136
2022-04-03 04:24:07 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-92ccd7d3-source will have desired state: Ready
2022-04-03 04:25:13 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-92ccd7d3-source is in desired state: Ready
2022-04-03 04:25:13 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-92ccd7d3-target in namespace namespace-136
2022-04-03 04:25:13 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-136
2022-04-03 04:25:13 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-92ccd7d3-target will have desired state: Ready
2022-04-03 04:26:18 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-92ccd7d3-target is in desired state: Ready
2022-04-03 04:26:18 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-92ccd7d3 in namespace namespace-136
2022-04-03 04:26:18 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-136
2022-04-03 04:26:18 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-92ccd7d3 will have desired state: Ready
2022-04-03 04:27:24 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-92ccd7d3 is in desired state: Ready
2022-04-03 04:27:24 [main] [32mINFO [m [MirrorMakerIsolatedST:763] Adding label to MirrorMaker resource, the CR should be recreateAndWaitForReadinessd
2022-04-03 04:27:24 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-92ccd7d3-mirror-maker will be ready
2022-04-03 04:27:24 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-92ccd7d3-mirror-maker is ready
2022-04-03 04:27:24 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-92ccd7d3-mirror-maker to be ready
2022-04-03 04:28:48 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-92ccd7d3-mirror-maker is ready
2022-04-03 04:28:48 [main] [32mINFO [m [MirrorMakerIsolatedST:770] Checking that observed gen. is still on 1 (recreation) and new label is present
2022-04-03 04:28:48 [main] [32mINFO [m [MirrorMakerIsolatedST:775] Changing deployment strategy to ROLLING_UPDATE
2022-04-03 04:28:48 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-92ccd7d3 will have desired state: Ready
2022-04-03 04:28:48 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-92ccd7d3 is in desired state: Ready
2022-04-03 04:28:48 [main] [32mINFO [m [MirrorMakerIsolatedST:780] Adding another label to MirrorMaker resource, pods should be rolled
2022-04-03 04:28:48 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-92ccd7d3-mirror-maker will be ready
2022-04-03 04:28:48 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-92ccd7d3-mirror-maker is ready
2022-04-03 04:28:48 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-92ccd7d3-mirror-maker to be ready
2022-04-03 04:30:10 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-92ccd7d3-mirror-maker is ready
2022-04-03 04:30:10 [main] [32mINFO [m [MirrorMakerIsolatedST:784] Checking that observed gen. higher (rolling update) and label is changed
2022-04-03 04:30:10 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 04:30:10 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testConfigureDeploymentStrategy
2022-04-03 04:30:10 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-92ccd7d3-target in namespace namespace-136
2022-04-03 04:30:10 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-92ccd7d3 in namespace namespace-136
2022-04-03 04:30:10 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-92ccd7d3-source in namespace namespace-136
2022-04-03 04:30:30 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 04:30:30 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-136 for test case:testConfigureDeploymentStrategy
2022-04-03 04:30:57 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testConfigureDeploymentStrategy-FINISHED
2022-04-03 04:30:57 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 04:30:57 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 04:30:57 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testScaleMirrorMakerToZero-STARTED
2022-04-03 04:30:57 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 04:30:57 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-137 for test case:testScaleMirrorMakerToZero
2022-04-03 04:30:57 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-137
2022-04-03 04:30:57 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-137
2022-04-03 04:30:57 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-137
2022-04-03 04:30:57 [main] [32mINFO [m [MirrorMakerIsolatedST:713] Creating kafka source cluster my-cluster-b615c1c7-source
2022-04-03 04:30:57 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-b615c1c7-source in namespace namespace-137
2022-04-03 04:30:57 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-137
2022-04-03 04:30:57 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-b615c1c7-source will have desired state: Ready
2022-04-03 04:32:04 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-b615c1c7-source is in desired state: Ready
2022-04-03 04:32:04 [main] [32mINFO [m [MirrorMakerIsolatedST:715] Creating kafka target cluster my-cluster-b615c1c7-target
2022-04-03 04:32:04 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-b615c1c7-target in namespace namespace-137
2022-04-03 04:32:04 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-137
2022-04-03 04:32:04 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-b615c1c7-target will have desired state: Ready
2022-04-03 04:33:13 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-b615c1c7-target is in desired state: Ready
2022-04-03 04:33:13 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-b615c1c7 in namespace namespace-137
2022-04-03 04:33:13 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-137
2022-04-03 04:33:13 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-b615c1c7 will have desired state: Ready
2022-04-03 04:34:19 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-b615c1c7 is in desired state: Ready
2022-04-03 04:34:19 [main] [32mINFO [m [MirrorMakerIsolatedST:725] Scaling MirrorMaker to zero
2022-04-03 04:34:22 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 04:34:22 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testScaleMirrorMakerToZero
2022-04-03 04:34:22 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-b615c1c7-target in namespace namespace-137
2022-04-03 04:34:22 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-b615c1c7 in namespace namespace-137
2022-04-03 04:34:22 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-b615c1c7-source in namespace namespace-137
2022-04-03 04:34:42 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 04:34:42 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-137 for test case:testScaleMirrorMakerToZero
2022-04-03 04:34:48 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testScaleMirrorMakerToZero-FINISHED
2022-04-03 04:34:48 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 04:34:48 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 04:34:48 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testScaleMirrorMakerSubresource-STARTED
2022-04-03 04:34:48 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 04:34:48 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-138 for test case:testScaleMirrorMakerSubresource
2022-04-03 04:34:48 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-138
2022-04-03 04:34:48 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-138
2022-04-03 04:34:48 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-138
2022-04-03 04:34:48 [main] [32mINFO [m [MirrorMakerIsolatedST:674] Creating kafka source cluster my-cluster-b68dd9e7-source
2022-04-03 04:34:48 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-b68dd9e7-source in namespace namespace-138
2022-04-03 04:34:48 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-138
2022-04-03 04:34:48 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-b68dd9e7-source will have desired state: Ready
2022-04-03 04:36:04 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-b68dd9e7-source is in desired state: Ready
2022-04-03 04:36:04 [main] [32mINFO [m [MirrorMakerIsolatedST:676] Creating kafka target cluster my-cluster-b68dd9e7-target
2022-04-03 04:36:04 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-b68dd9e7-target in namespace namespace-138
2022-04-03 04:36:04 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-138
2022-04-03 04:36:04 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-b68dd9e7-target will have desired state: Ready
2022-04-03 04:37:18 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-b68dd9e7-target is in desired state: Ready
2022-04-03 04:37:18 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-b68dd9e7 in namespace namespace-138
2022-04-03 04:37:18 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-138
2022-04-03 04:37:18 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-b68dd9e7 will have desired state: Ready
2022-04-03 04:38:24 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-b68dd9e7 is in desired state: Ready
2022-04-03 04:38:24 [main] [32mINFO [m [MirrorMakerIsolatedST:685] -------> Scaling KafkaMirrorMaker subresource <-------
2022-04-03 04:38:24 [main] [32mINFO [m [MirrorMakerIsolatedST:686] Scaling subresource replicas to 4
2022-04-03 04:38:25 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-b68dd9e7-mirror-maker will be ready
2022-04-03 04:38:25 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-b68dd9e7-mirror-maker is ready
2022-04-03 04:38:25 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 4 Pod(s) of Deployment my-cluster-b68dd9e7-mirror-maker to be ready
2022-04-03 04:39:45 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-b68dd9e7-mirror-maker is ready
2022-04-03 04:39:45 [main] [32mINFO [m [MirrorMakerIsolatedST:690] Check if replicas is set to 4, naming prefix should be same and observed generation higher
2022-04-03 04:39:45 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 04:39:45 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testScaleMirrorMakerSubresource
2022-04-03 04:39:45 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-b68dd9e7-target in namespace namespace-138
2022-04-03 04:39:45 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-b68dd9e7 in namespace namespace-138
2022-04-03 04:39:45 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-b68dd9e7-source in namespace namespace-138
2022-04-03 04:40:05 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 04:40:05 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-138 for test case:testScaleMirrorMakerSubresource
2022-04-03 04:40:10 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testScaleMirrorMakerSubresource-FINISHED
2022-04-03 04:40:10 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 04:40:10 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 04:40:10 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testCustomAndUpdatedValues-STARTED
2022-04-03 04:40:10 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 04:40:10 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-139 for test case:testCustomAndUpdatedValues
2022-04-03 04:40:10 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-139
2022-04-03 04:40:10 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-139
2022-04-03 04:40:10 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-139
2022-04-03 04:40:10 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-ffddeaa1 in namespace namespace-139
2022-04-03 04:40:10 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-139
2022-04-03 04:40:11 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-ffddeaa1 will have desired state: Ready
2022-04-03 04:40:52 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-ffddeaa1 is in desired state: Ready
2022-04-03 04:40:52 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-ffddeaa1 in namespace namespace-139
2022-04-03 04:40:52 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-139
2022-04-03 04:40:52 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-ffddeaa1 will have desired state: Ready
2022-04-03 04:41:29 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-ffddeaa1 is in desired state: Ready
2022-04-03 04:41:29 [main] [32mINFO [m [MirrorMakerIsolatedST:622] Verify values before update
2022-04-03 04:41:29 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-ffddeaa1-mirror-maker in pod name
2022-04-03 04:41:29 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container my-cluster-ffddeaa1-mirror-maker
2022-04-03 04:41:29 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-ffddeaa1-mirror-maker
2022-04-03 04:41:29 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container my-cluster-ffddeaa1-mirror-maker
2022-04-03 04:41:29 [main] [32mINFO [m [AbstractST:190] Getting pods by prefix in name my-cluster-ffddeaa1-mirror-maker
2022-04-03 04:41:29 [main] [32mINFO [m [AbstractST:194] Testing configuration for container my-cluster-ffddeaa1-mirror-maker
2022-04-03 04:41:29 [main] [32mINFO [m [AbstractST:190] Getting pods by prefix in name my-cluster-ffddeaa1-mirror-maker
2022-04-03 04:41:29 [main] [32mINFO [m [AbstractST:194] Testing configuration for container my-cluster-ffddeaa1-mirror-maker
2022-04-03 04:41:29 [main] [32mINFO [m [MirrorMakerIsolatedST:633] Check if actual env variable KAFKA_MIRRORMAKER_CONFIGURATION_PRODUCER has different value than test.value
2022-04-03 04:41:29 [main] [32mINFO [m [MirrorMakerIsolatedST:637] Updating values in MirrorMaker container
2022-04-03 04:41:29 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-ffddeaa1-mirror-maker rolling update
2022-04-03 04:42:14 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-ffddeaa1-mirror-maker will be ready
2022-04-03 04:42:14 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-ffddeaa1-mirror-maker is ready
2022-04-03 04:42:24 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-ffddeaa1-mirror-maker rolling update finished
2022-04-03 04:42:24 [main] [32mINFO [m [MirrorMakerIsolatedST:654] Verify values after update
2022-04-03 04:42:24 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-ffddeaa1-mirror-maker in pod name
2022-04-03 04:42:24 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container my-cluster-ffddeaa1-mirror-maker
2022-04-03 04:42:24 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-ffddeaa1-mirror-maker
2022-04-03 04:42:24 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container my-cluster-ffddeaa1-mirror-maker
2022-04-03 04:42:24 [main] [32mINFO [m [AbstractST:190] Getting pods by prefix in name my-cluster-ffddeaa1-mirror-maker
2022-04-03 04:42:24 [main] [32mINFO [m [AbstractST:194] Testing configuration for container my-cluster-ffddeaa1-mirror-maker
2022-04-03 04:42:24 [main] [32mINFO [m [AbstractST:190] Getting pods by prefix in name my-cluster-ffddeaa1-mirror-maker
2022-04-03 04:42:24 [main] [32mINFO [m [AbstractST:194] Testing configuration for container my-cluster-ffddeaa1-mirror-maker
2022-04-03 04:42:24 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 04:42:24 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCustomAndUpdatedValues
2022-04-03 04:42:24 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-ffddeaa1 in namespace namespace-139
2022-04-03 04:42:24 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-ffddeaa1 in namespace namespace-139
2022-04-03 04:42:34 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 04:42:34 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-139 for test case:testCustomAndUpdatedValues
2022-04-03 04:43:17 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testCustomAndUpdatedValues-FINISHED
2022-04-03 04:43:17 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 04:43:17 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 04:43:17 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testMirrorMaker-STARTED
2022-04-03 04:43:17 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 04:43:17 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-140 for test case:testMirrorMaker
2022-04-03 04:43:17 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-140
2022-04-03 04:43:17 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-140
2022-04-03 04:43:17 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-140
2022-04-03 04:43:17 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-2568a2b0-source in namespace namespace-140
2022-04-03 04:43:17 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-140
2022-04-03 04:43:17 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-2568a2b0-source will have desired state: Ready
2022-04-03 04:44:27 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-2568a2b0-source is in desired state: Ready
2022-04-03 04:44:27 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-2568a2b0-target in namespace namespace-140
2022-04-03 04:44:27 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-140
2022-04-03 04:44:27 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-2568a2b0-target will have desired state: Ready
2022-04-03 04:45:38 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-2568a2b0-target is in desired state: Ready
2022-04-03 04:45:38 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-467311057-683530871-source-1644546317 in namespace namespace-140
2022-04-03 04:45:38 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-140
2022-04-03 04:45:38 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-467311057-683530871-source-1644546317 will have desired state: Ready
2022-04-03 04:45:39 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-467311057-683530871-source-1644546317 is in desired state: Ready
2022-04-03 04:45:39 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-2568a2b0-kafka-clients in namespace namespace-140
2022-04-03 04:45:39 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-140
2022-04-03 04:45:39 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-2568a2b0-kafka-clients will be ready
2022-04-03 04:45:42 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-2568a2b0-kafka-clients is ready
2022-04-03 04:45:42 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-03 04:45:42 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@24cb7161, messages=[], arguments=[--max-messages, 200, --topic, topic-for-test-broker-1, --bootstrap-server, my-cluster-2568a2b0-source-kafka-bootstrap.namespace-140.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-2568a2b0-kafka-clients-5569b99487-xfsgs', podNamespace='namespace-140', bootstrapServer='my-cluster-2568a2b0-source-kafka-bootstrap.namespace-140.svc:9092', topicName='topic-for-test-broker-1', maxMessages=200, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3e88dc68}
2022-04-03 04:45:42 [main] [32mINFO [m [InternalKafkaClient:94] Producing 200 messages to my-cluster-2568a2b0-source-kafka-bootstrap.namespace-140.svc:9092:topic-for-test-broker-1 from pod my-cluster-2568a2b0-kafka-clients-5569b99487-xfsgs
2022-04-03 04:45:42 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-2568a2b0-kafka-clients-5569b99487-xfsgs -n namespace-140 -- /opt/kafka/producer.sh --max-messages 200 --topic topic-for-test-broker-1 --bootstrap-server my-cluster-2568a2b0-source-kafka-bootstrap.namespace-140.svc:9092
2022-04-03 04:45:44 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-03 04:45:44 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 200 messages
2022-04-03 04:45:44 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@6daf351d, messages=[], arguments=[--max-messages, 200, --group-instance-id, instance826695497, --group-id, my-consumer-group-1975651977, --topic, topic-for-test-broker-1, --bootstrap-server, my-cluster-2568a2b0-source-kafka-bootstrap.namespace-140.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-2568a2b0-kafka-clients-5569b99487-xfsgs', podNamespace='namespace-140', bootstrapServer='my-cluster-2568a2b0-source-kafka-bootstrap.namespace-140.svc:9092', topicName='topic-for-test-broker-1', maxMessages=200, kafkaUsername='null', consumerGroupName='my-consumer-group-1975651977', consumerInstanceId='instance826695497', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@153cd04e}
2022-04-03 04:45:44 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 200 messages from my-cluster-2568a2b0-source-kafka-bootstrap.namespace-140.svc:9092#topic-for-test-broker-1 from pod my-cluster-2568a2b0-kafka-clients-5569b99487-xfsgs
2022-04-03 04:45:44 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-2568a2b0-kafka-clients-5569b99487-xfsgs -n namespace-140 -- /opt/kafka/consumer.sh --max-messages 200 --group-instance-id instance826695497 --group-id my-consumer-group-1975651977 --topic topic-for-test-broker-1 --bootstrap-server my-cluster-2568a2b0-source-kafka-bootstrap.namespace-140.svc:9092
2022-04-03 04:45:50 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-03 04:45:50 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 200 messages
2022-04-03 04:45:50 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@1b9782d9, messages=[], arguments=[--max-messages, 200, --topic, topic-for-test-broker-2, --bootstrap-server, my-cluster-2568a2b0-target-kafka-bootstrap.namespace-140.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-2568a2b0-kafka-clients-5569b99487-xfsgs', podNamespace='namespace-140', bootstrapServer='my-cluster-2568a2b0-target-kafka-bootstrap.namespace-140.svc:9092', topicName='topic-for-test-broker-2', maxMessages=200, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@121001b0}
2022-04-03 04:45:50 [main] [32mINFO [m [InternalKafkaClient:94] Producing 200 messages to my-cluster-2568a2b0-target-kafka-bootstrap.namespace-140.svc:9092:topic-for-test-broker-2 from pod my-cluster-2568a2b0-kafka-clients-5569b99487-xfsgs
2022-04-03 04:45:50 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-2568a2b0-kafka-clients-5569b99487-xfsgs -n namespace-140 -- /opt/kafka/producer.sh --max-messages 200 --topic topic-for-test-broker-2 --bootstrap-server my-cluster-2568a2b0-target-kafka-bootstrap.namespace-140.svc:9092
2022-04-03 04:45:52 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-03 04:45:52 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 200 messages
2022-04-03 04:45:52 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@7c49488e, messages=[], arguments=[--max-messages, 200, --group-instance-id, instance1769668857, --group-id, my-consumer-group-543900920, --topic, topic-for-test-broker-2, --bootstrap-server, my-cluster-2568a2b0-target-kafka-bootstrap.namespace-140.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-2568a2b0-kafka-clients-5569b99487-xfsgs', podNamespace='namespace-140', bootstrapServer='my-cluster-2568a2b0-target-kafka-bootstrap.namespace-140.svc:9092', topicName='topic-for-test-broker-2', maxMessages=200, kafkaUsername='null', consumerGroupName='my-consumer-group-543900920', consumerInstanceId='instance1769668857', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@685a8f45}
2022-04-03 04:45:52 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 200 messages from my-cluster-2568a2b0-target-kafka-bootstrap.namespace-140.svc:9092#topic-for-test-broker-2 from pod my-cluster-2568a2b0-kafka-clients-5569b99487-xfsgs
2022-04-03 04:45:52 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-2568a2b0-kafka-clients-5569b99487-xfsgs -n namespace-140 -- /opt/kafka/consumer.sh --max-messages 200 --group-instance-id instance1769668857 --group-id my-consumer-group-543900920 --topic topic-for-test-broker-2 --bootstrap-server my-cluster-2568a2b0-target-kafka-bootstrap.namespace-140.svc:9092
2022-04-03 04:45:58 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-03 04:45:58 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 200 messages
2022-04-03 04:45:58 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-2568a2b0 in namespace namespace-140
2022-04-03 04:45:58 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-140
2022-04-03 04:45:58 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-2568a2b0 will have desired state: Ready
2022-04-03 04:47:01 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-2568a2b0 is in desired state: Ready
2022-04-03 04:47:01 [main] [32mINFO [m [AbstractST:311] Verifying labels on pod type mirror-maker
2022-04-03 04:47:01 [main] [32mINFO [m [AbstractST:315] Verifying labels for pod: my-cluster-2568a2b0-mirror-maker-55f6487f57-zl22m
2022-04-03 04:47:01 [main] [32mINFO [m [AbstractST:356] Verifying labels for Kafka Connect Services
2022-04-03 04:47:01 [main] [32mINFO [m [AbstractST:384] Verifying labels for Config maps
2022-04-03 04:47:01 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-2568a2b0-mirror-maker-config
2022-04-03 04:47:01 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-2568a2b0-source-entity-topic-operator-config
2022-04-03 04:47:01 [main] [32mINFO [m [AbstractST:407] CM my-cluster-2568a2b0-source-entity-topic-operator-config is not related to current test
2022-04-03 04:47:01 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-2568a2b0-source-entity-user-operator-config
2022-04-03 04:47:01 [main] [32mINFO [m [AbstractST:407] CM my-cluster-2568a2b0-source-entity-user-operator-config is not related to current test
2022-04-03 04:47:01 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-2568a2b0-source-kafka-config
2022-04-03 04:47:01 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-2568a2b0-source-zookeeper-config
2022-04-03 04:47:01 [main] [32mINFO [m [AbstractST:407] CM my-cluster-2568a2b0-source-zookeeper-config is not related to current test
2022-04-03 04:47:01 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-2568a2b0-target-entity-topic-operator-config
2022-04-03 04:47:01 [main] [32mINFO [m [AbstractST:407] CM my-cluster-2568a2b0-target-entity-topic-operator-config is not related to current test
2022-04-03 04:47:01 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-2568a2b0-target-entity-user-operator-config
2022-04-03 04:47:01 [main] [32mINFO [m [AbstractST:407] CM my-cluster-2568a2b0-target-entity-user-operator-config is not related to current test
2022-04-03 04:47:01 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-2568a2b0-target-kafka-config
2022-04-03 04:47:01 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-2568a2b0-target-zookeeper-config
2022-04-03 04:47:01 [main] [32mINFO [m [AbstractST:407] CM my-cluster-2568a2b0-target-zookeeper-config is not related to current test
2022-04-03 04:47:01 [main] [32mINFO [m [AbstractST:414] Verifying labels for Service Accounts
2022-04-03 04:47:01 [main] [32mINFO [m [AbstractST:427] Verifying labels for service account my-cluster-2568a2b0-source-entity-operator
2022-04-03 04:47:01 [main] [32mINFO [m [AbstractST:427] Verifying labels for service account my-cluster-2568a2b0-source-kafka
2022-04-03 04:47:01 [main] [32mINFO [m [AbstractST:427] Verifying labels for service account my-cluster-2568a2b0-source-zookeeper
2022-04-03 04:47:02 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-140 exec my-cluster-2568a2b0-mirror-maker-55f6487f57-zl22m -c my-cluster-2568a2b0-mirror-maker -- /bin/bash -c for proc in $(ls -1 /proc/ | grep [0-9]); do if echo "$(ls -lh /proc/$proc/exe 2>/dev/null || true)" | grep -q java; then cat /proc/$proc/cmdline; fi; done
2022-04-03 04:47:02 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-03 04:47:02 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@1b80c49f, messages=[], arguments=[--max-messages, 200, --topic, my-topic-467311057-683530871-source-1644546317, --bootstrap-server, my-cluster-2568a2b0-source-kafka-bootstrap.namespace-140.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-2568a2b0-kafka-clients-5569b99487-xfsgs', podNamespace='namespace-140', bootstrapServer='my-cluster-2568a2b0-source-kafka-bootstrap.namespace-140.svc:9092', topicName='my-topic-467311057-683530871-source-1644546317', maxMessages=200, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@4347a8ba}
2022-04-03 04:47:02 [main] [32mINFO [m [InternalKafkaClient:94] Producing 200 messages to my-cluster-2568a2b0-source-kafka-bootstrap.namespace-140.svc:9092:my-topic-467311057-683530871-source-1644546317 from pod my-cluster-2568a2b0-kafka-clients-5569b99487-xfsgs
2022-04-03 04:47:02 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-2568a2b0-kafka-clients-5569b99487-xfsgs -n namespace-140 -- /opt/kafka/producer.sh --max-messages 200 --topic my-topic-467311057-683530871-source-1644546317 --bootstrap-server my-cluster-2568a2b0-source-kafka-bootstrap.namespace-140.svc:9092
2022-04-03 04:47:04 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-03 04:47:04 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 200 messages
2022-04-03 04:47:04 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@43b25917, messages=[], arguments=[--max-messages, 200, --group-instance-id, instance1184154625, --group-id, my-consumer-group-193209786, --topic, my-topic-467311057-683530871-source-1644546317, --bootstrap-server, my-cluster-2568a2b0-source-kafka-bootstrap.namespace-140.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-2568a2b0-kafka-clients-5569b99487-xfsgs', podNamespace='namespace-140', bootstrapServer='my-cluster-2568a2b0-source-kafka-bootstrap.namespace-140.svc:9092', topicName='my-topic-467311057-683530871-source-1644546317', maxMessages=200, kafkaUsername='null', consumerGroupName='my-consumer-group-193209786', consumerInstanceId='instance1184154625', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5242a9f7}
2022-04-03 04:47:04 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 200 messages from my-cluster-2568a2b0-source-kafka-bootstrap.namespace-140.svc:9092#my-topic-467311057-683530871-source-1644546317 from pod my-cluster-2568a2b0-kafka-clients-5569b99487-xfsgs
2022-04-03 04:47:04 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-2568a2b0-kafka-clients-5569b99487-xfsgs -n namespace-140 -- /opt/kafka/consumer.sh --max-messages 200 --group-instance-id instance1184154625 --group-id my-consumer-group-193209786 --topic my-topic-467311057-683530871-source-1644546317 --bootstrap-server my-cluster-2568a2b0-source-kafka-bootstrap.namespace-140.svc:9092
2022-04-03 04:47:10 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-03 04:47:10 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 200 messages
2022-04-03 04:47:10 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@20f7b4b9, messages=[], arguments=[--max-messages, 200, --group-instance-id, instance1180345654, --group-id, my-consumer-group-386975213, --topic, my-topic-467311057-683530871-source-1644546317, --bootstrap-server, my-cluster-2568a2b0-target-kafka-bootstrap.namespace-140.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-2568a2b0-kafka-clients-5569b99487-xfsgs', podNamespace='namespace-140', bootstrapServer='my-cluster-2568a2b0-target-kafka-bootstrap.namespace-140.svc:9092', topicName='my-topic-467311057-683530871-source-1644546317', maxMessages=200, kafkaUsername='null', consumerGroupName='my-consumer-group-386975213', consumerInstanceId='instance1180345654', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3dce2ba3}
2022-04-03 04:47:10 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 200 messages from my-cluster-2568a2b0-target-kafka-bootstrap.namespace-140.svc:9092#my-topic-467311057-683530871-source-1644546317 from pod my-cluster-2568a2b0-kafka-clients-5569b99487-xfsgs
2022-04-03 04:47:10 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-2568a2b0-kafka-clients-5569b99487-xfsgs -n namespace-140 -- /opt/kafka/consumer.sh --max-messages 200 --group-instance-id instance1180345654 --group-id my-consumer-group-386975213 --topic my-topic-467311057-683530871-source-1644546317 --bootstrap-server my-cluster-2568a2b0-target-kafka-bootstrap.namespace-140.svc:9092
2022-04-03 04:47:16 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-03 04:47:16 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 200 messages
2022-04-03 04:47:16 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 04:47:16 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMirrorMaker
2022-04-03 04:47:16 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-467311057-683530871-source-1644546317 in namespace namespace-140
2022-04-03 04:47:16 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-2568a2b0-source in namespace namespace-140
2022-04-03 04:47:16 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-2568a2b0-target in namespace namespace-140
2022-04-03 04:47:16 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-2568a2b0-kafka-clients in namespace namespace-140
2022-04-03 04:47:16 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-2568a2b0 in namespace namespace-140
2022-04-03 04:48:06 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 04:48:06 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-140 for test case:testMirrorMaker
2022-04-03 04:48:11 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testMirrorMaker-FINISHED
2022-04-03 04:48:11 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 04:48:11 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 04:48:11 [main] [32mINFO [m [ResourceManager:346] In context MirrorMakerIsolatedST is everything deleted.
2022-04-03 04:48:11 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2,554.203 s - in io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.metrics.MetricsIsolatedST
2022-04-03 04:48:11 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-03 04:48:36 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-03 04:48:36 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-03 04:48:36 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-03 04:48:36 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 04:48:36 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-03 04:48:36 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-03 04:48:36 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-03 04:48:36 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-03 04:48:36 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-03 04:48:36 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 04:48:36 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-03 04:48:36 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-03 04:48:36 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 04:48:36 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-03 04:48:36 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-03 04:48:36 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-03 04:48:36 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-03 04:48:36 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-03 04:48:36 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-03 04:48:36 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-03 04:48:36 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-03 04:48:36 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-03 04:48:36 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-03 04:48:36 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-03 04:48:36 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-03 04:48:46 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-03 04:48:46 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-03 04:48:46 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-03 04:48:46 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-03 04:48:46 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-03 04:48:56 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 04:49:01 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7e2e5e3d
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace,second-metrics-cluster-test
bindingsNamespaces=[infra-namespace, second-metrics-cluster-test]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-03 04:49:01 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-03 04:49:01 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-03 04:49:01 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: second-metrics-cluster-test
2022-04-03 04:49:01 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-03 04:49:01 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-03 04:49:01 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 04:49:01 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-03 04:49:01 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-03 04:49:01 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-03 04:49:01 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-03 04:49:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-03 04:49:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-03 04:49:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-03 04:49:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-03 04:49:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-03 04:49:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-03 04:49:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-03 04:49:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-03 04:49:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-03 04:49:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-03 04:49:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-03 04:49:02 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-03 04:49:02 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: second-metrics-cluster-test
2022-04-03 04:49:02 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-03 04:49:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-03 04:49:02 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-03 04:49:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-03 04:49:02 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-03 04:49:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-03 04:49:02 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-03 04:49:02 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-03 04:49:02 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-03 04:49:02 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-03 04:49:02 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-03 04:49:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-03 04:49:02 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-03 04:49:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-03 04:49:02 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-03 04:49:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-03 04:49:02 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-03 04:49:02 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace second-metrics-cluster-test
2022-04-03 04:49:02 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-03 04:49:02 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace second-metrics-cluster-test
2022-04-03 04:49:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-03 04:49:02 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-03 04:49:23 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-03 04:49:23 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-03 04:49:33 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-03 04:49:33 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-03 04:49:33 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka metrics-cluster-name in namespace infra-namespace
2022-04-03 04:49:33 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka second-kafka-cluster in namespace second-metrics-cluster-test
2022-04-03 04:49:33 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment infra-namespace-kafka-clients in namespace infra-namespace
2022-04-03 04:49:33 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment second-metrics-cluster-test-kafka-clients in namespace second-metrics-cluster-test
2022-04-03 04:49:33 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: metrics-cluster-name will have desired state: Ready
2022-04-03 04:53:12 [main] [32mINFO [m [ResourceManager:444] Kafka: metrics-cluster-name is in desired state: Ready
2022-04-03 04:53:12 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: second-kafka-cluster will have desired state: Ready
2022-04-03 04:53:12 [main] [32mINFO [m [ResourceManager:444] Kafka: second-kafka-cluster is in desired state: Ready
2022-04-03 04:53:12 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: infra-namespace-kafka-clients will be ready
2022-04-03 04:53:12 [main] [32mINFO [m [DeploymentUtils:168] Deployment: infra-namespace-kafka-clients is ready
2022-04-03 04:53:12 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: second-metrics-cluster-test-kafka-clients will be ready
2022-04-03 04:53:12 [main] [32mINFO [m [DeploymentUtils:168] Deployment: second-metrics-cluster-test-kafka-clients is ready
2022-04-03 04:53:12 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge my-bridge in namespace infra-namespace
2022-04-03 04:53:12 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: my-bridge will have desired state: Ready
2022-04-03 04:53:39 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: my-bridge is in desired state: Ready
2022-04-03 04:53:39 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 mm2-cluster in namespace infra-namespace
2022-04-03 04:53:39 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: mm2-cluster will have desired state: Ready
2022-04-03 04:54:48 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: mm2-cluster is in desired state: Ready
2022-04-03 04:54:48 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-390174085-526226873 in namespace infra-namespace
2022-04-03 04:54:48 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-390174085-526226873 will have desired state: Ready
2022-04-03 04:54:49 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-390174085-526226873 is in desired state: Ready
2022-04-03 04:54:49 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-289553630-116824254 in namespace infra-namespace
2022-04-03 04:54:49 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-289553630-116824254 will have desired state: Ready
2022-04-03 04:54:50 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-289553630-116824254 is in desired state: Ready
2022-04-03 04:54:50 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-598170036-1467726275 in namespace infra-namespace
2022-04-03 04:54:50 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-598170036-1467726275 will have desired state: Ready
2022-04-03 04:54:52 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-598170036-1467726275 is in desired state: Ready
2022-04-03 04:54:52 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1956897560-1478932307 in namespace infra-namespace
2022-04-03 04:54:52 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1956897560-1478932307 will have desired state: Ready
2022-04-03 04:54:53 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1956897560-1478932307 is in desired state: Ready
2022-04-03 04:54:53 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-751448899-1775520553 in namespace infra-namespace
2022-04-03 04:54:53 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-751448899-1775520553 will have desired state: Ready
2022-04-03 04:54:54 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-751448899-1775520553 is in desired state: Ready
2022-04-03 04:54:54 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect metrics-cluster-name in namespace infra-namespace
2022-04-03 04:54:54 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: metrics-cluster-name will have desired state: Ready
2022-04-03 04:56:06 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: metrics-cluster-name is in desired state: Ready
2022-04-03 04:56:06 [main] [32mINFO [m [NetworkPolicyResource:72] Apply NetworkPolicy access to cluster-operator from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={})
2022-04-03 04:56:06 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy cluster-operator-allow in namespace infra-namespace
2022-04-03 04:56:06 [main] [32mINFO [m [NetworkPolicyResource:90] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={}) successfully created
2022-04-03 04:56:06 [main] [32mINFO [m [NetworkPolicyResource:104] Apply NetworkPolicy access to metrics-cluster-name-entity-operator from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={})
2022-04-03 04:56:06 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy metrics-cluster-name-entity-operator-allow in namespace infra-namespace
2022-04-03 04:56:06 [main] [32mINFO [m [NetworkPolicyResource:128] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={}) successfully created
2022-04-03 04:56:06 [main] [32mINFO [m [NetworkPolicyResource:104] Apply NetworkPolicy access to second-kafka-cluster-entity-operator from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={})
2022-04-03 04:56:06 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy second-kafka-cluster-entity-operator-allow in namespace second-metrics-cluster-test
2022-04-03 04:56:06 [main] [32mINFO [m [NetworkPolicyResource:128] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={}) successfully created
2022-04-03 04:56:06 [main] [32mINFO [m [NetworkPolicyResource:141] Apply NetworkPolicy access to metrics-cluster-name-kafka-exporter from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={})
2022-04-03 04:56:06 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy metrics-cluster-name-kafka-exporter-allow in namespace infra-namespace
2022-04-03 04:56:06 [main] [32mINFO [m [NetworkPolicyResource:161] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={}) successfully created
2022-04-03 04:56:06 [main] [32mINFO [m [NetworkPolicyResource:141] Apply NetworkPolicy access to second-kafka-cluster-kafka-exporter from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={})
2022-04-03 04:56:06 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy second-kafka-cluster-kafka-exporter-allow in namespace second-metrics-cluster-test
2022-04-03 04:56:06 [main] [32mINFO [m [NetworkPolicyResource:161] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={}) successfully created
2022-04-03 04:57:28 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.17 from Pod infra-namespace-kafka-clients-748578f786-rm9cd finished with return code: 0
2022-04-03 04:57:30 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.16 from Pod infra-namespace-kafka-clients-748578f786-rm9cd finished with return code: 0
2022-04-03 04:57:32 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.18 from Pod infra-namespace-kafka-clients-748578f786-rm9cd finished with return code: 0
2022-04-03 04:57:32 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.11 from Pod infra-namespace-kafka-clients-748578f786-rm9cd finished with return code: 0
2022-04-03 04:57:33 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.9 from Pod infra-namespace-kafka-clients-748578f786-rm9cd finished with return code: 0
2022-04-03 04:57:33 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.10 from Pod infra-namespace-kafka-clients-748578f786-rm9cd finished with return code: 0
2022-04-03 04:57:34 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.24 from Pod infra-namespace-kafka-clients-748578f786-rm9cd finished with return code: 0
2022-04-03 04:57:34 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.21 from Pod infra-namespace-kafka-clients-748578f786-rm9cd finished with return code: 0
2022-04-03 04:57:34 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 04:57:34 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testUserOperatorMetrics-STARTED
2022-04-03 04:57:34 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 04:57:35 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.19 from Pod infra-namespace-kafka-clients-748578f786-rm9cd finished with return code: 0
2022-04-03 04:57:35 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 04:57:35 [main] [32mINFO [m [ResourceManager:346] In context testUserOperatorMetrics is everything deleted.
2022-04-03 04:57:35 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 04:57:35 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testUserOperatorMetrics-FINISHED
2022-04-03 04:57:35 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 04:57:35 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 04:57:35 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testZookeeperWatchersCount-STARTED
2022-04-03 04:57:35 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 04:57:35 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 04:57:35 [main] [32mINFO [m [ResourceManager:346] In context testZookeeperWatchersCount is everything deleted.
2022-04-03 04:57:35 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 04:57:35 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testZookeeperWatchersCount-FINISHED
2022-04-03 04:57:35 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 04:57:35 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 04:57:35 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaConnectIoNetwork-STARTED
2022-04-03 04:57:35 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 04:57:35 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.24 from Pod infra-namespace-kafka-clients-748578f786-rm9cd finished with return code: 0
2022-04-03 04:57:35 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 04:57:35 [main] [32mINFO [m [ResourceManager:346] In context testKafkaConnectIoNetwork is everything deleted.
2022-04-03 04:57:35 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 04:57:35 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaConnectIoNetwork-FINISHED
2022-04-03 04:57:35 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 04:57:35 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 04:57:35 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaBrokersCount-STARTED
2022-04-03 04:57:35 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 04:57:35 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 04:57:35 [main] [32mINFO [m [ResourceManager:346] In context testKafkaBrokersCount is everything deleted.
2022-04-03 04:57:35 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 04:57:35 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaBrokersCount-FINISHED
2022-04-03 04:57:35 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 04:57:35 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 04:57:35 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaActiveControllers-STARTED
2022-04-03 04:57:35 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 04:57:35 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 04:57:35 [main] [32mINFO [m [ResourceManager:346] In context testKafkaActiveControllers is everything deleted.
2022-04-03 04:57:35 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 04:57:35 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaActiveControllers-FINISHED
2022-04-03 04:57:35 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 04:57:35 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 04:57:35 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaTopicUnderReplicatedPartitions-STARTED
2022-04-03 04:57:35 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 04:57:35 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 04:57:35 [main] [32mINFO [m [ResourceManager:346] In context testKafkaTopicUnderReplicatedPartitions is everything deleted.
2022-04-03 04:57:35 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 04:57:35 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaTopicUnderReplicatedPartitions-FINISHED
2022-04-03 04:57:35 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 04:57:35 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 04:57:35 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testZookeeperQuorumSize-STARTED
2022-04-03 04:57:35 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 04:57:35 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 04:57:35 [main] [32mINFO [m [ResourceManager:346] In context testZookeeperQuorumSize is everything deleted.
2022-04-03 04:57:35 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 04:57:35 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testZookeeperQuorumSize-FINISHED
2022-04-03 04:57:35 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 04:57:35 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 04:57:35 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testZookeeperAliveConnections-STARTED
2022-04-03 04:57:35 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 04:57:35 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 04:57:35 [main] [32mINFO [m [ResourceManager:346] In context testZookeeperAliveConnections is everything deleted.
2022-04-03 04:57:35 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 04:57:35 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testZookeeperAliveConnections-FINISHED
2022-04-03 04:57:35 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 04:57:35 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 04:57:35 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaTopicPartitions-STARTED
2022-04-03 04:57:35 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 04:57:35 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 04:57:35 [main] [32mINFO [m [ResourceManager:346] In context testKafkaTopicPartitions is everything deleted.
2022-04-03 04:57:35 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 04:57:35 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaTopicPartitions-FINISHED
2022-04-03 04:57:35 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 04:57:35 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 04:57:35 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testReconcileStateMetricInTopicOperator-STARTED
2022-04-03 04:57:35 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 04:57:35 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-metrics-cluster-test
2022-04-03 04:57:35 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1304257804-1424045912 in namespace second-metrics-cluster-test
2022-04-03 04:57:35 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1304257804-1424045912 will have desired state: Ready
2022-04-03 04:57:36 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1304257804-1424045912 is in desired state: Ready
2022-04-03 04:57:36 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.14 from Pod second-metrics-cluster-test-kafka-clients-6c57d6898-72sr9 finished with return code: 0
2022-04-03 04:57:36 [main] [32mINFO [m [MetricsIsolatedST:555] Checking if resource state metric reason message is "none" and KafkaTopic is ready
2022-04-03 04:57:36 [main] [32mINFO [m [MetricsIsolatedST:558] Changing topic name in spec.topicName
2022-04-03 04:57:36 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1304257804-1424045912 will have desired state: NotReady
2022-04-03 04:57:37 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1304257804-1424045912 is in desired state: NotReady
2022-04-03 04:57:38 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.14 from Pod second-metrics-cluster-test-kafka-clients-6c57d6898-72sr9 finished with return code: 0
2022-04-03 04:57:38 [main] [32mINFO [m [MetricsIsolatedST:566] Changing back to it's original name and scaling replicas to be higher number
2022-04-03 04:57:38 [main] [32mINFO [m [KafkaTopicUtils:132] Waiting for KafkaTopic change my-topic-1304257804-1424045912
2022-04-03 04:57:38 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.14 from Pod second-metrics-cluster-test-kafka-clients-6c57d6898-72sr9 finished with return code: 0
2022-04-03 04:57:38 [main] [32mINFO [m [MetricsIsolatedST:578] Scaling replicas to be higher than before
2022-04-03 04:57:38 [main] [32mINFO [m [KafkaTopicUtils:132] Waiting for KafkaTopic change my-topic-1304257804-1424045912
2022-04-03 04:57:38 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.14 from Pod second-metrics-cluster-test-kafka-clients-6c57d6898-72sr9 finished with return code: 0
2022-04-03 04:57:38 [main] [32mINFO [m [MetricsIsolatedST:586] Changing KafkaTopic's spec to correct state
2022-04-03 04:57:38 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1304257804-1424045912 will have desired state: Ready
2022-04-03 04:57:39 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1304257804-1424045912 is in desired state: Ready
2022-04-03 04:57:39 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.14 from Pod second-metrics-cluster-test-kafka-clients-6c57d6898-72sr9 finished with return code: 0
2022-04-03 04:57:39 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-03 04:57:39 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 04:57:39 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testReconcileStateMetricInTopicOperator
2022-04-03 04:57:39 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1304257804-1424045912 in namespace second-metrics-cluster-test
2022-04-03 04:57:49 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 04:57:49 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testReconcileStateMetricInTopicOperator-FINISHED
2022-04-03 04:57:49 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 04:57:49 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 04:57:49 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testMirrorMaker2Metrics-STARTED
2022-04-03 04:57:49 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 04:57:50 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.23 from Pod infra-namespace-kafka-clients-748578f786-rm9cd finished with return code: 0
2022-04-03 04:57:50 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 04:57:50 [main] [32mINFO [m [ResourceManager:346] In context testMirrorMaker2Metrics is everything deleted.
2022-04-03 04:57:50 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 04:57:50 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testMirrorMaker2Metrics-FINISHED
2022-04-03 04:57:50 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 04:57:50 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 04:57:50 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaBridgeMetrics-STARTED
2022-04-03 04:57:50 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 04:57:50 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-03 04:57:50 [main] [32mINFO [m [ResourceManager:155] Create/Update Job bridge-producer in namespace infra-namespace
2022-04-03 04:57:50 [main] [32mINFO [m [JobUtils:81] Waiting for job: bridge-producer will be in active state
2022-04-03 04:57:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Job bridge-consumer in namespace infra-namespace
2022-04-03 04:57:51 [main] [32mINFO [m [JobUtils:81] Waiting for job: bridge-consumer will be in active state
2022-04-03 04:57:52 [main] [32mINFO [m [MetricsIsolatedST:422] Looking for 'strimzi_bridge_kafka_producer_count' in bridge metrics
2022-04-03 04:57:53 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.22 from Pod infra-namespace-kafka-clients-748578f786-rm9cd finished with return code: 0
2022-04-03 04:57:53 [main] [32mINFO [m [MetricsIsolatedST:430] Looking for 'strimzi_bridge_kafka_consumer_connection_count' in bridge metrics
2022-04-03 04:57:53 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.22 from Pod infra-namespace-kafka-clients-748578f786-rm9cd finished with return code: 0
2022-04-03 04:57:54 [main] [32mINFO [m [MetricsIsolatedST:430] Looking for 'strimzi_bridge_kafka_consumer_connection_count' in bridge metrics
2022-04-03 04:57:54 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.22 from Pod infra-namespace-kafka-clients-748578f786-rm9cd finished with return code: 0
2022-04-03 04:57:54 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 04:57:54 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaBridgeMetrics
2022-04-03 04:57:54 [main] [32mINFO [m [ResourceManager:241] Delete of Job bridge-consumer in namespace infra-namespace
2022-04-03 04:57:54 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job bridge-producer in namespace infra-namespace
2022-04-03 04:57:54 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 04:57:54 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaBridgeMetrics-FINISHED
2022-04-03 04:57:54 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 04:57:54 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 04:57:54 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaMetricsSettings-STARTED
2022-04-03 04:57:54 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 04:57:54 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: second-kafka-cluster are stable
2022-04-03 04:57:55 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 50
2022-04-03 04:57:55 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-03 04:57:55 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-03 04:57:55 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-03 04:57:56 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 49
2022-04-03 04:57:56 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-03 04:57:56 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-03 04:57:56 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-03 04:57:57 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 48
2022-04-03 04:57:57 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-03 04:57:57 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-03 04:57:57 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-03 04:57:58 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 47
2022-04-03 04:57:58 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-03 04:57:58 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-03 04:57:58 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-03 04:57:59 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 46
2022-04-03 04:57:59 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-03 04:57:59 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-03 04:57:59 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-03 04:58:00 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 45
2022-04-03 04:58:00 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-03 04:58:00 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-03 04:58:00 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-03 04:58:01 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 44
2022-04-03 04:58:01 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-03 04:58:01 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-03 04:58:01 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-03 04:58:02 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 43
2022-04-03 04:58:02 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-03 04:58:02 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-03 04:58:02 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-03 04:58:03 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 42
2022-04-03 04:58:03 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-03 04:58:03 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-03 04:58:03 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-03 04:58:04 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 41
2022-04-03 04:58:04 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-03 04:58:04 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-03 04:58:04 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-03 04:58:05 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 40
2022-04-03 04:58:05 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-03 04:58:05 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-03 04:58:05 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-03 04:58:06 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 39
2022-04-03 04:58:06 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-03 04:58:06 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-03 04:58:06 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-03 04:58:07 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 38
2022-04-03 04:58:07 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-03 04:58:07 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-03 04:58:07 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-03 04:58:08 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 37
2022-04-03 04:58:08 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-03 04:58:08 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-03 04:58:08 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-03 04:58:09 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 36
2022-04-03 04:58:09 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-03 04:58:09 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-03 04:58:09 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-03 04:58:10 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 35
2022-04-03 04:58:10 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-03 04:58:10 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-03 04:58:10 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-03 04:58:11 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 34
2022-04-03 04:58:11 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-03 04:58:11 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-03 04:58:11 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-03 04:58:12 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 33
2022-04-03 04:58:12 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-03 04:58:12 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-03 04:58:12 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-03 04:58:13 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 32
2022-04-03 04:58:13 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-03 04:58:13 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-03 04:58:13 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-03 04:58:14 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 31
2022-04-03 04:58:14 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-03 04:58:14 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-03 04:58:14 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-03 04:58:15 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 30
2022-04-03 04:58:15 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-03 04:58:15 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-03 04:58:15 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-03 04:58:16 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 29
2022-04-03 04:58:16 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-03 04:58:16 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-03 04:58:16 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-03 04:58:17 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 28
2022-04-03 04:58:17 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-03 04:58:17 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-03 04:58:17 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-03 04:58:18 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 27
2022-04-03 04:58:18 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-03 04:58:18 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-03 04:58:18 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-03 04:58:19 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 26
2022-04-03 04:58:19 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-03 04:58:19 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-03 04:58:19 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-03 04:58:20 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 25
2022-04-03 04:58:20 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-03 04:58:20 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-03 04:58:20 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-03 04:58:21 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 24
2022-04-03 04:58:21 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-03 04:58:21 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-03 04:58:21 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-03 04:58:22 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 23
2022-04-03 04:58:22 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-03 04:58:22 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-03 04:58:22 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-03 04:58:23 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 22
2022-04-03 04:58:23 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-03 04:58:23 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-03 04:58:23 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-03 04:58:24 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 21
2022-04-03 04:58:24 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-03 04:58:24 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-03 04:58:24 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-03 04:58:25 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 20
2022-04-03 04:58:25 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-03 04:58:25 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-03 04:58:25 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-03 04:58:26 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 19
2022-04-03 04:58:26 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-03 04:58:26 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-03 04:58:26 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-03 04:58:27 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 18
2022-04-03 04:58:27 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-03 04:58:27 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-03 04:58:27 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-03 04:58:28 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 17
2022-04-03 04:58:28 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-03 04:58:28 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-03 04:58:28 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-03 04:58:29 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 16
2022-04-03 04:58:29 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-03 04:58:29 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-03 04:58:29 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-03 04:58:30 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 15
2022-04-03 04:58:30 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-03 04:58:30 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-03 04:58:30 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-03 04:58:31 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 14
2022-04-03 04:58:31 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-03 04:58:31 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-03 04:58:31 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-03 04:58:32 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 13
2022-04-03 04:58:32 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-03 04:58:32 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-03 04:58:32 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-03 04:58:33 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 12
2022-04-03 04:58:33 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-03 04:58:33 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-03 04:58:33 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-03 04:58:34 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 11
2022-04-03 04:58:34 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-03 04:58:34 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-03 04:58:34 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-03 04:58:35 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 10
2022-04-03 04:58:35 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-03 04:58:35 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-03 04:58:35 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-03 04:58:36 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 9
2022-04-03 04:58:36 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-03 04:58:36 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-03 04:58:36 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-03 04:58:37 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 8
2022-04-03 04:58:37 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-03 04:58:37 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-03 04:58:37 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-03 04:58:38 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 7
2022-04-03 04:58:38 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-03 04:58:38 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-03 04:58:38 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-03 04:58:39 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 6
2022-04-03 04:58:39 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-03 04:58:39 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-03 04:58:39 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-03 04:58:40 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 5
2022-04-03 04:58:40 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-03 04:58:40 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-03 04:58:40 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-03 04:58:41 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 4
2022-04-03 04:58:41 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-03 04:58:41 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-03 04:58:41 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-03 04:58:42 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 3
2022-04-03 04:58:42 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-03 04:58:42 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-03 04:58:42 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-03 04:58:43 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 2
2022-04-03 04:58:43 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-03 04:58:43 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-03 04:58:43 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-03 04:58:44 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 1
2022-04-03 04:58:44 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-03 04:58:44 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-03 04:58:44 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-03 04:58:44 [main] [32mINFO [m [PodUtils:335] All pods are stable second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 ,second-kafka-cluster-kafka-0 ,second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 ,second-kafka-cluster-zookeeper-0
2022-04-03 04:58:44 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: second-kafka-cluster are stable
2022-04-03 04:58:44 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 50
2022-04-03 04:58:44 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-03 04:58:44 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-03 04:58:44 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-03 04:58:45 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 49
2022-04-03 04:58:45 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-03 04:58:45 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-03 04:58:45 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-03 04:58:46 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 48
2022-04-03 04:58:46 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-03 04:58:46 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-03 04:58:46 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-03 04:58:47 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 47
2022-04-03 04:58:47 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-03 04:58:47 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-03 04:58:47 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-03 04:58:48 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 46
2022-04-03 04:58:48 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-03 04:58:48 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-03 04:58:48 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-03 04:58:49 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 45
2022-04-03 04:58:49 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-03 04:58:49 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-03 04:58:49 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-03 04:58:50 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 44
2022-04-03 04:58:50 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-03 04:58:50 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-03 04:58:50 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-03 04:58:51 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 43
2022-04-03 04:58:51 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-03 04:58:51 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-03 04:58:51 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-03 04:58:52 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 42
2022-04-03 04:58:52 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-03 04:58:52 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-03 04:58:52 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-03 04:58:53 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 41
2022-04-03 04:58:53 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-03 04:58:53 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-03 04:58:53 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-03 04:58:54 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 40
2022-04-03 04:58:54 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-03 04:58:54 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-03 04:58:54 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-03 04:58:55 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 39
2022-04-03 04:58:55 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-03 04:58:55 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-03 04:58:55 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-03 04:58:56 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 38
2022-04-03 04:58:56 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-03 04:58:56 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-03 04:58:56 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-03 04:58:57 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 37
2022-04-03 04:58:57 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-03 04:58:57 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-03 04:58:57 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-03 04:58:58 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 36
2022-04-03 04:58:58 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-03 04:58:58 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-03 04:58:58 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-03 04:58:59 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 35
2022-04-03 04:58:59 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-03 04:58:59 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-03 04:58:59 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-03 04:59:00 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 34
2022-04-03 04:59:00 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-03 04:59:00 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-03 04:59:00 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-03 04:59:01 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 33
2022-04-03 04:59:01 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-03 04:59:01 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-03 04:59:01 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-03 04:59:02 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 32
2022-04-03 04:59:02 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-03 04:59:02 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-03 04:59:02 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-03 04:59:03 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 31
2022-04-03 04:59:03 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-03 04:59:03 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-03 04:59:03 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-03 04:59:04 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 30
2022-04-03 04:59:04 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-03 04:59:04 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-03 04:59:04 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-03 04:59:05 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 29
2022-04-03 04:59:05 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-03 04:59:05 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-03 04:59:05 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-03 04:59:06 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 28
2022-04-03 04:59:06 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-03 04:59:06 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-03 04:59:06 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-03 04:59:07 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 27
2022-04-03 04:59:07 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-03 04:59:07 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-03 04:59:07 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-03 04:59:08 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 26
2022-04-03 04:59:08 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-03 04:59:08 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-03 04:59:08 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-03 04:59:09 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 25
2022-04-03 04:59:09 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-03 04:59:09 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-03 04:59:09 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-03 04:59:10 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 24
2022-04-03 04:59:10 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-03 04:59:10 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-03 04:59:10 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-03 04:59:11 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 23
2022-04-03 04:59:11 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-03 04:59:11 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-03 04:59:11 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-03 04:59:12 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 22
2022-04-03 04:59:12 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-03 04:59:12 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-03 04:59:12 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-03 04:59:13 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 21
2022-04-03 04:59:13 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-03 04:59:13 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-03 04:59:13 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-03 04:59:14 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 20
2022-04-03 04:59:14 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-03 04:59:14 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-03 04:59:14 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-03 04:59:15 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 19
2022-04-03 04:59:15 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-03 04:59:15 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-03 04:59:15 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-03 04:59:16 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 18
2022-04-03 04:59:16 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-03 04:59:16 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-03 04:59:16 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-03 04:59:17 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 17
2022-04-03 04:59:17 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-03 04:59:17 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-03 04:59:17 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-03 04:59:18 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 16
2022-04-03 04:59:18 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-03 04:59:18 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-03 04:59:18 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-03 04:59:19 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 15
2022-04-03 04:59:19 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-03 04:59:19 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-03 04:59:19 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-03 04:59:20 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 14
2022-04-03 04:59:20 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-03 04:59:20 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-03 04:59:20 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-03 04:59:21 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 13
2022-04-03 04:59:21 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-03 04:59:21 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-03 04:59:21 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-03 04:59:22 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 12
2022-04-03 04:59:22 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-03 04:59:22 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-03 04:59:22 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-03 04:59:23 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 11
2022-04-03 04:59:23 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-03 04:59:23 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-03 04:59:23 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-03 04:59:24 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 10
2022-04-03 04:59:24 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-03 04:59:24 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-03 04:59:24 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-03 04:59:25 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 9
2022-04-03 04:59:25 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-03 04:59:25 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-03 04:59:25 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-03 04:59:26 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 8
2022-04-03 04:59:26 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-03 04:59:26 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-03 04:59:26 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-03 04:59:27 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 7
2022-04-03 04:59:27 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-03 04:59:27 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-03 04:59:27 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-03 04:59:28 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 6
2022-04-03 04:59:28 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-03 04:59:28 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-03 04:59:28 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-03 04:59:29 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 5
2022-04-03 04:59:29 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-03 04:59:29 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-03 04:59:29 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-03 04:59:30 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 4
2022-04-03 04:59:30 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-03 04:59:30 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-03 04:59:30 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-03 04:59:31 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 3
2022-04-03 04:59:31 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-03 04:59:31 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-03 04:59:31 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-03 04:59:32 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 2
2022-04-03 04:59:32 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-03 04:59:32 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-03 04:59:32 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-03 04:59:33 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 is in the Running state. Remaining seconds pod to be stable 1
2022-04-03 04:59:33 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-03 04:59:33 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-03 04:59:33 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-03 04:59:33 [main] [32mINFO [m [PodUtils:335] All pods are stable second-kafka-cluster-entity-operator-5f8949dc9c-kj7x7 ,second-kafka-cluster-kafka-0 ,second-kafka-cluster-kafka-exporter-6dfb7ccc69-z7wr2 ,second-kafka-cluster-zookeeper-0
2022-04-03 04:59:33 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 04:59:33 [main] [32mINFO [m [ResourceManager:346] In context testKafkaMetricsSettings is everything deleted.
2022-04-03 04:59:33 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 04:59:33 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaMetricsSettings-FINISHED
2022-04-03 04:59:33 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 04:59:33 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 04:59:33 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testClusterOperatorMetrics-STARTED
2022-04-03 04:59:33 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 04:59:34 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.5 from Pod infra-namespace-kafka-clients-748578f786-rm9cd finished with return code: 0
2022-04-03 04:59:34 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 04:59:34 [main] [32mINFO [m [ResourceManager:346] In context testClusterOperatorMetrics is everything deleted.
2022-04-03 04:59:34 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 04:59:34 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testClusterOperatorMetrics-FINISHED
2022-04-03 04:59:34 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 04:59:34 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 04:59:34 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testCruiseControlMetrics-STARTED
2022-04-03 04:59:34 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 04:59:34 [main] [32mINFO [m [MetricsIsolatedST:452] Verifying that we have more than 0 groups
2022-04-03 04:59:34 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 04:59:34 [main] [32mINFO [m [ResourceManager:346] In context testCruiseControlMetrics is everything deleted.
2022-04-03 04:59:34 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 04:59:34 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testCruiseControlMetrics-FINISHED
2022-04-03 04:59:34 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 04:59:34 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 04:59:34 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaExporterDataAfterExchange-STARTED
2022-04-03 04:59:34 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 04:59:34 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-03 04:59:34 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@64a53dcb, messages=[], arguments=[--max-messages, 5000, --topic, my-topic-289553630-116824254, --bootstrap-server, metrics-cluster-name-kafka-bootstrap.infra-namespace.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='infra-namespace-kafka-clients-748578f786-rm9cd', podNamespace='infra-namespace', bootstrapServer='metrics-cluster-name-kafka-bootstrap.infra-namespace.svc:9092', topicName='my-topic-289553630-116824254', maxMessages=5000, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3719d95}
2022-04-03 04:59:34 [main] [32mINFO [m [InternalKafkaClient:94] Producing 5000 messages to metrics-cluster-name-kafka-bootstrap.infra-namespace.svc:9092:my-topic-289553630-116824254 from pod infra-namespace-kafka-clients-748578f786-rm9cd
2022-04-03 04:59:34 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec infra-namespace-kafka-clients-748578f786-rm9cd -n infra-namespace -- /opt/kafka/producer.sh --max-messages 5000 --topic my-topic-289553630-116824254 --bootstrap-server metrics-cluster-name-kafka-bootstrap.infra-namespace.svc:9092
2022-04-03 04:59:37 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-03 04:59:37 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 5000 messages
2022-04-03 04:59:37 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@4c2bb192, messages=[], arguments=[--max-messages, 5000, --group-instance-id, instance628929775, --group-id, my-consumer-group-767980974, --topic, my-topic-289553630-116824254, --bootstrap-server, metrics-cluster-name-kafka-bootstrap.infra-namespace.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='infra-namespace-kafka-clients-748578f786-rm9cd', podNamespace='infra-namespace', bootstrapServer='metrics-cluster-name-kafka-bootstrap.infra-namespace.svc:9092', topicName='my-topic-289553630-116824254', maxMessages=5000, kafkaUsername='null', consumerGroupName='my-consumer-group-767980974', consumerInstanceId='instance628929775', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5c499762}
2022-04-03 04:59:37 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 5000 messages from metrics-cluster-name-kafka-bootstrap.infra-namespace.svc:9092#my-topic-289553630-116824254 from pod infra-namespace-kafka-clients-748578f786-rm9cd
2022-04-03 04:59:37 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec infra-namespace-kafka-clients-748578f786-rm9cd -n infra-namespace -- /opt/kafka/consumer.sh --max-messages 5000 --group-instance-id instance628929775 --group-id my-consumer-group-767980974 --topic my-topic-289553630-116824254 --bootstrap-server metrics-cluster-name-kafka-bootstrap.infra-namespace.svc:9092
2022-04-03 04:59:43 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-03 04:59:43 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 5000 messages
2022-04-03 04:59:43 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.21 from Pod infra-namespace-kafka-clients-748578f786-rm9cd finished with return code: 0
2022-04-03 04:59:43 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 04:59:43 [main] [32mINFO [m [ResourceManager:346] In context testKafkaExporterDataAfterExchange is everything deleted.
2022-04-03 04:59:43 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 04:59:43 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaExporterDataAfterExchange-FINISHED
2022-04-03 04:59:43 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 04:59:43 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 04:59:43 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testTopicOperatorMetrics-STARTED
2022-04-03 04:59:43 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 04:59:43 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.19 from Pod infra-namespace-kafka-clients-748578f786-rm9cd finished with return code: 0
2022-04-03 04:59:43 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: consumer-offsets---84e7a678d08f4bd226872e5cdd4eb527fadc1c6a
2022-04-03 04:59:43 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: heartbeats
2022-04-03 04:59:43 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: metrics-cluster-name-connect-config
2022-04-03 04:59:43 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: metrics-cluster-name-connect-offsets
2022-04-03 04:59:43 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: metrics-cluster-name-connect-status
2022-04-03 04:59:43 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: mirrormaker2-cluster-configs
2022-04-03 04:59:43 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: mirrormaker2-cluster-offsets
2022-04-03 04:59:43 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: mirrormaker2-cluster-status
2022-04-03 04:59:43 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: my-topic-289553630-116824254
2022-04-03 04:59:43 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: my-topic-390174085-526226873
2022-04-03 04:59:43 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: my-topic-598170036-1467726275
2022-04-03 04:59:43 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: second-kafka-cluster.checkpoints.internal
2022-04-03 04:59:43 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: strimzi-store-topic---effb8e3e057afce1ecf67c3f5d8e4e3ff177fc55
2022-04-03 04:59:43 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: strimzi-topic-operator-kstreams-topic-store-changelog---b75e702040b99be8a9263134de3507fc0cc4017b
2022-04-03 04:59:43 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: strimzi.cruisecontrol.metrics
2022-04-03 04:59:43 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: strimzi.cruisecontrol.modeltrainingsamples
2022-04-03 04:59:43 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: strimzi.cruisecontrol.partitionmetricsamples
2022-04-03 04:59:43 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 04:59:43 [main] [32mINFO [m [ResourceManager:346] In context testTopicOperatorMetrics is everything deleted.
2022-04-03 04:59:43 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 04:59:43 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testTopicOperatorMetrics-FINISHED
2022-04-03 04:59:43 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 04:59:43 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 04:59:43 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaConnectRequests-STARTED
2022-04-03 04:59:43 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 04:59:44 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.24 from Pod infra-namespace-kafka-clients-748578f786-rm9cd finished with return code: 0
2022-04-03 04:59:44 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 04:59:44 [main] [32mINFO [m [ResourceManager:346] In context testKafkaConnectRequests is everything deleted.
2022-04-03 04:59:44 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 04:59:44 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaConnectRequests-FINISHED
2022-04-03 04:59:44 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 04:59:44 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 04:59:44 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaConnectResponse-STARTED
2022-04-03 04:59:44 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 04:59:44 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.24 from Pod infra-namespace-kafka-clients-748578f786-rm9cd finished with return code: 0
2022-04-03 04:59:44 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 04:59:44 [main] [32mINFO [m [ResourceManager:346] In context testKafkaConnectResponse is everything deleted.
2022-04-03 04:59:44 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 04:59:44 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaConnectResponse-FINISHED
2022-04-03 04:59:44 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 04:59:44 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 04:59:44 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaExporterDifferentSetting-STARTED
2022-04-03 04:59:44 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 04:59:45 [main] [32mINFO [m [MetricsIsolatedST:610] Metrics collection for pod metrics-cluster-name-kafka-exporter-8454677f49-49wjh return code - 0
2022-04-03 04:59:45 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment metrics-cluster-name-kafka-exporter rolling update
2022-04-03 05:00:15 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: metrics-cluster-name-kafka-exporter will be ready
2022-04-03 05:00:15 [main] [32mINFO [m [DeploymentUtils:168] Deployment: metrics-cluster-name-kafka-exporter is ready
2022-04-03 05:00:25 [main] [32mINFO [m [DeploymentUtils:141] Deployment metrics-cluster-name-kafka-exporter rolling update finished
2022-04-03 05:00:25 [main] [32mINFO [m [MetricsIsolatedST:610] Metrics collection for pod metrics-cluster-name-kafka-exporter-64b75d56f-dpxqf return code - 0
2022-04-03 05:00:25 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 05:00:25 [main] [32mINFO [m [ResourceManager:346] In context testKafkaExporterDifferentSetting is everything deleted.
2022-04-03 05:00:25 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 05:00:25 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaExporterDifferentSetting-FINISHED
2022-04-03 05:00:25 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 05:00:25 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 05:00:25 [main] [32mINFO [m [ResourceManager:348] Delete all resources for MetricsIsolatedST
2022-04-03 05:00:25 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 mm2-cluster in namespace infra-namespace
2022-04-03 05:00:25 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Deployment infra-namespace-kafka-clients in namespace infra-namespace
2022-04-03 05:00:25 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1956897560-1478932307 in namespace infra-namespace
2022-04-03 05:00:25 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-289553630-116824254 in namespace infra-namespace
2022-04-03 05:00:25 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-751448899-1775520553 in namespace infra-namespace
2022-04-03 05:00:25 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge my-bridge in namespace infra-namespace
2022-04-03 05:00:25 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy second-kafka-cluster-entity-operator-allow in namespace second-metrics-cluster-test
2022-04-03 05:00:25 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-598170036-1467726275 in namespace infra-namespace
2022-04-03 05:00:25 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy second-kafka-cluster-kafka-exporter-allow in namespace second-metrics-cluster-test
2022-04-03 05:00:25 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy metrics-cluster-name-kafka-exporter-allow in namespace infra-namespace
2022-04-03 05:00:25 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy metrics-cluster-name-entity-operator-allow in namespace infra-namespace
2022-04-03 05:00:25 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy cluster-operator-allow in namespace infra-namespace
2022-04-03 05:00:25 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect metrics-cluster-name in namespace infra-namespace
2022-04-03 05:00:35 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-390174085-526226873 in namespace infra-namespace
2022-04-03 05:00:35 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Kafka metrics-cluster-name in namespace infra-namespace
2022-04-03 05:00:35 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka second-kafka-cluster in namespace second-metrics-cluster-test
2022-04-03 05:00:35 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace infra-namespace, for cruise control Kafka cluster metrics-cluster-name
2022-04-03 05:00:35 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment second-metrics-cluster-test-kafka-clients in namespace second-metrics-cluster-test
2022-04-03 05:01:35 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 20, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 803.966 s - in io.strimzi.systemtest.metrics.MetricsIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.metrics.JmxIsolatedST
2022-04-03 05:01:35 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-03 05:02:00 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-03 05:02:00 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-03 05:02:00 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-03 05:02:00 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 05:02:00 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-03 05:02:00 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-03 05:02:00 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace second-metrics-cluster-test
2022-04-03 05:02:00 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-03 05:02:00 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-03 05:02:00 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-03 05:02:00 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-03 05:02:00 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 05:02:00 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:02:00 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-03 05:02:00 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-03 05:02:00 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-03 05:02:00 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-03 05:02:00 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-03 05:02:00 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:02:00 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-03 05:02:00 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-03 05:02:00 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-03 05:02:00 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:02:00 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-03 05:02:00 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-03 05:02:00 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-03 05:02:00 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace second-metrics-cluster-test
2022-04-03 05:02:00 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-03 05:02:10 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-03 05:02:10 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:02:10 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-03 05:02:10 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-03 05:02:10 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-03 05:02:20 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 05:02:41 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7e2e5e3d
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=30000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-03 05:02:41 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-03 05:02:41 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-03 05:02:41 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-03 05:02:41 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:02:41 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 05:02:41 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-03 05:02:41 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-03 05:02:41 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-03 05:02:41 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-03 05:02:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-03 05:02:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-03 05:02:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-03 05:02:42 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-03 05:02:42 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-03 05:02:42 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-03 05:02:42 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-03 05:02:42 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-03 05:02:42 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-03 05:02:42 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-03 05:02:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:02:42 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-03 05:02:42 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-03 05:02:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-03 05:02:42 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-03 05:02:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-03 05:02:42 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-03 05:02:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-03 05:02:42 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-03 05:02:42 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:02:42 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-03 05:02:42 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-03 05:02:42 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-03 05:02:42 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-03 05:02:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 05:02:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-03 05:02:42 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:02:42 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-03 05:03:11 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-03 05:03:11 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-03 05:03:21 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-03 05:03:21 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 05:03:21 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.JmxIsolatedST.testKafkaZookeeperAndKafkaConnectWithJMX-STARTED
2022-04-03 05:03:21 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 05:03:21 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-141 for test case:testKafkaZookeeperAndKafkaConnectWithJMX
2022-04-03 05:03:21 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-141
2022-04-03 05:03:21 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-141
2022-04-03 05:03:21 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-141
2022-04-03 05:03:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-3997e757 in namespace namespace-141
2022-04-03 05:03:21 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-141
2022-04-03 05:03:21 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-3997e757 will have desired state: Ready
2022-04-03 05:04:40 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-3997e757 is in desired state: Ready
2022-04-03 05:04:40 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-3997e757-kafka-clients in namespace namespace-141
2022-04-03 05:04:40 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-141
2022-04-03 05:04:40 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-3997e757-kafka-clients will be ready
2022-04-03 05:04:42 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-3997e757-kafka-clients is ready
2022-04-03 05:04:42 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-3997e757-scraper in namespace namespace-141
2022-04-03 05:04:42 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-141
2022-04-03 05:04:42 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-3997e757-scraper will be ready
2022-04-03 05:04:44 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-3997e757-scraper is ready
2022-04-03 05:04:44 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-3997e757-scraper to be ready
2022-04-03 05:04:54 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-3997e757-scraper is ready
2022-04-03 05:04:54 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-3997e757-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-03 05:04:54 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-3997e757-allow in namespace namespace-141
2022-04-03 05:04:54 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-141
2022-04-03 05:04:54 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-03 05:04:54 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-3997e757 in namespace namespace-141
2022-04-03 05:04:54 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-141
2022-04-03 05:04:54 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-3997e757 will have desired state: Ready
2022-04-03 05:05:56 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-3997e757 is in desired state: Ready
2022-04-03 05:05:56 [main] [32mINFO [m [JmxUtils:54] Getting username and password for service: my-cluster-3997e757-kafka-brokers and secret: my-cluster-3997e757-kafka-jmx
2022-04-03 05:05:56 [main] [32mINFO [m [JmxUtils:58] Creating script file for service: my-cluster-3997e757-kafka-brokers
2022-04-03 05:05:56 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-141 exec my-cluster-3997e757-kafka-clients-65bdf4d856-8l8k2 -- /bin/bash -c echo 'open service:jmx:rmi:///jndi/rmi://my-cluster-3997e757-kafka-brokers:9999/jmxrmi -u DMKMwrEMiPW14scP -p IzqDwLDSeOkVoZca
bean kafka.server:type=app-info
get -i *' > /tmp/my-cluster-3997e757-kafka-brokers.sh
2022-04-03 05:05:56 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-03 05:05:56 [main] [32mINFO [m [JmxUtils:63] Waiting for JMX metrics for service: my-cluster-3997e757-kafka-brokers will be present
2022-04-03 05:05:57 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-141 exec my-cluster-3997e757-kafka-clients-65bdf4d856-8l8k2 -- java -jar jmxterm/jmxterm.jar -i /tmp/my-cluster-3997e757-kafka-brokers.sh
2022-04-03 05:05:57 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-03 05:05:57 [main] [32mINFO [m [JmxUtils:54] Getting username and password for service: my-cluster-3997e757-connect-api and secret: my-cluster-3997e757-kafka-connect-jmx
2022-04-03 05:05:57 [main] [32mINFO [m [JmxUtils:58] Creating script file for service: my-cluster-3997e757-connect-api
2022-04-03 05:05:57 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-141 exec my-cluster-3997e757-kafka-clients-65bdf4d856-8l8k2 -- /bin/bash -c echo 'open service:jmx:rmi:///jndi/rmi://my-cluster-3997e757-connect-api:9999/jmxrmi -u LiWIOmc9AE49Ca3u -p j61hMu47JbbyPyIN
bean kafka.connect:type=app-info
get -i *' > /tmp/my-cluster-3997e757-connect-api.sh
2022-04-03 05:05:57 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-03 05:05:57 [main] [32mINFO [m [JmxUtils:63] Waiting for JMX metrics for service: my-cluster-3997e757-connect-api will be present
2022-04-03 05:05:58 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-141 exec my-cluster-3997e757-kafka-clients-65bdf4d856-8l8k2 -- java -jar jmxterm/jmxterm.jar -i /tmp/my-cluster-3997e757-connect-api.sh
2022-04-03 05:05:58 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-03 05:05:58 [main] [32mINFO [m [JmxUtils:54] Getting username and password for service: my-cluster-3997e757-zookeeper-nodes and secret: my-cluster-3997e757-zookeeper-jmx
2022-04-03 05:05:58 [main] [32mINFO [m [JmxUtils:58] Creating script file for service: my-cluster-3997e757-zookeeper-nodes
2022-04-03 05:05:58 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-141 exec my-cluster-3997e757-kafka-clients-65bdf4d856-8l8k2 -- /bin/bash -c echo 'open service:jmx:rmi:///jndi/rmi://my-cluster-3997e757-zookeeper-nodes:9999/jmxrmi -u fzB1lokfnv7Hc9jA -p U3GflRR9vz38ehmc
domain org.apache.ZooKeeperService
beans' > /tmp/my-cluster-3997e757-zookeeper-nodes.sh
2022-04-03 05:05:58 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-03 05:05:58 [main] [32mINFO [m [JmxUtils:63] Waiting for JMX metrics for service: my-cluster-3997e757-zookeeper-nodes will be present
2022-04-03 05:05:59 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-141 exec my-cluster-3997e757-kafka-clients-65bdf4d856-8l8k2 -- java -jar jmxterm/jmxterm.jar -i /tmp/my-cluster-3997e757-zookeeper-nodes.sh
2022-04-03 05:05:59 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-03 05:05:59 [main] [32mINFO [m [JmxUtils:54] Getting username and password for service: my-cluster-3997e757-zookeeper-nodes and secret: my-cluster-3997e757-zookeeper-jmx
2022-04-03 05:05:59 [main] [32mINFO [m [JmxUtils:58] Creating script file for service: my-cluster-3997e757-zookeeper-nodes
2022-04-03 05:05:59 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-141 exec my-cluster-3997e757-kafka-clients-65bdf4d856-8l8k2 -- /bin/bash -c echo 'open service:jmx:rmi:///jndi/rmi://my-cluster-3997e757-zookeeper-nodes:9999/jmxrmi -u fzB1lokfnv7Hc9jA -p U3GflRR9vz38ehmc
bean org.apache.ZooKeeperService:name0=ReplicatedServer_id3
get -i *' > /tmp/my-cluster-3997e757-zookeeper-nodes.sh
2022-04-03 05:05:59 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-03 05:05:59 [main] [32mINFO [m [JmxUtils:63] Waiting for JMX metrics for service: my-cluster-3997e757-zookeeper-nodes will be present
2022-04-03 05:06:00 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-141 exec my-cluster-3997e757-kafka-clients-65bdf4d856-8l8k2 -- java -jar jmxterm/jmxterm.jar -i /tmp/my-cluster-3997e757-zookeeper-nodes.sh
2022-04-03 05:06:00 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-03 05:06:01 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-141 exec my-cluster-3997e757-kafka-clients-65bdf4d856-8l8k2 -- java -jar jmxterm/jmxterm.jar -i /tmp/my-cluster-3997e757-zookeeper-nodes.sh
2022-04-03 05:06:01 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-03 05:06:03 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-141 exec my-cluster-3997e757-kafka-clients-65bdf4d856-8l8k2 -- java -jar jmxterm/jmxterm.jar -i /tmp/my-cluster-3997e757-zookeeper-nodes.sh
2022-04-03 05:06:03 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-03 05:06:05 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-141 exec my-cluster-3997e757-kafka-clients-65bdf4d856-8l8k2 -- java -jar jmxterm/jmxterm.jar -i /tmp/my-cluster-3997e757-zookeeper-nodes.sh
2022-04-03 05:06:05 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-03 05:06:05 [main] [32mINFO [m [JmxIsolatedST:110] Checking that Zookeeper JMX secret is created with custom labels and annotations
2022-04-03 05:06:05 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 05:06:05 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaZookeeperAndKafkaConnectWithJMX
2022-04-03 05:06:05 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-3997e757-scraper in namespace namespace-141
2022-04-03 05:06:05 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-3997e757-kafka-clients in namespace namespace-141
2022-04-03 05:06:05 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-3997e757 in namespace namespace-141
2022-04-03 05:06:05 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-3997e757-allow in namespace namespace-141
2022-04-03 05:06:05 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-3997e757 in namespace namespace-141
2022-04-03 05:06:55 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 05:06:55 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-141 for test case:testKafkaZookeeperAndKafkaConnectWithJMX
2022-04-03 05:07:00 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.JmxIsolatedST.testKafkaZookeeperAndKafkaConnectWithJMX-FINISHED
2022-04-03 05:07:00 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 05:07:00 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 05:07:00 [main] [32mINFO [m [ResourceManager:346] In context JmxIsolatedST is everything deleted.
2022-04-03 05:07:00 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 325.475 s - in io.strimzi.systemtest.metrics.JmxIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.dump.LogDumpScriptIsolatedST
2022-04-03 05:07:00 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-03 05:07:25 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-03 05:07:25 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-03 05:07:25 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-03 05:07:25 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 05:07:25 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-03 05:07:25 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-03 05:07:25 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 05:07:25 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-03 05:07:25 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-03 05:07:25 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-03 05:07:25 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-03 05:07:25 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:07:25 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-03 05:07:26 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-03 05:07:26 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:07:26 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:07:26 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-03 05:07:26 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 05:07:26 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-03 05:07:26 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-03 05:07:26 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-03 05:07:26 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-03 05:07:26 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-03 05:07:26 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-03 05:07:26 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:07:26 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-03 05:07:26 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-03 05:07:26 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-03 05:07:26 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-03 05:07:36 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-03 05:07:36 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 05:07:41 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7e2e5e3d
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-03 05:07:41 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-03 05:07:41 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-03 05:07:41 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-03 05:07:41 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:07:41 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 05:07:41 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-03 05:07:41 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-03 05:07:41 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-03 05:07:41 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-03 05:07:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-03 05:07:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-03 05:07:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-03 05:07:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-03 05:07:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-03 05:07:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-03 05:07:42 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-03 05:07:42 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-03 05:07:42 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-03 05:07:42 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-03 05:07:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:07:42 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-03 05:07:42 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-03 05:07:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-03 05:07:42 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-03 05:07:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-03 05:07:42 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-03 05:07:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-03 05:07:42 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-03 05:07:42 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:07:42 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-03 05:07:42 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-03 05:07:42 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-03 05:07:42 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-03 05:07:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 05:07:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-03 05:07:42 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:07:42 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-03 05:08:08 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-03 05:08:08 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-03 05:08:18 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-03 05:08:18 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 05:08:18 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.dump.LogDumpScriptIsolatedST.dumpPartitions-STARTED
2022-04-03 05:08:18 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 05:08:18 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-324ab54b in namespace infra-namespace
2022-04-03 05:08:18 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-324ab54b will have desired state: Ready
2022-04-03 05:09:26 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-324ab54b is in desired state: Ready
2022-04-03 05:09:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-324ab54b-hello-world-producer in namespace infra-namespace
2022-04-03 05:09:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-324ab54b-hello-world-consumer in namespace infra-namespace
2022-04-03 05:09:26 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-324ab54b-hello-world-producer will be in active state
2022-04-03 05:09:27 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-324ab54b-hello-world-consumer will be in active state
2022-04-03 05:09:27 [main] [32mINFO [m [ClientUtils:61] Waiting till producer my-cluster-324ab54b-hello-world-producer and consumer my-cluster-324ab54b-hello-world-consumer finish
2022-04-03 05:09:38 [main] [32mINFO [m [LogDumpScriptIsolatedST:78] Print partition segments from cluster infra-namespace/my-cluster-324ab54b
2022-04-03 05:09:38 [main] [32mINFO [m [Exec:417] Failed to exec command: /home/ec2-user/strimzi-kafka-operator/systemtest/../tools/log-dump/run.sh partition --namespace infra-namespace --cluster my-cluster-324ab54b --topic my-topic-1835402869-1021104995 --partition 0 --dry-run
2022-04-03 05:09:38 [main] [32mINFO [m [Exec:417] Return code: 127
2022-04-03 05:09:38 [main] [32mINFO [m [Exec:417] ======STDERR START=======
2022-04-03 05:09:38 [main] [32mINFO [m [Exec:417] /home/ec2-user/strimzi-kafka-operator/systemtest/../tools/log-dump/run.sh: line 47: yq: command not found
2022-04-03 05:09:38 [main] [32mINFO [m [Exec:417] ======STDERR END======
2022-04-03 05:09:38 [main] [1;31mERROR[m [TestExecutionWatcher:28] LogDumpScriptIsolatedST - Exception `/home/ec2-user/strimzi-kafka-operator/systemtest/../tools/log-dump/run.sh partition --namespace infra-namespace --cluster my-cluster-324ab54b --topic my-topic-1835402869-1021104995 --partition 0 --dry-run` got status code 127 and stderr:
------
/home/ec2-user/strimzi-kafka-operator/systemtest/../tools/log-dump/run.sh: line 47: yq: command not found

------
and stdout:
------

------ has been thrown in @Test. Going to collect logs from components.
2022-04-03 05:09:38 [main] [32mINFO [m [LogCollector:252] Collecting events in Namespace infra-namespace
2022-04-03 05:09:39 [main] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace infra-namespace
2022-04-03 05:09:39 [main] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace infra-namespace
2022-04-03 05:09:39 [main] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace infra-namespace
2022-04-03 05:09:39 [main] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace infra-namespace
2022-04-03 05:09:39 [main] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace infra-namespace
2022-04-03 05:09:40 [main] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace infra-namespace
2022-04-03 05:09:40 [main] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-04-03 05:09:40 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 05:09:40 [main] [32mINFO [m [ResourceManager:348] Delete all resources for dumpPartitions
2022-04-03 05:09:40 [main] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-324ab54b-hello-world-producer in namespace infra-namespace
2022-04-03 05:09:40 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-324ab54b-hello-world-consumer in namespace infra-namespace
2022-04-03 05:09:40 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-324ab54b in namespace infra-namespace
2022-04-03 05:09:50 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 05:09:50 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.dump.LogDumpScriptIsolatedST.dumpPartitions-FINISHED
2022-04-03 05:09:50 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 05:09:50 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 05:09:50 [main] [32mINFO [m [ResourceManager:346] In context LogDumpScriptIsolatedST is everything deleted.
2022-04-03 05:09:50 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;31mERROR[m] Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 169.46 s <<< FAILURE! - in io.strimzi.systemtest.dump.LogDumpScriptIsolatedST
[[1;31mERROR[m] io.strimzi.systemtest.dump.LogDumpScriptIsolatedST.dumpPartitions(ExtensionContext)  Time elapsed: 92.143 s  <<< ERROR!
io.strimzi.test.k8s.exceptions.KubeClusterException: 
`/home/ec2-user/strimzi-kafka-operator/systemtest/../tools/log-dump/run.sh partition --namespace infra-namespace --cluster my-cluster-324ab54b --topic my-topic-1835402869-1021104995 --partition 0 --dry-run` got status code 127 and stderr:
------
/home/ec2-user/strimzi-kafka-operator/systemtest/../tools/log-dump/run.sh: line 47: yq: command not found

------
and stdout:
------

------
	at io.strimzi.test.executor.Exec.exec(Exec.java:223)
	at io.strimzi.test.executor.Exec.exec(Exec.java:149)
	at io.strimzi.test.executor.Exec.exec(Exec.java:118)
	at io.strimzi.systemtest.dump.LogDumpScriptIsolatedST.dumpPartitions(LogDumpScriptIsolatedST.java:83)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)

2022-04-03 05:09:50 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-03 05:09:50 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-03 05:09:50 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-03 05:09:50 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 05:09:50 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-03 05:09:50 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-03 05:09:50 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-03 05:09:50 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-03 05:09:50 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 05:09:50 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 05:09:50 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-03 05:09:50 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-03 05:09:50 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-03 05:09:50 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-03 05:09:50 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-03 05:09:50 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-03 05:09:50 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-03 05:09:50 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:09:50 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-03 05:09:50 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-03 05:09:50 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-03 05:09:50 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:09:50 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:09:50 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-03 05:09:50 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-03 05:09:50 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-03 05:10:00 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-03 05:10:00 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:10:00 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-03 05:10:00 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-03 05:10:10 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 05:10:15 [main] [32mINFO [m [TestExecutionListener:40] =======================================================================
2022-04-03 05:10:15 [main] [32mINFO [m [TestExecutionListener:41] =======================================================================
2022-04-03 05:10:15 [main] [32mINFO [m [TestExecutionListener:42]                         Test run finished
2022-04-03 05:10:15 [main] [32mINFO [m [TestExecutionListener:43] =======================================================================
2022-04-03 05:10:15 [main] [32mINFO [m [TestExecutionListener:44] =======================================================================
2022-04-03 05:10:15 [main] [32mINFO [m [TestExecutionListener:29] =======================================================================
2022-04-03 05:10:15 [main] [32mINFO [m [TestExecutionListener:30] =======================================================================
2022-04-03 05:10:15 [main] [32mINFO [m [TestExecutionListener:31]                         Test run started
2022-04-03 05:10:15 [main] [32mINFO [m [TestExecutionListener:32] =======================================================================
2022-04-03 05:10:15 [main] [32mINFO [m [TestExecutionListener:33] =======================================================================
2022-04-03 05:10:15 [main] [32mINFO [m [TestExecutionListener:48] Following testclasses are selected for run:
2022-04-03 05:10:15 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.kafka.KafkaST
2022-04-03 05:10:15 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfSharedST
2022-04-03 05:10:15 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.rollingupdate.RollingUpdateST
2022-04-03 05:10:15 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.backup.ColdBackupScriptIsolatedST
2022-04-03 05:10:15 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.specific.HelmChartIsolatedST
2022-04-03 05:10:15 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST
2022-04-03 05:10:15 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.dump.LogDumpScriptIsolatedST
2022-04-03 05:10:15 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST
2022-04-03 05:10:15 [main] [32mINFO [m [TestExecutionListener:52] =======================================================================
2022-04-03 05:10:15 [main] [32mINFO [m [TestExecutionListener:53] =======================================================================
[[1;34mINFO[m] Running io.strimzi.systemtest.kafka.KafkaST
2022-04-03 05:10:15 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@5f4d6ac4
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-03 05:10:15 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-03 05:10:15 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-03 05:10:15 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-03 05:10:15 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:10:15 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 05:10:15 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-03 05:10:16 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-03 05:10:16 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-03 05:10:16 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-03 05:10:16 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-03 05:10:16 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-03 05:10:16 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-03 05:10:16 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-03 05:10:16 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-03 05:10:16 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-03 05:10:16 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-03 05:10:16 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-03 05:10:16 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-03 05:10:16 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-03 05:10:16 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:10:16 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-03 05:10:16 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-03 05:10:16 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-03 05:10:16 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-03 05:10:16 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-03 05:10:16 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-03 05:10:16 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-03 05:10:16 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-03 05:10:16 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:10:16 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-03 05:10:16 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-03 05:10:16 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-03 05:10:16 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-03 05:10:16 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 05:10:16 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-03 05:10:16 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:10:16 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-03 05:10:36 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-03 05:10:36 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-03 05:10:46 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-03 05:10:46 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: kafka-st
2022-04-03 05:10:46 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: kafka-st
2022-04-03 05:10:46 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: kafka-st
2022-04-03 05:10:46 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 05:10:46 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testLabelModificationDoesNotBreakCluster-STARTED
2022-04-03 05:10:46 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 05:10:46 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-142 for test case:testLabelModificationDoesNotBreakCluster
2022-04-03 05:10:46 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-142
2022-04-03 05:10:46 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-142
2022-04-03 05:10:46 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-142
2022-04-03 05:10:46 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-a56c6c64 in namespace namespace-142
2022-04-03 05:10:46 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-142
2022-04-03 05:10:46 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-a56c6c64 will have desired state: Ready
2022-04-03 05:12:11 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-a56c6c64 is in desired state: Ready
2022-04-03 05:12:11 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-149116762-1208379876 in namespace namespace-142
2022-04-03 05:12:11 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-142
2022-04-03 05:12:11 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-149116762-1208379876 will have desired state: Ready
2022-04-03 05:12:13 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-149116762-1208379876 is in desired state: Ready
2022-04-03 05:12:13 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-a56c6c64-kafka-clients in namespace namespace-142
2022-04-03 05:12:13 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-142
2022-04-03 05:12:13 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-a56c6c64-kafka-clients will be ready
2022-04-03 05:12:15 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-a56c6c64-kafka-clients is ready
2022-04-03 05:12:15 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-03 05:12:15 [main] [32mINFO [m [KafkaST:1078] Waiting for kafka stateful set labels changed {label-name-1=name-of-the-label-1, label-name-2=name-of-the-label-2}
2022-04-03 05:12:15 [main] [32mINFO [m [StatefulSetUtils:85] Waiting for Stateful set label change label-name-1 -> name-of-the-label-1
2022-04-03 05:12:15 [main] [32mINFO [m [StatefulSetUtils:85] Waiting for Stateful set label change label-name-2 -> name-of-the-label-2
2022-04-03 05:12:15 [main] [32mINFO [m [KafkaST:1081] Getting labels from stateful set resource
2022-04-03 05:12:15 [main] [32mINFO [m [KafkaST:1084] Verifying default labels in the Kafka CR
2022-04-03 05:12:15 [main] [32mINFO [m [KafkaST:1095] Setting new values of labels from name-of-the-label-1 to new-name-of-the-label-1 | from name-of-the-label-2 to new-name-of-the-label-2 and adding one label-name-3 with value name-of-the-label-3
2022-04-03 05:12:15 [main] [32mINFO [m [KafkaST:1098] Edit kafka labels in Kafka CR
2022-04-03 05:12:15 [main] [32mINFO [m [KafkaST:1109] Waiting for kafka service labels changed {label-name-1=new-name-of-the-label-1, label-name-2=new-name-of-the-label-2, label-name-3=name-of-the-label-3}
2022-04-03 05:12:15 [main] [32mINFO [m [ServiceUtils:33] Waiting for Service label change label-name-1 -> new-name-of-the-label-1
2022-04-03 05:12:43 [main] [32mINFO [m [ServiceUtils:33] Waiting for Service label change label-name-2 -> new-name-of-the-label-2
2022-04-03 05:12:43 [main] [32mINFO [m [ServiceUtils:33] Waiting for Service label change label-name-3 -> name-of-the-label-3
2022-04-03 05:12:43 [main] [32mINFO [m [KafkaST:1112] Verifying kafka labels via services
2022-04-03 05:12:43 [main] [32mINFO [m [KafkaST:1118] Waiting for Kafka ConfigMap my-cluster-a56c6c64-kafka-config in namespace namespace-142 to have new labels: {label-name-1=new-name-of-the-label-1, label-name-2=new-name-of-the-label-2, label-name-3=name-of-the-label-3}
2022-04-03 05:12:43 [main] [32mINFO [m [ConfigMapUtils:42] Waiting for ConfigMap my-cluster-a56c6c64-kafka-config label change label-name-1 -> new-name-of-the-label-1
2022-04-03 05:12:43 [main] [32mINFO [m [ConfigMapUtils:42] Waiting for ConfigMap my-cluster-a56c6c64-kafka-config label change label-name-2 -> new-name-of-the-label-2
2022-04-03 05:12:43 [main] [32mINFO [m [ConfigMapUtils:42] Waiting for ConfigMap my-cluster-a56c6c64-kafka-config label change label-name-3 -> name-of-the-label-3
2022-04-03 05:12:43 [main] [32mINFO [m [KafkaST:1121] Verifying Kafka labels on ConfigMap my-cluster-a56c6c64-kafka-config in namespace namespace-142
2022-04-03 05:12:43 [main] [32mINFO [m [KafkaST:1127] Waiting for kafka stateful set labels changed {label-name-1=new-name-of-the-label-1, label-name-2=new-name-of-the-label-2, label-name-3=name-of-the-label-3}
2022-04-03 05:12:43 [main] [32mINFO [m [StatefulSetUtils:85] Waiting for Stateful set label change label-name-1 -> new-name-of-the-label-1
2022-04-03 05:12:43 [main] [32mINFO [m [StatefulSetUtils:85] Waiting for Stateful set label change label-name-2 -> new-name-of-the-label-2
2022-04-03 05:12:43 [main] [32mINFO [m [StatefulSetUtils:85] Waiting for Stateful set label change label-name-3 -> name-of-the-label-3
2022-04-03 05:12:43 [main] [32mINFO [m [KafkaST:1130] Verifying kafka labels via stateful set
2022-04-03 05:12:43 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-a56c6c64-kafka rolling update
2022-04-03 05:13:53 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-a56c6c64-kafka has been successfully rolled
2022-04-03 05:13:53 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-a56c6c64-kafka to be ready
2022-04-03 05:14:19 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-a56c6c64 will have desired state: Ready
2022-04-03 05:14:19 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-a56c6c64 is in desired state: Ready
2022-04-03 05:14:19 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-a56c6c64 is ready
2022-04-03 05:14:19 [main] [32mINFO [m [KafkaST:1136] Verifying via kafka pods
2022-04-03 05:14:19 [main] [32mINFO [m [KafkaST:1143] Removing labels: label-name-1 -> new-name-of-the-label-1, label-name-2 -> new-name-of-the-label-2, label-name-3 -> name-of-the-label-3
2022-04-03 05:14:19 [main] [32mINFO [m [KafkaST:1155] Waiting for kafka service labels deletion {app.kubernetes.io/instance=my-cluster-a56c6c64, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-a56c6c64, controller-revision-hash=my-cluster-a56c6c64-kafka-74d8c57967, statefulset.kubernetes.io/pod-name=my-cluster-a56c6c64-kafka-0, strimzi.io/cluster=my-cluster-a56c6c64, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-a56c6c64-kafka, test.case=testLabelModificationDoesNotBreakCluster}
2022-04-03 05:14:19 [main] [32mINFO [m [ServiceUtils:44] Service label label-name-1 change to null
2022-04-03 05:15:28 [main] [32mINFO [m [ServiceUtils:44] Service label label-name-2 change to null
2022-04-03 05:15:28 [main] [32mINFO [m [ServiceUtils:44] Service label label-name-3 change to null
2022-04-03 05:15:28 [main] [32mINFO [m [KafkaST:1158] Verifying kafka labels via services
2022-04-03 05:15:28 [main] [32mINFO [m [KafkaST:1164] Waiting for Kafka ConfigMap my-cluster-a56c6c64-kafka-config in namespace namespace-142 to have labels removed: [label-name-1, label-name-2, label-name-3]
2022-04-03 05:15:28 [main] [32mINFO [m [ConfigMapUtils:53] Waiting for ConfigMap my-cluster-a56c6c64-kafka-config label label-name-1 change to null
2022-04-03 05:15:28 [main] [32mINFO [m [ConfigMapUtils:60] ConfigMap my-cluster-a56c6c64-kafka-config label label-name-1 change to null
2022-04-03 05:15:28 [main] [32mINFO [m [ConfigMapUtils:53] Waiting for ConfigMap my-cluster-a56c6c64-kafka-config label label-name-2 change to null
2022-04-03 05:15:28 [main] [32mINFO [m [ConfigMapUtils:60] ConfigMap my-cluster-a56c6c64-kafka-config label label-name-2 change to null
2022-04-03 05:15:28 [main] [32mINFO [m [ConfigMapUtils:53] Waiting for ConfigMap my-cluster-a56c6c64-kafka-config label label-name-3 change to null
2022-04-03 05:15:28 [main] [32mINFO [m [ConfigMapUtils:60] ConfigMap my-cluster-a56c6c64-kafka-config label label-name-3 change to null
2022-04-03 05:15:28 [main] [32mINFO [m [KafkaST:1167] Verifying Kafka labels on ConfigMap my-cluster-a56c6c64-kafka-config in namespace namespace-142
2022-04-03 05:15:28 [main] [32mINFO [m [KafkaST:1173] Waiting for kafka stateful set labels changed {app.kubernetes.io/instance=my-cluster-a56c6c64, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-a56c6c64, controller-revision-hash=my-cluster-a56c6c64-kafka-74d8c57967, statefulset.kubernetes.io/pod-name=my-cluster-a56c6c64-kafka-0, strimzi.io/cluster=my-cluster-a56c6c64, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-a56c6c64-kafka, test.case=testLabelModificationDoesNotBreakCluster}
2022-04-03 05:15:28 [main] [32mINFO [m [StatefulSetUtils:96] Waiting for StatefulSet label label-name-1 change to null
2022-04-03 05:15:28 [main] [32mINFO [m [StatefulSetUtils:101] StatefulSet label label-name-1 change to null
2022-04-03 05:15:28 [main] [32mINFO [m [StatefulSetUtils:96] Waiting for StatefulSet label label-name-2 change to null
2022-04-03 05:15:28 [main] [32mINFO [m [StatefulSetUtils:101] StatefulSet label label-name-2 change to null
2022-04-03 05:15:28 [main] [32mINFO [m [StatefulSetUtils:96] Waiting for StatefulSet label label-name-3 change to null
2022-04-03 05:15:28 [main] [32mINFO [m [StatefulSetUtils:101] StatefulSet label label-name-3 change to null
2022-04-03 05:15:28 [main] [32mINFO [m [KafkaST:1176] Verifying kafka labels via stateful set
2022-04-03 05:15:28 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-a56c6c64-kafka rolling update
2022-04-03 05:15:28 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-a56c6c64-kafka has been successfully rolled
2022-04-03 05:15:28 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-a56c6c64-kafka to be ready
2022-04-03 05:17:21 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-a56c6c64 will have desired state: Ready
2022-04-03 05:17:21 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-a56c6c64 is in desired state: Ready
2022-04-03 05:17:21 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-a56c6c64 is ready
2022-04-03 05:17:21 [main] [32mINFO [m [KafkaST:1181] Waiting for kafka pod labels deletion {app.kubernetes.io/instance=my-cluster-a56c6c64, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-a56c6c64, controller-revision-hash=my-cluster-a56c6c64-kafka-74d8c57967, statefulset.kubernetes.io/pod-name=my-cluster-a56c6c64-kafka-0, strimzi.io/cluster=my-cluster-a56c6c64, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-a56c6c64-kafka, test.case=testLabelModificationDoesNotBreakCluster}
2022-04-03 05:17:21 [main] [32mINFO [m [PodUtils:262] Waiting for Pod label label-name-1 change to null
2022-04-03 05:17:21 [main] [32mINFO [m [PodUtils:267] Pod label label-name-1 changed to null
2022-04-03 05:17:21 [main] [32mINFO [m [PodUtils:262] Waiting for Pod label label-name-2 change to null
2022-04-03 05:17:21 [main] [32mINFO [m [PodUtils:267] Pod label label-name-2 changed to null
2022-04-03 05:17:21 [main] [32mINFO [m [PodUtils:262] Waiting for Pod label label-name-3 change to null
2022-04-03 05:17:21 [main] [32mINFO [m [PodUtils:267] Pod label label-name-3 changed to null
2022-04-03 05:17:21 [main] [32mINFO [m [KafkaST:1186] Verifying via kafka pods
2022-04-03 05:17:21 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@2809647, messages=[], arguments=[--max-messages, 100, --topic, my-topic-149116762-1208379876, --bootstrap-server, my-cluster-a56c6c64-kafka-bootstrap.namespace-142.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-a56c6c64-kafka-clients-7b5c47b957-2c422', podNamespace='namespace-142', bootstrapServer='my-cluster-a56c6c64-kafka-bootstrap.namespace-142.svc:9092', topicName='my-topic-149116762-1208379876', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3fc11ef0}
2022-04-03 05:17:21 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-a56c6c64-kafka-bootstrap.namespace-142.svc:9092:my-topic-149116762-1208379876 from pod my-cluster-a56c6c64-kafka-clients-7b5c47b957-2c422
2022-04-03 05:17:21 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-a56c6c64-kafka-clients-7b5c47b957-2c422 -n namespace-142 -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-149116762-1208379876 --bootstrap-server my-cluster-a56c6c64-kafka-bootstrap.namespace-142.svc:9092
2022-04-03 05:17:23 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-03 05:17:23 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-03 05:17:23 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@66113d06, messages=[], arguments=[--max-messages, 100, --group-instance-id, instance939281060, --group-id, my-consumer-group-2031493671, --topic, my-topic-149116762-1208379876, --bootstrap-server, my-cluster-a56c6c64-kafka-bootstrap.namespace-142.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-a56c6c64-kafka-clients-7b5c47b957-2c422', podNamespace='namespace-142', bootstrapServer='my-cluster-a56c6c64-kafka-bootstrap.namespace-142.svc:9092', topicName='my-topic-149116762-1208379876', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-2031493671', consumerInstanceId='instance939281060', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@51109f4a}
2022-04-03 05:17:23 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-a56c6c64-kafka-bootstrap.namespace-142.svc:9092#my-topic-149116762-1208379876 from pod my-cluster-a56c6c64-kafka-clients-7b5c47b957-2c422
2022-04-03 05:17:23 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-a56c6c64-kafka-clients-7b5c47b957-2c422 -n namespace-142 -- /opt/kafka/consumer.sh --max-messages 100 --group-instance-id instance939281060 --group-id my-consumer-group-2031493671 --topic my-topic-149116762-1208379876 --bootstrap-server my-cluster-a56c6c64-kafka-bootstrap.namespace-142.svc:9092
2022-04-03 05:17:29 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-03 05:17:29 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-03 05:17:29 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 05:17:29 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testLabelModificationDoesNotBreakCluster
2022-04-03 05:17:29 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-149116762-1208379876 in namespace namespace-142
2022-04-03 05:17:29 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-a56c6c64 in namespace namespace-142
2022-04-03 05:17:29 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-a56c6c64-kafka-clients in namespace namespace-142
2022-04-03 05:18:10 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 05:18:10 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testLabelModificationDoesNotBreakCluster-FINISHED
2022-04-03 05:18:10 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 05:18:10 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 05:18:10 [main] [32mINFO [m [ResourceManager:346] In context KafkaST is everything deleted.
2022-04-03 05:18:10 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 479.66 s - in io.strimzi.systemtest.kafka.KafkaST
[[1;34mINFO[m] Running io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfSharedST
2022-04-03 05:18:15 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: dynamic-conf-shared-st
2022-04-03 05:18:15 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: dynamic-conf-shared-st
2022-04-03 05:18:15 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: dynamic-conf-shared-st
2022-04-03 05:18:15 [main] [32mINFO [m [DynamicConfSharedST:218] Deploying shared Kafka across all test cases!
2022-04-03 05:18:15 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka dynamic-configuration-shared-cluster-name in namespace dynamic-conf-shared-st
2022-04-03 05:18:15 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: dynamic-configuration-shared-cluster-name will have desired state: Ready
2022-04-03 05:20:11 [main] [32mINFO [m [ResourceManager:444] Kafka: dynamic-configuration-shared-cluster-name is in desired state: Ready
2022-04-03 05:20:11 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 05:20:11 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfSharedST.testDynConfiguration-STARTED
2022-04-03 05:20:11 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 05:20:11 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 05:20:11 [main] [32mINFO [m [ResourceManager:346] In context testDynConfiguration is everything deleted.
2022-04-03 05:20:11 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 05:20:11 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfSharedST.testDynConfiguration-FINISHED
2022-04-03 05:20:11 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 05:20:11 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 05:20:11 [main] [32mINFO [m [ResourceManager:348] Delete all resources for DynamicConfSharedST
2022-04-03 05:20:11 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka dynamic-configuration-shared-cluster-name in namespace dynamic-conf-shared-st
2022-04-03 05:20:21 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;31mERROR[m] Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 152.585 s <<< FAILURE! - in io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfSharedST
[[1;31mERROR[m] io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfSharedST.testDynConfiguration  Time elapsed: 115.44 s  <<< ERROR!
java.lang.RuntimeException: Error reading from classpath resource /home/ec2-user/strimzi-kafka-operator/systemtest/../cluster-operator/src/main/resources/kafka-3.1.0-config-model.json
	at io.strimzi.systemtest.utils.kafkaUtils.KafkaUtils.readConfigModel(KafkaUtils.java:320)
	at io.strimzi.systemtest.utils.kafkaUtils.KafkaUtils.getDynamicConfigurationProperties(KafkaUtils.java:332)
	at io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfSharedST.generateTestCases(DynamicConfSharedST.java:84)
	at io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfSharedST.testDynConfiguration(DynamicConfSharedST.java:57)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestFactoryMethod(TimeoutExtension.java:100)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestFactoryTestDescriptor.lambda$invokeTestMethod$1(TestFactoryTestDescriptor.java:97)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestFactoryTestDescriptor.invokeTestMethod(TestFactoryTestDescriptor.java:95)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:165)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
Caused by: java.io.FileNotFoundException: /home/ec2-user/strimzi-kafka-operator/systemtest/../cluster-operator/src/main/resources/kafka-3.1.0-config-model.json (No such file or directory)
	at java.base/java.io.FileInputStream.open0(Native Method)
	at java.base/java.io.FileInputStream.open(FileInputStream.java:219)
	at java.base/java.io.FileInputStream.<init>(FileInputStream.java:157)
	at java.base/java.io.FileInputStream.<init>(FileInputStream.java:112)
	at io.strimzi.systemtest.utils.kafkaUtils.KafkaUtils.readConfigModel(KafkaUtils.java:312)
	... 101 more

[[1;34mINFO[m] Running io.strimzi.systemtest.rollingupdate.RollingUpdateST
2022-04-03 05:20:48 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: rolling-update-st
2022-04-03 05:20:48 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: rolling-update-st
2022-04-03 05:20:48 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: rolling-update-st
2022-04-03 05:20:48 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 05:20:48 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testClusterOperatorFinishAllRollingUpdates-STARTED
2022-04-03 05:20:48 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 05:20:48 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-010969dd in namespace rolling-update-st
2022-04-03 05:20:48 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-010969dd will have desired state: Ready
2022-04-03 05:22:09 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-010969dd is in desired state: Ready
2022-04-03 05:22:14 [main] [32mINFO [m [RollingUpdateST:630] Deleting Cluster Operator pod with labels LabelSelector(matchExpressions=[], matchLabels={name=strimzi-cluster-operator}, additionalProperties={})
2022-04-03 05:22:14 [main] [32mINFO [m [RollingUpdateST:632] Cluster Operator pod deleted
2022-04-03 05:22:14 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-010969dd-zookeeper rolling update
2022-04-03 05:23:04 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-010969dd-zookeeper has been successfully rolled
2022-04-03 05:23:04 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-010969dd-zookeeper to be ready
2022-04-03 05:23:35 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-010969dd will have desired state: Ready
2022-04-03 05:23:35 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-010969dd is in desired state: Ready
2022-04-03 05:23:35 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-010969dd is ready
2022-04-03 05:23:36 [main] [32mINFO [m [RollingUpdateST:639] Deleting Cluster Operator pod with labels LabelSelector(matchExpressions=[], matchLabels={name=strimzi-cluster-operator}, additionalProperties={})
2022-04-03 05:23:36 [main] [32mINFO [m [RollingUpdateST:641] Cluster Operator pod deleted
2022-04-03 05:23:36 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-010969dd-kafka rolling update
2022-04-03 05:24:56 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-010969dd-kafka has been successfully rolled
2022-04-03 05:24:56 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-010969dd-kafka to be ready
2022-04-03 05:25:24 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-010969dd will have desired state: Ready
2022-04-03 05:25:24 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-010969dd is in desired state: Ready
2022-04-03 05:25:24 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-010969dd is ready
2022-04-03 05:25:24 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 05:25:24 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testClusterOperatorFinishAllRollingUpdates
2022-04-03 05:25:24 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-010969dd in namespace rolling-update-st
2022-04-03 05:25:34 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 05:25:34 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testClusterOperatorFinishAllRollingUpdates-FINISHED
2022-04-03 05:25:34 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 05:25:34 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 05:25:34 [main] [32mINFO [m [ResourceManager:346] In context RollingUpdateST is everything deleted.
2022-04-03 05:25:34 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 327.856 s - in io.strimzi.systemtest.rollingupdate.RollingUpdateST
[[1;34mINFO[m] Running io.strimzi.systemtest.backup.ColdBackupScriptIsolatedST
2022-04-03 05:26:16 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-03 05:26:41 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-03 05:26:41 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-03 05:26:41 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-03 05:26:41 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 05:26:41 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-03 05:26:41 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 05:26:41 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-03 05:26:41 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-03 05:26:41 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-03 05:26:41 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-03 05:26:41 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-03 05:26:41 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-03 05:26:41 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-03 05:26:41 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-03 05:26:41 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-03 05:26:41 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:26:41 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-03 05:26:41 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 05:26:41 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-03 05:26:41 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:26:41 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-03 05:26:51 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-03 05:26:51 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-03 05:26:51 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:26:51 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-03 05:26:51 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-03 05:26:51 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-03 05:26:51 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-03 05:26:51 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-03 05:26:51 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:27:01 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 05:27:11 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@5f4d6ac4
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-03 05:27:11 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-03 05:27:11 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-03 05:27:11 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-03 05:27:11 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:27:11 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 05:27:11 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-03 05:27:11 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-03 05:27:11 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-03 05:27:11 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-03 05:27:11 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-03 05:27:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-03 05:27:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-03 05:27:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-03 05:27:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-03 05:27:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-03 05:27:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-03 05:27:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-03 05:27:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-03 05:27:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-03 05:27:12 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:27:12 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-03 05:27:12 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-03 05:27:12 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-03 05:27:12 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-03 05:27:12 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-03 05:27:12 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-03 05:27:12 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-03 05:27:12 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-03 05:27:12 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:27:12 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-03 05:27:12 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-03 05:27:12 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-03 05:27:12 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-03 05:27:12 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 05:27:12 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-03 05:27:12 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:27:12 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-03 05:27:31 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-03 05:27:31 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-03 05:27:41 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-03 05:27:41 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 05:27:41 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.backup.ColdBackupScriptIsolatedST.backupAndRestore-STARTED
2022-04-03 05:27:41 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 05:27:41 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-54b5034b in namespace infra-namespace
2022-04-03 05:27:41 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-54b5034b will have desired state: Ready
2022-04-03 05:28:53 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-54b5034b is in desired state: Ready
2022-04-03 05:28:53 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-54b5034b-producer in namespace infra-namespace
2022-04-03 05:28:53 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-54b5034b-consumer in namespace infra-namespace
2022-04-03 05:28:53 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-54b5034b-producer will be in active state
2022-04-03 05:28:54 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-54b5034b-consumer will be in active state
2022-04-03 05:28:54 [main] [32mINFO [m [ClientUtils:61] Waiting till producer my-cluster-54b5034b-producer and consumer my-cluster-54b5034b-consumer finish
2022-04-03 05:29:12 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-54b5034b-kafka-0 -- /opt/kafka/bin/kafka-consumer-groups.sh --describe --bootstrap-server localhost:9092 --group my-group
2022-04-03 05:29:12 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-03 05:29:12 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-54b5034b-producer in namespace infra-namespace
2022-04-03 05:29:12 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-54b5034b-producer will be in active state
2022-04-03 05:29:13 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:my-cluster-54b5034b-producer to finished
2022-04-03 05:29:20 [main] [32mINFO [m [ColdBackupScriptIsolatedST:95] Running backup procedure for infra-namespace/my-cluster-54b5034b
2022-04-03 05:29:21 [main] [32mINFO [m [Exec:417] Failed to exec command: /home/ec2-user/strimzi-kafka-operator/systemtest/../tools/cold-backup/run.sh backup -n infra-namespace -c my-cluster-54b5034b -t /home/ec2-user/strimzi-kafka-operator/systemtest/target/my-cluster-54b5034b.tgz -y
2022-04-03 05:29:21 [main] [32mINFO [m [Exec:417] Return code: 1
2022-04-03 05:29:21 [main] [32mINFO [m [Exec:417] ======STDOUT START=======
2022-04-03 05:29:21 [main] [32mINFO [m [Exec:417] Exporting environment
Starting cluster my-cluster-54b5034b
2022-04-03 05:29:21 [main] [32mINFO [m [Exec:417] ======STDOUT END======
2022-04-03 05:29:21 [main] [32mINFO [m [Exec:417] ======STDERR START=======
2022-04-03 05:29:21 [main] [32mINFO [m [Exec:417] /home/ec2-user/strimzi-kafka-operator/systemtest/../tools/cold-backup/run.sh: line 145: yq: command not found
Error: invalid argument "Starting cluster my-cluster-54b5034b\nstatefulset.apps/my-cluster-54b5034b-zookeeper scaled\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/name=my-cluster-54b5034b-zookeeper\" in namespace \"infra-namespace\"\npod/my-cluster-54b5034b-zookeeper-0 condition met\nstatefulset.apps/my-cluster-54b5034b-kafka scaled\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/name=my-cluster-54b5034b-kafka\" in namespace \"infra-namespace\"\npod/my-cluster-54b5034b-kafka-0 condition met\ndeployment.apps/strimzi-cluster-operator scaled\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/kind=cluster-operator\" in namespace \"infra-namespace\"\npod/strimzi-cluster-operator-78689684d4-h9ckr condition met\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/name=my-cluster-54b5034b-kafka\" in namespace \"infra-namespace\"\npod/my-cluster-54b5034b-kafka-0 condition met\nbackup failed at 145: yq eval \".spec.zookeeper.replicas\" -" for "--replicas" flag: strconv.ParseInt: parsing "Starting cluster my-cluster-54b5034b\nstatefulset.apps/my-cluster-54b5034b-zookeeper scaled\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/name=my-cluster-54b5034b-zookeeper\" in namespace \"infra-namespace\"\npod/my-cluster-54b5034b-zookeeper-0 condition met\nstatefulset.apps/my-cluster-54b5034b-kafka scaled\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/name=my-cluster-54b5034b-kafka\" in namespace \"infra-namespace\"\npod/my-cluster-54b5034b-kafka-0 condition met\ndeployment.apps/strimzi-cluster-operator scaled\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/kind=cluster-operator\" in namespace \"infra-namespace\"\npod/strimzi-cluster-operator-78689684d4-h9ckr condition met\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/name=my-cluster-54b5034b-kafka\" in namespace \"infra-namespace\"\npod/my-cluster-54b5034b-kafka-0 condition met\nbackup failed at 145: yq eval \".spec.zookeeper.replicas\" -": invalid syntax


Examples:
  # Scale a replicaset named 'foo' to 3.
  kubectl scale --replicas=3 rs/foo
  
  # Scale a resource identified by type and name specified in "foo.yaml" to 3.
  kubectl scale --replicas=3 -f foo.yaml
  
  # If the deployment named mysql's current size is 2, scale mysql to 3.
  kubectl scale --current-replicas=2 --replicas=3 deployment/mysql
  
  # Scale multiple replication controllers.
  kubectl scale --replicas=5 rc/foo rc/bar rc/baz
  
  # Scale statefulset named 'web' to 3.
  kubectl scale --replicas=3 statefulset/web

Options:
      --all=false: Select all resources in the namespace of the specified resource types
      --allow-missing-template-keys=true: If true, ignore any errors in templates when a field or map key is missing in the template. Only applies to golang and jsonpath output formats.
      --current-replicas=-1: Precondition for current size. Requires that the current size of the resource match this value in order to scale.
  -f, --filename=[]: Filename, directory, or URL to files identifying the resource to set a new size
  -k, --kustomize='': Process the kustomization directory. This flag can't be used together with -f or -R.
  -o, --output='': Output format. One of: json|yaml|name|go-template|go-template-file|template|templatefile|jsonpath|jsonpath-file.
      --record=false: Record current kubectl command in the resource annotation. If set to false, do not record the command. If set to true, record the command. If not set, default to updating the existing annotation value only if one already exists.
  -R, --recursive=false: Process the directory used in -f, --filename recursively. Useful when you want to manage related manifests organized within the same directory.
      --replicas=0: The new desired number of replicas. Required.
      --resource-version='': Precondition for resource version. Requires that the current resource version match this value in order to scale.
  -l, --selector='': Selector (label query) to filter on, supports '=', '==', and '!='.(e.g. -l key1=value1,key2=value2)
      --template='': Template string or path to template file to use when -o=go-template, -o=go-template-file. The template format is golang templates [http://golang.org/pkg/text/template/#pkg-overview].
      --timeout=0s: The length of time to wait before giving up on a scale operation, zero means don't wait. Any other values should contain a corresponding time unit (e.g. 1s, 2m, 3h).

Usage:
  kubectl scale [--resource-version=version] [--current-replicas=count] --replicas=COUNT (-f FILENAME | TYPE NAME) [options]

Use "kubectl options" for a list of global command-line options (applies to all commands).
2022-04-03 05:29:21 [main] [32mINFO [m [Exec:417] ======STDERR END======
2022-04-03 05:29:21 [main] [1;31mERROR[m [TestExecutionWatcher:28] ColdBackupScriptIsolatedST - Exception `/home/ec2-user/strimzi-kafka-operator/systemtest/../tools/cold-backup/run.sh backup -n infra-namespace -c my-cluster-54b5034b -t /home/ec2-user/strimzi-kafka-operator/systemtest/target/my-cluster-54b5034b.tgz -y` got status code 1 and stderr:
------
/home/ec2-user/strimzi-kafka-operator/systemtest/../tools/cold-backup/run.sh: line 145: yq: command not found
Error: invalid argument "Starting cluster my-cluster-54b5034b\nstatefulset.apps/my-cluster-54b5034b-zookeeper scaled\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/name=my-cluster-54b5034b-zookeeper\" in namespace \"infra-namespace\"\npod/my-cluster-54b5034b-zookeeper-0 condition met\nstatefulset.apps/my-cluster-54b5034b-kafka scaled\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/name=my-cluster-54b5034b-kafka\" in namespace \"infra-namespace\"\npod/my-cluster-54b5034b-kafka-0 condition met\ndeployment.apps/strimzi-cluster-operator scaled\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/kind=cluster-operator\" in namespace \"infra-namespace\"\npod/strimzi-cluster-operator-78689684d4-h9ckr condition met\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/name=my-cluster-54b5034b-kafka\" in namespace \"infra-namespace\"\npod/my-cluster-54b5034b-kafka-0 condition met\nbackup failed at 145: yq eval \".spec.zookeeper.replicas\" -" for "--replicas" flag: strconv.ParseInt: parsing "Starting cluster my-cluster-54b5034b\nstatefulset.apps/my-cluster-54b5034b-zookeeper scaled\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/name=my-cluster-54b5034b-zookeeper\" in namespace \"infra-namespace\"\npod/my-cluster-54b5034b-zookeeper-0 condition met\nstatefulset.apps/my-cluster-54b5034b-kafka scaled\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/name=my-cluster-54b5034b-kafka\" in namespace \"infra-namespace\"\npod/my-cluster-54b5034b-kafka-0 condition met\ndeployment.apps/strimzi-cluster-operator scaled\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/kind=cluster-operator\" in namespace \"infra-namespace\"\npod/strimzi-cluster-operator-78689684d4-h9ckr condition met\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/name=my-cluster-54b5034b-kafka\" in namespace \"infra-namespace\"\npod/my-cluster-54b5034b-kafka-0 condition met\nbackup failed at 145: yq eval \".spec.zookeeper.replicas\" -": invalid syntax


Examples:
  # Scale a replicaset named 'foo' to 3.
  kubectl scale --replicas=3 rs/foo
  
  # Scale a resource identified by type and name specified in "foo.yaml" to 3.
  kubectl scale --replicas=3 -f foo.yaml
  
  # If the deployment named mysql's current size is 2, scale mysql to 3.
  kubectl scale --current-replicas=2 --replicas=3 deployment/mysql
  
  # Scale multiple replication controllers.
  kubectl scale --replicas=5 rc/foo rc/bar rc/baz
  
  # Scale statefulset named 'web' to 3.
  kubectl scale --replicas=3 statefulset/web

Options:
      --all=false: Select all resources in the namespace of the specified resource types
      --allow-missing-template-keys=true: If true, ignore any errors in templates when a field or map key is missing in the template. Only applies to golang and jsonpath output formats.
      --current-replicas=-1: Precondition for current size. Requires that the current size of the resource match this value in order to scale.
  -f, --filename=[]: Filename, directory, or URL to files identifying the resource to set a new size
  -k, --kustomize='': Process the kustomization directory. This flag can't be used together with -f or -R.
  -o, --output='': Output format. One of: json|yaml|name|go-template|go-template-file|template|templatefile|jsonpath|jsonpath-file.
      --record=false: Record current kubectl command in the resource annotation. If set to false, do not record the command. If set to true, record the command. If not set, default to updating the existing annotation value only if one already exists.
  -R, --recursive=false: Process the directory used in -f, --filename recursively. Useful when you want to manage related manifests organized within the same directory.
      --replicas=0: The new desired number of replicas. Required.
      --resource-version='': Precondition for resource version. Requires that the current resource version match this value in order to scale.
  -l, --selector='': Selector (label query) to filter on, supports '=', '==', and '!='.(e.g. -l key1=value1,key2=value2)
      --template='': Template string or path to template file to use when -o=go-template, -o=go-template-file. The template format is golang templates [http://golang.org/pkg/text/template/#pkg-overview].
      --timeout=0s: The length of time to wait before giving up on a scale operation, zero means don't wait. Any other values should contain a corresponding time unit (e.g. 1s, 2m, 3h).

Usage:
  kubectl scale [--resource-version=version] [--current-replicas=count] --replicas=COUNT (-f FILENAME | TYPE NAME) [options]

Use "kubectl options" for a list of global command-line options (applies to all commands).


------
and stdout:
------
Exporting environment
Starting cluster my-cluster-54b5034b

------ has been thrown in @Test. Going to collect logs from components.
2022-04-03 05:29:21 [main] [32mINFO [m [LogCollector:252] Collecting events in Namespace infra-namespace
2022-04-03 05:29:22 [main] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace infra-namespace
2022-04-03 05:29:22 [main] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace infra-namespace
2022-04-03 05:29:22 [main] [33mWARN [m [LogCollector:298] Unable to collect log from pod: my-cluster-54b5034b-zookeeper-0 and container: zookeeper - pod container is not initialized
2022-04-03 05:29:22 [main] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace infra-namespace
2022-04-03 05:29:22 [main] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace infra-namespace
2022-04-03 05:29:22 [main] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace infra-namespace
2022-04-03 05:29:22 [main] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace infra-namespace
2022-04-03 05:29:23 [main] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-04-03 05:29:23 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 05:29:23 [main] [32mINFO [m [ResourceManager:348] Delete all resources for backupAndRestore
2022-04-03 05:29:23 [main] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-54b5034b-consumer in namespace infra-namespace
2022-04-03 05:29:23 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-54b5034b-producer in namespace infra-namespace
2022-04-03 05:29:23 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-54b5034b in namespace infra-namespace
2022-04-03 05:29:23 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-54b5034b-producer in namespace infra-namespace
2022-04-03 05:29:33 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 05:29:33 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.backup.ColdBackupScriptIsolatedST.backupAndRestore-FINISHED
2022-04-03 05:29:33 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 05:29:33 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 05:29:33 [main] [32mINFO [m [ResourceManager:346] In context ColdBackupScriptIsolatedST is everything deleted.
2022-04-03 05:29:33 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;31mERROR[m] Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 197.345 s <<< FAILURE! - in io.strimzi.systemtest.backup.ColdBackupScriptIsolatedST
[[1;31mERROR[m] io.strimzi.systemtest.backup.ColdBackupScriptIsolatedST.backupAndRestore(ExtensionContext)  Time elapsed: 111.917 s  <<< ERROR!
io.strimzi.test.k8s.exceptions.KubeClusterException: 
`/home/ec2-user/strimzi-kafka-operator/systemtest/../tools/cold-backup/run.sh backup -n infra-namespace -c my-cluster-54b5034b -t /home/ec2-user/strimzi-kafka-operator/systemtest/target/my-cluster-54b5034b.tgz -y` got status code 1 and stderr:
------
/home/ec2-user/strimzi-kafka-operator/systemtest/../tools/cold-backup/run.sh: line 145: yq: command not found
Error: invalid argument "Starting cluster my-cluster-54b5034b\nstatefulset.apps/my-cluster-54b5034b-zookeeper scaled\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/name=my-cluster-54b5034b-zookeeper\" in namespace \"infra-namespace\"\npod/my-cluster-54b5034b-zookeeper-0 condition met\nstatefulset.apps/my-cluster-54b5034b-kafka scaled\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/name=my-cluster-54b5034b-kafka\" in namespace \"infra-namespace\"\npod/my-cluster-54b5034b-kafka-0 condition met\ndeployment.apps/strimzi-cluster-operator scaled\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/kind=cluster-operator\" in namespace \"infra-namespace\"\npod/strimzi-cluster-operator-78689684d4-h9ckr condition met\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/name=my-cluster-54b5034b-kafka\" in namespace \"infra-namespace\"\npod/my-cluster-54b5034b-kafka-0 condition met\nbackup failed at 145: yq eval \".spec.zookeeper.replicas\" -" for "--replicas" flag: strconv.ParseInt: parsing "Starting cluster my-cluster-54b5034b\nstatefulset.apps/my-cluster-54b5034b-zookeeper scaled\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/name=my-cluster-54b5034b-zookeeper\" in namespace \"infra-namespace\"\npod/my-cluster-54b5034b-zookeeper-0 condition met\nstatefulset.apps/my-cluster-54b5034b-kafka scaled\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/name=my-cluster-54b5034b-kafka\" in namespace \"infra-namespace\"\npod/my-cluster-54b5034b-kafka-0 condition met\ndeployment.apps/strimzi-cluster-operator scaled\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/kind=cluster-operator\" in namespace \"infra-namespace\"\npod/strimzi-cluster-operator-78689684d4-h9ckr condition met\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/name=my-cluster-54b5034b-kafka\" in namespace \"infra-namespace\"\npod/my-cluster-54b5034b-kafka-0 condition met\nbackup failed at 145: yq eval \".spec.zookeeper.replicas\" -": invalid syntax


Examples:
  # Scale a replicaset named 'foo' to 3.
  kubectl scale --replicas=3 rs/foo
  
  # Scale a resource identified by type and name specified in "foo.yaml" to 3.
  kubectl scale --replicas=3 -f foo.yaml
  
  # If the deployment named mysql's current size is 2, scale mysql to 3.
  kubectl scale --current-replicas=2 --replicas=3 deployment/mysql
  
  # Scale multiple replication controllers.
  kubectl scale --replicas=5 rc/foo rc/bar rc/baz
  
  # Scale statefulset named 'web' to 3.
  kubectl scale --replicas=3 statefulset/web

Options:
      --all=false: Select all resources in the namespace of the specified resource types
      --allow-missing-template-keys=true: If true, ignore any errors in templates when a field or map key is missing in the template. Only applies to golang and jsonpath output formats.
      --current-replicas=-1: Precondition for current size. Requires that the current size of the resource match this value in order to scale.
  -f, --filename=[]: Filename, directory, or URL to files identifying the resource to set a new size
  -k, --kustomize='': Process the kustomization directory. This flag can't be used together with -f or -R.
  -o, --output='': Output format. One of: json|yaml|name|go-template|go-template-file|template|templatefile|jsonpath|jsonpath-file.
      --record=false: Record current kubectl command in the resource annotation. If set to false, do not record the command. If set to true, record the command. If not set, default to updating the existing annotation value only if one already exists.
  -R, --recursive=false: Process the directory used in -f, --filename recursively. Useful when you want to manage related manifests organized within the same directory.
      --replicas=0: The new desired number of replicas. Required.
      --resource-version='': Precondition for resource version. Requires that the current resource version match this value in order to scale.
  -l, --selector='': Selector (label query) to filter on, supports '=', '==', and '!='.(e.g. -l key1=value1,key2=value2)
      --template='': Template string or path to template file to use when -o=go-template, -o=go-template-file. The template format is golang templates [http://golang.org/pkg/text/template/#pkg-overview].
      --timeout=0s: The length of time to wait before giving up on a scale operation, zero means don't wait. Any other values should contain a corresponding time unit (e.g. 1s, 2m, 3h).

Usage:
  kubectl scale [--resource-version=version] [--current-replicas=count] --replicas=COUNT (-f FILENAME | TYPE NAME) [options]

Use "kubectl options" for a list of global command-line options (applies to all commands).


------
and stdout:
------
Exporting environment
Starting cluster my-cluster-54b5034b

------
	at io.strimzi.test.executor.Exec.exec(Exec.java:223)
	at io.strimzi.test.executor.Exec.exec(Exec.java:149)
	at io.strimzi.test.executor.Exec.exec(Exec.java:118)
	at io.strimzi.systemtest.backup.ColdBackupScriptIsolatedST.backupAndRestore(ColdBackupScriptIsolatedST.java:99)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:165)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)

[[1;34mINFO[m] Running io.strimzi.systemtest.specific.HelmChartIsolatedST
2022-04-03 05:29:33 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-03 05:29:58 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-03 05:29:58 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-03 05:29:58 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-03 05:29:58 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 05:29:58 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-03 05:29:58 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-03 05:29:58 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-03 05:29:58 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-03 05:29:58 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-03 05:29:58 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 05:29:58 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:29:58 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-03 05:29:58 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-03 05:29:58 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-03 05:29:58 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:29:58 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-03 05:29:58 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:29:58 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-03 05:29:58 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-03 05:29:58 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-03 05:29:58 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 05:29:58 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-03 05:29:58 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-03 05:29:58 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-03 05:29:58 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:29:58 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-03 05:29:58 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-03 05:30:08 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-03 05:30:08 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-03 05:30:08 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-03 05:30:18 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 05:30:23 [main] [32mINFO [m [HelmChartIsolatedST:67] Creating resources before the test class
2022-04-03 05:30:23 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-03 05:30:23 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-03 05:30:23 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: kube-system
2022-04-03 05:30:24 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace kube-system apply -f -
2022-04-03 05:30:24 [main] [32mINFO [m [Exec:417] Input: apiVersion: v1
kind: ServiceAccount
metadata:
  name: tiller
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: tiller
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
  - kind: ServiceAccount
    name: tiller
    namespace: kube-system
2022-04-03 05:30:24 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-03 05:30:24 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-03 05:30:24 [main] [1;31mERROR[m [TestExecutionWatcher:39] HelmChartIsolatedST - Exception No helm client found on $PATH. $PATH=/home/ec2-user/.sdkman/candidates/maven/current/bin:/home/ec2-user/.local/bin:/home/ec2-user/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin has been thrown in @BeforeAll. Going to collect logs from components.
2022-04-03 05:30:24 [main] [32mINFO [m [LogCollector:252] Collecting events in Namespace infra-namespace
2022-04-03 05:30:24 [main] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace infra-namespace
2022-04-03 05:30:24 [main] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace infra-namespace
2022-04-03 05:30:24 [main] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace infra-namespace
2022-04-03 05:30:24 [main] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace infra-namespace
2022-04-03 05:30:24 [main] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace infra-namespace
2022-04-03 05:30:24 [main] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace infra-namespace
2022-04-03 05:30:24 [main] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-04-03 05:30:24 [main] [1;31mERROR[m [TestExecutionWatcher:70] HelmChartIsolatedST - Exception No helm client found on $PATH. $PATH=/home/ec2-user/.sdkman/candidates/maven/current/bin:/home/ec2-user/.local/bin:/home/ec2-user/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin has been thrown in @AfterAll. Going to collect logs from components.
2022-04-03 05:30:24 [main] [32mINFO [m [LogCollector:252] Collecting events in Namespace infra-namespace
2022-04-03 05:30:24 [main] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace infra-namespace
2022-04-03 05:30:24 [main] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace infra-namespace
2022-04-03 05:30:24 [main] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace infra-namespace
2022-04-03 05:30:24 [main] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace infra-namespace
2022-04-03 05:30:24 [main] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace infra-namespace
2022-04-03 05:30:25 [main] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace infra-namespace
2022-04-03 05:30:25 [main] [32mINFO [m [LogCollector:287] Collecting cluster status
[[1;31mERROR[m] Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 51.988 s <<< FAILURE! - in io.strimzi.systemtest.specific.HelmChartIsolatedST
[[1;31mERROR[m] io.strimzi.systemtest.specific.HelmChartIsolatedST  Time elapsed: 51.988 s  <<< ERROR!
java.lang.RuntimeException: No helm client found on $PATH. $PATH=/home/ec2-user/.sdkman/candidates/maven/current/bin:/home/ec2-user/.local/bin:/home/ec2-user/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin
	at io.strimzi.test.k8s.HelmClient.findClient(HelmClient.java:108)
	at io.strimzi.test.k8s.KubeClusterResource.helmClient(KubeClusterResource.java:354)
	at io.strimzi.test.k8s.KubeClusterResource.helmClusterClient(KubeClusterResource.java:129)
	at io.strimzi.systemtest.resources.ResourceManager.helmClient(ResourceManager.java:116)
	at io.strimzi.systemtest.resources.operator.specific.HelmResource.clusterOperator(HelmResource.java:104)
	at io.strimzi.systemtest.resources.operator.specific.HelmResource.create(HelmResource.java:55)
	at io.strimzi.systemtest.resources.operator.specific.HelmResource.create(HelmResource.java:49)
	at io.strimzi.systemtest.specific.HelmChartIsolatedST.setup(HelmChartIsolatedST.java:70)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptLifecycleMethod(TimeoutExtension.java:126)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptBeforeAllMethod(TimeoutExtension.java:68)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$invokeBeforeAllMethods$11(ClassBasedTestDescriptor.java:397)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.invokeBeforeAllMethods(ClassBasedTestDescriptor.java:395)
	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.before(ClassBasedTestDescriptor.java:209)
	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.before(ClassBasedTestDescriptor.java:80)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:148)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:165)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
	Suppressed: java.lang.RuntimeException: No helm client found on $PATH. $PATH=/home/ec2-user/.sdkman/candidates/maven/current/bin:/home/ec2-user/.local/bin:/home/ec2-user/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin
		at io.strimzi.test.k8s.HelmClient.findClient(HelmClient.java:108)
		at io.strimzi.test.k8s.KubeClusterResource.helmClient(KubeClusterResource.java:354)
		at io.strimzi.test.k8s.KubeClusterResource.helmClusterClient(KubeClusterResource.java:129)
		at io.strimzi.systemtest.resources.ResourceManager.helmClient(ResourceManager.java:116)
		at io.strimzi.systemtest.resources.operator.specific.HelmResource.deleteClusterOperator(HelmResource.java:129)
		at io.strimzi.systemtest.resources.operator.specific.HelmResource.delete(HelmResource.java:60)
		at io.strimzi.systemtest.specific.HelmChartIsolatedST.afterAllMayOverride(HelmChartIsolatedST.java:76)
		at io.strimzi.systemtest.AbstractST.tearDownTestSuite(AbstractST.java:691)
		at jdk.internal.reflect.GeneratedMethodAccessor1239.invoke(Unknown Source)
		at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
		at java.base/java.lang.reflect.Method.invoke(Method.java:566)
		at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
		at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
		at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
		at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
		at org.junit.jupiter.engine.extension.TimeoutExtension.interceptLifecycleMethod(TimeoutExtension.java:126)
		at org.junit.jupiter.engine.extension.TimeoutExtension.interceptAfterAllMethod(TimeoutExtension.java:116)
		at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
		at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
		at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
		at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
		at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
		at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
		at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
		at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
		at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$invokeAfterAllMethods$13(ClassBasedTestDescriptor.java:425)
		at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
		at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$invokeAfterAllMethods$14(ClassBasedTestDescriptor.java:423)
		at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
		at java.base/java.util.Collections$UnmodifiableCollection.forEach(Collections.java:1085)
		at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.invokeAfterAllMethods(ClassBasedTestDescriptor.java:423)
		at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.after(ClassBasedTestDescriptor.java:225)
		at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.after(ClassBasedTestDescriptor.java:80)
		at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$7(NodeTestTask.java:161)
		at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
		at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:161)
		... 63 more

[[1;34mINFO[m] Running io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST
2022-04-03 05:30:25 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-03 05:30:50 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-03 05:30:50 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-03 05:30:50 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-03 05:30:50 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 05:30:50 [main] [32mINFO [m [ResourceManager:346] In context JUnit Jupiter is everything deleted.
2022-04-03 05:30:50 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 05:30:55 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@5f4d6ac4
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-03 05:30:55 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-03 05:30:55 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-03 05:30:55 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-03 05:30:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:30:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 05:30:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-03 05:30:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-03 05:30:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-03 05:30:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-03 05:30:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-03 05:30:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-03 05:30:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-03 05:30:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-03 05:30:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-03 05:30:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-03 05:30:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-03 05:30:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-03 05:30:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-03 05:30:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-03 05:30:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:30:55 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-03 05:30:55 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-03 05:30:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-03 05:30:55 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-03 05:30:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-03 05:30:55 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-03 05:30:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-03 05:30:55 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-03 05:30:55 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:30:55 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-03 05:30:55 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-03 05:30:55 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-03 05:30:55 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-03 05:30:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 05:30:56 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-03 05:30:56 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:30:56 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-03 05:31:13 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-03 05:31:13 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-03 05:31:23 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-03 05:31:23 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy global-network-policy in namespace infra-namespace
2022-04-03 05:31:23 [main] [32mINFO [m [OauthAbstractST:125] Deploying keycloak...
2022-04-03 05:31:23 [main] [32mINFO [m [KeycloakUtils:35] Prepare Keycloak Operator in namespace: infra-namespace with watching namespace: infra-namespace
2022-04-03 05:32:54 [main] [32mINFO [m [Exec:417] Command: /bin/bash ../systemtest/src/test/resources/oauth2/prepare_keycloak_operator.sh infra-namespace 11.0.1 infra-namespace
2022-04-03 05:32:54 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-03 05:32:54 [main] [32mINFO [m [KeycloakUtils:48] Keycloak in namespace infra-namespace is ready
2022-04-03 05:32:54 [main] [32mINFO [m [SecretUtils:46] Waiting for Secret credential-example-keycloak
2022-04-03 05:32:54 [main] [32mINFO [m [SecretUtils:50] Secret credential-example-keycloak created
2022-04-03 05:32:54 [main] [32mINFO [m [SecretUtils:70] Creating secret hello-world-producer-secret
2022-04-03 05:32:54 [main] [32mINFO [m [SecretUtils:70] Creating secret hello-world-consumer-secret
2022-04-03 05:32:54 [main] [32mINFO [m [SecretUtils:70] Creating secret team-a-client-secret
2022-04-03 05:32:54 [main] [32mINFO [m [SecretUtils:70] Creating secret team-b-client-secret
2022-04-03 05:32:54 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-broker-secret
2022-04-03 05:32:54 [main] [32mINFO [m [SecretUtils:70] Creating secret my-connect-oauth
2022-04-03 05:32:54 [main] [32mINFO [m [SecretUtils:70] Creating secret my-mirror-maker-oauth
2022-04-03 05:32:54 [main] [32mINFO [m [SecretUtils:70] Creating secret my-mirror-maker-2-oauth
2022-04-03 05:32:54 [main] [32mINFO [m [SecretUtils:70] Creating secret my-bridge-oauth
2022-04-03 05:32:54 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-audience-secret
2022-04-03 05:32:54 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-client-secret
2022-04-03 05:32:54 [main] [32mINFO [m [KeycloakInstance:50] Replacing validIssuerUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal to pointing to internal realm
2022-04-03 05:32:54 [main] [32mINFO [m [KeycloakInstance:51] Replacing jwksEndpointUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/certs to pointing to internal realm
2022-04-03 05:32:54 [main] [32mINFO [m [KeycloakInstance:52] Replacing oauthTokenEndpointUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/token to pointing to internal realm
2022-04-03 05:32:54 [main] [32mINFO [m [KeycloakInstance:60] Using HTTP endpoints
2022-04-03 05:32:54 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka oauth-cluster-plain-name in namespace infra-namespace
2022-04-03 05:32:54 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: oauth-cluster-plain-name will have desired state: Ready
2022-04-03 05:34:12 [main] [32mINFO [m [ResourceManager:444] Kafka: oauth-cluster-plain-name is in desired state: Ready
2022-04-03 05:34:12 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 05:34:12 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerConnect-STARTED
2022-04-03 05:34:12 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 05:34:12 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-03 05:34:12 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-863571571-809737654 in namespace infra-namespace
2022-04-03 05:34:12 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-863571571-809737654 will have desired state: Ready
2022-04-03 05:34:13 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-863571571-809737654 is in desired state: Ready
2022-04-03 05:34:13 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-3dc99490 in namespace infra-namespace
2022-04-03 05:34:13 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-3dc99490 will be in active state
2022-04-03 05:34:14 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-3dc99490 to finished
2022-04-03 05:34:22 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-3dc99490 in namespace infra-namespace
2022-04-03 05:34:22 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-3dc99490 will be in active state
2022-04-03 05:34:23 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-3dc99490 to finished
2022-04-03 05:34:33 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-3dc99490-kafka-clients in namespace infra-namespace
2022-04-03 05:34:33 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-3dc99490-kafka-clients will be ready
2022-04-03 05:34:35 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-3dc99490-kafka-clients is ready
2022-04-03 05:34:35 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-3dc99490-scraper in namespace infra-namespace
2022-04-03 05:34:35 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-3dc99490-scraper will be ready
2022-04-03 05:34:37 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-3dc99490-scraper is ready
2022-04-03 05:34:37 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-3dc99490-scraper to be ready
2022-04-03 05:34:47 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-3dc99490-scraper is ready
2022-04-03 05:34:47 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-3dc99490-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-03 05:34:47 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-3dc99490-allow in namespace infra-namespace
2022-04-03 05:34:47 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-03 05:34:47 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-3dc99490 in namespace infra-namespace
2022-04-03 05:34:47 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-3dc99490 will have desired state: Ready
2022-04-03 05:35:49 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-3dc99490 is in desired state: Ready
2022-04-03 05:35:49 [main] [32mINFO [m [KafkaConnectUtils:63] Waiting until KafkaConnect API is available
2022-04-03 05:35:49 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-3dc99490-connect-7b4b748844-fkncw -- /bin/bash -c curl -I http://localhost:8083/connectors
2022-04-03 05:35:49 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-03 05:35:49 [main] [32mINFO [m [KafkaConnectUtils:66] KafkaConnect API is available
2022-04-03 05:35:50 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-3dc99490-connect-7b4b748844-fkncw -- /bin/bash -c curl -X POST -H "Content-Type: application/json" --data '{ "name": "sink-test", "config": { "connector.class": "FileStreamSink", "tasks.max": "1", "topics": "my-topic-863571571-809737654", "file": "/tmp/test-file-sink.txt" } }' http://localhost:8083/connectors
2022-04-03 05:35:50 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-03 05:35:50 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-3dc99490-connect-7b4b748844-fkncw
2022-04-03 05:35:53 [main] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-3dc99490-connect-7b4b748844-fkncw
2022-04-03 05:35:54 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 05:35:54 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumerConnect
2022-04-03 05:35:54 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-3dc99490-scraper in namespace infra-namespace
2022-04-03 05:35:54 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-863571571-809737654 in namespace infra-namespace
2022-04-03 05:35:54 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-3dc99490-allow in namespace infra-namespace
2022-04-03 05:35:54 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-3dc99490-kafka-clients in namespace infra-namespace
2022-04-03 05:35:54 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-3dc99490 in namespace infra-namespace
2022-04-03 05:35:54 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-3dc99490 in namespace infra-namespace
2022-04-03 05:35:54 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-3dc99490 in namespace infra-namespace
2022-04-03 05:36:34 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 05:36:34 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerConnect-FINISHED
2022-04-03 05:36:34 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 05:36:34 [main] [32mINFO [m [KeycloakUtils:52] Teardown Keycloak Operator in namespace: infra-namespace with watching namespace: infra-namespace
2022-04-03 05:36:38 [main] [32mINFO [m [Exec:417] Command: /bin/bash ../systemtest/src/test/resources/oauth2/teardown_keycloak_operator.sh infra-namespace 11.0.1 infra-namespace
2022-04-03 05:36:38 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-03 05:36:38 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 05:36:38 [main] [32mINFO [m [ResourceManager:348] Delete all resources for OauthPlainIsolatedST
2022-04-03 05:36:38 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka oauth-cluster-plain-name in namespace infra-namespace
2022-04-03 05:36:38 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy global-network-policy in namespace infra-namespace
2022-04-03 05:36:48 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 05:36:48 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 05:36:48 [main] [32mINFO [m [ResourceManager:346] In context OauthPlainIsolatedST is everything deleted.
2022-04-03 05:36:48 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 383.146 s - in io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.dump.LogDumpScriptIsolatedST
2022-04-03 05:36:48 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-03 05:37:13 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-03 05:37:13 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-03 05:37:13 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-03 05:37:13 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 05:37:13 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-03 05:37:13 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-03 05:37:13 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-03 05:37:13 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-03 05:37:13 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 05:37:13 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-03 05:37:13 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:37:13 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-03 05:37:13 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-03 05:37:13 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-03 05:37:13 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-03 05:37:13 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-03 05:37:13 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-03 05:37:13 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-03 05:37:13 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 05:37:13 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-03 05:37:13 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:37:23 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-03 05:37:23 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-03 05:37:23 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:37:23 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-03 05:37:23 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-03 05:37:23 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:37:23 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-03 05:37:23 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-03 05:37:23 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-03 05:37:33 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 05:37:39 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@5f4d6ac4
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-03 05:37:39 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-03 05:37:39 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-03 05:37:39 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-03 05:37:39 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:37:39 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 05:37:39 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-03 05:37:39 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-03 05:37:39 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-03 05:37:39 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-03 05:37:39 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-03 05:37:39 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-03 05:37:39 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-03 05:37:39 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-03 05:37:39 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-03 05:37:39 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-03 05:37:39 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-03 05:37:39 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-03 05:37:39 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-03 05:37:39 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-03 05:37:39 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:37:39 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-03 05:37:39 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-03 05:37:39 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-03 05:37:39 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-03 05:37:39 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-03 05:37:39 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-03 05:37:39 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-03 05:37:39 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-03 05:37:39 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:37:39 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-03 05:37:39 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-03 05:37:39 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-03 05:37:39 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-03 05:37:39 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 05:37:39 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-03 05:37:39 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:37:39 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-03 05:38:15 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-03 05:38:15 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-03 05:38:25 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-03 05:38:25 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 05:38:25 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.dump.LogDumpScriptIsolatedST.dumpPartitions-STARTED
2022-04-03 05:38:25 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 05:38:25 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-90b3f3c4 in namespace infra-namespace
2022-04-03 05:38:25 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-90b3f3c4 will have desired state: Ready
2022-04-03 05:39:36 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-90b3f3c4 is in desired state: Ready
2022-04-03 05:39:36 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-90b3f3c4-hello-world-producer in namespace infra-namespace
2022-04-03 05:39:36 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-90b3f3c4-hello-world-consumer in namespace infra-namespace
2022-04-03 05:39:36 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-90b3f3c4-hello-world-producer will be in active state
2022-04-03 05:39:37 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-90b3f3c4-hello-world-consumer will be in active state
2022-04-03 05:39:37 [main] [32mINFO [m [ClientUtils:61] Waiting till producer my-cluster-90b3f3c4-hello-world-producer and consumer my-cluster-90b3f3c4-hello-world-consumer finish
2022-04-03 05:39:53 [main] [32mINFO [m [LogDumpScriptIsolatedST:78] Print partition segments from cluster infra-namespace/my-cluster-90b3f3c4
2022-04-03 05:39:53 [main] [32mINFO [m [Exec:417] Failed to exec command: /home/ec2-user/strimzi-kafka-operator/systemtest/../tools/log-dump/run.sh partition --namespace infra-namespace --cluster my-cluster-90b3f3c4 --topic my-topic-444849363-288411998 --partition 0 --dry-run
2022-04-03 05:39:53 [main] [32mINFO [m [Exec:417] Return code: 127
2022-04-03 05:39:53 [main] [32mINFO [m [Exec:417] ======STDERR START=======
2022-04-03 05:39:53 [main] [32mINFO [m [Exec:417] /home/ec2-user/strimzi-kafka-operator/systemtest/../tools/log-dump/run.sh: line 47: yq: command not found
2022-04-03 05:39:53 [main] [32mINFO [m [Exec:417] ======STDERR END======
2022-04-03 05:39:53 [main] [1;31mERROR[m [TestExecutionWatcher:28] LogDumpScriptIsolatedST - Exception `/home/ec2-user/strimzi-kafka-operator/systemtest/../tools/log-dump/run.sh partition --namespace infra-namespace --cluster my-cluster-90b3f3c4 --topic my-topic-444849363-288411998 --partition 0 --dry-run` got status code 127 and stderr:
------
/home/ec2-user/strimzi-kafka-operator/systemtest/../tools/log-dump/run.sh: line 47: yq: command not found

------
and stdout:
------

------ has been thrown in @Test. Going to collect logs from components.
2022-04-03 05:39:53 [main] [32mINFO [m [LogCollector:252] Collecting events in Namespace infra-namespace
2022-04-03 05:39:53 [main] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace infra-namespace
2022-04-03 05:39:53 [main] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace infra-namespace
2022-04-03 05:39:54 [main] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace infra-namespace
2022-04-03 05:39:54 [main] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace infra-namespace
2022-04-03 05:39:54 [main] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace infra-namespace
2022-04-03 05:39:54 [main] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace infra-namespace
2022-04-03 05:39:54 [main] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-04-03 05:39:54 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 05:39:54 [main] [32mINFO [m [ResourceManager:348] Delete all resources for dumpPartitions
2022-04-03 05:39:54 [main] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-90b3f3c4-hello-world-producer in namespace infra-namespace
2022-04-03 05:39:54 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-90b3f3c4-hello-world-consumer in namespace infra-namespace
2022-04-03 05:39:54 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-90b3f3c4 in namespace infra-namespace
2022-04-03 05:40:04 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 05:40:04 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.dump.LogDumpScriptIsolatedST.dumpPartitions-FINISHED
2022-04-03 05:40:04 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 05:40:04 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 05:40:04 [main] [32mINFO [m [ResourceManager:346] In context LogDumpScriptIsolatedST is everything deleted.
2022-04-03 05:40:04 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;31mERROR[m] Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 196.388 s <<< FAILURE! - in io.strimzi.systemtest.dump.LogDumpScriptIsolatedST
[[1;31mERROR[m] io.strimzi.systemtest.dump.LogDumpScriptIsolatedST.dumpPartitions(ExtensionContext)  Time elapsed: 99.004 s  <<< ERROR!
io.strimzi.test.k8s.exceptions.KubeClusterException: 
`/home/ec2-user/strimzi-kafka-operator/systemtest/../tools/log-dump/run.sh partition --namespace infra-namespace --cluster my-cluster-90b3f3c4 --topic my-topic-444849363-288411998 --partition 0 --dry-run` got status code 127 and stderr:
------
/home/ec2-user/strimzi-kafka-operator/systemtest/../tools/log-dump/run.sh: line 47: yq: command not found

------
and stdout:
------

------
	at io.strimzi.test.executor.Exec.exec(Exec.java:223)
	at io.strimzi.test.executor.Exec.exec(Exec.java:149)
	at io.strimzi.test.executor.Exec.exec(Exec.java:118)
	at io.strimzi.systemtest.dump.LogDumpScriptIsolatedST.dumpPartitions(LogDumpScriptIsolatedST.java:83)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:165)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)

[[1;34mINFO[m] Running io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST
2022-04-03 05:40:04 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-03 05:40:29 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-03 05:40:29 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-03 05:40:29 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-03 05:40:29 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 05:40:29 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-03 05:40:29 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-03 05:40:29 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 05:40:29 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-03 05:40:29 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-03 05:40:29 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-03 05:40:29 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-03 05:40:29 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-03 05:40:29 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-03 05:40:29 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:40:29 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-03 05:40:29 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-03 05:40:29 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-03 05:40:29 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-03 05:40:29 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:40:29 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-03 05:40:29 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 05:40:29 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:40:29 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-03 05:40:30 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-03 05:40:30 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-03 05:40:39 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-03 05:40:39 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-03 05:40:39 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:40:39 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-03 05:40:39 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-03 05:40:50 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 05:40:55 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@5f4d6ac4
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=30000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-03 05:40:55 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-03 05:40:55 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-03 05:40:55 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-03 05:40:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:40:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 05:40:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-03 05:40:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-03 05:40:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-03 05:40:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-03 05:40:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-03 05:40:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-03 05:40:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-03 05:40:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-03 05:40:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-03 05:40:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-03 05:40:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-03 05:40:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-03 05:40:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-03 05:40:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-03 05:40:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:40:55 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-03 05:40:55 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-03 05:40:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-03 05:40:55 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-03 05:40:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-03 05:40:55 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-03 05:40:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-03 05:40:55 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-03 05:40:55 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:40:55 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-03 05:40:55 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-03 05:40:55 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:40:55 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-03 05:41:31 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-03 05:41:31 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-03 05:41:41 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-03 05:41:41 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka custom-resource-status-cluster-name in namespace infra-namespace
2022-04-03 05:41:42 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: custom-resource-status-cluster-name will have desired state: Ready
2022-04-03 05:43:08 [main] [32mINFO [m [ResourceManager:444] Kafka: custom-resource-status-cluster-name is in desired state: Ready
2022-04-03 05:43:08 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-467311057-683530871 in namespace infra-namespace
2022-04-03 05:43:08 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-467311057-683530871 will have desired state: Ready
2022-04-03 05:43:09 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-467311057-683530871 is in desired state: Ready
2022-04-03 05:43:09 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment infra-namespace-shared-kafka-clients in namespace infra-namespace
2022-04-03 05:43:09 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: infra-namespace-shared-kafka-clients will be ready
2022-04-03 05:43:10 [main] [32mINFO [m [DeploymentUtils:168] Deployment: infra-namespace-shared-kafka-clients is ready
2022-04-03 05:43:10 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 05:43:10 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaMirrorMakerStatus-STARTED
2022-04-03 05:43:10 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 05:43:10 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-93a59d3a-mirror-maker in namespace infra-namespace
2022-04-03 05:43:10 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-93a59d3a-mirror-maker will have desired state: Ready
2022-04-03 05:44:17 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-93a59d3a-mirror-maker is in desired state: Ready
2022-04-03 05:44:17 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-93a59d3a-mirror-maker will have desired state: Ready
2022-04-03 05:44:17 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-93a59d3a-mirror-maker is in desired state: Ready
2022-04-03 05:44:17 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-93a59d3a-mirror-maker will have desired state: NotReady
2022-04-03 05:44:48 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-93a59d3a-mirror-maker is in desired state: NotReady
2022-04-03 05:44:48 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-93a59d3a-mirror-maker will have desired state: Ready
2022-04-03 05:46:43 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-93a59d3a-mirror-maker is in desired state: Ready
2022-04-03 05:46:43 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 05:46:43 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaMirrorMakerStatus
2022-04-03 05:46:43 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-93a59d3a-mirror-maker in namespace infra-namespace
2022-04-03 05:46:53 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 05:46:53 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaMirrorMakerStatus-FINISHED
2022-04-03 05:46:53 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 05:46:53 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 05:46:53 [main] [32mINFO [m [ResourceManager:348] Delete all resources for CustomResourceStatusIsolatedST
2022-04-03 05:46:53 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-467311057-683530871 in namespace infra-namespace
2022-04-03 05:46:53 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka custom-resource-status-cluster-name in namespace infra-namespace
2022-04-03 05:46:53 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Deployment infra-namespace-shared-kafka-clients in namespace infra-namespace
2022-04-03 05:47:33 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 448.237 s - in io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST
2022-04-03 05:47:33 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-03 05:47:33 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-03 05:47:33 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-03 05:47:33 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 05:47:33 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-03 05:47:33 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-03 05:47:33 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-03 05:47:33 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-03 05:47:33 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-03 05:47:33 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-03 05:47:33 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-03 05:47:33 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:47:33 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:47:33 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-03 05:47:33 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:47:33 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-03 05:47:33 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-03 05:47:33 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 05:47:33 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:47:33 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-03 05:47:33 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-03 05:47:33 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-03 05:47:43 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-03 05:47:43 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-03 05:47:43 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-03 05:47:43 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-03 05:47:43 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-03 05:47:43 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-03 05:47:53 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 05:47:58 [main] [32mINFO [m [TestExecutionListener:40] =======================================================================
2022-04-03 05:47:58 [main] [32mINFO [m [TestExecutionListener:41] =======================================================================
2022-04-03 05:47:58 [main] [32mINFO [m [TestExecutionListener:42]                         Test run finished
2022-04-03 05:47:58 [main] [32mINFO [m [TestExecutionListener:43] =======================================================================
2022-04-03 05:47:58 [main] [32mINFO [m [TestExecutionListener:44] =======================================================================
2022-04-03 05:47:58 [main] [32mINFO [m [TestExecutionListener:29] =======================================================================
2022-04-03 05:47:58 [main] [32mINFO [m [TestExecutionListener:30] =======================================================================
2022-04-03 05:47:58 [main] [32mINFO [m [TestExecutionListener:31]                         Test run started
2022-04-03 05:47:58 [main] [32mINFO [m [TestExecutionListener:32] =======================================================================
2022-04-03 05:47:58 [main] [32mINFO [m [TestExecutionListener:33] =======================================================================
2022-04-03 05:47:58 [main] [32mINFO [m [TestExecutionListener:48] Following testclasses are selected for run:
2022-04-03 05:47:58 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfSharedST
2022-04-03 05:47:58 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.backup.ColdBackupScriptIsolatedST
2022-04-03 05:47:58 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.specific.HelmChartIsolatedST
2022-04-03 05:47:58 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.dump.LogDumpScriptIsolatedST
2022-04-03 05:47:58 [main] [32mINFO [m [TestExecutionListener:52] =======================================================================
2022-04-03 05:47:58 [main] [32mINFO [m [TestExecutionListener:53] =======================================================================
[[1;34mINFO[m] Running io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfSharedST
2022-04-03 05:47:58 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@65fb31f8
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-03 05:47:58 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-03 05:47:58 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-03 05:47:58 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-03 05:47:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:47:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 05:47:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-03 05:47:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-03 05:47:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-03 05:47:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-03 05:47:58 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-03 05:47:58 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-03 05:47:58 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-03 05:47:58 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-03 05:47:58 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-03 05:47:58 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-03 05:47:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-03 05:47:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-03 05:47:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-03 05:47:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-03 05:47:59 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:47:59 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-03 05:47:59 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-03 05:47:59 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-03 05:47:59 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-03 05:47:59 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-03 05:47:59 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-03 05:47:59 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-03 05:47:59 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-03 05:47:59 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:47:59 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-03 05:47:59 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-03 05:47:59 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-03 05:47:59 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-03 05:47:59 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 05:47:59 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-03 05:47:59 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:47:59 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-03 05:48:21 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-03 05:48:21 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-03 05:48:31 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-03 05:48:31 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: dynamic-conf-shared-st
2022-04-03 05:48:31 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: dynamic-conf-shared-st
2022-04-03 05:48:31 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: dynamic-conf-shared-st
2022-04-03 05:48:31 [main] [32mINFO [m [DynamicConfSharedST:218] Deploying shared Kafka across all test cases!
2022-04-03 05:48:31 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka dynamic-configuration-shared-cluster-name in namespace dynamic-conf-shared-st
2022-04-03 05:48:31 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: dynamic-configuration-shared-cluster-name will have desired state: Ready
2022-04-03 05:49:56 [main] [32mINFO [m [ResourceManager:444] Kafka: dynamic-configuration-shared-cluster-name is in desired state: Ready
2022-04-03 05:49:56 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 05:49:56 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfSharedST.testDynConfiguration-STARTED
2022-04-03 05:49:56 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 05:49:56 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 05:49:56 [main] [32mINFO [m [ResourceManager:346] In context testDynConfiguration is everything deleted.
2022-04-03 05:49:56 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 05:49:56 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfSharedST.testDynConfiguration-FINISHED
2022-04-03 05:49:56 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 05:49:56 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 05:49:56 [main] [32mINFO [m [ResourceManager:348] Delete all resources for DynamicConfSharedST
2022-04-03 05:49:56 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka dynamic-configuration-shared-cluster-name in namespace dynamic-conf-shared-st
2022-04-03 05:50:06 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;31mERROR[m] Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 171.335 s <<< FAILURE! - in io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfSharedST
[[1;31mERROR[m] io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfSharedST.testDynConfiguration  Time elapsed: 118.036 s  <<< ERROR!
java.lang.RuntimeException: Error reading from classpath resource /home/ec2-user/strimzi-kafka-operator/systemtest/../cluster-operator/src/main/resources/kafka-3.1.0-config-model.json
	at io.strimzi.systemtest.utils.kafkaUtils.KafkaUtils.readConfigModel(KafkaUtils.java:320)
	at io.strimzi.systemtest.utils.kafkaUtils.KafkaUtils.getDynamicConfigurationProperties(KafkaUtils.java:332)
	at io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfSharedST.generateTestCases(DynamicConfSharedST.java:84)
	at io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfSharedST.testDynConfiguration(DynamicConfSharedST.java:57)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestFactoryMethod(TimeoutExtension.java:100)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestFactoryTestDescriptor.lambda$invokeTestMethod$1(TestFactoryTestDescriptor.java:97)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestFactoryTestDescriptor.invokeTestMethod(TestFactoryTestDescriptor.java:95)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:165)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
Caused by: java.io.FileNotFoundException: /home/ec2-user/strimzi-kafka-operator/systemtest/../cluster-operator/src/main/resources/kafka-3.1.0-config-model.json (No such file or directory)
	at java.base/java.io.FileInputStream.open0(Native Method)
	at java.base/java.io.FileInputStream.open(FileInputStream.java:219)
	at java.base/java.io.FileInputStream.<init>(FileInputStream.java:157)
	at java.base/java.io.FileInputStream.<init>(FileInputStream.java:112)
	at io.strimzi.systemtest.utils.kafkaUtils.KafkaUtils.readConfigModel(KafkaUtils.java:312)
	... 101 more

[[1;34mINFO[m] Running io.strimzi.systemtest.backup.ColdBackupScriptIsolatedST
2022-04-03 05:50:49 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-03 05:51:14 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-03 05:51:14 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-03 05:51:14 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-03 05:51:14 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 05:51:14 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-03 05:51:14 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-03 05:51:14 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 05:51:14 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 05:51:14 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-03 05:51:14 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-03 05:51:14 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-03 05:51:14 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-03 05:51:14 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-03 05:51:14 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-03 05:51:14 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-03 05:51:14 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-03 05:51:14 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:51:15 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-03 05:51:15 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-03 05:51:15 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:51:15 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:51:15 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:51:15 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-03 05:51:15 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-03 05:51:15 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-03 05:51:15 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-03 05:51:15 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-03 05:51:24 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-03 05:51:25 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-03 05:51:25 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-03 05:51:35 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 05:51:40 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@65fb31f8
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-03 05:51:40 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-03 05:51:40 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-03 05:51:40 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-03 05:51:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:51:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 05:51:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-03 05:51:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-03 05:51:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-03 05:51:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-03 05:51:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-03 05:51:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-03 05:51:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-03 05:51:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-03 05:51:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-03 05:51:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-03 05:51:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-03 05:51:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-03 05:51:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-03 05:51:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-03 05:51:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:51:40 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-03 05:51:40 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-03 05:51:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-03 05:51:40 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-03 05:51:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-03 05:51:40 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-03 05:51:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-03 05:51:40 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-03 05:51:40 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:51:40 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-03 05:51:40 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-03 05:51:40 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-03 05:51:40 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-03 05:51:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 05:51:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-03 05:51:40 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:51:40 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-03 05:51:56 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-03 05:51:56 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-03 05:52:06 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-03 05:52:06 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 05:52:06 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.backup.ColdBackupScriptIsolatedST.backupAndRestore-STARTED
2022-04-03 05:52:06 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 05:52:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-008fdc6c in namespace infra-namespace
2022-04-03 05:52:06 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-008fdc6c will have desired state: Ready
2022-04-03 05:53:22 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-008fdc6c is in desired state: Ready
2022-04-03 05:53:22 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-008fdc6c-producer in namespace infra-namespace
2022-04-03 05:53:22 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-008fdc6c-consumer in namespace infra-namespace
2022-04-03 05:53:22 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-008fdc6c-producer will be in active state
2022-04-03 05:53:23 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-008fdc6c-consumer will be in active state
2022-04-03 05:53:23 [main] [32mINFO [m [ClientUtils:61] Waiting till producer my-cluster-008fdc6c-producer and consumer my-cluster-008fdc6c-consumer finish
2022-04-03 05:53:41 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-008fdc6c-kafka-0 -- /opt/kafka/bin/kafka-consumer-groups.sh --describe --bootstrap-server localhost:9092 --group my-group
2022-04-03 05:53:41 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-03 05:53:41 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-008fdc6c-producer in namespace infra-namespace
2022-04-03 05:53:41 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-008fdc6c-producer will be in active state
2022-04-03 05:53:42 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:my-cluster-008fdc6c-producer to finished
2022-04-03 05:53:50 [main] [32mINFO [m [ColdBackupScriptIsolatedST:95] Running backup procedure for infra-namespace/my-cluster-008fdc6c
2022-04-03 05:53:51 [main] [32mINFO [m [Exec:417] Failed to exec command: /home/ec2-user/strimzi-kafka-operator/systemtest/../tools/cold-backup/run.sh backup -n infra-namespace -c my-cluster-008fdc6c -t /home/ec2-user/strimzi-kafka-operator/systemtest/target/my-cluster-008fdc6c.tgz -y
2022-04-03 05:53:51 [main] [32mINFO [m [Exec:417] Return code: 1
2022-04-03 05:53:51 [main] [32mINFO [m [Exec:417] ======STDOUT START=======
2022-04-03 05:53:51 [main] [32mINFO [m [Exec:417] Exporting environment
Starting cluster my-cluster-008fdc6c
2022-04-03 05:53:51 [main] [32mINFO [m [Exec:417] ======STDOUT END======
2022-04-03 05:53:51 [main] [32mINFO [m [Exec:417] ======STDERR START=======
2022-04-03 05:53:51 [main] [32mINFO [m [Exec:417] /home/ec2-user/strimzi-kafka-operator/systemtest/../tools/cold-backup/run.sh: line 145: yq: command not found
Error: invalid argument "Starting cluster my-cluster-008fdc6c\nstatefulset.apps/my-cluster-008fdc6c-zookeeper scaled\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/name=my-cluster-008fdc6c-zookeeper\" in namespace \"infra-namespace\"\npod/my-cluster-008fdc6c-zookeeper-0 condition met\nstatefulset.apps/my-cluster-008fdc6c-kafka scaled\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/name=my-cluster-008fdc6c-kafka\" in namespace \"infra-namespace\"\npod/my-cluster-008fdc6c-kafka-0 condition met\ndeployment.apps/strimzi-cluster-operator scaled\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/kind=cluster-operator\" in namespace \"infra-namespace\"\npod/strimzi-cluster-operator-78689684d4-fzpd4 condition met\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/name=my-cluster-008fdc6c-kafka\" in namespace \"infra-namespace\"\npod/my-cluster-008fdc6c-kafka-0 condition met\nbackup failed at 145: yq eval \".spec.zookeeper.replicas\" -" for "--replicas" flag: strconv.ParseInt: parsing "Starting cluster my-cluster-008fdc6c\nstatefulset.apps/my-cluster-008fdc6c-zookeeper scaled\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/name=my-cluster-008fdc6c-zookeeper\" in namespace \"infra-namespace\"\npod/my-cluster-008fdc6c-zookeeper-0 condition met\nstatefulset.apps/my-cluster-008fdc6c-kafka scaled\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/name=my-cluster-008fdc6c-kafka\" in namespace \"infra-namespace\"\npod/my-cluster-008fdc6c-kafka-0 condition met\ndeployment.apps/strimzi-cluster-operator scaled\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/kind=cluster-operator\" in namespace \"infra-namespace\"\npod/strimzi-cluster-operator-78689684d4-fzpd4 condition met\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/name=my-cluster-008fdc6c-kafka\" in namespace \"infra-namespace\"\npod/my-cluster-008fdc6c-kafka-0 condition met\nbackup failed at 145: yq eval \".spec.zookeeper.replicas\" -": invalid syntax


Examples:
  # Scale a replicaset named 'foo' to 3.
  kubectl scale --replicas=3 rs/foo
  
  # Scale a resource identified by type and name specified in "foo.yaml" to 3.
  kubectl scale --replicas=3 -f foo.yaml
  
  # If the deployment named mysql's current size is 2, scale mysql to 3.
  kubectl scale --current-replicas=2 --replicas=3 deployment/mysql
  
  # Scale multiple replication controllers.
  kubectl scale --replicas=5 rc/foo rc/bar rc/baz
  
  # Scale statefulset named 'web' to 3.
  kubectl scale --replicas=3 statefulset/web

Options:
      --all=false: Select all resources in the namespace of the specified resource types
      --allow-missing-template-keys=true: If true, ignore any errors in templates when a field or map key is missing in the template. Only applies to golang and jsonpath output formats.
      --current-replicas=-1: Precondition for current size. Requires that the current size of the resource match this value in order to scale.
  -f, --filename=[]: Filename, directory, or URL to files identifying the resource to set a new size
  -k, --kustomize='': Process the kustomization directory. This flag can't be used together with -f or -R.
  -o, --output='': Output format. One of: json|yaml|name|go-template|go-template-file|template|templatefile|jsonpath|jsonpath-file.
      --record=false: Record current kubectl command in the resource annotation. If set to false, do not record the command. If set to true, record the command. If not set, default to updating the existing annotation value only if one already exists.
  -R, --recursive=false: Process the directory used in -f, --filename recursively. Useful when you want to manage related manifests organized within the same directory.
      --replicas=0: The new desired number of replicas. Required.
      --resource-version='': Precondition for resource version. Requires that the current resource version match this value in order to scale.
  -l, --selector='': Selector (label query) to filter on, supports '=', '==', and '!='.(e.g. -l key1=value1,key2=value2)
      --template='': Template string or path to template file to use when -o=go-template, -o=go-template-file. The template format is golang templates [http://golang.org/pkg/text/template/#pkg-overview].
      --timeout=0s: The length of time to wait before giving up on a scale operation, zero means don't wait. Any other values should contain a corresponding time unit (e.g. 1s, 2m, 3h).

Usage:
  kubectl scale [--resource-version=version] [--current-replicas=count] --replicas=COUNT (-f FILENAME | TYPE NAME) [options]

Use "kubectl options" for a list of global command-line options (applies to all commands).
2022-04-03 05:53:51 [main] [32mINFO [m [Exec:417] ======STDERR END======
2022-04-03 05:53:51 [main] [1;31mERROR[m [TestExecutionWatcher:28] ColdBackupScriptIsolatedST - Exception `/home/ec2-user/strimzi-kafka-operator/systemtest/../tools/cold-backup/run.sh backup -n infra-namespace -c my-cluster-008fdc6c -t /home/ec2-user/strimzi-kafka-operator/systemtest/target/my-cluster-008fdc6c.tgz -y` got status code 1 and stderr:
------
/home/ec2-user/strimzi-kafka-operator/systemtest/../tools/cold-backup/run.sh: line 145: yq: command not found
Error: invalid argument "Starting cluster my-cluster-008fdc6c\nstatefulset.apps/my-cluster-008fdc6c-zookeeper scaled\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/name=my-cluster-008fdc6c-zookeeper\" in namespace \"infra-namespace\"\npod/my-cluster-008fdc6c-zookeeper-0 condition met\nstatefulset.apps/my-cluster-008fdc6c-kafka scaled\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/name=my-cluster-008fdc6c-kafka\" in namespace \"infra-namespace\"\npod/my-cluster-008fdc6c-kafka-0 condition met\ndeployment.apps/strimzi-cluster-operator scaled\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/kind=cluster-operator\" in namespace \"infra-namespace\"\npod/strimzi-cluster-operator-78689684d4-fzpd4 condition met\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/name=my-cluster-008fdc6c-kafka\" in namespace \"infra-namespace\"\npod/my-cluster-008fdc6c-kafka-0 condition met\nbackup failed at 145: yq eval \".spec.zookeeper.replicas\" -" for "--replicas" flag: strconv.ParseInt: parsing "Starting cluster my-cluster-008fdc6c\nstatefulset.apps/my-cluster-008fdc6c-zookeeper scaled\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/name=my-cluster-008fdc6c-zookeeper\" in namespace \"infra-namespace\"\npod/my-cluster-008fdc6c-zookeeper-0 condition met\nstatefulset.apps/my-cluster-008fdc6c-kafka scaled\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/name=my-cluster-008fdc6c-kafka\" in namespace \"infra-namespace\"\npod/my-cluster-008fdc6c-kafka-0 condition met\ndeployment.apps/strimzi-cluster-operator scaled\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/kind=cluster-operator\" in namespace \"infra-namespace\"\npod/strimzi-cluster-operator-78689684d4-fzpd4 condition met\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/name=my-cluster-008fdc6c-kafka\" in namespace \"infra-namespace\"\npod/my-cluster-008fdc6c-kafka-0 condition met\nbackup failed at 145: yq eval \".spec.zookeeper.replicas\" -": invalid syntax


Examples:
  # Scale a replicaset named 'foo' to 3.
  kubectl scale --replicas=3 rs/foo
  
  # Scale a resource identified by type and name specified in "foo.yaml" to 3.
  kubectl scale --replicas=3 -f foo.yaml
  
  # If the deployment named mysql's current size is 2, scale mysql to 3.
  kubectl scale --current-replicas=2 --replicas=3 deployment/mysql
  
  # Scale multiple replication controllers.
  kubectl scale --replicas=5 rc/foo rc/bar rc/baz
  
  # Scale statefulset named 'web' to 3.
  kubectl scale --replicas=3 statefulset/web

Options:
      --all=false: Select all resources in the namespace of the specified resource types
      --allow-missing-template-keys=true: If true, ignore any errors in templates when a field or map key is missing in the template. Only applies to golang and jsonpath output formats.
      --current-replicas=-1: Precondition for current size. Requires that the current size of the resource match this value in order to scale.
  -f, --filename=[]: Filename, directory, or URL to files identifying the resource to set a new size
  -k, --kustomize='': Process the kustomization directory. This flag can't be used together with -f or -R.
  -o, --output='': Output format. One of: json|yaml|name|go-template|go-template-file|template|templatefile|jsonpath|jsonpath-file.
      --record=false: Record current kubectl command in the resource annotation. If set to false, do not record the command. If set to true, record the command. If not set, default to updating the existing annotation value only if one already exists.
  -R, --recursive=false: Process the directory used in -f, --filename recursively. Useful when you want to manage related manifests organized within the same directory.
      --replicas=0: The new desired number of replicas. Required.
      --resource-version='': Precondition for resource version. Requires that the current resource version match this value in order to scale.
  -l, --selector='': Selector (label query) to filter on, supports '=', '==', and '!='.(e.g. -l key1=value1,key2=value2)
      --template='': Template string or path to template file to use when -o=go-template, -o=go-template-file. The template format is golang templates [http://golang.org/pkg/text/template/#pkg-overview].
      --timeout=0s: The length of time to wait before giving up on a scale operation, zero means don't wait. Any other values should contain a corresponding time unit (e.g. 1s, 2m, 3h).

Usage:
  kubectl scale [--resource-version=version] [--current-replicas=count] --replicas=COUNT (-f FILENAME | TYPE NAME) [options]

Use "kubectl options" for a list of global command-line options (applies to all commands).


------
and stdout:
------
Exporting environment
Starting cluster my-cluster-008fdc6c

------ has been thrown in @Test. Going to collect logs from components.
2022-04-03 05:53:51 [main] [32mINFO [m [LogCollector:252] Collecting events in Namespace infra-namespace
2022-04-03 05:53:51 [main] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace infra-namespace
2022-04-03 05:53:51 [main] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace infra-namespace
2022-04-03 05:53:52 [main] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace infra-namespace
2022-04-03 05:53:52 [main] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace infra-namespace
2022-04-03 05:53:52 [main] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace infra-namespace
2022-04-03 05:53:52 [main] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace infra-namespace
2022-04-03 05:53:52 [main] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-04-03 05:53:52 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 05:53:52 [main] [32mINFO [m [ResourceManager:348] Delete all resources for backupAndRestore
2022-04-03 05:53:52 [main] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-008fdc6c-consumer in namespace infra-namespace
2022-04-03 05:53:52 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-008fdc6c-producer in namespace infra-namespace
2022-04-03 05:53:52 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-008fdc6c in namespace infra-namespace
2022-04-03 05:53:52 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-008fdc6c-producer in namespace infra-namespace
2022-04-03 05:54:02 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 05:54:02 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.backup.ColdBackupScriptIsolatedST.backupAndRestore-FINISHED
2022-04-03 05:54:02 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 05:54:02 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 05:54:02 [main] [32mINFO [m [ResourceManager:346] In context ColdBackupScriptIsolatedST is everything deleted.
2022-04-03 05:54:02 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;31mERROR[m] Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 192.935 s <<< FAILURE! - in io.strimzi.systemtest.backup.ColdBackupScriptIsolatedST
[[1;31mERROR[m] io.strimzi.systemtest.backup.ColdBackupScriptIsolatedST.backupAndRestore(ExtensionContext)  Time elapsed: 115.941 s  <<< ERROR!
io.strimzi.test.k8s.exceptions.KubeClusterException: 
`/home/ec2-user/strimzi-kafka-operator/systemtest/../tools/cold-backup/run.sh backup -n infra-namespace -c my-cluster-008fdc6c -t /home/ec2-user/strimzi-kafka-operator/systemtest/target/my-cluster-008fdc6c.tgz -y` got status code 1 and stderr:
------
/home/ec2-user/strimzi-kafka-operator/systemtest/../tools/cold-backup/run.sh: line 145: yq: command not found
Error: invalid argument "Starting cluster my-cluster-008fdc6c\nstatefulset.apps/my-cluster-008fdc6c-zookeeper scaled\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/name=my-cluster-008fdc6c-zookeeper\" in namespace \"infra-namespace\"\npod/my-cluster-008fdc6c-zookeeper-0 condition met\nstatefulset.apps/my-cluster-008fdc6c-kafka scaled\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/name=my-cluster-008fdc6c-kafka\" in namespace \"infra-namespace\"\npod/my-cluster-008fdc6c-kafka-0 condition met\ndeployment.apps/strimzi-cluster-operator scaled\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/kind=cluster-operator\" in namespace \"infra-namespace\"\npod/strimzi-cluster-operator-78689684d4-fzpd4 condition met\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/name=my-cluster-008fdc6c-kafka\" in namespace \"infra-namespace\"\npod/my-cluster-008fdc6c-kafka-0 condition met\nbackup failed at 145: yq eval \".spec.zookeeper.replicas\" -" for "--replicas" flag: strconv.ParseInt: parsing "Starting cluster my-cluster-008fdc6c\nstatefulset.apps/my-cluster-008fdc6c-zookeeper scaled\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/name=my-cluster-008fdc6c-zookeeper\" in namespace \"infra-namespace\"\npod/my-cluster-008fdc6c-zookeeper-0 condition met\nstatefulset.apps/my-cluster-008fdc6c-kafka scaled\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/name=my-cluster-008fdc6c-kafka\" in namespace \"infra-namespace\"\npod/my-cluster-008fdc6c-kafka-0 condition met\ndeployment.apps/strimzi-cluster-operator scaled\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/kind=cluster-operator\" in namespace \"infra-namespace\"\npod/strimzi-cluster-operator-78689684d4-fzpd4 condition met\nWaiting for \"condition=Ready\" on \"pod -l strimzi.io/name=my-cluster-008fdc6c-kafka\" in namespace \"infra-namespace\"\npod/my-cluster-008fdc6c-kafka-0 condition met\nbackup failed at 145: yq eval \".spec.zookeeper.replicas\" -": invalid syntax


Examples:
  # Scale a replicaset named 'foo' to 3.
  kubectl scale --replicas=3 rs/foo
  
  # Scale a resource identified by type and name specified in "foo.yaml" to 3.
  kubectl scale --replicas=3 -f foo.yaml
  
  # If the deployment named mysql's current size is 2, scale mysql to 3.
  kubectl scale --current-replicas=2 --replicas=3 deployment/mysql
  
  # Scale multiple replication controllers.
  kubectl scale --replicas=5 rc/foo rc/bar rc/baz
  
  # Scale statefulset named 'web' to 3.
  kubectl scale --replicas=3 statefulset/web

Options:
      --all=false: Select all resources in the namespace of the specified resource types
      --allow-missing-template-keys=true: If true, ignore any errors in templates when a field or map key is missing in the template. Only applies to golang and jsonpath output formats.
      --current-replicas=-1: Precondition for current size. Requires that the current size of the resource match this value in order to scale.
  -f, --filename=[]: Filename, directory, or URL to files identifying the resource to set a new size
  -k, --kustomize='': Process the kustomization directory. This flag can't be used together with -f or -R.
  -o, --output='': Output format. One of: json|yaml|name|go-template|go-template-file|template|templatefile|jsonpath|jsonpath-file.
      --record=false: Record current kubectl command in the resource annotation. If set to false, do not record the command. If set to true, record the command. If not set, default to updating the existing annotation value only if one already exists.
  -R, --recursive=false: Process the directory used in -f, --filename recursively. Useful when you want to manage related manifests organized within the same directory.
      --replicas=0: The new desired number of replicas. Required.
      --resource-version='': Precondition for resource version. Requires that the current resource version match this value in order to scale.
  -l, --selector='': Selector (label query) to filter on, supports '=', '==', and '!='.(e.g. -l key1=value1,key2=value2)
      --template='': Template string or path to template file to use when -o=go-template, -o=go-template-file. The template format is golang templates [http://golang.org/pkg/text/template/#pkg-overview].
      --timeout=0s: The length of time to wait before giving up on a scale operation, zero means don't wait. Any other values should contain a corresponding time unit (e.g. 1s, 2m, 3h).

Usage:
  kubectl scale [--resource-version=version] [--current-replicas=count] --replicas=COUNT (-f FILENAME | TYPE NAME) [options]

Use "kubectl options" for a list of global command-line options (applies to all commands).


------
and stdout:
------
Exporting environment
Starting cluster my-cluster-008fdc6c

------
	at io.strimzi.test.executor.Exec.exec(Exec.java:223)
	at io.strimzi.test.executor.Exec.exec(Exec.java:149)
	at io.strimzi.test.executor.Exec.exec(Exec.java:118)
	at io.strimzi.systemtest.backup.ColdBackupScriptIsolatedST.backupAndRestore(ColdBackupScriptIsolatedST.java:99)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:165)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)

[[1;34mINFO[m] Running io.strimzi.systemtest.specific.HelmChartIsolatedST
2022-04-03 05:54:02 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-03 05:54:27 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-03 05:54:27 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-03 05:54:27 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-03 05:54:27 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 05:54:27 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-03 05:54:27 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-03 05:54:27 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-03 05:54:27 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-03 05:54:27 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-03 05:54:27 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 05:54:27 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-03 05:54:27 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-03 05:54:27 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-03 05:54:27 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-03 05:54:27 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:54:27 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:54:27 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-03 05:54:27 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:54:27 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-03 05:54:27 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 05:54:27 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-03 05:54:27 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-03 05:54:28 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:54:28 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-03 05:54:28 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-03 05:54:28 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-03 05:54:37 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-03 05:54:37 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-03 05:54:37 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-03 05:54:37 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-03 05:54:48 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 05:54:53 [main] [32mINFO [m [HelmChartIsolatedST:67] Creating resources before the test class
2022-04-03 05:54:53 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-03 05:54:53 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-03 05:54:53 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: kube-system
2022-04-03 05:54:53 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace kube-system apply -f -
2022-04-03 05:54:53 [main] [32mINFO [m [Exec:417] Input: apiVersion: v1
kind: ServiceAccount
metadata:
  name: tiller
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: tiller
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
  - kind: ServiceAccount
    name: tiller
    namespace: kube-system
2022-04-03 05:54:53 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-03 05:54:53 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-03 05:54:53 [main] [1;31mERROR[m [TestExecutionWatcher:39] HelmChartIsolatedST - Exception No helm client found on $PATH. $PATH=/home/ec2-user/.sdkman/candidates/maven/current/bin:/home/ec2-user/.local/bin:/home/ec2-user/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin has been thrown in @BeforeAll. Going to collect logs from components.
2022-04-03 05:54:53 [main] [32mINFO [m [LogCollector:252] Collecting events in Namespace infra-namespace
2022-04-03 05:54:53 [main] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace infra-namespace
2022-04-03 05:54:53 [main] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace infra-namespace
2022-04-03 05:54:53 [main] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace infra-namespace
2022-04-03 05:54:53 [main] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace infra-namespace
2022-04-03 05:54:53 [main] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace infra-namespace
2022-04-03 05:54:53 [main] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace infra-namespace
2022-04-03 05:54:54 [main] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-04-03 05:54:54 [main] [1;31mERROR[m [TestExecutionWatcher:70] HelmChartIsolatedST - Exception No helm client found on $PATH. $PATH=/home/ec2-user/.sdkman/candidates/maven/current/bin:/home/ec2-user/.local/bin:/home/ec2-user/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin has been thrown in @AfterAll. Going to collect logs from components.
2022-04-03 05:54:54 [main] [32mINFO [m [LogCollector:252] Collecting events in Namespace infra-namespace
2022-04-03 05:54:54 [main] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace infra-namespace
2022-04-03 05:54:54 [main] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace infra-namespace
2022-04-03 05:54:54 [main] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace infra-namespace
2022-04-03 05:54:54 [main] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace infra-namespace
2022-04-03 05:54:54 [main] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace infra-namespace
2022-04-03 05:54:54 [main] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace infra-namespace
2022-04-03 05:54:54 [main] [32mINFO [m [LogCollector:287] Collecting cluster status
[[1;31mERROR[m] Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 51.875 s <<< FAILURE! - in io.strimzi.systemtest.specific.HelmChartIsolatedST
[[1;31mERROR[m] io.strimzi.systemtest.specific.HelmChartIsolatedST  Time elapsed: 51.875 s  <<< ERROR!
java.lang.RuntimeException: No helm client found on $PATH. $PATH=/home/ec2-user/.sdkman/candidates/maven/current/bin:/home/ec2-user/.local/bin:/home/ec2-user/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin
	at io.strimzi.test.k8s.HelmClient.findClient(HelmClient.java:108)
	at io.strimzi.test.k8s.KubeClusterResource.helmClient(KubeClusterResource.java:354)
	at io.strimzi.test.k8s.KubeClusterResource.helmClusterClient(KubeClusterResource.java:129)
	at io.strimzi.systemtest.resources.ResourceManager.helmClient(ResourceManager.java:116)
	at io.strimzi.systemtest.resources.operator.specific.HelmResource.clusterOperator(HelmResource.java:104)
	at io.strimzi.systemtest.resources.operator.specific.HelmResource.create(HelmResource.java:55)
	at io.strimzi.systemtest.resources.operator.specific.HelmResource.create(HelmResource.java:49)
	at io.strimzi.systemtest.specific.HelmChartIsolatedST.setup(HelmChartIsolatedST.java:70)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptLifecycleMethod(TimeoutExtension.java:126)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptBeforeAllMethod(TimeoutExtension.java:68)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$invokeBeforeAllMethods$11(ClassBasedTestDescriptor.java:397)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.invokeBeforeAllMethods(ClassBasedTestDescriptor.java:395)
	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.before(ClassBasedTestDescriptor.java:209)
	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.before(ClassBasedTestDescriptor.java:80)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:148)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:165)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
	Suppressed: java.lang.RuntimeException: No helm client found on $PATH. $PATH=/home/ec2-user/.sdkman/candidates/maven/current/bin:/home/ec2-user/.local/bin:/home/ec2-user/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin
		at io.strimzi.test.k8s.HelmClient.findClient(HelmClient.java:108)
		at io.strimzi.test.k8s.KubeClusterResource.helmClient(KubeClusterResource.java:354)
		at io.strimzi.test.k8s.KubeClusterResource.helmClusterClient(KubeClusterResource.java:129)
		at io.strimzi.systemtest.resources.ResourceManager.helmClient(ResourceManager.java:116)
		at io.strimzi.systemtest.resources.operator.specific.HelmResource.deleteClusterOperator(HelmResource.java:129)
		at io.strimzi.systemtest.resources.operator.specific.HelmResource.delete(HelmResource.java:60)
		at io.strimzi.systemtest.specific.HelmChartIsolatedST.afterAllMayOverride(HelmChartIsolatedST.java:76)
		at io.strimzi.systemtest.AbstractST.tearDownTestSuite(AbstractST.java:691)
		at jdk.internal.reflect.GeneratedMethodAccessor1239.invoke(Unknown Source)
		at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
		at java.base/java.lang.reflect.Method.invoke(Method.java:566)
		at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
		at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
		at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
		at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
		at org.junit.jupiter.engine.extension.TimeoutExtension.interceptLifecycleMethod(TimeoutExtension.java:126)
		at org.junit.jupiter.engine.extension.TimeoutExtension.interceptAfterAllMethod(TimeoutExtension.java:116)
		at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
		at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
		at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
		at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
		at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
		at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
		at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
		at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
		at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$invokeAfterAllMethods$13(ClassBasedTestDescriptor.java:425)
		at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
		at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$invokeAfterAllMethods$14(ClassBasedTestDescriptor.java:423)
		at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
		at java.base/java.util.Collections$UnmodifiableCollection.forEach(Collections.java:1085)
		at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.invokeAfterAllMethods(ClassBasedTestDescriptor.java:423)
		at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.after(ClassBasedTestDescriptor.java:225)
		at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.after(ClassBasedTestDescriptor.java:80)
		at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$7(NodeTestTask.java:161)
		at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
		at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:161)
		... 63 more

[[1;34mINFO[m] Running io.strimzi.systemtest.dump.LogDumpScriptIsolatedST
2022-04-03 05:54:54 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-03 05:55:19 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-03 05:55:19 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-03 05:55:19 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-03 05:55:19 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 05:55:19 [main] [32mINFO [m [ResourceManager:346] In context JUnit Jupiter is everything deleted.
2022-04-03 05:55:19 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 05:55:24 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@65fb31f8
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-03 05:55:24 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-03 05:55:24 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-03 05:55:24 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-03 05:55:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:55:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 05:55:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-03 05:55:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-03 05:55:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-03 05:55:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-03 05:55:25 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-03 05:55:25 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-03 05:55:25 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-03 05:55:25 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-03 05:55:25 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-03 05:55:25 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-03 05:55:25 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-03 05:55:25 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-03 05:55:25 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-03 05:55:25 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-03 05:55:25 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:55:25 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-03 05:55:25 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-03 05:55:25 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-03 05:55:25 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-03 05:55:25 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-03 05:55:25 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-03 05:55:25 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-03 05:55:25 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-03 05:55:25 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:55:25 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-03 05:55:25 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-03 05:55:25 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-03 05:55:25 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-03 05:55:25 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 05:55:25 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-03 05:55:25 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:55:25 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-03 05:55:50 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-03 05:55:50 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-03 05:56:00 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-03 05:56:00 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-03 05:56:00 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.dump.LogDumpScriptIsolatedST.dumpPartitions-STARTED
2022-04-03 05:56:00 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-03 05:56:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-b9802a8a in namespace infra-namespace
2022-04-03 05:56:00 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-b9802a8a will have desired state: Ready
2022-04-03 05:57:10 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-b9802a8a is in desired state: Ready
2022-04-03 05:57:10 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-b9802a8a-hello-world-producer in namespace infra-namespace
2022-04-03 05:57:10 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-b9802a8a-hello-world-consumer in namespace infra-namespace
2022-04-03 05:57:10 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-b9802a8a-hello-world-producer will be in active state
2022-04-03 05:57:11 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-b9802a8a-hello-world-consumer will be in active state
2022-04-03 05:57:11 [main] [32mINFO [m [ClientUtils:61] Waiting till producer my-cluster-b9802a8a-hello-world-producer and consumer my-cluster-b9802a8a-hello-world-consumer finish
2022-04-03 05:57:22 [main] [32mINFO [m [LogDumpScriptIsolatedST:78] Print partition segments from cluster infra-namespace/my-cluster-b9802a8a
2022-04-03 05:57:23 [main] [32mINFO [m [Exec:417] Failed to exec command: /home/ec2-user/strimzi-kafka-operator/systemtest/../tools/log-dump/run.sh partition --namespace infra-namespace --cluster my-cluster-b9802a8a --topic my-topic-1447543861-1771068370 --partition 0 --dry-run
2022-04-03 05:57:23 [main] [32mINFO [m [Exec:417] Return code: 127
2022-04-03 05:57:23 [main] [32mINFO [m [Exec:417] ======STDERR START=======
2022-04-03 05:57:23 [main] [32mINFO [m [Exec:417] /home/ec2-user/strimzi-kafka-operator/systemtest/../tools/log-dump/run.sh: line 47: yq: command not found
2022-04-03 05:57:23 [main] [32mINFO [m [Exec:417] ======STDERR END======
2022-04-03 05:57:23 [main] [1;31mERROR[m [TestExecutionWatcher:28] LogDumpScriptIsolatedST - Exception `/home/ec2-user/strimzi-kafka-operator/systemtest/../tools/log-dump/run.sh partition --namespace infra-namespace --cluster my-cluster-b9802a8a --topic my-topic-1447543861-1771068370 --partition 0 --dry-run` got status code 127 and stderr:
------
/home/ec2-user/strimzi-kafka-operator/systemtest/../tools/log-dump/run.sh: line 47: yq: command not found

------
and stdout:
------

------ has been thrown in @Test. Going to collect logs from components.
2022-04-03 05:57:23 [main] [32mINFO [m [LogCollector:252] Collecting events in Namespace infra-namespace
2022-04-03 05:57:23 [main] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace infra-namespace
2022-04-03 05:57:23 [main] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace infra-namespace
2022-04-03 05:57:24 [main] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace infra-namespace
2022-04-03 05:57:24 [main] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace infra-namespace
2022-04-03 05:57:24 [main] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace infra-namespace
2022-04-03 05:57:24 [main] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace infra-namespace
2022-04-03 05:57:24 [main] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-04-03 05:57:24 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 05:57:24 [main] [32mINFO [m [ResourceManager:348] Delete all resources for dumpPartitions
2022-04-03 05:57:24 [main] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-b9802a8a-hello-world-producer in namespace infra-namespace
2022-04-03 05:57:24 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-b9802a8a-hello-world-consumer in namespace infra-namespace
2022-04-03 05:57:24 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-b9802a8a in namespace infra-namespace
2022-04-03 05:57:34 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 05:57:34 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.dump.LogDumpScriptIsolatedST.dumpPartitions-FINISHED
2022-04-03 05:57:34 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-03 05:57:34 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 05:57:34 [main] [32mINFO [m [ResourceManager:346] In context LogDumpScriptIsolatedST is everything deleted.
2022-04-03 05:57:34 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;31mERROR[m] Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 159.936 s <<< FAILURE! - in io.strimzi.systemtest.dump.LogDumpScriptIsolatedST
[[1;31mERROR[m] io.strimzi.systemtest.dump.LogDumpScriptIsolatedST.dumpPartitions(ExtensionContext)  Time elapsed: 94.125 s  <<< ERROR!
io.strimzi.test.k8s.exceptions.KubeClusterException: 
`/home/ec2-user/strimzi-kafka-operator/systemtest/../tools/log-dump/run.sh partition --namespace infra-namespace --cluster my-cluster-b9802a8a --topic my-topic-1447543861-1771068370 --partition 0 --dry-run` got status code 127 and stderr:
------
/home/ec2-user/strimzi-kafka-operator/systemtest/../tools/log-dump/run.sh: line 47: yq: command not found

------
and stdout:
------

------
	at io.strimzi.test.executor.Exec.exec(Exec.java:223)
	at io.strimzi.test.executor.Exec.exec(Exec.java:149)
	at io.strimzi.test.executor.Exec.exec(Exec.java:118)
	at io.strimzi.systemtest.dump.LogDumpScriptIsolatedST.dumpPartitions(LogDumpScriptIsolatedST.java:83)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:165)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)

2022-04-03 05:57:34 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-03 05:57:34 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-03 05:57:34 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-03 05:57:34 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-03 05:57:34 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-03 05:57:34 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-03 05:57:34 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-03 05:57:34 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-03 05:57:34 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-03 05:57:34 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-03 05:57:34 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-03 05:57:34 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 05:57:34 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:57:34 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:57:34 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:57:34 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-03 05:57:34 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-03 05:57:34 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-03 05:57:34 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-03 05:57:34 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-03 05:57:34 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-03 05:57:34 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-03 05:57:34 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-03 05:57:34 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-03 05:57:34 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-03 05:57:34 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-03 05:57:44 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-03 05:57:44 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-03 05:57:44 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-03 05:57:44 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-03 05:57:55 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-03 05:58:00 [main] [32mINFO [m [TestExecutionListener:40] =======================================================================
2022-04-03 05:58:00 [main] [32mINFO [m [TestExecutionListener:41] =======================================================================
2022-04-03 05:58:00 [main] [32mINFO [m [TestExecutionListener:42]                         Test run finished
2022-04-03 05:58:00 [main] [32mINFO [m [TestExecutionListener:43] =======================================================================
2022-04-03 05:58:00 [main] [32mINFO [m [TestExecutionListener:44] =======================================================================
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;31mERROR[m] Errors: 
[[1;31mERROR[m] io.strimzi.systemtest.backup.ColdBackupScriptIsolatedST.backupAndRestore(ExtensionContext)
[[1;31mERROR[m]   Run 1: ColdBackupScriptIsolatedST.backupAndRestore:99 ? KubeCluster `/home/ec2-user/s...
[[1;31mERROR[m]   Run 2: ColdBackupScriptIsolatedST.backupAndRestore:99 ? KubeCluster `/home/ec2-user/s...
[[1;31mERROR[m]   Run 3: ColdBackupScriptIsolatedST.backupAndRestore:99 ? KubeCluster `/home/ec2-user/s...
[[1;34mINFO[m] 
[[1;31mERROR[m] io.strimzi.systemtest.dump.LogDumpScriptIsolatedST.dumpPartitions(ExtensionContext)
[[1;31mERROR[m]   Run 1: LogDumpScriptIsolatedST.dumpPartitions:83 ? KubeCluster `/home/ec2-user/strimz...
[[1;31mERROR[m]   Run 2: LogDumpScriptIsolatedST.dumpPartitions:83 ? KubeCluster `/home/ec2-user/strimz...
[[1;31mERROR[m]   Run 3: LogDumpScriptIsolatedST.dumpPartitions:83 ? KubeCluster `/home/ec2-user/strimz...
[[1;34mINFO[m] 
[[1;31mERROR[m] io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfSharedST.testDynConfiguration
[[1;31mERROR[m]   Run 1: DynamicConfSharedST.testDynConfiguration:57->generateTestCases:84 ? Runtime Er...
[[1;31mERROR[m]   Run 2: DynamicConfSharedST.testDynConfiguration:57->generateTestCases:84 ? Runtime Er...
[[1;31mERROR[m]   Run 3: DynamicConfSharedST.testDynConfiguration:57->generateTestCases:84 ? Runtime Er...
[[1;34mINFO[m] 
[[1;31mERROR[m] io.strimzi.systemtest.specific.HelmChartIsolatedST.null
[[1;31mERROR[m]   Run 1: HelmChartIsolatedST.setup:70 ? Runtime No helm client found on $PATH. $PATH=/h...
[[1;31mERROR[m]   Run 2: HelmChartIsolatedST.setup:70 ? Runtime No helm client found on $PATH. $PATH=/h...
[[1;31mERROR[m]   Run 3: HelmChartIsolatedST.setup:70 ? Runtime No helm client found on $PATH. $PATH=/h...
[[1;34mINFO[m] 
[[1;33mWARNING[m] Flakes: 
[[1;33mWARNING[m] io.strimzi.systemtest.kafka.KafkaST.testLabelModificationDoesNotBreakCluster(ExtensionContext)
[[1;31mERROR[m]   Run 1: KafkaST.testLabelModificationDoesNotBreakCluster:1156 ? Wait Timeout after 180...
[[1;34mINFO[m]   Run 2: PASS
[[1;34mINFO[m] 
[[1;33mWARNING[m] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaMirrorMakerStatus(ExtensionContext)
[[1;31mERROR[m]   Run 1: CustomResourceStatusIsolatedST.testKafkaMirrorMakerStatus(ExtensionContext) ? IO
[[1;34mINFO[m]   Run 2: PASS
[[1;34mINFO[m] 
[[1;33mWARNING[m] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testClusterOperatorFinishAllRollingUpdates(ExtensionContext)
[[1;31mERROR[m]   Run 1: RollingUpdateST.testClusterOperatorFinishAllRollingUpdates:625 ? Wait Timeout ...
[[1;34mINFO[m]   Run 2: PASS
[[1;34mINFO[m] 
[[1;33mWARNING[m] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerConnect(ExtensionContext)
[[1;31mERROR[m]   Run 1: OauthPlainIsolatedST.testProducerConsumerConnect:287 ? Wait Timeout after 6000...
[[1;34mINFO[m]   Run 2: PASS
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;31mERROR[m] Tests run: 302, Failures: 0, Errors: 4, Skipped: 10, Flakes: 4
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] [1m------------------------------------------------------------------------[m
[[1;34mINFO[m] [1mReactor Summary for Strimzi - Apache Kafka on Kubernetes and OpenShift 0.29.0-SNAPSHOT:[m
[[1;34mINFO[m] 
[[1;34mINFO[m] Strimzi - Apache Kafka on Kubernetes and OpenShift . [1;32mSUCCESS[m [  2.566 s]
[[1;34mINFO[m] test ............................................... [1;32mSUCCESS[m [  0.987 s]
[[1;34mINFO[m] crd-annotations .................................... [1;32mSUCCESS[m [  0.995 s]
[[1;34mINFO[m] crd-generator ...................................... [1;32mSUCCESS[m [  2.526 s]
[[1;34mINFO[m] api ................................................ [1;32mSUCCESS[m [  6.705 s]
[[1;34mINFO[m] mockkube ........................................... [1;32mSUCCESS[m [  0.865 s]
[[1;34mINFO[m] config-model ....................................... [1;32mSUCCESS[m [  0.698 s]
[[1;34mINFO[m] certificate-manager ................................ [1;32mSUCCESS[m [  0.758 s]
[[1;34mINFO[m] operator-common .................................... [1;32mSUCCESS[m [  1.810 s]
[[1;34mINFO[m] systemtest ......................................... [1;31mFAILURE[m [  21:11 h]
[[1;34mINFO[m] [1m------------------------------------------------------------------------[m
[[1;34mINFO[m] [1;31mBUILD FAILURE[m
[[1;34mINFO[m] [1m------------------------------------------------------------------------[m
[[1;34mINFO[m] Total time:  21:12 h
[[1;34mINFO[m] Finished at: 2022-04-03T05:58:00Z
[[1;34mINFO[m] [1m------------------------------------------------------------------------[m
[[1;31mERROR[m] Failed to execute goal [32morg.apache.maven.plugins:maven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m on project [36msystemtest[m: [1;31mThere are test failures.[m
[[1;31mERROR[m] [1;31m[m
[[1;31mERROR[m] [1;31mPlease refer to /home/ec2-user/strimzi-kafka-operator/systemtest/target/failsafe-reports for the individual test results.[m
[[1;31mERROR[m] [1;31mPlease refer to dump files (if any exist) [date].dump, [date]-jvmRun[N].dump and [date].dumpstream.[m
[[1;31mERROR[m] -> [1m[Help 1][m
[[1;31mERROR[m] 
[[1;31mERROR[m] To see the full stack trace of the errors, re-run Maven with the [1m-e[m switch.
[[1;31mERROR[m] Re-run Maven using the [1m-X[m switch to enable full debug logging.
[[1;31mERROR[m] 
[[1;31mERROR[m] For more information about the errors and possible solutions, please read the following articles:
[[1;31mERROR[m] [1m[Help 1][m http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[[1;31mERROR[m] 
[[1;31mERROR[m] After correcting the problems, you can resume the build with the command
[[1;31mERROR[m]   [1mmvn <args> -rf :systemtest[m
