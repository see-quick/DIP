\section{Strimzi system tests}
\label{02:sec:strimzisystemtests}

This section describes the basics of the Strimzi system tests.
At first, we will go through a short description of how we test Strimzi.
Then in Section~\ref{02:subsec:strimziJunit5relation:execution} we explain the fundamentals of JUnit5 and how tests are discovered and executed.
Lastly, in Section~\ref{02:subsec:strimzisystemtestsexecution} we explain Strimzi system test management and execution flow.

Overall testing begins, as we know from textbooks with unit testing.
Subsequently, if this phase is successful, we move on to integration tests and then to system tests.
Of course, the most time-consuming is the system tests, which in our case take about 40 hours to complete.
\begin{figure}[!ht]
    \centering
    \includegraphics[scale=0.70]{obrazky-figures/02-preliminaries/04-strimzi-system-tests/01-architecture-overall}
    \caption{Strimzi system tests top-level component architecture}
    \label{02d:fig:strimzisystemtestarch}
\end{figure}
The testing phases are dependent on each other in the order in which they are executed.
For instance, integration tests will not run if unit tests fail, similarly to integration and system tests.
Furthermore, system tests run on multiple infrastructures such as \emph{Openstack}, \emph{Microsoft Azure} or \emph{Amazon Web Services}.
There are certain limitations to the set of tests on each of these infrastructures.
Since these are Kubernetes system tests, it is essential to realise that the total load on the computing resource is enormous.
At the same time, the preparation of resources and their cleaning is time-consuming.
Therefore, our system tests have two essential parts.
The first is resource classes that provide the user interface for creating, retrieving, deleting, and updating these resources.
Moreover, we have three independent stacks that serve as resource storage.
These stacks are responsible for storing all resources based on the test case.
Furthermore, the deletion of these resources is transparent for the user just as if it is a resource created in a \emph{@BeforeAll}\footnote{\textbf{@BeforeAll } \---\ is JUnit5 annotation, where one specifies what must be executed before all tests in the test suite.} annotated method.
The second fundamental part is auxiliary classes such as Utils\footnote {\textbf{Utils} \---\ type of class that consists of static methods, which in general dynamically wait for a specific event. For instance, waiting for Rolling Update, if one changes Kafka configuration}, Apache Kafka clients for external communication, Kubernetes client offering an API for communication with the Kubernetes cluster and finally classes such as \emph{Constants} and \emph{Environment}. This can be seen in Figure~\ref{02d:fig:strimzisystemtestarch}.

\subsection{JUnit5 relation and execution of test cases}
\label{02:subsec:strimziJunit5relation:execution}

Junit5 Engine handles the entire implementation and management of the test lifecycle.
The Engine facilitates the discovery and execution of tests for a specific programming model.
In other words, it is the entity in charge of discovering and executing tests.
Discovering can be thought of as scanning all the classes and methods in specific directories.
The Engine has specified in advance which signatures to include in the test tree.
In the case of the Junit5 Engine, it is a sequence of chaining methods, which gradually add all classes (test suites) and methods (test cases) to the test tree.
They also add the test types defined by them (i.e., \emph{@TestFactory}, \emph{@ParametrizedTest}, \emph{@TestTemplate}).
Everything is depicted in Algorithm~\ref{02:alg:selectorresolver}.

\begin{algorithm}[H]
    \label{02:alg:selectorresolver}
    \caption{Junit5 Engine: Discovery selector resolver}
    \begin{algorithmic}[1]
        \Procedure{resolveSelectors}{DiscoveryRequest request, Descriptor descriptor}
            \State {EngineDiscoveryRequestResolver.$<$JupiterEngineDescriptor$>$builder()}
            \State {.addClassContainerSelectorResolver(new IsTestClassWithTests())}
            \State {.addSelectorResolver(c $\rightarrow$ new ClassSelectorResolver(classFilter, config))}
            \State {.addSelectorResolver(c $\rightarrow$ new MethodSelectorResolver(config))}
            \State {.addTestDescriptorVisitor(c $\rightarrow$ new ClassOrderingVisitor(config))}
            \State {.addTestDescriptorVisitor(c $\rightarrow$ new MethodOrderingVisitor(config))}
            \State {.addTestDescriptorVisitor(c $\rightarrow$ TestDescriptor::prune)}
            \State {.build();}
            \State {.resolve(request, descriptor);}
        \EndProcedure
    \end{algorithmic}
\end{algorithm}

Once the resolver is created, we can run the following algorithm, using the resolver and creating the already mentioned tree of \emph{TestDescriptors}.
Here is a detailed description of how the algorithm works:

\begin{enumerate}[itemsep=1mm, parsep=0pt]
    \item Enqueue all selectors in the supplied request to be resolved.
    \item While there are selectors to be resolved, get the next one.
    Otherwise, the resolution is finished.
    \begin{enumerate}
        \item iterates over recorded resolvers in the directive that they were recorded in and discover the foremost one that yields a resolution other than unresolved().
        \item If such a resolution exists, enqueue its selectors.
        \item For each exact match in the resolution, expand its children and enqueue them as well.
    \end{enumerate}
    \item Iterate over all registered visitors and let the engine test descriptor accept them.
\end{enumerate}

The second phase after the correct scan of test cases that the user wants to perform is execution.
In this case, TestEngine already has a TestDescriptor in which all the information needed to run is available.
At this stage, the TestEngine must always notify the Junit5 platform of the success or failure of the test case.
Moreover, Engine instantiates the \emph{SameThreadHierarchicalTestExecutorService} class, which ensures that each test is performed sequentially.

\subsection{Strimzi system test management and execution flow}
\label{02:subsec:strimzisystemtestsexecution}

In the previous Section~\ref{02:subsec:strimziJunit5relation:execution}, we described the intricate parts of loading and the type of tests performed.
In the case of the Strimzi part, adding several mechanisms (i.e., creation of Kubernetes cluster, communication with Kubernetes cluster, management of Kubernetes resources, waiting for conditions) is necessary.
We solve all these parts in Strimzi.
We create Kubernetes clusters in several ways as we test the product on several infrastructures.
For example, on Microsoft Azure, we create a Minikube (a subset of the Kubernetes cluster, one-node cluster) with approximately eight CPUs and 16GB of RAM. In Openstack, we typically create a six-node cluster with three master nodes and three worker nodes.
Each has eight CPUs and 16GB available (similarly to Amazon Web Services).

Communication with the Kubernetes cluster is guaranteed by the Fabri8 Kubernetes client \url {https://github.com/fabric8io/kubernetes-client}.
This client provides a Java client with many methods that communicate directly via the Kubernetes REST API.
Most methods are designed to create, update, delete and retrieve a given resource.
In practice, we will also encounter the term CRUD methods.
To illustrate, we can imagine getting all the namespaces on a given Kubernetes cluster.
All namespaces are obtained using the command \emph{client.namespaces().List();}.

The overall orchestration of Kubernetes resources is handled by the \emph{ResourceManager} class and its additional resource classes.
As we wrote at the beginning of Section~\ref{02:sec:strimzisystemtests}, it includes three stacks where the main/pointer stack points to the method or class stack based on context.
For example, suppose the execution is located in \emph{@BeforeAll} or \emph{@AfterAll} annotation, we add elements to the class stack.
In other scenarios, such as in the test case or \emph{@BeforeEach}, we add elements to the method stack.
This data structure will guarantee the correct order of resources deletion at the end of each test or test class.
This is because we want to delete resources in the order they were created.
So if we create first Kafka, Producer, and lastly Consumer, then in the clean-up phase, we will first delete Consumer, Producer, and finally Kafka.
Thus, the user who creates the test cases does not have to delete individual resources created for the entire test.
In other words, the clean-up phase is transparent to the user.
However, if one wants to delete the resource explicitly, it is possible via the following command \emph{ResourceType.delete(name)}.
Algorithm~\ref{02:alg:deletionalg} defines clean-up phase.

\begin{algorithm}[H]
    \label{02:alg:deletionalg}
    \caption{ResourceManager generic deletion algorithm}
    \begin{algorithmic}[1]
        \Procedure{deleteLater}{MixedOperation$<$T, ?, ?, ?$>$ operation, T resource}
            \State switch(resource.getKind()) \{
            \State \hspace{2em} case Kafka.RESOURCE\_KIND$:$
            \State \hspace{4em} pointerResources.push(() $\rightarrow$ {
                \State \hspace{4em} operation.inNamespace(resource.getMetadata().getNamespace())
                \State \hspace{4em} .withName(resource.getMetadata().getName())
                \State \hspace{4em} .withPropagationPolicy(DeletionPropagation.FOREGROUND)
                \State \hspace{4em} .delete();
                \State \hspace{4em} waitForDeletion((Kafka) resource);
                \State \hspace{2em} });
            \State \hspace{2em} break;
            \State \hspace{2em} case KafkaConnect.RESOURCE\_KIND$:$
            \State \hspace{2em} case KafkaMirrorMaker.RESOURCE\_KIND$:$
            \State \hspace{2em} \dots (other resource)
            \State \hspace{4em} // similar to Kafka resource
            \State \hspace{2em} default:
            \State \hspace{4em}        pointerResources.push(() $\rightarrow$  {
                \State \hspace{4em}           operation.inNamespace(resource.getMetadata().getNamespace())
                \State \hspace{4em}                  .withName(resource.getMetadata().getName())
                \State \hspace{4em}                  .withPropagationPolicy(DeletionPropagation.FOREGROUND)
                \State \hspace{4em}                  .delete();
                \State \hspace{2em}     });
            \State \}
            \State return resource;
        \EndProcedure
    \end{algorithmic}
\end{algorithm}


By contrast, when creating any resources, the user has at his disposal, for example, KafkaResource, KafkaTopicResource, and the like.
Each of these classes contains predefined templates that include specific configuration settings.
A typical example is Kafka, which can be seen in Listing~\ref{kafka:resource}.

\begin{lstlisting}[language=Java,label=kafka:resource,caption=Default Kafka Custom Resource in KafkaResource\.class,frame=tb]
private static KafkaBuilder defaultKafka(Kafka kafka,
            String name, int kafkaReplicas, int zookeeperReplicas) {
    return new KafkaBuilder(kafka)
        .withNewMetadata()
            .withName(name)
            .withNamespace(ResourceManager.kubeClient().getNamespace())
        .endMetadata()
        .editSpec()
            .editKafka()
                .withVersion(Environment.ST_KAFKA_VERSION)
                .withReplicas(kafkaReplicas)
            .endKafka()
            .editZookeeper()
                .withReplicas(zookeeperReplicas)
            .endZookeeper()
        .endSpec();
}
\end{lstlisting}

Another part of the Strimzi system tests is the wait for methods mechanism.
It is used primarily in scenarios where it is necessary to wait for an event to occur.
An example could be waiting for a Rolling Update to occur when Kafka's original Statefulset changes. \begin{figure}[!ht]
    \centering
    \includegraphics[scale=0.70]{obrazky-figures/02-preliminaries/04-strimzi-system-tests/02d-strimzisystemtest-sequence-execution}
    \caption{Strimzi system tests execution flow}
    \label{02d:fig:strimzisysmtetest:execution}
\end{figure}
The second example could be while waiting for a particular pessimistic scenario (i.e., the Cluster Operator Pod will switch to the CrashLoopBack state, and the KafkaBridge Deployment Status will contain the text in the message).

So if we summarise everything we have learned.
It all starts with scanning the test directory, which provides a tree of TestDescriptors.
This is the primary responsibility of TestEngine, which uses selectors to filter out all test cases and the visitors who accept the individual test cases.
As soon as we have a tree available consisting of TestDescriptor nodes, TestEngine starts execution.
This execution is sequential for each test case.
At the same time, thanks to our management and defined resources, we can communicate with the Kubernetes cluster.
For example, in Figure~\ref{02d:fig:strimzisysmtetest:execution} we can execute n Test cases where Test Suite 2 is currently executed and specifically Test Case 1.
The attentive reader will realise that the execution model is sequential due to Java's main thread, the primary thread identifier.